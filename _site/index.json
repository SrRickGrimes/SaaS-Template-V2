{
  "api/Projects.AppHost.html": {
    "href": "api/Projects.AppHost.html",
    "title": "Class AppHost",
    "summary": "Class AppHost Namespace Projects Assembly AppHost.dll public class AppHost Inheritance object AppHost Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Properties ProjectPath public static string ProjectPath { get; } Property Value string"
  },
  "api/Projects.html": {
    "href": "api/Projects.html",
    "title": "Namespace Projects",
    "summary": "Namespace Projects Classes AppHost Server"
  },
  "api/Projects.Server.html": {
    "href": "api/Projects.Server.html",
    "title": "Class Server",
    "summary": "Class Server Namespace Projects Assembly AppHost.dll public class Server : IProjectMetadata, IResourceAnnotation Inheritance object Server Implements IProjectMetadata IResourceAnnotation Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Properties ProjectPath Gets the fully-qualified path to the project. public string ProjectPath { get; } Property Value string"
  },
  "api/Server.Controllers.html": {
    "href": "api/Server.Controllers.html",
    "title": "Namespace Server.Controllers",
    "summary": "Namespace Server.Controllers Classes WeatherForecastController"
  },
  "api/Server.Controllers.WeatherForecastController.html": {
    "href": "api/Server.Controllers.WeatherForecastController.html",
    "title": "Class WeatherForecastController",
    "summary": "Class WeatherForecastController Namespace Server.Controllers Assembly Server.dll [ApiController] [Route(\"[controller]\")] public class WeatherForecastController : ControllerBase Inheritance object ControllerBase WeatherForecastController Inherited Members ControllerBase.StatusCode(int) ControllerBase.StatusCode(int, object) ControllerBase.Content(string) ControllerBase.Content(string, string) ControllerBase.Content(string, string, Encoding) ControllerBase.Content(string, MediaTypeHeaderValue) ControllerBase.NoContent() ControllerBase.Ok() ControllerBase.Ok(object) ControllerBase.Redirect(string) ControllerBase.RedirectPermanent(string) ControllerBase.RedirectPreserveMethod(string) ControllerBase.RedirectPermanentPreserveMethod(string) ControllerBase.LocalRedirect(string) ControllerBase.LocalRedirectPermanent(string) ControllerBase.LocalRedirectPreserveMethod(string) ControllerBase.LocalRedirectPermanentPreserveMethod(string) ControllerBase.RedirectToAction() ControllerBase.RedirectToAction(string) ControllerBase.RedirectToAction(string, object) ControllerBase.RedirectToAction(string, string) ControllerBase.RedirectToAction(string, string, object) ControllerBase.RedirectToAction(string, string, string) ControllerBase.RedirectToAction(string, string, object, string) ControllerBase.RedirectToActionPreserveMethod(string, string, object, string) ControllerBase.RedirectToActionPermanent(string) ControllerBase.RedirectToActionPermanent(string, object) ControllerBase.RedirectToActionPermanent(string, string) ControllerBase.RedirectToActionPermanent(string, string, string) ControllerBase.RedirectToActionPermanent(string, string, object) ControllerBase.RedirectToActionPermanent(string, string, object, string) ControllerBase.RedirectToActionPermanentPreserveMethod(string, string, object, string) ControllerBase.RedirectToRoute(string) ControllerBase.RedirectToRoute(object) ControllerBase.RedirectToRoute(string, object) ControllerBase.RedirectToRoute(string, string) ControllerBase.RedirectToRoute(string, object, string) ControllerBase.RedirectToRoutePreserveMethod(string, object, string) ControllerBase.RedirectToRoutePermanent(string) ControllerBase.RedirectToRoutePermanent(object) ControllerBase.RedirectToRoutePermanent(string, object) ControllerBase.RedirectToRoutePermanent(string, string) ControllerBase.RedirectToRoutePermanent(string, object, string) ControllerBase.RedirectToRoutePermanentPreserveMethod(string, object, string) ControllerBase.RedirectToPage(string) ControllerBase.RedirectToPage(string, object) ControllerBase.RedirectToPage(string, string) ControllerBase.RedirectToPage(string, string, object) ControllerBase.RedirectToPage(string, string, string) ControllerBase.RedirectToPage(string, string, object, string) ControllerBase.RedirectToPagePermanent(string) ControllerBase.RedirectToPagePermanent(string, object) ControllerBase.RedirectToPagePermanent(string, string) ControllerBase.RedirectToPagePermanent(string, string, string) ControllerBase.RedirectToPagePermanent(string, string, object, string) ControllerBase.RedirectToPagePreserveMethod(string, string, object, string) ControllerBase.RedirectToPagePermanentPreserveMethod(string, string, object, string) ControllerBase.File(byte[], string) ControllerBase.File(byte[], string, bool) ControllerBase.File(byte[], string, string) ControllerBase.File(byte[], string, string, bool) ControllerBase.File(byte[], string, DateTimeOffset?, EntityTagHeaderValue) ControllerBase.File(byte[], string, DateTimeOffset?, EntityTagHeaderValue, bool) ControllerBase.File(byte[], string, string, DateTimeOffset?, EntityTagHeaderValue) ControllerBase.File(byte[], string, string, DateTimeOffset?, EntityTagHeaderValue, bool) ControllerBase.File(Stream, string) ControllerBase.File(Stream, string, bool) ControllerBase.File(Stream, string, string) ControllerBase.File(Stream, string, string, bool) ControllerBase.File(Stream, string, DateTimeOffset?, EntityTagHeaderValue) ControllerBase.File(Stream, string, DateTimeOffset?, EntityTagHeaderValue, bool) ControllerBase.File(Stream, string, string, DateTimeOffset?, EntityTagHeaderValue) ControllerBase.File(Stream, string, string, DateTimeOffset?, EntityTagHeaderValue, bool) ControllerBase.File(string, string) ControllerBase.File(string, string, bool) ControllerBase.File(string, string, string) ControllerBase.File(string, string, string, bool) ControllerBase.File(string, string, DateTimeOffset?, EntityTagHeaderValue) ControllerBase.File(string, string, DateTimeOffset?, EntityTagHeaderValue, bool) ControllerBase.File(string, string, string, DateTimeOffset?, EntityTagHeaderValue) ControllerBase.File(string, string, string, DateTimeOffset?, EntityTagHeaderValue, bool) ControllerBase.PhysicalFile(string, string) ControllerBase.PhysicalFile(string, string, bool) ControllerBase.PhysicalFile(string, string, string) ControllerBase.PhysicalFile(string, string, string, bool) ControllerBase.PhysicalFile(string, string, DateTimeOffset?, EntityTagHeaderValue) ControllerBase.PhysicalFile(string, string, DateTimeOffset?, EntityTagHeaderValue, bool) ControllerBase.PhysicalFile(string, string, string, DateTimeOffset?, EntityTagHeaderValue) ControllerBase.PhysicalFile(string, string, string, DateTimeOffset?, EntityTagHeaderValue, bool) ControllerBase.Unauthorized() ControllerBase.Unauthorized(object) ControllerBase.NotFound() ControllerBase.NotFound(object) ControllerBase.BadRequest() ControllerBase.BadRequest(object) ControllerBase.BadRequest(ModelStateDictionary) ControllerBase.UnprocessableEntity() ControllerBase.UnprocessableEntity(object) ControllerBase.UnprocessableEntity(ModelStateDictionary) ControllerBase.Conflict() ControllerBase.Conflict(object) ControllerBase.Conflict(ModelStateDictionary) ControllerBase.Problem(string, string, int?, string, string) ControllerBase.Problem(string, string, int?, string, string, IDictionary<string, object>) ControllerBase.ValidationProblem(ValidationProblemDetails) ControllerBase.ValidationProblem(ModelStateDictionary) ControllerBase.ValidationProblem() ControllerBase.ValidationProblem(string, string, int?, string, string, ModelStateDictionary) ControllerBase.ValidationProblem(string, string, int?, string, string, ModelStateDictionary, IDictionary<string, object>) ControllerBase.Created() ControllerBase.Created(string, object) ControllerBase.Created(Uri, object) ControllerBase.CreatedAtAction(string, object) ControllerBase.CreatedAtAction(string, object, object) ControllerBase.CreatedAtAction(string, string, object, object) ControllerBase.CreatedAtRoute(string, object) ControllerBase.CreatedAtRoute(object, object) ControllerBase.CreatedAtRoute(string, object, object) ControllerBase.Accepted() ControllerBase.Accepted(object) ControllerBase.Accepted(Uri) ControllerBase.Accepted(string) ControllerBase.Accepted(string, object) ControllerBase.Accepted(Uri, object) ControllerBase.AcceptedAtAction(string) ControllerBase.AcceptedAtAction(string, string) ControllerBase.AcceptedAtAction(string, object) ControllerBase.AcceptedAtAction(string, string, object) ControllerBase.AcceptedAtAction(string, object, object) ControllerBase.AcceptedAtAction(string, string, object, object) ControllerBase.AcceptedAtRoute(object) ControllerBase.AcceptedAtRoute(string) ControllerBase.AcceptedAtRoute(string, object) ControllerBase.AcceptedAtRoute(object, object) ControllerBase.AcceptedAtRoute(string, object, object) ControllerBase.Challenge() ControllerBase.Challenge(params string[]) ControllerBase.Challenge(AuthenticationProperties) ControllerBase.Challenge(AuthenticationProperties, params string[]) ControllerBase.Forbid() ControllerBase.Forbid(params string[]) ControllerBase.Forbid(AuthenticationProperties) ControllerBase.Forbid(AuthenticationProperties, params string[]) ControllerBase.SignIn(ClaimsPrincipal) ControllerBase.SignIn(ClaimsPrincipal, string) ControllerBase.SignIn(ClaimsPrincipal, AuthenticationProperties) ControllerBase.SignIn(ClaimsPrincipal, AuthenticationProperties, string) ControllerBase.SignOut() ControllerBase.SignOut(AuthenticationProperties) ControllerBase.SignOut(params string[]) ControllerBase.SignOut(AuthenticationProperties, params string[]) ControllerBase.TryUpdateModelAsync<TModel>(TModel) ControllerBase.TryUpdateModelAsync<TModel>(TModel, string) ControllerBase.TryUpdateModelAsync<TModel>(TModel, string, IValueProvider) ControllerBase.TryUpdateModelAsync<TModel>(TModel, string, params Expression<Func<TModel, object>>[]) ControllerBase.TryUpdateModelAsync<TModel>(TModel, string, Func<ModelMetadata, bool>) ControllerBase.TryUpdateModelAsync<TModel>(TModel, string, IValueProvider, params Expression<Func<TModel, object>>[]) ControllerBase.TryUpdateModelAsync<TModel>(TModel, string, IValueProvider, Func<ModelMetadata, bool>) ControllerBase.TryUpdateModelAsync(object, Type, string) ControllerBase.TryUpdateModelAsync(object, Type, string, IValueProvider, Func<ModelMetadata, bool>) ControllerBase.TryValidateModel(object) ControllerBase.TryValidateModel(object, string) ControllerBase.HttpContext ControllerBase.Request ControllerBase.Response ControllerBase.RouteData ControllerBase.ModelState ControllerBase.ControllerContext ControllerBase.MetadataProvider ControllerBase.ModelBinderFactory ControllerBase.Url ControllerBase.ObjectValidator ControllerBase.ProblemDetailsFactory ControllerBase.User ControllerBase.Empty object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Constructors WeatherForecastController(ILogger<WeatherForecastController>) public WeatherForecastController(ILogger<WeatherForecastController> logger) Parameters logger ILogger<WeatherForecastController> Methods Get() [HttpGet(Name = \"GetWeatherForecast\")] public IEnumerable<WeatherForecast> Get() Returns IEnumerable<WeatherForecast>"
  },
  "api/Server.EndPoints.GetWeatherForecastEndpoint.html": {
    "href": "api/Server.EndPoints.GetWeatherForecastEndpoint.html",
    "title": "Class GetWeatherForecastEndpoint",
    "summary": "Class GetWeatherForecastEndpoint Namespace Server.EndPoints Assembly Server.dll public class GetWeatherForecastEndpoint : EndpointWithoutRequest<IEnumerable<WeatherForecast>>, IEndpoint, IEventBus, IServiceResolverBase, INoRequest Inheritance object BaseEndpoint Endpoint<EmptyRequest, IEnumerable<WeatherForecast>> EndpointWithoutRequest<IEnumerable<WeatherForecast>> GetWeatherForecastEndpoint Implements IEndpoint IEventBus IServiceResolverBase INoRequest Inherited Members EndpointWithoutRequest<IEnumerable<WeatherForecast>>.HandleAsync(EmptyRequest, CancellationToken) EndpointWithoutRequest<IEnumerable<WeatherForecast>>.ExecuteAsync(CancellationToken) EndpointWithoutRequest<IEnumerable<WeatherForecast>>.ExecuteAsync(EmptyRequest, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.HandleAsync(EmptyRequest, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.ExecuteAsync(EmptyRequest, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.TryResolve<TService>() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.TryResolve(Type) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Resolve<TService>() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Resolve(Type) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.CreateScope() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.TryResolve<TService>(string) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.TryResolve(Type, string) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Resolve<TService>(string) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Resolve(Type, string) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Route<T>(string, bool) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Query<T>(string, bool) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.FormFileSectionsAsync(CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.FormMultipartSectionsAsync(CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.PublishAsync<TEvent>(TEvent, Mode, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.CreateTokenWith<TService>(string, Action<UserPrivileges>, EmptyRequest) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.ProcessorState<TState>() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.OnBeforeValidate(EmptyRequest) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.OnBeforeValidateAsync(EmptyRequest, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.OnAfterValidate(EmptyRequest) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.OnAfterValidateAsync(EmptyRequest, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.OnBeforeHandle(EmptyRequest) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.OnBeforeHandleAsync(EmptyRequest, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.OnAfterHandle(EmptyRequest, IEnumerable<WeatherForecast>) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.OnAfterHandleAsync(EmptyRequest, IEnumerable<WeatherForecast>, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.OnValidationFailed() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.OnValidationFailedAsync(CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendAsync(IEnumerable<WeatherForecast>, int, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendResultAsync(IResult) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendInterceptedAsync(object, int, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendCreatedAtAsync<TEndpoint>(object, IEnumerable<WeatherForecast>, Http?, int?, bool, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendCreatedAtAsync(string, object, IEnumerable<WeatherForecast>, bool, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendStringAsync(string, int, string, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendOkAsync(IEnumerable<WeatherForecast>, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendOkAsync(CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendErrorsAsync(int, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendNoContentAsync(CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendNotFoundAsync(CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendUnauthorizedAsync(CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendForbiddenAsync(CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendRedirectAsync(string, bool, bool) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendHeadersAsync(Action<IHeaderDictionary>, int, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendBytesAsync(byte[], string, string, DateTimeOffset?, bool, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendFileAsync(FileInfo, string, DateTimeOffset?, bool, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendStreamAsync(Stream, string, long?, string, DateTimeOffset?, bool, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendEventStreamAsync<T>(string, IAsyncEnumerable<T>, CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SendEmptyJsonObject(CancellationToken) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.AccessControl(string, Apply?, params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.AccessControl(string, params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.AllowAnonymous(params Http[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.AllowAnonymous(string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.AllowFileUploads(bool) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.AllowFormData(bool) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.AuthSchemes(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Claims(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.ClaimsAll(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Delete(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Delete(string, Expression<Func<EmptyRequest, object>>) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Description(Action<RouteHandlerBuilder>, bool) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.DontAutoSendResponse() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.DontAutoTag() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.DontCatchExceptions() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.DontThrowIfValidationFails() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.EnableAntiforgery() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Get(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Get(string, Expression<Func<EmptyRequest, object>>) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Group<TEndpointGroup>() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Head(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Head(string, Expression<Func<EmptyRequest, object>>) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Idempotency(Action<IdempotencyOptions>) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Options(Action<RouteHandlerBuilder>) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Patch(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Patch(string, Expression<Func<EmptyRequest, object>>) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Permissions(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.PermissionsAll(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Policy(Action<AuthorizationPolicyBuilder>) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Policies(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Post(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Post(string, Expression<Func<EmptyRequest, object>>) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.PostProcessor<TPostProcessor>() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.PostProcessors(params IPostProcessor<EmptyRequest, IEnumerable<WeatherForecast>>[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.PreProcessor<TPreProcessor>() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.PreProcessors(params IPreProcessor<EmptyRequest>[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Put(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Put(string, Expression<Func<EmptyRequest, object>>) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.RequestBinder(IRequestBinder<EmptyRequest>) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.ResponseCache(int, ResponseCacheLocation, bool, string, string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.ResponseInterceptor(IResponseInterceptor) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Roles(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.RoutePrefixOverride(string) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Routes(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SerializerContext<TContext>(TContext) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.SerializerContext<TContext>() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Summary(Action<EndpointSummary>) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Summary(Action<EndpointSummary<EmptyRequest>>) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Summary(EndpointSummary) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Tags(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Throttle(int, double, string) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Validator<TValidator>() Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Verbs(params Http[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Verbs(params string[]) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Version(int, int) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.AddError(ValidationFailure) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.AddError(string, string, Severity) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.AddError(Expression<Func<EmptyRequest, object>>, string, string, Severity) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.ThrowError(ValidationFailure, int?) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.ThrowError(string, int?) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.ThrowError(Expression<Func<EmptyRequest, object>>, string, int?) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.ThrowIfAnyErrors(int?) Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.User Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Response Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Config Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Env Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Logger Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.BaseURL Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.HttpMethod Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Form Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.Files Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.ResponseStarted Endpoint<EmptyRequest, IEnumerable<WeatherForecast>>.ValidationFailed BaseEndpoint.Verbs(params string[]) BaseEndpoint.Routes(params string[]) BaseEndpoint.Group<TEndpointGroup>() BaseEndpoint.GetAclHash(string) BaseEndpoint.Definition BaseEndpoint.HttpContext BaseEndpoint.ValidationFailures object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Methods Configure() use this method to configure how the endpoint should be listening to incoming requests. HINT: it is only called once during endpoint auto registration during app startup. public override void Configure() HandleAsync(CancellationToken) the handler method for the endpoint. this method is called for each request received. public override Task HandleAsync(CancellationToken ct) Parameters ct CancellationToken a cancellation token Returns Task"
  },
  "api/Server.EndPoints.html": {
    "href": "api/Server.EndPoints.html",
    "title": "Namespace Server.EndPoints",
    "summary": "Namespace Server.EndPoints Classes GetWeatherForecastEndpoint"
  },
  "api/Server.html": {
    "href": "api/Server.html",
    "title": "Namespace Server",
    "summary": "Namespace Server Classes WeatherForecast"
  },
  "api/Server.WeatherForecast.html": {
    "href": "api/Server.WeatherForecast.html",
    "title": "Class WeatherForecast",
    "summary": "Class WeatherForecast Namespace Server Assembly Server.dll public class WeatherForecast Inheritance object WeatherForecast Inherited Members object.Equals(object) object.Equals(object, object) object.GetHashCode() object.GetType() object.MemberwiseClone() object.ReferenceEquals(object, object) object.ToString() Properties Date public DateOnly Date { get; set; } Property Value DateOnly Summary public string? Summary { get; set; } Property Value string TemperatureC public int TemperatureC { get; set; } Property Value int TemperatureF public int TemperatureF { get; } Property Value int"
  },
  "docs/docfx.html": {
    "href": "docs/docfx.html",
    "title": "DocFX: Documentation and API Reference Generator",
    "summary": "DocFX: Documentation and API Reference Generator What is DocFX? DocFX is a comprehensive documentation generation tool specifically designed for technical documentation. It converts multiple sources into a cohesive documentation website, including: .NET assembly files XML code comments REST API Swagger/OpenAPI specifications Markdown content The output can be rendered as HTML pages, JSON models, or PDF files, making it versatile for various documentation needs. Key Features Multiple Input Sources: Combines API documentation with conceptual content Cross-platform: Works on Windows, macOS, and Linux Highly Customizable: Templates, themes, and plugins available Metadata Extraction: Automatically extracts documentation from .NET code and XML comments Modern Output: Generates responsive, searchable websites PDF Generation: Creates professional PDF documentation (requires Node.js) Installation Guide Prerequisites Before installing DocFX, ensure you have: Required: .NET SDK 8.0 or higher Optional: Node.js v20 or higher (needed only for PDF generation) Basic familiarity with command-line operations Installation Steps DocFX is distributed as a .NET tool. To install it globally on your system: dotnet tool update -g docfx This command will install the latest version of DocFX as a global tool, making it available from any directory. Getting Started Creating a New Documentation Project To create a new documentation project: docfx init This interactive command will guide you through setting up a new DocFX project in your current directory. It will create the necessary configuration files and folder structure. Building Your Documentation Once you've created a project, you can build it with: docfx docfx.json --serve This command: Builds your documentation based on the configuration in docfx.json Starts a local web server Makes your documentation available at http://localhost:8080 Previewing Changes To preview changes as you work: Save your changes to content files In a new terminal window, run: docfx docfx.json Refresh your browser to see the updated content Understanding DocFX DocFX brings together static documentation pages and .NET API documentation in a seamless way. It supports both C# and VB.NET projects, utilizing the standard XML comment syntax for code documentation. For example, this C# code with XML comments: /// <summary> /// Calculates the age of a person on a certain date based on the supplied date of birth. Takes account of leap years, /// using the convention that someone born on 29th February in a leap year is not legally one year older until 1st March /// of a non-leap year. /// </summary> /// <param name=\"dateOfBirth\">Individual's date of birth.</param> /// <param name=\"date\">Date at which to evaluate age at.</param> /// <returns>Age of the individual in years (as an integer).</returns> /// <remarks>This code is not guaranteed to be correct for non-UK locales, as some countries have skipped certain dates /// within living memory.</remarks> public static int AgeAt(this DateOnly dateOfBirth, DateOnly date) { int age = date.Year - dateOfBirth.Year; return dateOfBirth > date.AddYears(-age) ? --age : age; } Will be transformed into well-formatted API documentation with proper sections for description, parameters, return values, and remarks. Next Steps After setting up your basic documentation: Customize your theme: Modify templates to match your brand Add navigation: Create a meaningful table of contents Include examples: Add code snippets and examples Set up CI/CD: Automate documentation builds with GitHub Actions or Azure DevOps Resources Official DocFX Documentation GitHub Repository Sample Projects"
  },
  "docs/fastendpoints.html": {
    "href": "docs/fastendpoints.html",
    "title": "FastEndpoints: A Modern Minimal API Framework for .NET",
    "summary": "FastEndpoints: A Modern Minimal API Framework for .NET What is FastEndpoints? FastEndpoints is a powerful, developer-friendly API framework for .NET that provides a clean, code-first approach to building HTTP endpoints. It combines the performance benefits of minimal APIs with the organization and structure of a controller-based architecture, offering the best of both worlds. Key Features High Performance: Optimized for speed with minimal overhead Minimal API Approach: Clean, focused endpoint implementation Structured Organization: Each endpoint in its own class for better separation of concerns Request/Response Pattern: Built-in support for strong typing of requests and responses Validation: Built-in validation capabilities Testing: First-class support for integration testing Low Ceremony: Minimal boilerplate code required Installation Guide Prerequisites Before installing FastEndpoints, ensure you have: .NET SDK: .NET 6.0 or higher Installation Steps To create a new project and install FastEndpoints: dotnet new web -n MyWebApp cd MyWebApp dotnet add package FastEndpoints Getting Started Setting Up Your Application First, configure your application in Program.cs: using FastEndpoints; var bld = WebApplication.CreateBuilder(); bld.Services.AddFastEndpoints(); var app = bld.Build(); app.UseFastEndpoints(); app.Run(); Creating Your First Endpoint Follow these steps to create a simple endpoint: 1. Create a Request DTO // MyRequest.cs public class MyRequest { public string FirstName { get; set; } public string LastName { get; set; } public int Age { get; set; } } 2. Create a Response DTO // MyResponse.cs public class MyResponse { public string FullName { get; set; } public bool IsOver18 { get; set; } } 3. Create an Endpoint Class // MyEndpoint.cs public class MyEndpoint : Endpoint<MyRequest, MyResponse> { public override void Configure() { Post(\"/api/user/create\"); AllowAnonymous(); } public override async Task HandleAsync(MyRequest req, CancellationToken ct) { await SendAsync(new() { FullName = req.FirstName + \" \" + req.LastName, IsOver18 = req.Age > 18 }); } } 4. Run and Test Start your application and send a POST request to /api/user/create with a JSON body like: { \"FirstName\": \"Marlon\", \"LastName\": \"Brando\", \"Age\": 40 } You should receive a response: { \"FullName\": \"Marlon Brando\", \"IsOver18\": true } Understanding Endpoint Types FastEndpoints offers four different base types for endpoints: Endpoint<TRequest> For endpoints with only a request DTO Can still send serializable responses Endpoint<TRequest, TResponse> For endpoints with both request and response DTOs Provides strongly-typed access for testing and validation EndpointWithoutRequest For endpoints with no request or response DTOs Can send any serializable object as response EndpointWithoutRequest<TResponse> For endpoints with no request DTO but with a response DTO You can also use EmptyRequest and EmptyResponse types: public class MyEndpoint : Endpoint<EmptyRequest, EmptyResponse> { } Fluent Generics FastEndpoints offers a fluent syntax for endpoint definition: // Equivalent of Endpoint<TRequest> public class MyEndpoint : Ep.Req<MyRequest>.NoRes { } // Equivalent of Endpoint<TRequest,TResponse> public class MyEndpoint : Ep.Req<MyRequest>.Res<MyResponse> { } // Equivalent of EndpointWithoutRequest public class MyEndpoint : Ep.NoReq.NoRes { } // Equivalent of EndpointWithoutRequest<TResponse> public class MyEndpoint : Ep.NoReq.Res<MyResponse> { } Sending Responses There are multiple ways to send responses: Using the Response Property You can simply populate the Response property: public override async Task HandleAsync(CancellationToken ct) { var person = await dbContext.GetFirstPersonAsync(); Response.FullName = person.FullName; Response.Age = person.Age; } Or assign a new instance to it: public override Task HandleAsync(CancellationToken ct) { Response = new() { FullName = \"john doe\", Age = 124 }; return Task.CompletedTask; } Using Union Types (.NET 7+) FastEndpoints supports union types for multiple possible responses: public class MyEndpoint : Endpoint<MyRequest, Results<Ok<MyResponse>, NotFound, ProblemDetails>> { public override void Configure() { ... } public override async Task<Results<Ok<MyResponse>, NotFound, ProblemDetails>> ExecuteAsync( MyRequest req, CancellationToken ct) { await Task.CompletedTask; // Simulate async work if (req.Id == 0) // Condition for a not found response { return TypedResults.NotFound(); } if (req.Id == 1) // Condition for a problem details response { AddError(r => r.Id, \"value has to be greater than 1\"); return new FastEndpoints.ProblemDetails(ValidationFailures); } // 200 OK response with a DTO return TypedResults.Ok(new MyResponse { RequestedId = req.Id }); } } Configuring with Attributes Instead of overriding the Configure() method, you can use attributes: [HttpPost(\"/my-endpoint\")] [Authorize(Roles = \"Admin,Manager\")] [PreProcessor<MyProcessor>] public class MyEndpoint : Endpoint<MyRequest, MyResponse> { // ... } Available attributes include: [Http{VERB}(\"/route\")] - Sets up verb and route [AllowAnonymous] - Allows unauthenticated access [AllowFileUploads] - Allows file uploads with multipart/form-data [Authorize(...)] - Specifies authorization requirements [Group<TGroup>] - Associates endpoint with a configuration group [PreProcessor<TProcessor>] - Adds a pre-processor [PostProcessor<TProcessor>] - Adds a post-processor Working with Cancellation Tokens FastEndpoints provides cancellation token support for asynchronous operations: public override async Task HandleAsync(MyRequest req, CancellationToken ct) { // Pass the token to your async methods var data = await _repository.GetDataAsync(ct); // No need to explicitly pass the token to SendAsync // It automatically uses the same token from HandleAsync await SendAsync(new MyResponse { ... }); } Next Steps After mastering the basics: Add validation to your request DTOs Implement authorization for secure endpoints Set up dependency injection for your endpoints Create integration tests for your API Explore more advanced features like versioning and documentation Resources Official GitHub Repository Documentation NuGet Package"
  },
  "docs/getting-started.html": {
    "href": "docs/getting-started.html",
    "title": "Getting Started",
    "summary": "Getting Started"
  },
  "docs/introduction.html": {
    "href": "docs/introduction.html",
    "title": "Introduction",
    "summary": "Introduction"
  },
  "index.html": {
    "href": "index.html",
    "title": "This is the HOMEPAGE.",
    "summary": "This is the HOMEPAGE. Refer to Markdown for how to write markdown files. Quick Start Notes: Add images to the images folder if the file is referencing an image."
  },
  "src/frontend/app-client/node_modules/@ampproject/remapping/README.html": {
    "href": "src/frontend/app-client/node_modules/@ampproject/remapping/README.html",
    "title": "",
    "summary": "@ampproject/remapping Remap sequential sourcemaps through transformations to point at the original source code Remapping allows you to take the sourcemaps generated through transforming your code and \"remap\" them to the original source locations. Think \"my minified code, transformed with babel and bundled with webpack\", all pointing to the correct location in your original source code. With remapping, none of your source code transformations need to be aware of the input's sourcemap, they only need to generate an output sourcemap. This greatly simplifies building custom transformations (think a find-and-replace). Installation npm install @ampproject/remapping Usage function remapping( map: SourceMap | SourceMap[], loader: (file: string, ctx: LoaderContext) => (SourceMap | null | undefined), options?: { excludeContent: boolean, decodedMappings: boolean } ): SourceMap; // LoaderContext gives the loader the importing sourcemap, tree depth, the ability to override the // \"source\" location (where child sources are resolved relative to, or the location of original // source), and the ability to override the \"content\" of an original source for inclusion in the // output sourcemap. type LoaderContext = { readonly importer: string; readonly depth: number; source: string; content: string | null | undefined; } remapping takes the final output sourcemap, and a loader function. For every source file pointer in the sourcemap, the loader will be called with the resolved path. If the path itself represents a transformed file (it has a sourcmap associated with it), then the loader should return that sourcemap. If not, the path will be treated as an original, untransformed source code. // Babel transformed \"helloworld.js\" into \"transformed.js\" const transformedMap = JSON.stringify({ file: 'transformed.js', // 1st column of 2nd line of output file translates into the 1st source // file, line 3, column 2 mappings: ';CAEE', sources: ['helloworld.js'], version: 3, }); // Uglify minified \"transformed.js\" into \"transformed.min.js\" const minifiedTransformedMap = JSON.stringify({ file: 'transformed.min.js', // 0th column of 1st line of output file translates into the 1st source // file, line 2, column 1. mappings: 'AACC', names: [], sources: ['transformed.js'], version: 3, }); const remapped = remapping( minifiedTransformedMap, (file, ctx) => { // The \"transformed.js\" file is an transformed file. if (file === 'transformed.js') { // The root importer is empty. console.assert(ctx.importer === ''); // The depth in the sourcemap tree we're currently loading. // The root `minifiedTransformedMap` is depth 0, and its source children are depth 1, etc. console.assert(ctx.depth === 1); return transformedMap; } // Loader will be called to load transformedMap's source file pointers as well. console.assert(file === 'helloworld.js'); // `transformed.js`'s sourcemap points into `helloworld.js`. console.assert(ctx.importer === 'transformed.js'); // This is a source child of `transformed`, which is a source child of `minifiedTransformedMap`. console.assert(ctx.depth === 2); return null; } ); console.log(remapped); // { // file: 'transpiled.min.js', // mappings: 'AAEE', // sources: ['helloworld.js'], // version: 3, // }; In this example, loader will be called twice: \"transformed.js\", the first source file pointer in the minifiedTransformedMap. We return the associated sourcemap for it (its a transformed file, after all) so that sourcemap locations can be traced through it into the source files it represents. \"helloworld.js\", our original, unmodified source code. This file does not have a sourcemap, so we return null. The remapped sourcemap now points from transformed.min.js into locations in helloworld.js. If you were to read the mappings, it says \"0th column of the first line output line points to the 1st column of the 2nd line of the file helloworld.js\". Multiple transformations of a file As a convenience, if you have multiple single-source transformations of a file, you may pass an array of sourcemap files in the order of most-recent transformation sourcemap first. Note that this changes the importer and depth of each call to our loader. So our above example could have been written as: const remapped = remapping( [minifiedTransformedMap, transformedMap], () => null ); console.log(remapped); // { // file: 'transpiled.min.js', // mappings: 'AAEE', // sources: ['helloworld.js'], // version: 3, // }; Advanced control of the loading graph source The source property can overridden to any value to change the location of the current load. Eg, for an original source file, it allows us to change the location to the original source regardless of what the sourcemap source entry says. And for transformed files, it allows us to change the relative resolving location for child sources of the loaded sourcemap. const remapped = remapping( minifiedTransformedMap, (file, ctx) => { if (file === 'transformed.js') { // We pretend the transformed.js file actually exists in the 'src/' directory. When the nested // source files are loaded, they will now be relative to `src/`. ctx.source = 'src/transformed.js'; return transformedMap; } console.assert(file === 'src/helloworld.js'); // We could futher change the source of this original file, eg, to be inside a nested directory // itself. This will be reflected in the remapped sourcemap. ctx.source = 'src/nested/transformed.js'; return null; } ); console.log(remapped); // { // …, // sources: ['src/nested/helloworld.js'], // }; content The content property can be overridden when we encounter an original source file. Eg, this allows you to manually provide the source content of the original file regardless of whether the sourcesContent field is present in the parent sourcemap. It can also be set to null to remove the source content. const remapped = remapping( minifiedTransformedMap, (file, ctx) => { if (file === 'transformed.js') { // transformedMap does not include a `sourcesContent` field, so usually the remapped sourcemap // would not include any `sourcesContent` values. return transformedMap; } console.assert(file === 'helloworld.js'); // We can read the file to provide the source content. ctx.content = fs.readFileSync(file, 'utf8'); return null; } ); console.log(remapped); // { // …, // sourcesContent: [ // 'console.log(\"Hello world!\")', // ], // }; Options excludeContent By default, excludeContent is false. Passing { excludeContent: true } will exclude the sourcesContent field from the returned sourcemap. This is mainly useful when you want to reduce the size out the sourcemap. decodedMappings By default, decodedMappings is false. Passing { decodedMappings: true } will leave the mappings field in a decoded state instead of encoding into a VLQ string."
  },
  "src/frontend/app-client/node_modules/@azure/abort-controller/README.html": {
    "href": "src/frontend/app-client/node_modules/@azure/abort-controller/README.html",
    "title": "Azure Abort Controller client library for JavaScript",
    "summary": "Azure Abort Controller client library for JavaScript The @azure/abort-controller package provides AbortSignalLike interface and AbortError classes to make it easier to work with the AbortController and the AbortSignal used by fetch built into modern JavaScript platforms. Customers of Azure SDK for JavaScript in general do not need to use this library. Instead they use AbortController and AbortSignal provided by their platforms and pass the abort signals to Azure SDK operations. Key links: Source code Package (npm) API Reference Documentation Getting started Installation Install this library using npm as follows npm install @azure/abort-controller Key Concepts Use AbortController to create an AbortSignal which can then be passed to Azure SDK operations to cancel pending work. The AbortSignal can be accessed via the signal property on an instantiated AbortController. An AbortSignal can also be returned directly from a static method, e.g. AbortSignal.timeout(100). that is cancelled after 100 milliseconds. Examples The below examples assume that doAsyncWork is a function that takes a bag of properties, one of which is of the abort signal. Example 1 - basic usage const controller = new AbortController(); doAsyncWork({ abortSignal: controller.signal }); // at some point later controller.abort(); Example 2 - Aborting with timeout const signal = AbortSignal.timeout(1000); doAsyncWork({ abortSignal: signal }); Next steps You can build and run the tests locally by executing rushx test. Explore the test folder to see advanced usage and behavior of the public classes. Troubleshooting If you run into issues while using this library, please feel free to file an issue. Contributing If you'd like to contribute to this library, please read the contributing guide to learn more about how to build and test the code."
  },
  "src/frontend/app-client/node_modules/@azure/core-auth/README.html": {
    "href": "src/frontend/app-client/node_modules/@azure/core-auth/README.html",
    "title": "Azure Core Authentication client library for JavaScript",
    "summary": "Azure Core Authentication client library for JavaScript The @azure/core-auth package provides core interfaces and helper methods for authenticating with Azure services using Azure Active Directory and other authentication schemes common across the Azure SDK. As a \"core\" library, it shouldn't need to be added as a dependency to any user code, only other Azure SDK libraries. Getting started Installation Install this library using npm as follows npm install @azure/core-auth Key Concepts The TokenCredential interface represents a credential capable of providing an authentication token. The @azure/identity package contains various credentials that implement the TokenCredential interface. The AzureKeyCredential is a static key-based credential that supports key rotation via the update method. Use this when a single secret value is needed for authentication, e.g. when using a shared access key. The AzureNamedKeyCredential is a static name/key-based credential that supports name and key rotation via the update method. Use this when both a secret value and a label are needed, e.g. when using a shared access key and shared access key name. The AzureSASCredential is a static signature-based credential that supports updating the signature value via the update method. Use this when using a shared access signature. Examples AzureKeyCredential import { AzureKeyCredential } from \"@azure/core-auth\"; const credential = new AzureKeyCredential(\"secret value\"); // prints: \"secret value\" console.log(credential.key); credential.update(\"other secret value\"); // prints: \"other secret value\" console.log(credential.key); AzureNamedKeyCredential import { AzureNamedKeyCredential } from \"@azure/core-auth\"; const credential = new AzureNamedKeyCredential(\"ManagedPolicy\", \"secret value\"); // prints: \"ManagedPolicy, secret value\" console.log(`${credential.name}, ${credential.key}`); credential.update(\"OtherManagedPolicy\", \"other secret value\"); // prints: \"OtherManagedPolicy, other secret value\" console.log(`${credential.name}, ${credential.key}`); AzureSASCredential import { AzureSASCredential } from \"@azure/core-auth\"; const credential = new AzureSASCredential(\"signature1\"); // prints: \"signature1\" console.log(credential.signature); credential.update(\"signature2\"); // prints: \"signature2\" console.log(credential.signature); Next steps You can build and run the tests locally by executing rushx test. Explore the test folder to see advanced usage and behavior of the public classes. Troubleshooting If you run into issues while using this library, please feel free to file an issue. Contributing If you'd like to contribute to this library, please read the contributing guide to learn more about how to build and test the code."
  },
  "src/frontend/app-client/node_modules/@azure/core-util/README.html": {
    "href": "src/frontend/app-client/node_modules/@azure/core-util/README.html",
    "title": "Azure Core Util client library for JavaScript (Experimental)",
    "summary": "Azure Core Util client library for JavaScript (Experimental) This library is intended to provide various shared utility functions for client SDK packages. Getting started Requirements Currently supported environments LTS versions of Node.js Latest versions of Safari, Chrome, Edge, and Firefox. See our support policy for more details. Installation This package is primarily used in authoring client SDKs and not meant to be consumed directly by end users. Key concepts Utility methods provided by this library should be stateless. Examples Examples can be found in the samples folder. Next steps Look at usage in dependent client SDKs. Troubleshooting If you run into issues while using this library, please feel free to file an issue. Contributing If you'd like to contribute to this library, please read the contributing guide to learn more about how to build and test the code."
  },
  "src/frontend/app-client/node_modules/@babel/code-frame/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/code-frame/README.html",
    "title": "",
    "summary": "@babel/code-frame Generate errors that contain a code frame that point to source locations. See our website @babel/code-frame for more information. Install Using npm: npm install --save-dev @babel/code-frame or using yarn: yarn add @babel/code-frame --dev"
  },
  "src/frontend/app-client/node_modules/@babel/compat-data/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/compat-data/README.html",
    "title": "",
    "summary": "@babel/compat-data The compat-data to determine required Babel plugins See our website @babel/compat-data for more information. Install Using npm: npm install --save @babel/compat-data or using yarn: yarn add @babel/compat-data"
  },
  "src/frontend/app-client/node_modules/@babel/core/node_modules/semver/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/core/node_modules/semver/README.html",
    "title": "semver(1) -- The semantic versioner for npm",
    "summary": "semver(1) -- The semantic versioner for npm Install npm install semver Usage As a node module: const semver = require('semver') semver.valid('1.2.3') // '1.2.3' semver.valid('a.b.c') // null semver.clean(' =v1.2.3 ') // '1.2.3' semver.satisfies('1.2.3', '1.x || >=2.5.0 || 5.0.0 - 7.2.3') // true semver.gt('1.2.3', '9.8.7') // false semver.lt('1.2.3', '9.8.7') // true semver.minVersion('>=1.0.0') // '1.0.0' semver.valid(semver.coerce('v2')) // '2.0.0' semver.valid(semver.coerce('42.6.7.9.3-alpha')) // '42.6.7' As a command-line utility: $ semver -h A JavaScript implementation of the https://semver.org/ specification Copyright Isaac Z. Schlueter Usage: semver [options] <version> [<version> [...]] Prints valid versions sorted by SemVer precedence Options: -r --range <range> Print versions that match the specified range. -i --increment [<level>] Increment a version by the specified level. Level can be one of: major, minor, patch, premajor, preminor, prepatch, or prerelease. Default level is 'patch'. Only one version may be specified. --preid <identifier> Identifier to be used to prefix premajor, preminor, prepatch or prerelease version increments. -l --loose Interpret versions and ranges loosely -p --include-prerelease Always include prerelease versions in range matching -c --coerce Coerce a string into SemVer if possible (does not imply --loose) --rtl Coerce version strings right to left --ltr Coerce version strings left to right (default) Program exits successfully if any valid version satisfies all supplied ranges, and prints all satisfying versions. If no satisfying versions are found, then exits failure. Versions are printed in ascending order, so supplying multiple versions to the utility will just sort them. Versions A \"version\" is described by the v2.0.0 specification found at https://semver.org/. A leading \"=\" or \"v\" character is stripped off and ignored. Ranges A version range is a set of comparators which specify versions that satisfy the range. A comparator is composed of an operator and a version. The set of primitive operators is: < Less than <= Less than or equal to > Greater than >= Greater than or equal to = Equal. If no operator is specified, then equality is assumed, so this operator is optional, but MAY be included. For example, the comparator >=1.2.7 would match the versions 1.2.7, 1.2.8, 2.5.3, and 1.3.9, but not the versions 1.2.6 or 1.1.0. Comparators can be joined by whitespace to form a comparator set, which is satisfied by the intersection of all of the comparators it includes. A range is composed of one or more comparator sets, joined by ||. A version matches a range if and only if every comparator in at least one of the ||-separated comparator sets is satisfied by the version. For example, the range >=1.2.7 <1.3.0 would match the versions 1.2.7, 1.2.8, and 1.2.99, but not the versions 1.2.6, 1.3.0, or 1.1.0. The range 1.2.7 || >=1.2.9 <2.0.0 would match the versions 1.2.7, 1.2.9, and 1.4.6, but not the versions 1.2.8 or 2.0.0. Prerelease Tags If a version has a prerelease tag (for example, 1.2.3-alpha.3) then it will only be allowed to satisfy comparator sets if at least one comparator with the same [major, minor, patch] tuple also has a prerelease tag. For example, the range >1.2.3-alpha.3 would be allowed to match the version 1.2.3-alpha.7, but it would not be satisfied by 3.4.5-alpha.9, even though 3.4.5-alpha.9 is technically \"greater than\" 1.2.3-alpha.3 according to the SemVer sort rules. The version range only accepts prerelease tags on the 1.2.3 version. The version 3.4.5 would satisfy the range, because it does not have a prerelease flag, and 3.4.5 is greater than 1.2.3-alpha.7. The purpose for this behavior is twofold. First, prerelease versions frequently are updated very quickly, and contain many breaking changes that are (by the author's design) not yet fit for public consumption. Therefore, by default, they are excluded from range matching semantics. Second, a user who has opted into using a prerelease version has clearly indicated the intent to use that specific set of alpha/beta/rc versions. By including a prerelease tag in the range, the user is indicating that they are aware of the risk. However, it is still not appropriate to assume that they have opted into taking a similar risk on the next set of prerelease versions. Note that this behavior can be suppressed (treating all prerelease versions as if they were normal versions, for the purpose of range matching) by setting the includePrerelease flag on the options object to any functions that do range matching. Prerelease Identifiers The method .inc takes an additional identifier string argument that will append the value of the string as a prerelease identifier: semver.inc('1.2.3', 'prerelease', 'beta') // '1.2.4-beta.0' command-line example: $ semver 1.2.3 -i prerelease --preid beta 1.2.4-beta.0 Which then can be used to increment further: $ semver 1.2.4-beta.0 -i prerelease 1.2.4-beta.1 Advanced Range Syntax Advanced range syntax desugars to primitive comparators in deterministic ways. Advanced ranges may be combined in the same way as primitive comparators using white space or ||. Hyphen Ranges X.Y.Z - A.B.C Specifies an inclusive set. 1.2.3 - 2.3.4 := >=1.2.3 <=2.3.4 If a partial version is provided as the first version in the inclusive range, then the missing pieces are replaced with zeroes. 1.2 - 2.3.4 := >=1.2.0 <=2.3.4 If a partial version is provided as the second version in the inclusive range, then all versions that start with the supplied parts of the tuple are accepted, but nothing that would be greater than the provided tuple parts. 1.2.3 - 2.3 := >=1.2.3 <2.4.0 1.2.3 - 2 := >=1.2.3 <3.0.0 X-Ranges 1.2.x 1.X 1.2.* * Any of X, x, or * may be used to \"stand in\" for one of the numeric values in the [major, minor, patch] tuple. * := >=0.0.0 (Any version satisfies) 1.x := >=1.0.0 <2.0.0 (Matching major version) 1.2.x := >=1.2.0 <1.3.0 (Matching major and minor versions) A partial version range is treated as an X-Range, so the special character is in fact optional. \"\" (empty string) := * := >=0.0.0 1 := 1.x.x := >=1.0.0 <2.0.0 1.2 := 1.2.x := >=1.2.0 <1.3.0 Tilde Ranges ~1.2.3 ~1.2 ~1 Allows patch-level changes if a minor version is specified on the comparator. Allows minor-level changes if not. ~1.2.3 := >=1.2.3 <1.(2+1).0 := >=1.2.3 <1.3.0 ~1.2 := >=1.2.0 <1.(2+1).0 := >=1.2.0 <1.3.0 (Same as 1.2.x) ~1 := >=1.0.0 <(1+1).0.0 := >=1.0.0 <2.0.0 (Same as 1.x) ~0.2.3 := >=0.2.3 <0.(2+1).0 := >=0.2.3 <0.3.0 ~0.2 := >=0.2.0 <0.(2+1).0 := >=0.2.0 <0.3.0 (Same as 0.2.x) ~0 := >=0.0.0 <(0+1).0.0 := >=0.0.0 <1.0.0 (Same as 0.x) ~1.2.3-beta.2 := >=1.2.3-beta.2 <1.3.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. Caret Ranges ^1.2.3 ^0.2.5 ^0.0.4 Allows changes that do not modify the left-most non-zero element in the [major, minor, patch] tuple. In other words, this allows patch and minor updates for versions 1.0.0 and above, patch updates for versions 0.X >=0.1.0, and no updates for versions 0.0.X. Many authors treat a 0.x version as if the x were the major \"breaking-change\" indicator. Caret ranges are ideal when an author may make breaking changes between 0.2.4 and 0.3.0 releases, which is a common practice. However, it presumes that there will not be breaking changes between 0.2.4 and 0.2.5. It allows for changes that are presumed to be additive (but non-breaking), according to commonly observed practices. ^1.2.3 := >=1.2.3 <2.0.0 ^0.2.3 := >=0.2.3 <0.3.0 ^0.0.3 := >=0.0.3 <0.0.4 ^1.2.3-beta.2 := >=1.2.3-beta.2 <2.0.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. ^0.0.3-beta := >=0.0.3-beta <0.0.4 Note that prereleases in the 0.0.3 version only will be allowed, if they are greater than or equal to beta. So, 0.0.3-pr.2 would be allowed. When parsing caret ranges, a missing patch value desugars to the number 0, but will allow flexibility within that value, even if the major and minor versions are both 0. ^1.2.x := >=1.2.0 <2.0.0 ^0.0.x := >=0.0.0 <0.1.0 ^0.0 := >=0.0.0 <0.1.0 A missing minor and patch values will desugar to zero, but also allow flexibility within those values, even if the major version is zero. ^1.x := >=1.0.0 <2.0.0 ^0.x := >=0.0.0 <1.0.0 Range Grammar Putting all this together, here is a Backus-Naur grammar for ranges, for the benefit of parser authors: range-set ::= range ( logical-or range ) * logical-or ::= ( ' ' ) * '||' ( ' ' ) * range ::= hyphen | simple ( ' ' simple ) * | '' hyphen ::= partial ' - ' partial simple ::= primitive | partial | tilde | caret primitive ::= ( '<' | '>' | '>=' | '<=' | '=' ) partial partial ::= xr ( '.' xr ( '.' xr qualifier ? )? )? xr ::= 'x' | 'X' | '*' | nr nr ::= '0' | ['1'-'9'] ( ['0'-'9'] ) * tilde ::= '~' partial caret ::= '^' partial qualifier ::= ( '-' pre )? ( '+' build )? pre ::= parts build ::= parts parts ::= part ( '.' part ) * part ::= nr | [-0-9A-Za-z]+ Functions All methods and classes take a final options object argument. All options in this object are false by default. The options supported are: loose Be more forgiving about not-quite-valid semver strings. (Any resulting output will always be 100% strict compliant, of course.) For backwards compatibility reasons, if the options argument is a boolean value instead of an object, it is interpreted to be the loose param. includePrerelease Set to suppress the default behavior of excluding prerelease tagged versions from ranges unless they are explicitly opted into. Strict-mode Comparators and Ranges will be strict about the SemVer strings that they parse. valid(v): Return the parsed version, or null if it's not valid. inc(v, release): Return the version incremented by the release type (major, premajor, minor, preminor, patch, prepatch, or prerelease), or null if it's not valid premajor in one call will bump the version up to the next major version and down to a prerelease of that major version. preminor, and prepatch work the same way. If called from a non-prerelease version, the prerelease will work the same as prepatch. It increments the patch version, then makes a prerelease. If the input version is already a prerelease it simply increments it. prerelease(v): Returns an array of prerelease components, or null if none exist. Example: prerelease('1.2.3-alpha.1') -> ['alpha', 1] major(v): Return the major version number. minor(v): Return the minor version number. patch(v): Return the patch version number. intersects(r1, r2, loose): Return true if the two supplied ranges or comparators intersect. parse(v): Attempt to parse a string as a semantic version, returning either a SemVer object or null. Comparison gt(v1, v2): v1 > v2 gte(v1, v2): v1 >= v2 lt(v1, v2): v1 < v2 lte(v1, v2): v1 <= v2 eq(v1, v2): v1 == v2 This is true if they're logically equivalent, even if they're not the exact same string. You already know how to compare strings. neq(v1, v2): v1 != v2 The opposite of eq. cmp(v1, comparator, v2): Pass in a comparison string, and it'll call the corresponding function above. \"===\" and \"!==\" do simple string comparison, but are included for completeness. Throws if an invalid comparison string is provided. compare(v1, v2): Return 0 if v1 == v2, or 1 if v1 is greater, or -1 if v2 is greater. Sorts in ascending order if passed to Array.sort(). rcompare(v1, v2): The reverse of compare. Sorts an array of versions in descending order when passed to Array.sort(). compareBuild(v1, v2): The same as compare but considers build when two versions are equal. Sorts in ascending order if passed to Array.sort(). v2 is greater. Sorts in ascending order if passed to Array.sort(). diff(v1, v2): Returns difference between two versions by the release type (major, premajor, minor, preminor, patch, prepatch, or prerelease), or null if the versions are the same. Comparators intersects(comparator): Return true if the comparators intersect Ranges validRange(range): Return the valid range or null if it's not valid satisfies(version, range): Return true if the version satisfies the range. maxSatisfying(versions, range): Return the highest version in the list that satisfies the range, or null if none of them do. minSatisfying(versions, range): Return the lowest version in the list that satisfies the range, or null if none of them do. minVersion(range): Return the lowest version that can possibly match the given range. gtr(version, range): Return true if version is greater than all the versions possible in the range. ltr(version, range): Return true if version is less than all the versions possible in the range. outside(version, range, hilo): Return true if the version is outside the bounds of the range in either the high or low direction. The hilo argument must be either the string '>' or '<'. (This is the function called by gtr and ltr.) intersects(range): Return true if any of the ranges comparators intersect Note that, since ranges may be non-contiguous, a version might not be greater than a range, less than a range, or satisfy a range! For example, the range 1.2 <1.2.9 || >2.0.0 would have a hole from 1.2.9 until 2.0.0, so the version 1.2.10 would not be greater than the range (because 2.0.1 satisfies, which is higher), nor less than the range (since 1.2.8 satisfies, which is lower), and it also does not satisfy the range. If you want to know if a version satisfies or does not satisfy a range, use the satisfies(version, range) function. Coercion coerce(version, options): Coerces a string to semver if possible This aims to provide a very forgiving translation of a non-semver string to semver. It looks for the first digit in a string, and consumes all remaining characters which satisfy at least a partial semver (e.g., 1, 1.2, 1.2.3) up to the max permitted length (256 characters). Longer versions are simply truncated (4.6.3.9.2-alpha2 becomes 4.6.3). All surrounding text is simply ignored (v3.4 replaces v3.3.1 becomes 3.4.0). Only text which lacks digits will fail coercion (version one is not valid). The maximum length for any semver component considered for coercion is 16 characters; longer components will be ignored (10000000000000000.4.7.4 becomes 4.7.4). The maximum value for any semver component is Integer.MAX_SAFE_INTEGER || (2**53 - 1); higher value components are invalid (9999999999999999.4.7.4 is likely invalid). If the options.rtl flag is set, then coerce will return the right-most coercible tuple that does not share an ending index with a longer coercible tuple. For example, 1.2.3.4 will return 2.3.4 in rtl mode, not 4.0.0. 1.2.3/4 will return 4.0.0, because the 4 is not a part of any other overlapping SemVer tuple. Clean clean(version): Clean a string to be a valid semver if possible This will return a cleaned and trimmed semver version. If the provided version is not valid a null will be returned. This does not work for ranges. ex. s.clean(' = v 2.1.5foo'): null s.clean(' = v 2.1.5foo', { loose: true }): '2.1.5-foo' s.clean(' = v 2.1.5-foo'): null s.clean(' = v 2.1.5-foo', { loose: true }): '2.1.5-foo' s.clean('=v2.1.5'): '2.1.5' s.clean(' =v2.1.5'): 2.1.5 s.clean(' 2.1.5 '): '2.1.5' s.clean('~1.0.0'): null"
  },
  "src/frontend/app-client/node_modules/@babel/core/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/core/README.html",
    "title": "",
    "summary": "@babel/core Babel compiler core. See our website @babel/core for more information or the issues associated with this package. Install Using npm: npm install --save-dev @babel/core or using yarn: yarn add @babel/core --dev"
  },
  "src/frontend/app-client/node_modules/@babel/generator/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/generator/README.html",
    "title": "",
    "summary": "@babel/generator Turns an AST into code. See our website @babel/generator for more information or the issues associated with this package. Install Using npm: npm install --save-dev @babel/generator or using yarn: yarn add @babel/generator --dev"
  },
  "src/frontend/app-client/node_modules/@babel/helper-annotate-as-pure/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-annotate-as-pure/README.html",
    "title": "",
    "summary": "@babel/helper-annotate-as-pure Helper function to annotate paths and nodes with #PURE comment See our website @babel/helper-annotate-as-pure for more information. Install Using npm: npm install --save @babel/helper-annotate-as-pure or using yarn: yarn add @babel/helper-annotate-as-pure"
  },
  "src/frontend/app-client/node_modules/@babel/helper-compilation-targets/node_modules/semver/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-compilation-targets/node_modules/semver/README.html",
    "title": "semver(1) -- The semantic versioner for npm",
    "summary": "semver(1) -- The semantic versioner for npm Install npm install semver Usage As a node module: const semver = require('semver') semver.valid('1.2.3') // '1.2.3' semver.valid('a.b.c') // null semver.clean(' =v1.2.3 ') // '1.2.3' semver.satisfies('1.2.3', '1.x || >=2.5.0 || 5.0.0 - 7.2.3') // true semver.gt('1.2.3', '9.8.7') // false semver.lt('1.2.3', '9.8.7') // true semver.minVersion('>=1.0.0') // '1.0.0' semver.valid(semver.coerce('v2')) // '2.0.0' semver.valid(semver.coerce('42.6.7.9.3-alpha')) // '42.6.7' As a command-line utility: $ semver -h A JavaScript implementation of the https://semver.org/ specification Copyright Isaac Z. Schlueter Usage: semver [options] <version> [<version> [...]] Prints valid versions sorted by SemVer precedence Options: -r --range <range> Print versions that match the specified range. -i --increment [<level>] Increment a version by the specified level. Level can be one of: major, minor, patch, premajor, preminor, prepatch, or prerelease. Default level is 'patch'. Only one version may be specified. --preid <identifier> Identifier to be used to prefix premajor, preminor, prepatch or prerelease version increments. -l --loose Interpret versions and ranges loosely -p --include-prerelease Always include prerelease versions in range matching -c --coerce Coerce a string into SemVer if possible (does not imply --loose) --rtl Coerce version strings right to left --ltr Coerce version strings left to right (default) Program exits successfully if any valid version satisfies all supplied ranges, and prints all satisfying versions. If no satisfying versions are found, then exits failure. Versions are printed in ascending order, so supplying multiple versions to the utility will just sort them. Versions A \"version\" is described by the v2.0.0 specification found at https://semver.org/. A leading \"=\" or \"v\" character is stripped off and ignored. Ranges A version range is a set of comparators which specify versions that satisfy the range. A comparator is composed of an operator and a version. The set of primitive operators is: < Less than <= Less than or equal to > Greater than >= Greater than or equal to = Equal. If no operator is specified, then equality is assumed, so this operator is optional, but MAY be included. For example, the comparator >=1.2.7 would match the versions 1.2.7, 1.2.8, 2.5.3, and 1.3.9, but not the versions 1.2.6 or 1.1.0. Comparators can be joined by whitespace to form a comparator set, which is satisfied by the intersection of all of the comparators it includes. A range is composed of one or more comparator sets, joined by ||. A version matches a range if and only if every comparator in at least one of the ||-separated comparator sets is satisfied by the version. For example, the range >=1.2.7 <1.3.0 would match the versions 1.2.7, 1.2.8, and 1.2.99, but not the versions 1.2.6, 1.3.0, or 1.1.0. The range 1.2.7 || >=1.2.9 <2.0.0 would match the versions 1.2.7, 1.2.9, and 1.4.6, but not the versions 1.2.8 or 2.0.0. Prerelease Tags If a version has a prerelease tag (for example, 1.2.3-alpha.3) then it will only be allowed to satisfy comparator sets if at least one comparator with the same [major, minor, patch] tuple also has a prerelease tag. For example, the range >1.2.3-alpha.3 would be allowed to match the version 1.2.3-alpha.7, but it would not be satisfied by 3.4.5-alpha.9, even though 3.4.5-alpha.9 is technically \"greater than\" 1.2.3-alpha.3 according to the SemVer sort rules. The version range only accepts prerelease tags on the 1.2.3 version. The version 3.4.5 would satisfy the range, because it does not have a prerelease flag, and 3.4.5 is greater than 1.2.3-alpha.7. The purpose for this behavior is twofold. First, prerelease versions frequently are updated very quickly, and contain many breaking changes that are (by the author's design) not yet fit for public consumption. Therefore, by default, they are excluded from range matching semantics. Second, a user who has opted into using a prerelease version has clearly indicated the intent to use that specific set of alpha/beta/rc versions. By including a prerelease tag in the range, the user is indicating that they are aware of the risk. However, it is still not appropriate to assume that they have opted into taking a similar risk on the next set of prerelease versions. Note that this behavior can be suppressed (treating all prerelease versions as if they were normal versions, for the purpose of range matching) by setting the includePrerelease flag on the options object to any functions that do range matching. Prerelease Identifiers The method .inc takes an additional identifier string argument that will append the value of the string as a prerelease identifier: semver.inc('1.2.3', 'prerelease', 'beta') // '1.2.4-beta.0' command-line example: $ semver 1.2.3 -i prerelease --preid beta 1.2.4-beta.0 Which then can be used to increment further: $ semver 1.2.4-beta.0 -i prerelease 1.2.4-beta.1 Advanced Range Syntax Advanced range syntax desugars to primitive comparators in deterministic ways. Advanced ranges may be combined in the same way as primitive comparators using white space or ||. Hyphen Ranges X.Y.Z - A.B.C Specifies an inclusive set. 1.2.3 - 2.3.4 := >=1.2.3 <=2.3.4 If a partial version is provided as the first version in the inclusive range, then the missing pieces are replaced with zeroes. 1.2 - 2.3.4 := >=1.2.0 <=2.3.4 If a partial version is provided as the second version in the inclusive range, then all versions that start with the supplied parts of the tuple are accepted, but nothing that would be greater than the provided tuple parts. 1.2.3 - 2.3 := >=1.2.3 <2.4.0 1.2.3 - 2 := >=1.2.3 <3.0.0 X-Ranges 1.2.x 1.X 1.2.* * Any of X, x, or * may be used to \"stand in\" for one of the numeric values in the [major, minor, patch] tuple. * := >=0.0.0 (Any version satisfies) 1.x := >=1.0.0 <2.0.0 (Matching major version) 1.2.x := >=1.2.0 <1.3.0 (Matching major and minor versions) A partial version range is treated as an X-Range, so the special character is in fact optional. \"\" (empty string) := * := >=0.0.0 1 := 1.x.x := >=1.0.0 <2.0.0 1.2 := 1.2.x := >=1.2.0 <1.3.0 Tilde Ranges ~1.2.3 ~1.2 ~1 Allows patch-level changes if a minor version is specified on the comparator. Allows minor-level changes if not. ~1.2.3 := >=1.2.3 <1.(2+1).0 := >=1.2.3 <1.3.0 ~1.2 := >=1.2.0 <1.(2+1).0 := >=1.2.0 <1.3.0 (Same as 1.2.x) ~1 := >=1.0.0 <(1+1).0.0 := >=1.0.0 <2.0.0 (Same as 1.x) ~0.2.3 := >=0.2.3 <0.(2+1).0 := >=0.2.3 <0.3.0 ~0.2 := >=0.2.0 <0.(2+1).0 := >=0.2.0 <0.3.0 (Same as 0.2.x) ~0 := >=0.0.0 <(0+1).0.0 := >=0.0.0 <1.0.0 (Same as 0.x) ~1.2.3-beta.2 := >=1.2.3-beta.2 <1.3.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. Caret Ranges ^1.2.3 ^0.2.5 ^0.0.4 Allows changes that do not modify the left-most non-zero element in the [major, minor, patch] tuple. In other words, this allows patch and minor updates for versions 1.0.0 and above, patch updates for versions 0.X >=0.1.0, and no updates for versions 0.0.X. Many authors treat a 0.x version as if the x were the major \"breaking-change\" indicator. Caret ranges are ideal when an author may make breaking changes between 0.2.4 and 0.3.0 releases, which is a common practice. However, it presumes that there will not be breaking changes between 0.2.4 and 0.2.5. It allows for changes that are presumed to be additive (but non-breaking), according to commonly observed practices. ^1.2.3 := >=1.2.3 <2.0.0 ^0.2.3 := >=0.2.3 <0.3.0 ^0.0.3 := >=0.0.3 <0.0.4 ^1.2.3-beta.2 := >=1.2.3-beta.2 <2.0.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. ^0.0.3-beta := >=0.0.3-beta <0.0.4 Note that prereleases in the 0.0.3 version only will be allowed, if they are greater than or equal to beta. So, 0.0.3-pr.2 would be allowed. When parsing caret ranges, a missing patch value desugars to the number 0, but will allow flexibility within that value, even if the major and minor versions are both 0. ^1.2.x := >=1.2.0 <2.0.0 ^0.0.x := >=0.0.0 <0.1.0 ^0.0 := >=0.0.0 <0.1.0 A missing minor and patch values will desugar to zero, but also allow flexibility within those values, even if the major version is zero. ^1.x := >=1.0.0 <2.0.0 ^0.x := >=0.0.0 <1.0.0 Range Grammar Putting all this together, here is a Backus-Naur grammar for ranges, for the benefit of parser authors: range-set ::= range ( logical-or range ) * logical-or ::= ( ' ' ) * '||' ( ' ' ) * range ::= hyphen | simple ( ' ' simple ) * | '' hyphen ::= partial ' - ' partial simple ::= primitive | partial | tilde | caret primitive ::= ( '<' | '>' | '>=' | '<=' | '=' ) partial partial ::= xr ( '.' xr ( '.' xr qualifier ? )? )? xr ::= 'x' | 'X' | '*' | nr nr ::= '0' | ['1'-'9'] ( ['0'-'9'] ) * tilde ::= '~' partial caret ::= '^' partial qualifier ::= ( '-' pre )? ( '+' build )? pre ::= parts build ::= parts parts ::= part ( '.' part ) * part ::= nr | [-0-9A-Za-z]+ Functions All methods and classes take a final options object argument. All options in this object are false by default. The options supported are: loose Be more forgiving about not-quite-valid semver strings. (Any resulting output will always be 100% strict compliant, of course.) For backwards compatibility reasons, if the options argument is a boolean value instead of an object, it is interpreted to be the loose param. includePrerelease Set to suppress the default behavior of excluding prerelease tagged versions from ranges unless they are explicitly opted into. Strict-mode Comparators and Ranges will be strict about the SemVer strings that they parse. valid(v): Return the parsed version, or null if it's not valid. inc(v, release): Return the version incremented by the release type (major, premajor, minor, preminor, patch, prepatch, or prerelease), or null if it's not valid premajor in one call will bump the version up to the next major version and down to a prerelease of that major version. preminor, and prepatch work the same way. If called from a non-prerelease version, the prerelease will work the same as prepatch. It increments the patch version, then makes a prerelease. If the input version is already a prerelease it simply increments it. prerelease(v): Returns an array of prerelease components, or null if none exist. Example: prerelease('1.2.3-alpha.1') -> ['alpha', 1] major(v): Return the major version number. minor(v): Return the minor version number. patch(v): Return the patch version number. intersects(r1, r2, loose): Return true if the two supplied ranges or comparators intersect. parse(v): Attempt to parse a string as a semantic version, returning either a SemVer object or null. Comparison gt(v1, v2): v1 > v2 gte(v1, v2): v1 >= v2 lt(v1, v2): v1 < v2 lte(v1, v2): v1 <= v2 eq(v1, v2): v1 == v2 This is true if they're logically equivalent, even if they're not the exact same string. You already know how to compare strings. neq(v1, v2): v1 != v2 The opposite of eq. cmp(v1, comparator, v2): Pass in a comparison string, and it'll call the corresponding function above. \"===\" and \"!==\" do simple string comparison, but are included for completeness. Throws if an invalid comparison string is provided. compare(v1, v2): Return 0 if v1 == v2, or 1 if v1 is greater, or -1 if v2 is greater. Sorts in ascending order if passed to Array.sort(). rcompare(v1, v2): The reverse of compare. Sorts an array of versions in descending order when passed to Array.sort(). compareBuild(v1, v2): The same as compare but considers build when two versions are equal. Sorts in ascending order if passed to Array.sort(). v2 is greater. Sorts in ascending order if passed to Array.sort(). diff(v1, v2): Returns difference between two versions by the release type (major, premajor, minor, preminor, patch, prepatch, or prerelease), or null if the versions are the same. Comparators intersects(comparator): Return true if the comparators intersect Ranges validRange(range): Return the valid range or null if it's not valid satisfies(version, range): Return true if the version satisfies the range. maxSatisfying(versions, range): Return the highest version in the list that satisfies the range, or null if none of them do. minSatisfying(versions, range): Return the lowest version in the list that satisfies the range, or null if none of them do. minVersion(range): Return the lowest version that can possibly match the given range. gtr(version, range): Return true if version is greater than all the versions possible in the range. ltr(version, range): Return true if version is less than all the versions possible in the range. outside(version, range, hilo): Return true if the version is outside the bounds of the range in either the high or low direction. The hilo argument must be either the string '>' or '<'. (This is the function called by gtr and ltr.) intersects(range): Return true if any of the ranges comparators intersect Note that, since ranges may be non-contiguous, a version might not be greater than a range, less than a range, or satisfy a range! For example, the range 1.2 <1.2.9 || >2.0.0 would have a hole from 1.2.9 until 2.0.0, so the version 1.2.10 would not be greater than the range (because 2.0.1 satisfies, which is higher), nor less than the range (since 1.2.8 satisfies, which is lower), and it also does not satisfy the range. If you want to know if a version satisfies or does not satisfy a range, use the satisfies(version, range) function. Coercion coerce(version, options): Coerces a string to semver if possible This aims to provide a very forgiving translation of a non-semver string to semver. It looks for the first digit in a string, and consumes all remaining characters which satisfy at least a partial semver (e.g., 1, 1.2, 1.2.3) up to the max permitted length (256 characters). Longer versions are simply truncated (4.6.3.9.2-alpha2 becomes 4.6.3). All surrounding text is simply ignored (v3.4 replaces v3.3.1 becomes 3.4.0). Only text which lacks digits will fail coercion (version one is not valid). The maximum length for any semver component considered for coercion is 16 characters; longer components will be ignored (10000000000000000.4.7.4 becomes 4.7.4). The maximum value for any semver component is Integer.MAX_SAFE_INTEGER || (2**53 - 1); higher value components are invalid (9999999999999999.4.7.4 is likely invalid). If the options.rtl flag is set, then coerce will return the right-most coercible tuple that does not share an ending index with a longer coercible tuple. For example, 1.2.3.4 will return 2.3.4 in rtl mode, not 4.0.0. 1.2.3/4 will return 4.0.0, because the 4 is not a part of any other overlapping SemVer tuple. Clean clean(version): Clean a string to be a valid semver if possible This will return a cleaned and trimmed semver version. If the provided version is not valid a null will be returned. This does not work for ranges. ex. s.clean(' = v 2.1.5foo'): null s.clean(' = v 2.1.5foo', { loose: true }): '2.1.5-foo' s.clean(' = v 2.1.5-foo'): null s.clean(' = v 2.1.5-foo', { loose: true }): '2.1.5-foo' s.clean('=v2.1.5'): '2.1.5' s.clean(' =v2.1.5'): 2.1.5 s.clean(' 2.1.5 '): '2.1.5' s.clean('~1.0.0'): null"
  },
  "src/frontend/app-client/node_modules/@babel/helper-compilation-targets/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-compilation-targets/README.html",
    "title": "",
    "summary": "@babel/helper-compilation-targets Helper functions on Babel compilation targets See our website @babel/helper-compilation-targets for more information. Install Using npm: npm install --save @babel/helper-compilation-targets or using yarn: yarn add @babel/helper-compilation-targets"
  },
  "src/frontend/app-client/node_modules/@babel/helper-create-class-features-plugin/node_modules/semver/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-create-class-features-plugin/node_modules/semver/README.html",
    "title": "semver(1) -- The semantic versioner for npm",
    "summary": "semver(1) -- The semantic versioner for npm Install npm install semver Usage As a node module: const semver = require('semver') semver.valid('1.2.3') // '1.2.3' semver.valid('a.b.c') // null semver.clean(' =v1.2.3 ') // '1.2.3' semver.satisfies('1.2.3', '1.x || >=2.5.0 || 5.0.0 - 7.2.3') // true semver.gt('1.2.3', '9.8.7') // false semver.lt('1.2.3', '9.8.7') // true semver.minVersion('>=1.0.0') // '1.0.0' semver.valid(semver.coerce('v2')) // '2.0.0' semver.valid(semver.coerce('42.6.7.9.3-alpha')) // '42.6.7' As a command-line utility: $ semver -h A JavaScript implementation of the https://semver.org/ specification Copyright Isaac Z. Schlueter Usage: semver [options] <version> [<version> [...]] Prints valid versions sorted by SemVer precedence Options: -r --range <range> Print versions that match the specified range. -i --increment [<level>] Increment a version by the specified level. Level can be one of: major, minor, patch, premajor, preminor, prepatch, or prerelease. Default level is 'patch'. Only one version may be specified. --preid <identifier> Identifier to be used to prefix premajor, preminor, prepatch or prerelease version increments. -l --loose Interpret versions and ranges loosely -p --include-prerelease Always include prerelease versions in range matching -c --coerce Coerce a string into SemVer if possible (does not imply --loose) --rtl Coerce version strings right to left --ltr Coerce version strings left to right (default) Program exits successfully if any valid version satisfies all supplied ranges, and prints all satisfying versions. If no satisfying versions are found, then exits failure. Versions are printed in ascending order, so supplying multiple versions to the utility will just sort them. Versions A \"version\" is described by the v2.0.0 specification found at https://semver.org/. A leading \"=\" or \"v\" character is stripped off and ignored. Ranges A version range is a set of comparators which specify versions that satisfy the range. A comparator is composed of an operator and a version. The set of primitive operators is: < Less than <= Less than or equal to > Greater than >= Greater than or equal to = Equal. If no operator is specified, then equality is assumed, so this operator is optional, but MAY be included. For example, the comparator >=1.2.7 would match the versions 1.2.7, 1.2.8, 2.5.3, and 1.3.9, but not the versions 1.2.6 or 1.1.0. Comparators can be joined by whitespace to form a comparator set, which is satisfied by the intersection of all of the comparators it includes. A range is composed of one or more comparator sets, joined by ||. A version matches a range if and only if every comparator in at least one of the ||-separated comparator sets is satisfied by the version. For example, the range >=1.2.7 <1.3.0 would match the versions 1.2.7, 1.2.8, and 1.2.99, but not the versions 1.2.6, 1.3.0, or 1.1.0. The range 1.2.7 || >=1.2.9 <2.0.0 would match the versions 1.2.7, 1.2.9, and 1.4.6, but not the versions 1.2.8 or 2.0.0. Prerelease Tags If a version has a prerelease tag (for example, 1.2.3-alpha.3) then it will only be allowed to satisfy comparator sets if at least one comparator with the same [major, minor, patch] tuple also has a prerelease tag. For example, the range >1.2.3-alpha.3 would be allowed to match the version 1.2.3-alpha.7, but it would not be satisfied by 3.4.5-alpha.9, even though 3.4.5-alpha.9 is technically \"greater than\" 1.2.3-alpha.3 according to the SemVer sort rules. The version range only accepts prerelease tags on the 1.2.3 version. The version 3.4.5 would satisfy the range, because it does not have a prerelease flag, and 3.4.5 is greater than 1.2.3-alpha.7. The purpose for this behavior is twofold. First, prerelease versions frequently are updated very quickly, and contain many breaking changes that are (by the author's design) not yet fit for public consumption. Therefore, by default, they are excluded from range matching semantics. Second, a user who has opted into using a prerelease version has clearly indicated the intent to use that specific set of alpha/beta/rc versions. By including a prerelease tag in the range, the user is indicating that they are aware of the risk. However, it is still not appropriate to assume that they have opted into taking a similar risk on the next set of prerelease versions. Note that this behavior can be suppressed (treating all prerelease versions as if they were normal versions, for the purpose of range matching) by setting the includePrerelease flag on the options object to any functions that do range matching. Prerelease Identifiers The method .inc takes an additional identifier string argument that will append the value of the string as a prerelease identifier: semver.inc('1.2.3', 'prerelease', 'beta') // '1.2.4-beta.0' command-line example: $ semver 1.2.3 -i prerelease --preid beta 1.2.4-beta.0 Which then can be used to increment further: $ semver 1.2.4-beta.0 -i prerelease 1.2.4-beta.1 Advanced Range Syntax Advanced range syntax desugars to primitive comparators in deterministic ways. Advanced ranges may be combined in the same way as primitive comparators using white space or ||. Hyphen Ranges X.Y.Z - A.B.C Specifies an inclusive set. 1.2.3 - 2.3.4 := >=1.2.3 <=2.3.4 If a partial version is provided as the first version in the inclusive range, then the missing pieces are replaced with zeroes. 1.2 - 2.3.4 := >=1.2.0 <=2.3.4 If a partial version is provided as the second version in the inclusive range, then all versions that start with the supplied parts of the tuple are accepted, but nothing that would be greater than the provided tuple parts. 1.2.3 - 2.3 := >=1.2.3 <2.4.0 1.2.3 - 2 := >=1.2.3 <3.0.0 X-Ranges 1.2.x 1.X 1.2.* * Any of X, x, or * may be used to \"stand in\" for one of the numeric values in the [major, minor, patch] tuple. * := >=0.0.0 (Any version satisfies) 1.x := >=1.0.0 <2.0.0 (Matching major version) 1.2.x := >=1.2.0 <1.3.0 (Matching major and minor versions) A partial version range is treated as an X-Range, so the special character is in fact optional. \"\" (empty string) := * := >=0.0.0 1 := 1.x.x := >=1.0.0 <2.0.0 1.2 := 1.2.x := >=1.2.0 <1.3.0 Tilde Ranges ~1.2.3 ~1.2 ~1 Allows patch-level changes if a minor version is specified on the comparator. Allows minor-level changes if not. ~1.2.3 := >=1.2.3 <1.(2+1).0 := >=1.2.3 <1.3.0 ~1.2 := >=1.2.0 <1.(2+1).0 := >=1.2.0 <1.3.0 (Same as 1.2.x) ~1 := >=1.0.0 <(1+1).0.0 := >=1.0.0 <2.0.0 (Same as 1.x) ~0.2.3 := >=0.2.3 <0.(2+1).0 := >=0.2.3 <0.3.0 ~0.2 := >=0.2.0 <0.(2+1).0 := >=0.2.0 <0.3.0 (Same as 0.2.x) ~0 := >=0.0.0 <(0+1).0.0 := >=0.0.0 <1.0.0 (Same as 0.x) ~1.2.3-beta.2 := >=1.2.3-beta.2 <1.3.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. Caret Ranges ^1.2.3 ^0.2.5 ^0.0.4 Allows changes that do not modify the left-most non-zero element in the [major, minor, patch] tuple. In other words, this allows patch and minor updates for versions 1.0.0 and above, patch updates for versions 0.X >=0.1.0, and no updates for versions 0.0.X. Many authors treat a 0.x version as if the x were the major \"breaking-change\" indicator. Caret ranges are ideal when an author may make breaking changes between 0.2.4 and 0.3.0 releases, which is a common practice. However, it presumes that there will not be breaking changes between 0.2.4 and 0.2.5. It allows for changes that are presumed to be additive (but non-breaking), according to commonly observed practices. ^1.2.3 := >=1.2.3 <2.0.0 ^0.2.3 := >=0.2.3 <0.3.0 ^0.0.3 := >=0.0.3 <0.0.4 ^1.2.3-beta.2 := >=1.2.3-beta.2 <2.0.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. ^0.0.3-beta := >=0.0.3-beta <0.0.4 Note that prereleases in the 0.0.3 version only will be allowed, if they are greater than or equal to beta. So, 0.0.3-pr.2 would be allowed. When parsing caret ranges, a missing patch value desugars to the number 0, but will allow flexibility within that value, even if the major and minor versions are both 0. ^1.2.x := >=1.2.0 <2.0.0 ^0.0.x := >=0.0.0 <0.1.0 ^0.0 := >=0.0.0 <0.1.0 A missing minor and patch values will desugar to zero, but also allow flexibility within those values, even if the major version is zero. ^1.x := >=1.0.0 <2.0.0 ^0.x := >=0.0.0 <1.0.0 Range Grammar Putting all this together, here is a Backus-Naur grammar for ranges, for the benefit of parser authors: range-set ::= range ( logical-or range ) * logical-or ::= ( ' ' ) * '||' ( ' ' ) * range ::= hyphen | simple ( ' ' simple ) * | '' hyphen ::= partial ' - ' partial simple ::= primitive | partial | tilde | caret primitive ::= ( '<' | '>' | '>=' | '<=' | '=' ) partial partial ::= xr ( '.' xr ( '.' xr qualifier ? )? )? xr ::= 'x' | 'X' | '*' | nr nr ::= '0' | ['1'-'9'] ( ['0'-'9'] ) * tilde ::= '~' partial caret ::= '^' partial qualifier ::= ( '-' pre )? ( '+' build )? pre ::= parts build ::= parts parts ::= part ( '.' part ) * part ::= nr | [-0-9A-Za-z]+ Functions All methods and classes take a final options object argument. All options in this object are false by default. The options supported are: loose Be more forgiving about not-quite-valid semver strings. (Any resulting output will always be 100% strict compliant, of course.) For backwards compatibility reasons, if the options argument is a boolean value instead of an object, it is interpreted to be the loose param. includePrerelease Set to suppress the default behavior of excluding prerelease tagged versions from ranges unless they are explicitly opted into. Strict-mode Comparators and Ranges will be strict about the SemVer strings that they parse. valid(v): Return the parsed version, or null if it's not valid. inc(v, release): Return the version incremented by the release type (major, premajor, minor, preminor, patch, prepatch, or prerelease), or null if it's not valid premajor in one call will bump the version up to the next major version and down to a prerelease of that major version. preminor, and prepatch work the same way. If called from a non-prerelease version, the prerelease will work the same as prepatch. It increments the patch version, then makes a prerelease. If the input version is already a prerelease it simply increments it. prerelease(v): Returns an array of prerelease components, or null if none exist. Example: prerelease('1.2.3-alpha.1') -> ['alpha', 1] major(v): Return the major version number. minor(v): Return the minor version number. patch(v): Return the patch version number. intersects(r1, r2, loose): Return true if the two supplied ranges or comparators intersect. parse(v): Attempt to parse a string as a semantic version, returning either a SemVer object or null. Comparison gt(v1, v2): v1 > v2 gte(v1, v2): v1 >= v2 lt(v1, v2): v1 < v2 lte(v1, v2): v1 <= v2 eq(v1, v2): v1 == v2 This is true if they're logically equivalent, even if they're not the exact same string. You already know how to compare strings. neq(v1, v2): v1 != v2 The opposite of eq. cmp(v1, comparator, v2): Pass in a comparison string, and it'll call the corresponding function above. \"===\" and \"!==\" do simple string comparison, but are included for completeness. Throws if an invalid comparison string is provided. compare(v1, v2): Return 0 if v1 == v2, or 1 if v1 is greater, or -1 if v2 is greater. Sorts in ascending order if passed to Array.sort(). rcompare(v1, v2): The reverse of compare. Sorts an array of versions in descending order when passed to Array.sort(). compareBuild(v1, v2): The same as compare but considers build when two versions are equal. Sorts in ascending order if passed to Array.sort(). v2 is greater. Sorts in ascending order if passed to Array.sort(). diff(v1, v2): Returns difference between two versions by the release type (major, premajor, minor, preminor, patch, prepatch, or prerelease), or null if the versions are the same. Comparators intersects(comparator): Return true if the comparators intersect Ranges validRange(range): Return the valid range or null if it's not valid satisfies(version, range): Return true if the version satisfies the range. maxSatisfying(versions, range): Return the highest version in the list that satisfies the range, or null if none of them do. minSatisfying(versions, range): Return the lowest version in the list that satisfies the range, or null if none of them do. minVersion(range): Return the lowest version that can possibly match the given range. gtr(version, range): Return true if version is greater than all the versions possible in the range. ltr(version, range): Return true if version is less than all the versions possible in the range. outside(version, range, hilo): Return true if the version is outside the bounds of the range in either the high or low direction. The hilo argument must be either the string '>' or '<'. (This is the function called by gtr and ltr.) intersects(range): Return true if any of the ranges comparators intersect Note that, since ranges may be non-contiguous, a version might not be greater than a range, less than a range, or satisfy a range! For example, the range 1.2 <1.2.9 || >2.0.0 would have a hole from 1.2.9 until 2.0.0, so the version 1.2.10 would not be greater than the range (because 2.0.1 satisfies, which is higher), nor less than the range (since 1.2.8 satisfies, which is lower), and it also does not satisfy the range. If you want to know if a version satisfies or does not satisfy a range, use the satisfies(version, range) function. Coercion coerce(version, options): Coerces a string to semver if possible This aims to provide a very forgiving translation of a non-semver string to semver. It looks for the first digit in a string, and consumes all remaining characters which satisfy at least a partial semver (e.g., 1, 1.2, 1.2.3) up to the max permitted length (256 characters). Longer versions are simply truncated (4.6.3.9.2-alpha2 becomes 4.6.3). All surrounding text is simply ignored (v3.4 replaces v3.3.1 becomes 3.4.0). Only text which lacks digits will fail coercion (version one is not valid). The maximum length for any semver component considered for coercion is 16 characters; longer components will be ignored (10000000000000000.4.7.4 becomes 4.7.4). The maximum value for any semver component is Integer.MAX_SAFE_INTEGER || (2**53 - 1); higher value components are invalid (9999999999999999.4.7.4 is likely invalid). If the options.rtl flag is set, then coerce will return the right-most coercible tuple that does not share an ending index with a longer coercible tuple. For example, 1.2.3.4 will return 2.3.4 in rtl mode, not 4.0.0. 1.2.3/4 will return 4.0.0, because the 4 is not a part of any other overlapping SemVer tuple. Clean clean(version): Clean a string to be a valid semver if possible This will return a cleaned and trimmed semver version. If the provided version is not valid a null will be returned. This does not work for ranges. ex. s.clean(' = v 2.1.5foo'): null s.clean(' = v 2.1.5foo', { loose: true }): '2.1.5-foo' s.clean(' = v 2.1.5-foo'): null s.clean(' = v 2.1.5-foo', { loose: true }): '2.1.5-foo' s.clean('=v2.1.5'): '2.1.5' s.clean(' =v2.1.5'): 2.1.5 s.clean(' 2.1.5 '): '2.1.5' s.clean('~1.0.0'): null"
  },
  "src/frontend/app-client/node_modules/@babel/helper-create-class-features-plugin/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-create-class-features-plugin/README.html",
    "title": "",
    "summary": "@babel/helper-create-class-features-plugin Compile class public and private fields, private methods and decorators to ES6 See our website @babel/helper-create-class-features-plugin for more information. Install Using npm: npm install --save @babel/helper-create-class-features-plugin or using yarn: yarn add @babel/helper-create-class-features-plugin"
  },
  "src/frontend/app-client/node_modules/@babel/helper-member-expression-to-functions/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-member-expression-to-functions/README.html",
    "title": "",
    "summary": "@babel/helper-member-expression-to-functions Helper function to replace certain member expressions with function calls See our website @babel/helper-member-expression-to-functions for more information. Install Using npm: npm install --save @babel/helper-member-expression-to-functions or using yarn: yarn add @babel/helper-member-expression-to-functions"
  },
  "src/frontend/app-client/node_modules/@babel/helper-module-imports/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-module-imports/README.html",
    "title": "",
    "summary": "@babel/helper-module-imports Babel helper functions for inserting module loads See our website @babel/helper-module-imports for more information. Install Using npm: npm install --save @babel/helper-module-imports or using yarn: yarn add @babel/helper-module-imports"
  },
  "src/frontend/app-client/node_modules/@babel/helper-module-transforms/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-module-transforms/README.html",
    "title": "",
    "summary": "@babel/helper-module-transforms Babel helper functions for implementing ES6 module transformations See our website @babel/helper-module-transforms for more information. Install Using npm: npm install --save @babel/helper-module-transforms or using yarn: yarn add @babel/helper-module-transforms"
  },
  "src/frontend/app-client/node_modules/@babel/helper-optimise-call-expression/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-optimise-call-expression/README.html",
    "title": "",
    "summary": "@babel/helper-optimise-call-expression Helper function to optimise call expression See our website @babel/helper-optimise-call-expression for more information. Install Using npm: npm install --save @babel/helper-optimise-call-expression or using yarn: yarn add @babel/helper-optimise-call-expression"
  },
  "src/frontend/app-client/node_modules/@babel/helper-plugin-utils/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-plugin-utils/README.html",
    "title": "",
    "summary": "@babel/helper-plugin-utils General utilities for plugins to use See our website @babel/helper-plugin-utils for more information. Install Using npm: npm install --save @babel/helper-plugin-utils or using yarn: yarn add @babel/helper-plugin-utils"
  },
  "src/frontend/app-client/node_modules/@babel/helper-replace-supers/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-replace-supers/README.html",
    "title": "",
    "summary": "@babel/helper-replace-supers Helper function to replace supers See our website @babel/helper-replace-supers for more information. Install Using npm: npm install --save @babel/helper-replace-supers or using yarn: yarn add @babel/helper-replace-supers"
  },
  "src/frontend/app-client/node_modules/@babel/helper-skip-transparent-expression-wrappers/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-skip-transparent-expression-wrappers/README.html",
    "title": "",
    "summary": "@babel/helper-skip-transparent-expression-wrappers Helper which skips types and parentheses See our website @babel/helper-skip-transparent-expression-wrappers for more information. Install Using npm: npm install --save @babel/helper-skip-transparent-expression-wrappers or using yarn: yarn add @babel/helper-skip-transparent-expression-wrappers"
  },
  "src/frontend/app-client/node_modules/@babel/helper-string-parser/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-string-parser/README.html",
    "title": "",
    "summary": "@babel/helper-string-parser A utility package to parse strings See our website @babel/helper-string-parser for more information. Install Using npm: npm install --save @babel/helper-string-parser or using yarn: yarn add @babel/helper-string-parser"
  },
  "src/frontend/app-client/node_modules/@babel/helper-validator-identifier/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-validator-identifier/README.html",
    "title": "",
    "summary": "@babel/helper-validator-identifier Validate identifier/keywords name See our website @babel/helper-validator-identifier for more information. Install Using npm: npm install --save @babel/helper-validator-identifier or using yarn: yarn add @babel/helper-validator-identifier"
  },
  "src/frontend/app-client/node_modules/@babel/helper-validator-option/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helper-validator-option/README.html",
    "title": "",
    "summary": "@babel/helper-validator-option Validate plugin/preset options See our website @babel/helper-validator-option for more information. Install Using npm: npm install --save @babel/helper-validator-option or using yarn: yarn add @babel/helper-validator-option"
  },
  "src/frontend/app-client/node_modules/@babel/helpers/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/helpers/README.html",
    "title": "",
    "summary": "@babel/helpers Collection of helper functions used by Babel transforms. See our website @babel/helpers for more information. Install Using npm: npm install --save-dev @babel/helpers or using yarn: yarn add @babel/helpers --dev"
  },
  "src/frontend/app-client/node_modules/@babel/parser/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/@babel/parser/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog Tags: \uD83D\uDCA5 [Breaking Change] \uD83D\uDC53 [Spec Compliance] \uD83D\uDE80 [New Feature] \uD83D\uDC1B [Bug Fix] \uD83D\uDCDD [Documentation] \uD83C\uDFE0 [Internal] \uD83D\uDC85 [Polish] Semver Policy: https://github.com/babel/babel/tree/main/packages/babel-parser#semver Note: Gaps between patch versions are faulty, broken or test releases. See the Babel Changelog for the pre-6.8.0 version Changelog. 6.17.1 (2017-05-10) \uD83D\uDC1B Bug Fix Fix typo in flow spread operator error (Brian Ng) Fixed invalid number literal parsing (#473) (Alex Kuzmenko) Fix number parser (#433) (Alex Kuzmenko) Ensure non pattern shorthand props are checked for reserved words (#479) (Brian Ng) Remove jsx context when parsing arrow functions (#475) (Brian Ng) Allow super in class properties (#499) (Brian Ng) Allow flow class field to be named constructor (#510) (Brian Ng) 6.17.0 (2017-04-20) \uD83D\uDC1B Bug Fix Cherry-pick #418 to 6.x (#476) (Sebastian McKenzie) Add support for invalid escapes in tagged templates (#274) (Kevin Gibbons) Throw error if new.target is used outside of a function (#402) (Brian Ng) Fix parsing of class properties (#351) (Kevin Gibbons) Fix parsing yield with dynamicImport (#383) (Brian Ng) Ensure consistent start args for parseParenItem (#386) (Brian Ng) 7.0.0-beta.8 (2017-04-04) New Feature Add support for flow type spread (#418) (Conrad Buck) Allow statics in flow interfaces (#427) (Brian Ng) Bug Fix Fix predicate attachment to match flow parser (#428) (Brian Ng) Add extra.raw back to JSXText and JSXAttribute (#344) (Alex Rattray) Fix rest parameters with array and objects (#424) (Brian Ng) Fix number parser (#433) (Alex Kuzmenko) Docs Fix CONTRIBUTING.md [skip ci] (#432) (Alex Kuzmenko) Internal Use babel-register script when running babel smoke tests (#442) (Brian Ng) 7.0.0-beta.7 (2017-03-22) Spec Compliance Remove babylon plugin for template revision since it's stage-4 (#426) (Henry Zhu) Bug Fix Fix push-pop logic in flow (#405) (Daniel Tschinder) 7.0.0-beta.6 (2017-03-21) New Feature Add support for invalid escapes in tagged templates (#274) (Kevin Gibbons) Polish Improves error message when super is called outside of constructor (#408) (Arshabh Kumar Agarwal) Docs [7.0] Moved value field in spec from ObjectMember to ObjectProperty as ObjectMethod's don't have it (#415) [skip ci] (James Browning) 7.0.0-beta.5 (2017-03-21) Bug Fix Throw error if new.target is used outside of a function (#402) (Brian Ng) Fix parsing of class properties (#351) (Kevin Gibbons) Other Test runner: Detect extra property in 'actual' but not in 'expected'. (#407) (Andy) Optimize travis builds (#419) (Daniel Tschinder) Update codecov to 2.0 (#412) (Daniel Tschinder) Fix spec for ClassMethod: It doesn't have a function, it is a function. (#406) [skip ci] (Andy) Changed Non-existent RestPattern to RestElement which is what is actually parsed (#409) [skip ci] (James Browning) Upgrade flow to 0.41 (Daniel Tschinder) Fix watch command (#403) (Brian Ng) Update yarn lock (Daniel Tschinder) Fix watch command (#403) (Brian Ng) chore(package): update flow-bin to version 0.41.0 (#395) (greenkeeper[bot]) Add estree test for correct order of directives (Daniel Tschinder) Add DoExpression to spec (#364) (Alex Kuzmenko) Mention cloning of repository in CONTRIBUTING.md (#391) [skip ci] (Sumedh Nimkarde) Explain how to run only one test (#389) [skip ci] (Aaron Ang) 7.0.0-beta.4 (2017-03-01) Don't consume async when checking for async func decl (#377) (Brian Ng) add ranges option [skip ci] (Henry Zhu) Don't parse class properties without initializers when classProperties is disabled and Flow is enabled (#300) (Andrew Levine) 7.0.0-beta.3 (2017-02-28) [7.0] Change RestProperty/SpreadProperty to RestElement/SpreadElement (#384) Merge changes from 6.x 7.0.0-beta.2 (2017-02-20) estree: correctly change literals in all cases (#368) (Daniel Tschinder) 7.0.0-beta.1 (2017-02-20) Fix negative number literal typeannotations (#366) (Daniel Tschinder) Update contributing with more test info [skip ci] (#355) (Brian Ng) 7.0.0-beta.0 (2017-02-15) Reintroduce Variance node (#333) (Daniel Tschinder) Rename NumericLiteralTypeAnnotation to NumberLiteralTypeAnnotation (#332) (Charles Pick) [7.0] Remove ForAwaitStatement, add await flag to ForOfStatement (#349) (Brandon Dail) chore(package): update ava to version 0.18.0 (#345) (greenkeeper[bot]) chore(package): update babel-plugin-istanbul to version 4.0.0 (#350) (greenkeeper[bot]) Change location of ObjectTypeIndexer to match flow (#228) (Daniel Tschinder) Rename flow AST Type ExistentialTypeParam to ExistsTypeAnnotation (#322) (Toru Kobayashi) Revert \"Temporary rollback for erroring on trailing comma with spread (#154)\" (#290) (Daniel Tschinder) Remove classConstructorCall plugin (#291) (Brian Ng) Update yarn.lock (Daniel Tschinder) Update cross-env to 3.x (Daniel Tschinder) [7.0] Remove node 0.10, 0.12 and 5 from Travis (#284) (Sergey Rubanov) Remove String.fromCodePoint shim (#279) (Mathias Bynens) 6.16.1 (2017-02-23) \uD83D\uDC1B Regression Revert \"Fix export default async function to be FunctionDeclaration\" (#375) Need to modify Babel for this AST node change, so moving to 7.0. Revert \"Don't parse class properties without initializers when classProperties plugin is disabled, and Flow is enabled\" (#376) react-native broke with this so we reverted. 6.16.0 (2017-02-23) \uD83D\uDE80 New Feature ESTree compatibility as plugin (#277) (Daniel Tschinder) We finally introduce a new compatibility layer for ESTree. To put babylon into ESTree-compatible mode the new plugin estree can be enabled. In this mode the parser will output an AST that is compliant to the specs of ESTree We highly recommend everyone who uses babylon outside of babel to use this plugin. This will make it much easier for users to switch between different ESTree-compatible parsers. We so far tested several projects with different parsers and exchanged their parser to babylon and in nearly all cases it worked out of the box. Some other estree-compatible parsers include acorn, esprima, espree, flow-parser, etc. To enable estree mode simply add the plugin in the config: { \"plugins\": [ \"estree\" ] } If you want to migrate your project from non-ESTree mode to ESTree, have a look at our Readme, where all deviations are mentioned. Add a parseExpression public method (#213) (jeromew) Babylon exports a new function to parse a single expression import { parseExpression } from 'babylon'; const ast = parseExpression('x || y && z', options); The returned AST will only consist of the expression. The options are the same as for parse() Add startLine option (#346) (Raphael Mu) A new option was added to babylon allowing to change the initial linenumber for the first line which is usually 1. Changing this for example to 100 will make line 1 of the input source to be marked as line 100, line 2 as 101, line 3 as 102, ... Function predicate declaration (#103) (Panagiotis Vekris) Added support for function predicates which flow introduced in version 0.33.0 declare function is_number(x: mixed): boolean %checks(typeof x === \"number\"); Allow imports in declare module (#315) (Daniel Tschinder) Added support for imports within module declarations which flow introduced in version 0.37.0 declare module \"C\" { import type { DT } from \"D\"; declare export type CT = { D: DT }; } \uD83D\uDC53 Spec Compliance Forbid semicolons after decorators in classes (#352) (Kevin Gibbons) This example now correctly throws an error when there is a semicolon after the decorator: class A { @a; foo(){} } Keywords are not allowed as local specifier (#307) (Daniel Tschinder) Using keywords in imports is not allowed anymore: import { default } from \"foo\"; import { a as debugger } from \"foo\"; Do not allow overwritting of primitive types (#314) (Daniel Tschinder) In flow it is now forbidden to overwrite the primitive types \"any\", \"mixed\", \"empty\", \"bool\", \"boolean\", \"number\", \"string\", \"void\" and \"null\" with your own type declaration. Disallow import type { type a } from … (#305) (Daniel Tschinder) The following code now correctly throws an error import type { type a } from \"foo\"; Don't parse class properties without initializers when classProperties is disabled and Flow is enabled (#300) (Andrew Levine) Ensure that you enable the classProperties plugin in order to enable correct parsing of class properties. Prior to this version it was possible to parse them by enabling the flow plugin but this was not intended the behaviour. If you enable the flow plugin you can only define the type of the class properties, but not initialize them. Fix export default async function to be FunctionDeclaration (#324) (Daniel Tschinder) Parsing the following code now returns a FunctionDeclaration AST node instead of FunctionExpression. export default async function bar() {}; \uD83D\uDC85 Polish Improve error message on attempt to destructure named import (#288) (Brian Ng) \uD83D\uDC1B Bug Fix Fix negative number literal typeannotations (#366) (Daniel Tschinder) Ensure takeDecorators is called on exported class (#358) (Brian Ng) ESTree: correctly change literals in all cases (#368) (Daniel Tschinder) Correctly convert RestProperty to Assignable (#339) (Daniel Tschinder) Fix #321 by allowing question marks in type params (#338) (Daniel Tschinder) Fix #336 by correctly setting arrow-param (#337) (Daniel Tschinder) Fix parse error when destructuring set with default value (#317) (Brian Ng) Fix ObjectTypeCallProperty static (#298) (Dan Harper) \uD83C\uDFE0 Internal Fix generator-method-with-computed-name spec (#360) (Alex Rattray) Fix flow type-parameter-declaration test with unintended semantic (#361) (Alex Rattray) Cleanup and splitup parser functions (#295) (Daniel Tschinder) chore(package): update flow-bin to version 0.38.0 (#313) (greenkeeper[bot]) Call inner function instead of 1:1 copy to plugin (#294) (Daniel Tschinder) Update eslint-config-babel to the latest version \uD83D\uDE80 (#299) (greenkeeper[bot]) Update eslint-config-babel to the latest version \uD83D\uDE80 (#293) (greenkeeper[bot]) devDeps: remove eslint-plugin-babel (#292) (Kai Cataldo) Correct indent eslint rule config (#276) (Daniel Tschinder) Fail tests that have expected.json and throws-option (#285) (Daniel Tschinder) \uD83D\uDCDD Documentation Update contributing with more test info [skip ci] (#355) (Brian Ng) Update API documentation (#330) (Timothy Gu) Added keywords to package.json (#323) (Dmytro) AST spec: fix casing of RegExpLiteral (#318) (Mathias Bynens) 6.15.0 (2017-01-10) \uD83D\uDC53 Spec Compliance Add support for Flow shorthand import type (#267) (Jeff Morrison) This change implements flows new shorthand import syntax and where previously you had to write this code: import {someValue} from \"blah\"; import type {someType} from \"blah\"; import typeof {someOtherValue} from \"blah\"; you can now write it like this: import { someValue, type someType, typeof someOtherValue, } from \"blah\"; For more information look at this pull request. flow: allow leading pipes in all positions (#256) (Vladimir Kurchatkin) This change now allows a leading pipe everywhere types can be used: var f = (x): | 1 | 2 => 1; Throw error when exporting non-declaration (#241) (Kai Cataldo) Previously babylon parsed the following exports, although they are not valid: export typeof foo; export new Foo(); export function() {}; export for (;;); export while(foo); \uD83D\uDC1B Bug Fix Don't set inType flag when parsing property names (#266) (Vladimir Kurchatkin) This fixes parsing of this case: const map = { [age <= 17] : 'Too young' }; Fix source location for JSXEmptyExpression nodes (fixes #248) (#249) (James Long) The following case produced an invalid AST <div>{/* foo */}</div> Use fromCodePoint to convert high value unicode entities (#243) (Ryan Duffy) When high value unicode entities (e.g. \uD83D\uDCA9) were used in the input source code they are now correctly encoded in the resulting AST. Rename folder to avoid Windows-illegal characters (#281) (Ryan Plant) Allow this.state.clone() when parsing decorators (#262) (Alex Rattray) \uD83C\uDFE0 Internal User external-helpers (#254) (Daniel Tschinder) Add watch script for dev (#234) (Kai Cataldo) Freeze current plugins list for \"*\" option, and remove from README.md (#245) (Andrew Levine) Prepare tests for multiple fixture runners. (#240) (Daniel Tschinder) Add some test coverage for decorators stage-0 plugin (#250) (Andrew Levine) Refactor tokenizer types file (#263) (Sven SAULEAU) Update eslint-config-babel to the latest version \uD83D\uDE80 (#273) (greenkeeper[bot]) chore(package): update rollup to version 0.41.0 (#272) (greenkeeper[bot]) chore(package): update flow-bin to version 0.37.0 (#255) (greenkeeper[bot]) 6.14.1 (2016-11-17) \uD83D\uDC1B Bug Fix Allow \"plugins\": [\"*\"] (#229) (Daniel Tschinder) { \"plugins\": [\"*\"] } Will include all parser plugins instead of specifying each one individually. Useful for tools like babel-eslint, jscodeshift, and ast-explorer. 6.14.0 (2016-11-16) \uD83D\uDC53 Spec Compliance Throw error for reserved words enum and await (#195) (Kai Cataldo) 11.6.2.2 Future Reserved Words Babylon will throw for more reserved words such as enum or await (in strict mode). class enum {} // throws class await {} // throws in strict mode (module) Optional names for function types and object type indexers (#197) (Gabe Levi) So where you used to have to write type A = (x: string, y: boolean) => number; type B = (z: string) => number; type C = { [key: string]: number }; you can now write (with flow 0.34.0) type A = (string, boolean) => number; type B = string => number; type C = { [string]: number }; Parse flow nested array type annotations like number[][] (#219) (Bernhard Häussner) Supports these form now of specifying array types: var a: number[][][][]; var b: string[][]; \uD83D\uDC1B Bug Fix Correctly eat semicolon at the end of DelcareModuleExports (#223) (Daniel Tschinder) declare module \"foo\" { declare module.exports: number } declare module \"foo\" { declare module.exports: number; } // also allowed now \uD83C\uDFE0 Internal Count Babel tests towards Babylon code coverage (#182) (Moti Zilberman) Fix strange line endings (#214) (Thomas Grainger) Add node 7 (Daniel Tschinder) chore(package): update flow-bin to version 0.34.0 (#204) (Greenkeeper) v6.13.1 (2016-10-26) \uD83D\uDC85 Polish Use rollup for bundling to speed up startup time (#190) (@drewml) const babylon = require('babylon'); const ast = babylon.parse('var foo = \"lol\";'); With that test case, there was a ~95ms savings by removing the need for node to build/traverse the dependency graph. Without bundling With bundling add clean command [skip ci] (#201) (Henry Zhu) add ForAwaitStatement (async generator already added) [skip ci] (#196) (Henry Zhu) v6.13.0 (2016-10-21) \uD83D\uDC53 Spec Compliance Property variance type annotations for Flow plugin (#161) (Sam Goldman) See https://flowtype.org/docs/variance.html for more information type T = { +p: T }; interface T { -p: T }; declare class T { +[k:K]: V }; class T { -[k:K]: V }; class C2 { +p: T = e }; Raise error on duplicate definition of proto (#183) (Moti Zilberman) ({ __proto__: 1, __proto__: 2 }) // Throws an error now \uD83D\uDC1B Bug Fix Flow: Allow class properties to be named static (#184) (Moti Zilberman) declare class A { static: T; } Allow \"async\" as identifier for object literal property shorthand (#187) (Andrew Levine) var foo = { async, bar }; \uD83D\uDC85 Polish Fix flowtype and add inType to state (#189) (Daniel Tschinder) This improves the performance slightly (because of hidden classes) \uD83C\uDFE0 Internal Fix .gitattributes line ending setting (#191) (Moti Zilberman) Increase test coverage (#175 (Moti Zilberman) Readd missin .eslinignore for IDEs (Daniel Tschinder) Error on missing expected.json fixture in CI (#188) (Moti Zilberman) Add .gitattributes and .editorconfig for LF line endings (#179) (Moti Zilberman) Fixes two tests that are failing after the merge of #172 (#177) (Moti Zilberman) v6.12.0 (2016-10-14) \uD83D\uDC53 Spec Compliance Implement import() syntax (#163) (Jordan Gensler) Dynamic Import Proposal Repo: https://github.com/domenic/proposal-dynamic-import Championed by @domenic stage-2 sept-28 tc39 notes This repository contains a proposal for adding a \"function-like\" import() module loading syntactic form to JavaScript import(`./section-modules/${link.dataset.entryModule}.js`) .then(module => { module.loadPageInto(main); }) Add EmptyTypeAnnotation (#171) (Sam Goldman) EmptyTypeAnnotation Just wasn't covered before. type T = empty; \uD83D\uDC1B Bug Fix Fix crash when exporting with destructuring and sparse array (#170) (Jeroen Engels) // was failing due to sparse array export const { foo: [ ,, qux7 ] } = bar; Allow keyword in Flow object declaration property names with type parameters (#146) (Dan Harper) declare class X { foobar<T>(): void; static foobar<T>(): void; } Allow keyword in object/class property names with Flow type parameters (#145) (Dan Harper) class Foo { delete<T>(item: T): T { return item; } } Allow typeAnnotations for yield expressions (#174)) (Daniel Tschinder) function *foo() { const x = (yield 5: any); } \uD83D\uDC85 Polish Annotate more errors with expected token (#172)) (Moti Zilberman) // Unexpected token, expected ; (1:6) { set 1 } \uD83C\uDFE0 Internal Remove kcheck (#173)) (Daniel Tschinder) Also run flow, linting, babel tests on separate instances (add back node 0.10) v6.11.6 (2016-10-12) \uD83D\uDC1B Bug Fix/Regression Fix crash when exporting with destructuring and sparse array (#170) (Jeroen Engels) // was failing with `Cannot read property 'type' of null` because of null identifiers export const { foo: [ ,, qux7 ] } = bar; v6.11.5 (2016-10-12) \uD83D\uDC53 Spec Compliance Fix: Check for duplicate named exports in exported destructuring assignments (#144) (Kai Cataldo) // `foo` has already been exported. Exported identifiers must be unique. (2:20) export function foo() {}; export const { a: [{foo}] } = bar; Fix: Check for duplicate named exports in exported rest elements/properties (#164) (Kai Cataldo) // `foo` has already been exported. Exported identifiers must be unique. (2:22) export const foo = 1; export const [bar, ...foo] = baz; \uD83D\uDC1B Bug Fix Fix: Allow identifier async for default param in arrow expression (#165) (Kai Cataldo) // this is ok now const test = ({async = true}) => {}; \uD83D\uDC85 Polish Babylon will now print out the token it's expecting if there's a SyntaxError (#150) (Daniel Tschinder) # So in the case of a missing ending curly (`}`) Module build failed: SyntaxError: Unexpected token, expected } (30:0) 28 | } 29 | > 30 | | ^ v6.11.4 (2016-10-03) Temporary rollback for erroring on trailing comma with spread (#154) (Henry Zhu) v6.11.3 (2016-10-01) \uD83D\uDC53 Spec Compliance Add static errors for object rest (#149) (@danez) https://github.com/sebmarkbage/ecmascript-rest-spread Object rest copies the rest of properties from the right hand side obj starting from the left to right. let { x, y, ...z } = { x: 1, y: 2, z: 3 }; // x = 1 // y = 2 // z = { z: 3 } New Syntax Errors: SyntaxError: The rest element has to be the last element when destructuring (1:10) > 1 | let { ...x, y, z } = { x: 1, y: 2, z: 3}; | ^ # Previous behavior: # x = { x: 1, y: 2, z: 3 } # y = 2 # z = 3 Before, this was just a more verbose way of shallow copying obj since it doesn't actually do what you think. SyntaxError: Cannot have multiple rest elements when destructuring (1:13) > 1 | let { x, ...y, ...z } = { x: 1, y: 2, z: 3}; | ^ # Previous behavior: # x = 1 # y = { y: 2, z: 3 } # z = { y: 2, z: 3 } Before y and z would just be the same value anyway so there is no reason to need to have both. SyntaxError: A trailing comma is not permitted after the rest element (1:16) let { x, y, ...z, } = obj; The rationale for this is that the use case for trailing comma is that you can add something at the end without affecting the line above. Since a RestProperty always has to be the last property it doesn't make sense. get / set are valid property names in default assignment (#142) (@jezell) // valid function something({ set = null, get = null }) {} v6.11.2 (2016-09-23) Bug Fix #139 Don't do the duplicate check if not an identifier (#140) @hzoo // regression with duplicate export check SyntaxError: ./typography.js: `undefined` has already been exported. Exported identifiers must be unique. (22:13) 20 | 21 | export const { rhythm } = typography; > 22 | export const { TypographyStyle } = typography Bail out for now, and make a change to account for destructuring in the next release. 6.11.1 (2016-09-22) Bug Fix #137 - Fix a regression with duplicate exports - it was erroring on all keys in Object.prototype. @danez export toString from './toString'; `toString` has already been exported. Exported identifiers must be unique. (1:7) > 1 | export toString from './toString'; | ^ 2 | 6.11.0 (2016-09-22) Spec Compliance (will break CI) Disallow duplicate named exports (#107) @kaicataldo // Only one default export allowed per module. (2:9) export default function() {}; export { foo as default }; // Only one default export allowed per module. (2:0) export default {}; export default function() {}; // `Foo` has already been exported. Exported identifiers must be unique. (2:0) export { Foo }; export class Foo {}; New Feature (Syntax) Add support for computed class property names (#121) @motiz88 // AST interface ClassProperty <: Node { type: \"ClassProperty\"; key: Identifier; value: Expression; computed: boolean; // added } // with \"plugins\": [\"classProperties\"] class Foo { [x] ['y'] } class Bar { [p] [m] () {} } Bug Fix Fix static property falling through in the declare class Flow AST (#135) @danharper declare class X { a: number; static b: number; // static c: number; // this was being marked as static in the AST as well } Polish Rephrase \"assigning/binding to rvalue\" errors to include context (#119) @motiz88 // Used to error with: // SyntaxError: Assigning to rvalue (1:0) // Now: // Invalid left-hand side in assignment expression (1:0) 3 = 4 // Invalid left-hand side in for-in statement (1:5) for (+i in {}); Internal Fix call to this.parseMaybeAssign with correct arguments (#133) @danez Add semver note to changelog (#131) @hzoo 6.10.0 (2016-09-19) We plan to include some spec compliance bugs in patch versions. An example was the multiple default exports issue. Spec Compliance Implement ES2016 check for simple parameter list in strict mode (#106) (Timothy Gu) It is a Syntax Error if ContainsUseStrict of FunctionBody is true and IsSimpleParameterList of FormalParameters is false. https://tc39.github.io/ecma262/2016/#sec-function-definitions-static-semantics-early-errors More Context: tc39-notes For example: // this errors because it uses destructuring and default parameters // in a function with a \"use strict\" directive function a([ option1, option2 ] = []) { \"use strict\"; } The solution would be to use a top level \"use strict\" or to remove the destructuring or default parameters when using a function + \"use strict\" or to. New Feature Exact object type annotations for Flow plugin (#104) (Basil Hosmer) Added to flow in https://github.com/facebook/flow/commit/c710c40aa2a115435098d6c0dfeaadb023cd39b8 Looks like: var a : {| x: number, y: string |} = { x: 0, y: 'foo' }; Bug Fixes Include typeParameter location in ArrowFunctionExpression (#126) (Daniel Tschinder) Error on invalid flow type annotation with default assignment (#122) (Dan Harper) Fix Flow return types on arrow functions (#124) (Dan Harper) Misc Add tests for export extensions (#127) (Daniel Tschinder) Fix Contributing guidelines [skip ci] (Daniel Tschinder) 6.9.2 (2016-09-09) The only change is to remove the babel-runtime dependency by compiling with Babel's ES2015 loose mode. So using babylon standalone should be smaller. 6.9.1 (2016-08-23) This release contains mainly small bugfixes but also updates babylons default mode to es2017. The features for exponentiationOperator, asyncFunctions and trailingFunctionCommas which previously needed to be activated via plugin are now enabled by default and the plugins are now no-ops. Bug Fixes Fix issues with default object params in async functions (#96) @danez Fix issues with flow-types and async function (#95) @danez Fix arrow functions with destructuring, types & default value (#94) @danharper Fix declare class with qualified type identifier (#97) @danez Remove exponentiationOperator, asyncFunctions, trailingFunctionCommas plugins and enable them by default (#98) @danez 6.9.0 (2016-08-16) New syntax support Add JSX spread children (#42) @calebmer (Be aware that React is not going to support this syntax) <div> {...todos.map(todo => <Todo key={todo.id} todo={todo}/>)} </div> Add support for declare module.exports (#72) @danez declare module \"foo\" { declare module.exports: {} } New Features If supplied, attach filename property to comment node loc. (#80) @divmain Add identifier name to node loc field (#90) @kittens Bug Fixes Fix exponential operator to behave according to spec (#75) @danez Fix lookahead to not add comments to arrays which are not cloned (#76) @danez Fix accidental fall-through in Flow type parsing. (#82) @xiemaisi Only allow declares inside declare module (#73) @danez Small fix for parsing type parameter declarations (#83) @gabelevi Fix arrow param locations with flow types (#57) @danez Fixes SyntaxError position with flow optional type (#65) @danez Internal Add codecoverage to tests @danez Fix tests to not save expected output if we expect the test to fail @danez Make a shallow clone of babel for testing @danez chore(package): update cross-env to version 2.0.0 (#77) @greenkeeperio-bot chore(package): update ava to version 0.16.0 (#86) @greenkeeperio-bot chore(package): update babel-plugin-istanbul to version 2.0.0 (#89) @greenkeeperio-bot chore(package): update nyc to version 8.0.0 (#88) @greenkeeperio-bot 6.8.4 (2016-07-06) Bug Fixes Fix the location of params, when flow and default value used (#68) @danez 6.8.3 (2016-07-02) Bug Fixes Fix performance regression introduced in 6.8.2 with conditionals (#63) @danez 6.8.2 (2016-06-24) Bug Fixes Fix parse error with yielding jsx elements in generators function* it() { yield <a></a>; } (#31) @eldereal When cloning nodes do not clone its comments (#24) @danez Fix parse errors when using arrow functions with an spread element and return type (...props): void => {} (#10) @danez Fix leading comments added from previous node (#23) @danez Fix parse errors with flow's optional arguments (arg?) => {} (#19) @danez Support negative numeric type literals @kittens Remove line terminator restriction after await keyword @kittens Remove grouped type arrow restriction as it seems flow no longer has it @kittens Fix parse error with generic methods that have the name get or set class foo { get() {} } (#55) @vkurchatkin Fix parse error with arrow functions that have flow type parameter declarations <T>(x: T): T => x; (#54) @gabelevi Documentation Document AST differences from ESTree (#41) @nene Move ast spec from babel/babel (#46) @hzoo Internal Enable skipped tests (#16) @danez Add script to test latest version of babylon with babel (#21) @danez Upgrade test runner ava @kittens Add missing generate-identifier-regex script @kittens Rename parser context types @kittens Add node v6 to travis testing @hzoo Update to Unicode v9 (#45) @mathiasbynens 6.8.1 (2016-06-06) New Feature Parse type parameter declarations with defaults like type Foo<T = string> = T Bug Fixes Type parameter declarations need 1 or more type parameters. The existential type * is not a valid type parameter. The existential type * is a primary type Spec Compliance The param list for type parameter declarations now consists of TypeParameter nodes New TypeParameter AST Node (replaces using the Identifier node before) interface TypeParameter <: Node { bound: TypeAnnotation; default: TypeAnnotation; name: string; variance: \"plus\" | \"minus\"; } 6.8.0 (2016-05-02) New Feature Parse Method Parameter Decorators (#12) Method Parameter Decorators is now a TC39 stage 0 proposal. Examples: class Foo { constructor(@foo() x, @bar({ a: 123 }) @baz() y) {} } export default function func(@foo() x, @bar({ a: 123 }) @baz() y) {} var obj = { method(@foo() x, @bar({ a: 123 }) @baz() y) {} }; Parse for-await statements (w/ asyncGenerators plugin) (#17) There is also a new node type, ForAwaitStatement. Async generators and for-await are now a stage 2 proposal. Example: async function f() { for await (let x of y); }"
  },
  "src/frontend/app-client/node_modules/@babel/parser/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/parser/README.html",
    "title": "",
    "summary": "@babel/parser A JavaScript parser See our website @babel/parser for more information or the issues associated with this package. Install Using npm: npm install --save-dev @babel/parser or using yarn: yarn add @babel/parser --dev"
  },
  "src/frontend/app-client/node_modules/@babel/plugin-syntax-decorators/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/plugin-syntax-decorators/README.html",
    "title": "",
    "summary": "@babel/plugin-syntax-decorators Allow parsing of decorators See our website @babel/plugin-syntax-decorators for more information. Install Using npm: npm install --save-dev @babel/plugin-syntax-decorators or using yarn: yarn add @babel/plugin-syntax-decorators --dev"
  },
  "src/frontend/app-client/node_modules/@babel/plugin-syntax-jsx/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/plugin-syntax-jsx/README.html",
    "title": "",
    "summary": "@babel/plugin-syntax-jsx Allow parsing of jsx See our website @babel/plugin-syntax-jsx for more information. Install Using npm: npm install --save-dev @babel/plugin-syntax-jsx or using yarn: yarn add @babel/plugin-syntax-jsx --dev"
  },
  "src/frontend/app-client/node_modules/@babel/plugin-syntax-typescript/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/plugin-syntax-typescript/README.html",
    "title": "",
    "summary": "@babel/plugin-syntax-typescript Allow parsing of TypeScript syntax See our website @babel/plugin-syntax-typescript for more information. Install Using npm: npm install --save-dev @babel/plugin-syntax-typescript or using yarn: yarn add @babel/plugin-syntax-typescript --dev"
  },
  "src/frontend/app-client/node_modules/@babel/plugin-transform-modules-commonjs/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/plugin-transform-modules-commonjs/README.html",
    "title": "",
    "summary": "@babel/plugin-transform-modules-commonjs This plugin transforms ES2015 modules to CommonJS See our website @babel/plugin-transform-modules-commonjs for more information. Install Using npm: npm install --save-dev @babel/plugin-transform-modules-commonjs or using yarn: yarn add @babel/plugin-transform-modules-commonjs --dev"
  },
  "src/frontend/app-client/node_modules/@babel/plugin-transform-typescript/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/plugin-transform-typescript/README.html",
    "title": "",
    "summary": "@babel/plugin-transform-typescript Transform TypeScript into ES.next See our website @babel/plugin-transform-typescript for more information. Install Using npm: npm install --save-dev @babel/plugin-transform-typescript or using yarn: yarn add @babel/plugin-transform-typescript --dev"
  },
  "src/frontend/app-client/node_modules/@babel/preset-typescript/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/preset-typescript/README.html",
    "title": "",
    "summary": "@babel/preset-typescript Babel preset for TypeScript. See our website @babel/preset-typescript for more information or the issues associated with this package. Install Using npm: npm install --save-dev @babel/preset-typescript or using yarn: yarn add @babel/preset-typescript --dev"
  },
  "src/frontend/app-client/node_modules/@babel/runtime/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/runtime/README.html",
    "title": "",
    "summary": "@babel/runtime babel's modular runtime helpers See our website @babel/runtime for more information. Install Using npm: npm install --save @babel/runtime or using yarn: yarn add @babel/runtime"
  },
  "src/frontend/app-client/node_modules/@babel/template/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/template/README.html",
    "title": "",
    "summary": "@babel/template Generate an AST from a string template. See our website @babel/template for more information or the issues associated with this package. Install Using npm: npm install --save-dev @babel/template or using yarn: yarn add @babel/template --dev"
  },
  "src/frontend/app-client/node_modules/@babel/traverse/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/traverse/README.html",
    "title": "",
    "summary": "@babel/traverse The Babel Traverse module maintains the overall tree state, and is responsible for replacing, removing, and adding nodes See our website @babel/traverse for more information or the issues associated with this package. Install Using npm: npm install --save-dev @babel/traverse or using yarn: yarn add @babel/traverse --dev"
  },
  "src/frontend/app-client/node_modules/@babel/types/README.html": {
    "href": "src/frontend/app-client/node_modules/@babel/types/README.html",
    "title": "",
    "summary": "@babel/types Babel Types is a Lodash-esque utility library for AST nodes See our website @babel/types for more information or the issues associated with this package. Install Using npm: npm install --save-dev @babel/types or using yarn: yarn add @babel/types --dev"
  },
  "src/frontend/app-client/node_modules/@emotion/babel-plugin/node_modules/convert-source-map/README.html": {
    "href": "src/frontend/app-client/node_modules/@emotion/babel-plugin/node_modules/convert-source-map/README.html",
    "title": "convert-source-map",
    "summary": "convert-source-map Converts a source-map from/to different formats and allows adding/changing properties. var convert = require('convert-source-map'); var json = convert .fromComment('//# sourceMappingURL=data:application/json;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoiYnVpbGQvZm9vLm1pbi5qcyIsInNvdXJjZXMiOlsic3JjL2Zvby5qcyJdLCJuYW1lcyI6W10sIm1hcHBpbmdzIjoiQUFBQSIsInNvdXJjZVJvb3QiOiIvIn0=') .toJSON(); var modified = convert .fromComment('//# sourceMappingURL=data:application/json;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoiYnVpbGQvZm9vLm1pbi5qcyIsInNvdXJjZXMiOlsic3JjL2Zvby5qcyJdLCJuYW1lcyI6W10sIm1hcHBpbmdzIjoiQUFBQSIsInNvdXJjZVJvb3QiOiIvIn0=') .setProperty('sources', [ 'SRC/FOO.JS' ]) .toJSON(); console.log(json); console.log(modified); {\"version\":3,\"file\":\"build/foo.min.js\",\"sources\":[\"src/foo.js\"],\"names\":[],\"mappings\":\"AAAA\",\"sourceRoot\":\"/\"} {\"version\":3,\"file\":\"build/foo.min.js\",\"sources\":[\"SRC/FOO.JS\"],\"names\":[],\"mappings\":\"AAAA\",\"sourceRoot\":\"/\"} API fromObject(obj) Returns source map converter from given object. fromJSON(json) Returns source map converter from given json string. fromBase64(base64) Returns source map converter from given base64 encoded json string. fromComment(comment) Returns source map converter from given base64 encoded json string prefixed with //# sourceMappingURL=.... fromMapFileComment(comment, mapFileDir) Returns source map converter from given filename by parsing //# sourceMappingURL=filename. filename must point to a file that is found inside the mapFileDir. Most tools store this file right next to the generated file, i.e. the one containing the source map. fromSource(source) Finds last sourcemap comment in file and returns source map converter or returns null if no source map comment was found. fromMapFileSource(source, mapFileDir) Finds last sourcemap comment in file and returns source map converter or returns null if no source map comment was found. The sourcemap will be read from the map file found by parsing # sourceMappingURL=file comment. For more info see fromMapFileComment. toObject() Returns a copy of the underlying source map. toJSON([space]) Converts source map to json string. If space is given (optional), this will be passed to JSON.stringify when the JSON string is generated. toBase64() Converts source map to base64 encoded json string. toComment([options]) Converts source map to an inline comment that can be appended to the source-file. By default, the comment is formatted like: //# sourceMappingURL=..., which you would normally see in a JS source file. When options.multiline == true, the comment is formatted like: /*# sourceMappingURL=... */, which you would find in a CSS source file. addProperty(key, value) Adds given property to the source map. Throws an error if property already exists. setProperty(key, value) Sets given property to the source map. If property doesn't exist it is added, otherwise its value is updated. getProperty(key) Gets given property of the source map. removeComments(src) Returns src with all source map comments removed removeMapFileComments(src) Returns src with all source map comments pointing to map files removed. commentRegex Provides a fresh RegExp each time it is accessed. Can be used to find source map comments. mapFileCommentRegex Provides a fresh RegExp each time it is accessed. Can be used to find source map comments pointing to map files. generateMapFileComment(file, [options]) Returns a comment that links to an external source map via file. By default, the comment is formatted like: //# sourceMappingURL=..., which you would normally see in a JS source file. When options.multiline == true, the comment is formatted like: /*# sourceMappingURL=... */, which you would find in a CSS source file."
  },
  "src/frontend/app-client/node_modules/@emotion/babel-plugin/README.html": {
    "href": "src/frontend/app-client/node_modules/@emotion/babel-plugin/README.html",
    "title": "",
    "summary": "@emotion/babel-plugin Babel plugin for the minification and optimization of emotion styles. @emotion/babel-plugin is highly recommended, but not required in version 8 and above of Emotion. Features Feature/Syntax Native Babel Plugin Required Notes css`` ✅ css(...) ✅ Generally used for object styles. components as selectors ✅ Allows an emotion component to be used as a CSS selector. Minification ✅ Any leading/trailing space between properties in your css and styled blocks is removed. This can reduce the size of your final bundle. Dead Code Elimination ✅ Uglifyjs will use the injected /*#__PURE__*/ flag comments to mark your css and styled blocks as candidates for dead code elimination. Source Maps ✅ When enabled, navigate directly to the style declaration in your javascript file. Contextual Class Names ✅ Generated class names include the name of the variable or component they were defined in. Example In const myStyles = css` font-size: 20px; @media (min-width: 420px) { color: blue; ${css` width: 96px; height: 96px; `}; line-height: 26px; } background: green; ${{ backgroundColor: 'hotpink' }}; ` Out const myStyles = /* #__PURE__ */ css( 'font-size:20px;@media(min-width:420px){color:blue;', /* #__PURE__ */ css('width:96px;height:96px;'), ';line-height:26px;}background:green;', { backgroundColor: 'hotpink' }, ';' ) Installation yarn add --dev @emotion/babel-plugin or if you prefer npm npm install --save-dev @emotion/babel-plugin Usage Via .babelrc (Recommended) .babelrc Without options: { \"plugins\": [\"@emotion\"] } With options: Defaults Shown { \"plugins\": [ [ \"@emotion\", { // sourceMap is on by default but source maps are dead code eliminated in production \"sourceMap\": true, \"autoLabel\": \"dev-only\", \"labelFormat\": \"[local]\", \"cssPropOptimization\": true } ] ] } Recommended Setup .babelrc { \"plugins\": [\"@emotion\"] } Via CLI babel --plugins @emotion/babel-plugin script.js Via Node API require('@babel/core').transform('code', { plugins: ['@emotion/babel-plugin'] }) Options sourceMap boolean, defaults to true. This option enables the following: Injected source maps for use in browser dev tools Documentation Note: Source maps are on by default in @emotion/babel-plugin but they will be removed in production builds autoLabel 'dev-only' | 'always' | 'never', defaults to dev-only. This option enables the following: Automatically adds the label property to styles so that class names generated by css or styled include the name of the variable the result is assigned to. Please note that non word characters in the variable will be removed (Eg. iconStyles$1 will become iconStyles1) because $ is not valid CSS ClassName Selector Each possible value for this option produces different output code: with dev-only we optimize the production code, so there are no labels added there, but at the same time we keep labels for development environments, with always we always add labels when possible, with never we disable this entirely and no labels are added. css In const brownStyles = css({ color: 'brown' }) Out const brownStyles = /*#__PURE__*/ css({ color: 'brown' }, 'label:brownStyles;') brownStyles's value would be css-1q8eu9e-brownStyles labelFormat string, defaults to \"[local]\". This option only works when autoLabel is set to 'dev-only' or 'always'. It allows you to define the format of the resulting label. The format is defined via string where variable parts are enclosed in square brackets []. For example labelFormat: \"my-classname--[local]\", where [local] will be replaced with the name of the variable the result is assigned to. Allowed values: [local] - the name of the variable the result of the css or styled expression is assigned to. [filename] - name of the file (without extension) where css or styled expression is located. [dirname] - name of the directory containing the file where css or styled expression is located. This format only affects the label property of the expression, meaning that the css prefix and hash will be prepended automatically. css In // BrownView.js // autoLabel: 'dev-only' // labelFormat: '[filename]--[local]' const brownStyles = css({ color: 'brown' }) Out const brownStyles = /*#__PURE__*/ css( { color: 'brown' }, 'label:BrownView--brownStyles;' ) BrownView--brownStyles's value would be css-hash-BrownView--brownStyles styled In const H1 = styled.h1({ borderRadius: '50%', transition: 'transform 400ms ease-in-out', boxSizing: 'border-box', display: 'flex', ':hover': { transform: 'scale(1.2)' } }) Out const H1 = /*#__PURE__*/ styled('h1', { label: 'H1' })({ borderRadius: '50%', transition: 'transform 400ms ease-in-out', boxSizing: 'border-box', display: 'flex', ':hover': { transform: 'scale(1.2)' } }) H1's class name attribute would be css-hash-H1 cssPropOptimization boolean, defaults to true. This option assumes that you are using something to make @emotion/react's jsx function work for all jsx. If you are not doing so and you do not want such optimizations to occur, disable this option. importMap This option allows you to tell @emotion/babel-plugin what imports it should look at to determine what it should transform so if you re-export Emotion's exports, you can still use the Babel transforms An example file: import { anotherExport } from 'my-package' import { someExport, thisIsTheJsxExport } from 'some-package' An example config: { \"my-package\": { \"anotherExport\": { \"canonicalImport\": [\"@emotion/styled\", \"default\"], \"styledBaseImport\": [\"my-package/base\", \"anotherExport\"] } }, \"some-package\": { \"someExport\": { \"canonicalImport\": [\"@emotion/react\", \"css\"] }, \"thisIsTheJsxExport\": { \"canonicalImport\": [\"@emotion/react\", \"jsx\"] } } } Babel Macros Instead of using @emotion/babel-plugin, you can use emotion with babel-plugin-macros. Add babel-plugin-macros to your babel config (which is included in Create React App 2.0) and use the imports/packages shown below. import { css, keyframes, injectGlobal, flush, hydrate } from '@emotion/css/macro' import { jsx, css, Global, keyframes } from '@emotion/react/macro' import styled from '@emotion/styled/macro'"
  },
  "src/frontend/app-client/node_modules/@emotion/cache/README.html": {
    "href": "src/frontend/app-client/node_modules/@emotion/cache/README.html",
    "title": "",
    "summary": "@emotion/cache createCache createCache allows for low level customization of how styles get inserted by emotion. It's intended to be used with the <CacheProvider/> component to override the default cache, which is created with sensible defaults for most applications. import createCache from '@emotion/cache' export const myCache = createCache({ key: 'my-prefix-key', stylisPlugins: [ /* your plugins here */ ] }) Primary use cases Using emotion in embedded contexts such as an <iframe/> Setting a nonce on any <style/> tag emotion creates for security purposes Using emotion with a developer defined <style/> tag Using emotion with custom Stylis plugins Options nonce string A nonce that will be set on each style tag that emotion inserts for Content Security Policies. stylisPlugins Array<Function> A Stylis plugins that will be run by Stylis during preprocessing. Read the Stylis docs to find out more. This can be used for many purposes such as RTL. Note: Prefixer is just a plugin which happens to be put in default stylisPlugins. If you plan to use custom stylisPlugins and you want to have your styles prefixed automatically you must include prefixer in your custom stylisPlugins. You can import prefixer from the stylis module to do that (import { prefixer } from 'stylis'); key string (Pattern: [^a-z-]) The prefix before class names. It will also be set as the value of the data-emotion attribute on the style tags that emotion inserts and it's used in the attribute name that marks style elements in renderStylesToString and renderStylesToNodeStream. This is required if using multiple emotion caches in the same app. container Node A DOM node that emotion will insert all of its style tags into. This is useful for inserting styles into iframes or windows. prepend boolean A boolean representing whether to prepend rather than append style tags into the specified container DOM node."
  },
  "src/frontend/app-client/node_modules/@emotion/css/README.html": {
    "href": "src/frontend/app-client/node_modules/@emotion/css/README.html",
    "title": "",
    "summary": "@emotion/css The @emotion/css package is framework agnostic and the simplest way to use Emotion. Table of Contents Quick Start API Generate Class Names — css Global Styles — injectGlobal Animation Keyframes — keyframes Composing Class Names — cx Custom Instances Server Side Rendering Babel Plugin Quick Start Get up and running with a single import. npm install --save @emotion/css import { css } from '@emotion/css' const app = document.getElementById('root') const myStyle = css` color: rebeccapurple; ` app.classList.add(myStyle) API css The css function accepts styles as a template literal, object, or array of objects and returns a class name. It is the foundation of emotion. String Styles // @live import { css } from '@emotion/css' const color = 'darkgreen' render( <div className={css` background-color: hotpink; &:hover { color: ${color}; } `} > This has a hotpink background. </div> ) Object Styles // @live import { css } from '@emotion/css' const color = 'darkgreen' render( <div className={css({ backgroundColor: 'hotpink', '&:hover': { color } })} > This has a hotpink background. </div> ) Array of Object Styles // @live import { css } from '@emotion/css' const color = 'darkgreen' const isDanger = true render( <div className={css([ { backgroundColor: 'hotpink', '&:hover': { color } }, isDanger && { color: 'red' } ])} > This has a hotpink background. </div> ) Global Styles injectGlobal injects styles into the global scope and is useful for applications such as css resets or font faces. import { injectGlobal } from '@emotion/css' injectGlobal` * { box-sizing: border-box; } @font-face { font-family: 'Patrick Hand SC'; font-style: normal; font-weight: 400; src: local('Patrick Hand SC'), local('PatrickHandSC-Regular'), url(https://fonts.gstatic.com/s/patrickhandsc/v4/OYFWCgfCR-7uHIovjUZXsZ71Uis0Qeb9Gqo8IZV7ckE.woff2) format('woff2'); unicode-range: U+0100-024f, U+1-1eff, U+20a0-20ab, U+20ad-20cf, U+2c60-2c7f, U+A720-A7FF; } ` Animation Keyframes keyframes generates a unique animation name that can be used to animate elements with CSS animations. String Styles // @live import { css, keyframes } from '@emotion/css' const bounce = keyframes` from, 20%, 53%, 80%, to { transform: translate3d(0,0,0); } 40%, 43% { transform: translate3d(0, -30px, 0); } 70% { transform: translate3d(0, -15px, 0); } 90% { transform: translate3d(0,-4px,0); } ` render( <img className={css` width: 96px; height: 96px; border-radius: 50%; animation: ${bounce} 1s ease infinite; transform-origin: center bottom; `} src={logoUrl} /> ) Object Styles // @live import { css, keyframes } from '@emotion/css' const bounce = keyframes({ 'from, 20%, 53%, 80%, to': { transform: 'translate3d(0,0,0)' }, '40%, 43%': { transform: 'translate3d(0, -30px, 0)' }, '70%': { transform: 'translate3d(0, -15px, 0)' }, '90%': { transform: 'translate3d(0, -4px, 0)' } }) render( <img src={logoUrl} className={css({ width: 96, height: 96, borderRadius: '50%', animation: `${bounce} 1s ease infinite`, transformOrigin: 'center bottom' })} /> ) cx cx is emotion's version of the popular classnames library. The key advantage of cx is that it detects emotion generated class names ensuring styles are overwritten in the correct order. Emotion generated styles are applied from left to right. Subsequent styles overwrite property values of previous styles. Combining class names import { cx, css } from '@emotion/css' const cls1 = css` font-size: 20px; background: green; ` const cls2 = css` font-size: 20px; background: blue; ` <div className={cx(cls1, cls2)} /> Conditional class names const cls1 = css` font-size: 20px; background: green; ` const cls2 = css` font-size: 20px; background: blue; ` const foo = true const bar = false <div className={cx( { [cls1]: foo }, { [cls2]: bar } )} /> Using class names from other sources const cls1 = css` font-size: 20px; background: green; ` <div className={cx(cls1, 'profile')} /> Custom Instances With @emotion/css/create-instance, you can provide custom options to Emotion's cache. The main @emotion/css entrypoint can be thought of as a call to @emotion/css/create-instance with sensible defaults for most applications. import createEmotion from '@emotion/css/create-instance' export const { flush, hydrate, cx, merge, getRegisteredStyles, injectGlobal, keyframes, css, sheet, cache } = createEmotion() Upside Calling it directly will allow for some low level customization. Create custom names for emotion APIs to help with migration from other, similar libraries. Could set custom key to something other than css Downside Introduces some amount of complexity to your application that can vary depending on developer experience. Required to keep up with changes in the repo and API at a lower level than if using @emotion/css directly Primary use cases Using emotion in embedded contexts such as an <iframe/> Setting a nonce on any <style/> tag emotion creates for security purposes Use emotion with a container different than document.head for style elements Using emotion with custom stylis plugins Multiple instances in a single app example import createEmotion from '@emotion/css/create-instance' export const { flush, hydrate, cx, merge, getRegisteredStyles, injectGlobal, keyframes, css, sheet, cache } = createEmotion({ // The key option is required when there will be multiple instances in a single app key: 'some-key' }) Options createEmotion accepts the same options as createCache from @emotion/cache."
  },
  "src/frontend/app-client/node_modules/@emotion/hash/README.html": {
    "href": "src/frontend/app-client/node_modules/@emotion/hash/README.html",
    "title": "",
    "summary": "@emotion/hash A MurmurHash2 implementation import hash from '@emotion/hash' hash('some-string') // 12fj1d The source of this is from https://github.com/garycourt/murmurhash-js/blob/master/murmurhash2_gc.js."
  },
  "src/frontend/app-client/node_modules/@emotion/react/README.html": {
    "href": "src/frontend/app-client/node_modules/@emotion/react/README.html",
    "title": "",
    "summary": "@emotion/react Simple styling in React. Install yarn add @emotion/react Usage /** @jsx jsx */ import { jsx, css, Global, ClassNames } from '@emotion/react' render( <div css={{ color: 'hotpink' }}> <div css={css` color: green; `} /> <Global styles={{ body: { margin: 0, padding: 0 } }} /> <ClassNames> {({ css, cx }) => ( <div className={cx( 'some-class', css` color: yellow; ` )} /> )} </ClassNames> </div> ) More documentation is available at https://emotion.sh."
  },
  "src/frontend/app-client/node_modules/@emotion/sheet/README.html": {
    "href": "src/frontend/app-client/node_modules/@emotion/sheet/README.html",
    "title": "",
    "summary": "@emotion/sheet A StyleSheet for css-in-js libraries yarn add @emotion/sheet import { StyleSheet } from '@emotion/sheet' const sheet = new StyleSheet({ key: '', container: document.head }) sheet.insert('html { color: hotpink; }') Note: This is not useful for server-side rendering, you should implement SSR seperately StyleSheet Options type Options = { nonce?: string key: string container: Node speedy?: boolean prepend?: boolean } nonce A nonce that will be set on each style tag that the sheet inserts for Content Security Policies. container A DOM Node that the sheet will insert all of it's style tags into, this is useful for inserting styles into iframes. key This will be set as the value of the data-emotion attribute on the style tags that get inserted. This is useful to identify different sheets. speedy This defines how rules are inserted. If it is true, rules will be inserted with insertRule which is very fast but doesn't allow rules to be edited in DevTools. If it is false, rules will be inserted by appending text nodes to style elements which is much slower than insertRule but allows rules to be edited in DevTools. By default, speedy is enabled in production and disabled in development. prepend Deprecated: Please use insertionPoint option instead. This defines where rules are inserted into the container. By default they are appended but this can be changed by using prepend: true option. insertionPoint This defines specific dom node after which the rules are inserted into the container. You can use a meta tag to specify the specific location: const head = document.querySelector('head') // <meta name=\"emotion-insertion-point\" content=\"\"> const emotionInsertionPoint = document.createElement('meta') emotionInsertionPoint.setAttribute('name', 'emotion-insertion-point') emotionInsertionPoint.setAttribute('content', '') head.appendChild(emotionInsertionPoint) // the emotion sheets should be inserted right after the meta tag const cache = createCache({ key: 'my-app', insertionPoint: emotionInsertionPoint }) function App() { return ( <CacheProvider value={cache}> <Main /> </CacheProvider> ) } Methods insert This method inserts a single rule into the document. It must be a single rule otherwise an error will be thrown in speedy mode which is enabled by default in production. flush This method will remove all style tags that were inserted into the document. hydrate This method moves given style elements into sheet's container and put them into internal tags collection. It's can be used for SSRed styles. Example with all options import { StyleSheet } from '@emotion/sheet' const container = document.createElement('div') document.head.appendChild(container) const sheet = new StyleSheet({ nonce: 'some-nonce', key: 'some-key', container }) sheet.insert('html { color: hotpink; }') sheet.flush() Thanks This StyleSheet is based on glamor's StyleSheet written by Sunil Pai. ❤️"
  },
  "src/frontend/app-client/node_modules/@emotion/unitless/README.html": {
    "href": "src/frontend/app-client/node_modules/@emotion/unitless/README.html",
    "title": "",
    "summary": "@emotion/unitless An object of css properties that don't accept values with units import unitless from '@emotion/unitless' unitless.flex === 1 unitless.padding === undefined"
  },
  "src/frontend/app-client/node_modules/@emotion/use-insertion-effect-with-fallbacks/README.html": {
    "href": "src/frontend/app-client/node_modules/@emotion/use-insertion-effect-with-fallbacks/README.html",
    "title": "",
    "summary": "@emotion/use-insertion-effect-with-fallbacks"
  },
  "src/frontend/app-client/node_modules/@emotion/weak-memoize/README.html": {
    "href": "src/frontend/app-client/node_modules/@emotion/weak-memoize/README.html",
    "title": "",
    "summary": "@emotion/weak-memoize A memoization function that uses a WeakMap Install yarn add @emotion/weak-memoize Usage Because @emotion/weak-memoize uses a WeakMap the argument must be a non primitive type, e.g. objects, functions, arrays and etc. The function passed to weakMemoize must also only accept a single argument. import weakMemoize from '@emotion/weak-memoize' let doThing = weakMemoize(({ someProperty }) => { return { newName: someProperty } }) let obj = { someProperty: true } let firstResult = doThing(obj) let secondResult = doThing(obj) firstResult === secondResult // true let newObj = { someProperty: true } let thirdResult = doThing(newObj) thirdResult === firstResult // false"
  },
  "src/frontend/app-client/node_modules/@esbuild/win32-x64/README.html": {
    "href": "src/frontend/app-client/node_modules/@esbuild/win32-x64/README.html",
    "title": "esbuild",
    "summary": "esbuild This is the Windows 64-bit binary for esbuild, a JavaScript bundler and minifier. See https://github.com/evanw/esbuild for details."
  },
  "src/frontend/app-client/node_modules/@floating-ui/core/README.html": {
    "href": "src/frontend/app-client/node_modules/@floating-ui/core/README.html",
    "title": "",
    "summary": "@floating-ui/core This is the platform-agnostic core of Floating UI, exposing the main computePosition function but no platform interface logic."
  },
  "src/frontend/app-client/node_modules/@floating-ui/dom/README.html": {
    "href": "src/frontend/app-client/node_modules/@floating-ui/dom/README.html",
    "title": "",
    "summary": "@floating-ui/dom This is the library to use Floating UI on the web, wrapping @floating-ui/core with DOM interface logic."
  },
  "src/frontend/app-client/node_modules/@floating-ui/react-dom/README.html": {
    "href": "src/frontend/app-client/node_modules/@floating-ui/react-dom/README.html",
    "title": "",
    "summary": "@floating-ui/react-dom This is the library to use Floating UI with React DOM."
  },
  "src/frontend/app-client/node_modules/@floating-ui/utils/README.html": {
    "href": "src/frontend/app-client/node_modules/@floating-ui/utils/README.html",
    "title": "",
    "summary": "@floating-ui/utils Utility functions shared across Floating UI packages. You may use these functions in your own projects, but are subject to breaking changes."
  },
  "src/frontend/app-client/node_modules/@isaacs/cliui/README.html": {
    "href": "src/frontend/app-client/node_modules/@isaacs/cliui/README.html",
    "title": "",
    "summary": "@isaacs/cliui Temporary fork of cliui. easily create complex multi-column command-line-interfaces. Example const ui = require('cliui')() ui.div('Usage: $0 [command] [options]') ui.div({ text: 'Options:', padding: [2, 0, 1, 0] }) ui.div( { text: \"-f, --file\", width: 20, padding: [0, 4, 0, 4] }, { text: \"the file to load.\" + chalk.green(\"(if this description is long it wraps).\") , width: 20 }, { text: chalk.red(\"[required]\"), align: 'right' } ) console.log(ui.toString()) Deno/ESM Support As of v7 cliui supports Deno and ESM: import cliui from \"https://deno.land/x/cliui/deno.ts\"; const ui = cliui({}) ui.div('Usage: $0 [command] [options]') ui.div({ text: 'Options:', padding: [2, 0, 1, 0] }) ui.div({ text: \"-f, --file\", width: 20, padding: [0, 4, 0, 4] }) console.log(ui.toString()) Layout DSL cliui exposes a simple layout DSL: If you create a single ui.div, passing a string rather than an object: \\n: characters will be interpreted as new rows. \\t: characters will be interpreted as new columns. \\s: characters will be interpreted as padding. as an example... var ui = require('./')({ width: 60 }) ui.div( 'Usage: node ./bin/foo.js\\n' + ' <regex>\\t provide a regex\\n' + ' <glob>\\t provide a glob\\t [required]' ) console.log(ui.toString()) will output: Usage: node ./bin/foo.js <regex> provide a regex <glob> provide a glob [required] Methods cliui = require('cliui') cliui({width: integer}) Specify the maximum width of the UI being generated. If no width is provided, cliui will try to get the current window's width and use it, and if that doesn't work, width will be set to 80. cliui({wrap: boolean}) Enable or disable the wrapping of text in a column. cliui.div(column, column, column) Create a row with any number of columns, a column can either be a string, or an object with the following options: text: some text to place in the column. width: the width of a column. align: alignment, right or center. padding: [top, right, bottom, left]. border: should a border be placed around the div? cliui.span(column, column, column) Similar to div, except the next row will be appended without a new line being created. cliui.resetOutput() Resets the UI elements of the current cliui instance, maintaining the values set for width and wrap."
  },
  "src/frontend/app-client/node_modules/@jridgewell/gen-mapping/README.html": {
    "href": "src/frontend/app-client/node_modules/@jridgewell/gen-mapping/README.html",
    "title": "",
    "summary": "@jridgewell/gen-mapping Generate source maps gen-mapping allows you to generate a source map during transpilation or minification. With a source map, you're able to trace the original location in the source file, either in Chrome's DevTools or using a library like @jridgewell/trace-mapping. You may already be familiar with the source-map package's SourceMapGenerator. This provides the same addMapping and setSourceContent API. Installation npm install @jridgewell/gen-mapping Usage import { GenMapping, addMapping, setSourceContent, toEncodedMap, toDecodedMap } from '@jridgewell/gen-mapping'; const map = new GenMapping({ file: 'output.js', sourceRoot: 'https://example.com/', }); setSourceContent(map, 'input.js', `function foo() {}`); addMapping(map, { // Lines start at line 1, columns at column 0. generated: { line: 1, column: 0 }, source: 'input.js', original: { line: 1, column: 0 }, }); addMapping(map, { generated: { line: 1, column: 9 }, source: 'input.js', original: { line: 1, column: 9 }, name: 'foo', }); assert.deepEqual(toDecodedMap(map), { version: 3, file: 'output.js', names: ['foo'], sourceRoot: 'https://example.com/', sources: ['input.js'], sourcesContent: ['function foo() {}'], mappings: [ [ [0, 0, 0, 0], [9, 0, 0, 9, 0] ] ], }); assert.deepEqual(toEncodedMap(map), { version: 3, file: 'output.js', names: ['foo'], sourceRoot: 'https://example.com/', sources: ['input.js'], sourcesContent: ['function foo() {}'], mappings: 'AAAA,SAASA', }); Smaller Sourcemaps Not everything needs to be added to a sourcemap, and needless markings can cause signficantly larger file sizes. gen-mapping exposes maybeAddSegment/maybeAddMapping APIs that will intelligently determine if this marking adds useful information. If not, the marking will be skipped. import { maybeAddMapping } from '@jridgewell/gen-mapping'; const map = new GenMapping(); // Adding a sourceless marking at the beginning of a line isn't useful. maybeAddMapping(map, { generated: { line: 1, column: 0 }, }); // Adding a new source marking is useful. maybeAddMapping(map, { generated: { line: 1, column: 0 }, source: 'input.js', original: { line: 1, column: 0 }, }); // But adding another marking pointing to the exact same original location isn't, even if the // generated column changed. maybeAddMapping(map, { generated: { line: 1, column: 9 }, source: 'input.js', original: { line: 1, column: 0 }, }); assert.deepEqual(toEncodedMap(map), { version: 3, names: [], sources: ['input.js'], sourcesContent: [null], mappings: 'AAAA', }); Benchmarks node v18.0.0 amp.js.map Memory Usage: gen-mapping: addSegment 5852872 bytes gen-mapping: addMapping 7716042 bytes source-map-js 6143250 bytes source-map-0.6.1 6124102 bytes source-map-0.8.0 6121173 bytes Smallest memory usage is gen-mapping: addSegment Adding speed: gen-mapping: addSegment x 441 ops/sec ±2.07% (90 runs sampled) gen-mapping: addMapping x 350 ops/sec ±2.40% (86 runs sampled) source-map-js: addMapping x 169 ops/sec ±2.42% (80 runs sampled) source-map-0.6.1: addMapping x 167 ops/sec ±2.56% (80 runs sampled) source-map-0.8.0: addMapping x 168 ops/sec ±2.52% (80 runs sampled) Fastest is gen-mapping: addSegment Generate speed: gen-mapping: decoded output x 150,824,370 ops/sec ±0.07% (102 runs sampled) gen-mapping: encoded output x 663 ops/sec ±0.22% (98 runs sampled) source-map-js: encoded output x 197 ops/sec ±0.45% (84 runs sampled) source-map-0.6.1: encoded output x 198 ops/sec ±0.33% (85 runs sampled) source-map-0.8.0: encoded output x 197 ops/sec ±0.06% (93 runs sampled) Fastest is gen-mapping: decoded output *** babel.min.js.map Memory Usage: gen-mapping: addSegment 37578063 bytes gen-mapping: addMapping 37212897 bytes source-map-js 47638527 bytes source-map-0.6.1 47690503 bytes source-map-0.8.0 47470188 bytes Smallest memory usage is gen-mapping: addMapping Adding speed: gen-mapping: addSegment x 31.05 ops/sec ±8.31% (43 runs sampled) gen-mapping: addMapping x 29.83 ops/sec ±7.36% (51 runs sampled) source-map-js: addMapping x 20.73 ops/sec ±6.22% (38 runs sampled) source-map-0.6.1: addMapping x 20.03 ops/sec ±10.51% (38 runs sampled) source-map-0.8.0: addMapping x 19.30 ops/sec ±8.27% (37 runs sampled) Fastest is gen-mapping: addSegment Generate speed: gen-mapping: decoded output x 381,379,234 ops/sec ±0.29% (96 runs sampled) gen-mapping: encoded output x 95.15 ops/sec ±2.98% (72 runs sampled) source-map-js: encoded output x 15.20 ops/sec ±7.41% (33 runs sampled) source-map-0.6.1: encoded output x 16.36 ops/sec ±10.46% (31 runs sampled) source-map-0.8.0: encoded output x 16.06 ops/sec ±6.45% (31 runs sampled) Fastest is gen-mapping: decoded output *** preact.js.map Memory Usage: gen-mapping: addSegment 416247 bytes gen-mapping: addMapping 419824 bytes source-map-js 1024619 bytes source-map-0.6.1 1146004 bytes source-map-0.8.0 1113250 bytes Smallest memory usage is gen-mapping: addSegment Adding speed: gen-mapping: addSegment x 13,755 ops/sec ±0.15% (98 runs sampled) gen-mapping: addMapping x 13,013 ops/sec ±0.11% (101 runs sampled) source-map-js: addMapping x 4,564 ops/sec ±0.21% (98 runs sampled) source-map-0.6.1: addMapping x 4,562 ops/sec ±0.11% (99 runs sampled) source-map-0.8.0: addMapping x 4,593 ops/sec ±0.11% (100 runs sampled) Fastest is gen-mapping: addSegment Generate speed: gen-mapping: decoded output x 379,864,020 ops/sec ±0.23% (93 runs sampled) gen-mapping: encoded output x 14,368 ops/sec ±4.07% (82 runs sampled) source-map-js: encoded output x 5,261 ops/sec ±0.21% (99 runs sampled) source-map-0.6.1: encoded output x 5,124 ops/sec ±0.58% (99 runs sampled) source-map-0.8.0: encoded output x 5,434 ops/sec ±0.33% (96 runs sampled) Fastest is gen-mapping: decoded output *** react.js.map Memory Usage: gen-mapping: addSegment 975096 bytes gen-mapping: addMapping 1102981 bytes source-map-js 2918836 bytes source-map-0.6.1 2885435 bytes source-map-0.8.0 2874336 bytes Smallest memory usage is gen-mapping: addSegment Adding speed: gen-mapping: addSegment x 4,772 ops/sec ±0.15% (100 runs sampled) gen-mapping: addMapping x 4,456 ops/sec ±0.13% (97 runs sampled) source-map-js: addMapping x 1,618 ops/sec ±0.24% (97 runs sampled) source-map-0.6.1: addMapping x 1,622 ops/sec ±0.12% (99 runs sampled) source-map-0.8.0: addMapping x 1,631 ops/sec ±0.12% (100 runs sampled) Fastest is gen-mapping: addSegment Generate speed: gen-mapping: decoded output x 379,107,695 ops/sec ±0.07% (99 runs sampled) gen-mapping: encoded output x 5,421 ops/sec ±1.60% (89 runs sampled) source-map-js: encoded output x 2,113 ops/sec ±1.81% (98 runs sampled) source-map-0.6.1: encoded output x 2,126 ops/sec ±0.10% (100 runs sampled) source-map-0.8.0: encoded output x 2,176 ops/sec ±0.39% (98 runs sampled) Fastest is gen-mapping: decoded output"
  },
  "src/frontend/app-client/node_modules/@jridgewell/resolve-uri/README.html": {
    "href": "src/frontend/app-client/node_modules/@jridgewell/resolve-uri/README.html",
    "title": "",
    "summary": "@jridgewell/resolve-uri Resolve a URI relative to an optional base URI Resolve any combination of absolute URIs, protocol-realtive URIs, absolute paths, or relative paths. Installation npm install @jridgewell/resolve-uri Usage function resolve(input: string, base?: string): string; import resolve from '@jridgewell/resolve-uri'; resolve('foo', 'https://example.com'); // => 'https://example.com/foo' Input Base Resolution Explanation https://example.com any https://example.com/ Input is normalized only //example.com https://base.com/ https://example.com/ Input inherits the base's protocol //example.com rest //example.com/ Input is normalized only /example https://base.com/ https://base.com/example Input inherits the base's origin /example //base.com/ //base.com/example Input inherits the base's host and remains protocol relative /example rest /example Input is normalized only example https://base.com/dir/ https://base.com/dir/example Input is joined with the base example https://base.com/file https://base.com/example Input is joined with the base without its file example //base.com/dir/ //base.com/dir/example Input is joined with the base's last directory example //base.com/file //base.com/example Input is joined with the base without its file example /base/dir/ /base/dir/example Input is joined with the base's last directory example /base/file /base/example Input is joined with the base without its file example base/dir/ base/dir/example Input is joined with the base's last directory example base/file base/example Input is joined with the base without its file"
  },
  "src/frontend/app-client/node_modules/@jridgewell/set-array/README.html": {
    "href": "src/frontend/app-client/node_modules/@jridgewell/set-array/README.html",
    "title": "",
    "summary": "@jridgewell/set-array Like a Set, but provides the index of the key in the backing array This is designed to allow synchronizing a second array with the contents of the backing array, like how in a sourcemap sourcesContent[i] is the source content associated with source[i], and there are never duplicates. Installation npm install @jridgewell/set-array Usage import { SetArray, get, put, pop } from '@jridgewell/set-array'; const sa = new SetArray(); let index = put(sa, 'first'); assert.strictEqual(index, 0); index = put(sa, 'second'); assert.strictEqual(index, 1); assert.deepEqual(sa.array, [ 'first', 'second' ]); index = get(sa, 'first'); assert.strictEqual(index, 0); pop(sa); index = get(sa, 'second'); assert.strictEqual(index, undefined); assert.deepEqual(sa.array, [ 'first' ]);"
  },
  "src/frontend/app-client/node_modules/@jridgewell/sourcemap-codec/README.html": {
    "href": "src/frontend/app-client/node_modules/@jridgewell/sourcemap-codec/README.html",
    "title": "",
    "summary": "@jridgewell/sourcemap-codec Encode/decode the mappings property of a sourcemap. Why? Sourcemaps are difficult to generate and manipulate, because the mappings property – the part that actually links the generated code back to the original source – is encoded using an obscure method called Variable-length quantity. On top of that, each segment in the mapping contains offsets rather than absolute indices, which means that you can't look at a segment in isolation – you have to understand the whole sourcemap. This package makes the process slightly easier. Installation npm install @jridgewell/sourcemap-codec Usage import { encode, decode } from '@jridgewell/sourcemap-codec'; var decoded = decode( ';EAEEA,EAAE,EAAC,CAAE;ECQY,UACC' ); assert.deepEqual( decoded, [ // the first line (of the generated code) has no mappings, // as shown by the starting semi-colon (which separates lines) [], // the second line contains four (comma-separated) segments [ // segments are encoded as you'd expect: // [ generatedCodeColumn, sourceIndex, sourceCodeLine, sourceCodeColumn, nameIndex ] // i.e. the first segment begins at column 2, and maps back to the second column // of the second line (both zero-based) of the 0th source, and uses the 0th // name in the `map.names` array [ 2, 0, 2, 2, 0 ], // the remaining segments are 4-length rather than 5-length, // because they don't map a name [ 4, 0, 2, 4 ], [ 6, 0, 2, 5 ], [ 7, 0, 2, 7 ] ], // the final line contains two segments [ [ 2, 1, 10, 19 ], [ 12, 1, 11, 20 ] ] ]); var encoded = encode( decoded ); assert.equal( encoded, ';EAEEA,EAAE,EAAC,CAAE;ECQY,UACC' ); Benchmarks node v20.10.0 amp.js.map - 45120 segments Decode Memory Usage: local code 5815135 bytes @jridgewell/sourcemap-codec 1.4.15 5868160 bytes sourcemap-codec 5492584 bytes source-map-0.6.1 13569984 bytes source-map-0.8.0 6390584 bytes chrome dev tools 8011136 bytes Smallest memory usage is sourcemap-codec Decode speed: decode: local code x 492 ops/sec ±1.22% (90 runs sampled) decode: @jridgewell/sourcemap-codec 1.4.15 x 499 ops/sec ±1.16% (89 runs sampled) decode: sourcemap-codec x 376 ops/sec ±1.66% (89 runs sampled) decode: source-map-0.6.1 x 34.99 ops/sec ±0.94% (48 runs sampled) decode: source-map-0.8.0 x 351 ops/sec ±0.07% (95 runs sampled) chrome dev tools x 165 ops/sec ±0.91% (86 runs sampled) Fastest is decode: @jridgewell/sourcemap-codec 1.4.15 Encode Memory Usage: local code 444248 bytes @jridgewell/sourcemap-codec 1.4.15 623024 bytes sourcemap-codec 8696280 bytes source-map-0.6.1 8745176 bytes source-map-0.8.0 8736624 bytes Smallest memory usage is local code Encode speed: encode: local code x 796 ops/sec ±0.11% (97 runs sampled) encode: @jridgewell/sourcemap-codec 1.4.15 x 795 ops/sec ±0.25% (98 runs sampled) encode: sourcemap-codec x 231 ops/sec ±0.83% (86 runs sampled) encode: source-map-0.6.1 x 166 ops/sec ±0.57% (86 runs sampled) encode: source-map-0.8.0 x 203 ops/sec ±0.45% (88 runs sampled) Fastest is encode: local code,encode: @jridgewell/sourcemap-codec 1.4.15 *** babel.min.js.map - 347793 segments Decode Memory Usage: local code 35424960 bytes @jridgewell/sourcemap-codec 1.4.15 35424696 bytes sourcemap-codec 36033464 bytes source-map-0.6.1 62253704 bytes source-map-0.8.0 43843920 bytes chrome dev tools 45111400 bytes Smallest memory usage is @jridgewell/sourcemap-codec 1.4.15 Decode speed: decode: local code x 38.18 ops/sec ±5.44% (52 runs sampled) decode: @jridgewell/sourcemap-codec 1.4.15 x 38.36 ops/sec ±5.02% (52 runs sampled) decode: sourcemap-codec x 34.05 ops/sec ±4.45% (47 runs sampled) decode: source-map-0.6.1 x 4.31 ops/sec ±2.76% (15 runs sampled) decode: source-map-0.8.0 x 55.60 ops/sec ±0.13% (73 runs sampled) chrome dev tools x 16.94 ops/sec ±3.78% (46 runs sampled) Fastest is decode: source-map-0.8.0 Encode Memory Usage: local code 2606016 bytes @jridgewell/sourcemap-codec 1.4.15 2626440 bytes sourcemap-codec 21152576 bytes source-map-0.6.1 25023928 bytes source-map-0.8.0 25256448 bytes Smallest memory usage is local code Encode speed: encode: local code x 127 ops/sec ±0.18% (83 runs sampled) encode: @jridgewell/sourcemap-codec 1.4.15 x 128 ops/sec ±0.26% (83 runs sampled) encode: sourcemap-codec x 29.31 ops/sec ±2.55% (53 runs sampled) encode: source-map-0.6.1 x 18.85 ops/sec ±3.19% (36 runs sampled) encode: source-map-0.8.0 x 19.34 ops/sec ±1.97% (36 runs sampled) Fastest is encode: @jridgewell/sourcemap-codec 1.4.15 *** preact.js.map - 1992 segments Decode Memory Usage: local code 261696 bytes @jridgewell/sourcemap-codec 1.4.15 244296 bytes sourcemap-codec 302816 bytes source-map-0.6.1 939176 bytes source-map-0.8.0 336 bytes chrome dev tools 587368 bytes Smallest memory usage is source-map-0.8.0 Decode speed: decode: local code x 17,782 ops/sec ±0.32% (97 runs sampled) decode: @jridgewell/sourcemap-codec 1.4.15 x 17,863 ops/sec ±0.40% (100 runs sampled) decode: sourcemap-codec x 12,453 ops/sec ±0.27% (101 runs sampled) decode: source-map-0.6.1 x 1,288 ops/sec ±1.05% (96 runs sampled) decode: source-map-0.8.0 x 9,289 ops/sec ±0.27% (101 runs sampled) chrome dev tools x 4,769 ops/sec ±0.18% (100 runs sampled) Fastest is decode: @jridgewell/sourcemap-codec 1.4.15 Encode Memory Usage: local code 262944 bytes @jridgewell/sourcemap-codec 1.4.15 25544 bytes sourcemap-codec 323048 bytes source-map-0.6.1 507808 bytes source-map-0.8.0 507480 bytes Smallest memory usage is @jridgewell/sourcemap-codec 1.4.15 Encode speed: encode: local code x 24,207 ops/sec ±0.79% (95 runs sampled) encode: @jridgewell/sourcemap-codec 1.4.15 x 24,288 ops/sec ±0.48% (96 runs sampled) encode: sourcemap-codec x 6,761 ops/sec ±0.21% (100 runs sampled) encode: source-map-0.6.1 x 5,374 ops/sec ±0.17% (99 runs sampled) encode: source-map-0.8.0 x 5,633 ops/sec ±0.32% (99 runs sampled) Fastest is encode: @jridgewell/sourcemap-codec 1.4.15,encode: local code *** react.js.map - 5726 segments Decode Memory Usage: local code 678816 bytes @jridgewell/sourcemap-codec 1.4.15 678816 bytes sourcemap-codec 816400 bytes source-map-0.6.1 2288864 bytes source-map-0.8.0 721360 bytes chrome dev tools 1012512 bytes Smallest memory usage is local code Decode speed: decode: local code x 6,178 ops/sec ±0.19% (98 runs sampled) decode: @jridgewell/sourcemap-codec 1.4.15 x 6,261 ops/sec ±0.22% (100 runs sampled) decode: sourcemap-codec x 4,472 ops/sec ±0.90% (99 runs sampled) decode: source-map-0.6.1 x 449 ops/sec ±0.31% (95 runs sampled) decode: source-map-0.8.0 x 3,219 ops/sec ±0.13% (100 runs sampled) chrome dev tools x 1,743 ops/sec ±0.20% (99 runs sampled) Fastest is decode: @jridgewell/sourcemap-codec 1.4.15 Encode Memory Usage: local code 140960 bytes @jridgewell/sourcemap-codec 1.4.15 159808 bytes sourcemap-codec 969304 bytes source-map-0.6.1 930520 bytes source-map-0.8.0 930248 bytes Smallest memory usage is local code Encode speed: encode: local code x 8,013 ops/sec ±0.19% (100 runs sampled) encode: @jridgewell/sourcemap-codec 1.4.15 x 7,989 ops/sec ±0.20% (101 runs sampled) encode: sourcemap-codec x 2,472 ops/sec ±0.21% (99 runs sampled) encode: source-map-0.6.1 x 2,200 ops/sec ±0.17% (99 runs sampled) encode: source-map-0.8.0 x 2,220 ops/sec ±0.37% (99 runs sampled) Fastest is encode: local code *** vscode.map - 2141001 segments Decode Memory Usage: local code 198955264 bytes @jridgewell/sourcemap-codec 1.4.15 199175352 bytes sourcemap-codec 199102688 bytes source-map-0.6.1 386323432 bytes source-map-0.8.0 244116432 bytes chrome dev tools 293734280 bytes Smallest memory usage is local code Decode speed: decode: local code x 3.90 ops/sec ±22.21% (15 runs sampled) decode: @jridgewell/sourcemap-codec 1.4.15 x 3.95 ops/sec ±23.53% (15 runs sampled) decode: sourcemap-codec x 3.82 ops/sec ±17.94% (14 runs sampled) decode: source-map-0.6.1 x 0.61 ops/sec ±7.81% (6 runs sampled) decode: source-map-0.8.0 x 9.54 ops/sec ±0.28% (28 runs sampled) chrome dev tools x 2.18 ops/sec ±10.58% (10 runs sampled) Fastest is decode: source-map-0.8.0 Encode Memory Usage: local code 13509880 bytes @jridgewell/sourcemap-codec 1.4.15 13537648 bytes sourcemap-codec 32540104 bytes source-map-0.6.1 127531040 bytes source-map-0.8.0 127535312 bytes Smallest memory usage is local code Encode speed: encode: local code x 20.10 ops/sec ±0.19% (38 runs sampled) encode: @jridgewell/sourcemap-codec 1.4.15 x 20.26 ops/sec ±0.32% (38 runs sampled) encode: sourcemap-codec x 5.44 ops/sec ±1.64% (18 runs sampled) encode: source-map-0.6.1 x 2.30 ops/sec ±4.79% (10 runs sampled) encode: source-map-0.8.0 x 2.46 ops/sec ±6.53% (10 runs sampled) Fastest is encode: @jridgewell/sourcemap-codec 1.4.15 License MIT"
  },
  "src/frontend/app-client/node_modules/@jridgewell/trace-mapping/README.html": {
    "href": "src/frontend/app-client/node_modules/@jridgewell/trace-mapping/README.html",
    "title": "",
    "summary": "@jridgewell/trace-mapping Trace the original position through a source map trace-mapping allows you to take the line and column of an output file and trace it to the original location in the source file through a source map. You may already be familiar with the source-map package's SourceMapConsumer. This provides the same originalPositionFor and generatedPositionFor API, without requiring WASM. Installation npm install @jridgewell/trace-mapping Usage import { TraceMap, originalPositionFor, generatedPositionFor, sourceContentFor, isIgnored, } from '@jridgewell/trace-mapping'; const tracer = new TraceMap({ version: 3, sources: ['input.js'], sourcesContent: ['content of input.js'], names: ['foo'], mappings: 'KAyCIA', ignoreList: [], }); // Lines start at line 1, columns at column 0. const traced = originalPositionFor(tracer, { line: 1, column: 5 }); assert.deepEqual(traced, { source: 'input.js', line: 42, column: 4, name: 'foo', }); const content = sourceContentFor(tracer, traced.source); assert.strictEqual(content, 'content for input.js'); const generated = generatedPositionFor(tracer, { source: 'input.js', line: 42, column: 4, }); assert.deepEqual(generated, { line: 1, column: 5, }); const ignored = isIgnored(tracer, 'input.js'); assert.equal(ignored, false); We also provide a lower level API to get the actual segment that matches our line and column. Unlike originalPositionFor, traceSegment uses a 0-base for line: import { traceSegment } from '@jridgewell/trace-mapping'; // line is 0-base. const traced = traceSegment(tracer, /* line */ 0, /* column */ 5); // Segments are [outputColumn, sourcesIndex, sourceLine, sourceColumn, namesIndex] // Again, line is 0-base and so is sourceLine assert.deepEqual(traced, [5, 0, 41, 4, 0]); SectionedSourceMaps The sourcemap spec defines a special sections field that's designed to handle concatenation of output code with associated sourcemaps. This type of sourcemap is rarely used (no major build tool produces it), but if you are hand coding a concatenation you may need it. We provide an AnyMap helper that can receive either a regular sourcemap or a SectionedSourceMap and returns a TraceMap instance: import { AnyMap } from '@jridgewell/trace-mapping'; const fooOutput = 'foo'; const barOutput = 'bar'; const output = [fooOutput, barOutput].join('\\n'); const sectioned = new AnyMap({ version: 3, sections: [ { // 0-base line and column offset: { line: 0, column: 0 }, // fooOutput's sourcemap map: { version: 3, sources: ['foo.js'], names: ['foo'], mappings: 'AAAAA', }, }, { // barOutput's sourcemap will not affect the first line, only the second offset: { line: 1, column: 0 }, map: { version: 3, sources: ['bar.js'], names: ['bar'], mappings: 'AAAAA', }, }, ], }); const traced = originalPositionFor(sectioned, { line: 2, column: 0, }); assert.deepEqual(traced, { source: 'bar.js', line: 1, column: 0, name: 'bar', }); Benchmarks node v18.0.0 amp.js.map - 45120 segments Memory Usage: trace-mapping decoded 562400 bytes trace-mapping encoded 5706544 bytes source-map-js 10717664 bytes source-map-0.6.1 17446384 bytes source-map-0.8.0 9701757 bytes Smallest memory usage is trace-mapping decoded Init speed: trace-mapping: decoded JSON input x 180 ops/sec ±0.34% (85 runs sampled) trace-mapping: encoded JSON input x 364 ops/sec ±1.77% (89 runs sampled) trace-mapping: decoded Object input x 3,116 ops/sec ±0.50% (96 runs sampled) trace-mapping: encoded Object input x 410 ops/sec ±2.62% (85 runs sampled) source-map-js: encoded Object input x 84.23 ops/sec ±0.91% (73 runs sampled) source-map-0.6.1: encoded Object input x 37.21 ops/sec ±2.08% (51 runs sampled) Fastest is trace-mapping: decoded Object input Trace speed: trace-mapping: decoded originalPositionFor x 3,952,212 ops/sec ±0.17% (98 runs sampled) trace-mapping: encoded originalPositionFor x 3,487,468 ops/sec ±1.58% (90 runs sampled) source-map-js: encoded originalPositionFor x 827,730 ops/sec ±0.78% (97 runs sampled) source-map-0.6.1: encoded originalPositionFor x 748,991 ops/sec ±0.53% (94 runs sampled) source-map-0.8.0: encoded originalPositionFor x 2,532,894 ops/sec ±0.57% (95 runs sampled) Fastest is trace-mapping: decoded originalPositionFor *** babel.min.js.map - 347793 segments Memory Usage: trace-mapping decoded 89832 bytes trace-mapping encoded 35474640 bytes source-map-js 51257176 bytes source-map-0.6.1 63515664 bytes source-map-0.8.0 42933752 bytes Smallest memory usage is trace-mapping decoded Init speed: trace-mapping: decoded JSON input x 15.41 ops/sec ±8.65% (34 runs sampled) trace-mapping: encoded JSON input x 28.20 ops/sec ±12.87% (42 runs sampled) trace-mapping: decoded Object input x 964 ops/sec ±0.36% (99 runs sampled) trace-mapping: encoded Object input x 31.77 ops/sec ±13.79% (45 runs sampled) source-map-js: encoded Object input x 6.45 ops/sec ±5.16% (21 runs sampled) source-map-0.6.1: encoded Object input x 4.07 ops/sec ±5.24% (15 runs sampled) Fastest is trace-mapping: decoded Object input Trace speed: trace-mapping: decoded originalPositionFor x 7,183,038 ops/sec ±0.58% (95 runs sampled) trace-mapping: encoded originalPositionFor x 5,192,185 ops/sec ±0.41% (100 runs sampled) source-map-js: encoded originalPositionFor x 4,259,489 ops/sec ±0.79% (94 runs sampled) source-map-0.6.1: encoded originalPositionFor x 3,742,629 ops/sec ±0.71% (95 runs sampled) source-map-0.8.0: encoded originalPositionFor x 6,270,211 ops/sec ±0.64% (94 runs sampled) Fastest is trace-mapping: decoded originalPositionFor *** preact.js.map - 1992 segments Memory Usage: trace-mapping decoded 37128 bytes trace-mapping encoded 247280 bytes source-map-js 1143536 bytes source-map-0.6.1 1290992 bytes source-map-0.8.0 96544 bytes Smallest memory usage is trace-mapping decoded Init speed: trace-mapping: decoded JSON input x 3,483 ops/sec ±0.30% (98 runs sampled) trace-mapping: encoded JSON input x 6,092 ops/sec ±0.18% (97 runs sampled) trace-mapping: decoded Object input x 249,076 ops/sec ±0.24% (98 runs sampled) trace-mapping: encoded Object input x 14,555 ops/sec ±0.48% (100 runs sampled) source-map-js: encoded Object input x 2,447 ops/sec ±0.36% (99 runs sampled) source-map-0.6.1: encoded Object input x 1,201 ops/sec ±0.57% (96 runs sampled) Fastest is trace-mapping: decoded Object input Trace speed: trace-mapping: decoded originalPositionFor x 7,620,192 ops/sec ±0.09% (99 runs sampled) trace-mapping: encoded originalPositionFor x 6,872,554 ops/sec ±0.30% (97 runs sampled) source-map-js: encoded originalPositionFor x 2,489,570 ops/sec ±0.35% (94 runs sampled) source-map-0.6.1: encoded originalPositionFor x 1,698,633 ops/sec ±0.28% (98 runs sampled) source-map-0.8.0: encoded originalPositionFor x 4,015,644 ops/sec ±0.22% (98 runs sampled) Fastest is trace-mapping: decoded originalPositionFor *** react.js.map - 5726 segments Memory Usage: trace-mapping decoded 16176 bytes trace-mapping encoded 681552 bytes source-map-js 2418352 bytes source-map-0.6.1 2443672 bytes source-map-0.8.0 111768 bytes Smallest memory usage is trace-mapping decoded Init speed: trace-mapping: decoded JSON input x 1,720 ops/sec ±0.34% (98 runs sampled) trace-mapping: encoded JSON input x 4,406 ops/sec ±0.35% (100 runs sampled) trace-mapping: decoded Object input x 92,122 ops/sec ±0.10% (99 runs sampled) trace-mapping: encoded Object input x 5,385 ops/sec ±0.37% (99 runs sampled) source-map-js: encoded Object input x 794 ops/sec ±0.40% (98 runs sampled) source-map-0.6.1: encoded Object input x 416 ops/sec ±0.54% (91 runs sampled) Fastest is trace-mapping: decoded Object input Trace speed: trace-mapping: decoded originalPositionFor x 32,759,519 ops/sec ±0.33% (100 runs sampled) trace-mapping: encoded originalPositionFor x 31,116,306 ops/sec ±0.33% (97 runs sampled) source-map-js: encoded originalPositionFor x 17,458,435 ops/sec ±0.44% (97 runs sampled) source-map-0.6.1: encoded originalPositionFor x 12,687,097 ops/sec ±0.43% (95 runs sampled) source-map-0.8.0: encoded originalPositionFor x 23,538,275 ops/sec ±0.38% (95 runs sampled) Fastest is trace-mapping: decoded originalPositionFor"
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-abstractions/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-abstractions/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog 1.0.0-preview.92 (2025-03-24) Bug Fixes Removes singleton registries (#1634) (8baf6e3) 1.0.0-preview.91 (2025-03-21) Miscellaneous Chores **@microsoft/kiota-abstractions:** Synchronize microsoft-kiota versions 1.0.0-preview.90 (2025-03-21) Bug Fixes revert to IterableIterator type (554acbc) 1.0.0-preview.89 (2025-03-19) Miscellaneous Chores **@microsoft/kiota-abstractions:** Synchronize microsoft-kiota versions 1.0.0-preview.88 (2025-03-19) Miscellaneous Chores **@microsoft/kiota-abstractions:** Synchronize microsoft-kiota versions 1.0.0-preview.87 (2025-03-17) Bug Fixes use compatible iterator types for the base types (9608918) use compatible iterator types for the base types (3b2c7fa) 1.0.0-preview.86 (2025-03-12) Miscellaneous Chores **@microsoft/kiota-abstractions:** Synchronize microsoft-kiota versions 1.0.0-preview.85 (2025-03-04) Miscellaneous Chores **@microsoft/kiota-abstractions:** Synchronize microsoft-kiota versions 1.0.0-preview.84 (2025-02-17) Features add support for filename in Content-Disposition header (29c4d09) Bug Fixes corrects SerializationWriter.writeByteArrayValue to ensure consistency with other method writers (e895a13) SerializationWriter.writeByteArrayValue should accept a null value (91bec86) 1.0.0-preview.83 (2025-02-13) Bug Fixes removes uuid package references (cba577f) removes uuid usage from backing store (f1b7911) 1.0.0-preview.82 (2025-02-03) Bug Fixes implements serialization of enum collections (0a09f5c) implements serialization of enum collections (#1578) (0a09f5c) 1.0.0-preview.81 (2025-01-31) Miscellaneous Chores **@microsoft/kiota-abstractions:** Synchronize microsoft-kiota versions 1.0.0-preview.80 (2025-01-21) Miscellaneous Chores **@microsoft/kiota-abstractions:** Synchronize microsoft-kiota versions 1.0.0-preview.79 (2025-01-09) Miscellaneous Chores **@microsoft/kiota-abstractions:** Synchronize microsoft-kiota versions 1.0.0-preview.78 (2024-12-19) Bug Fixes missing duration normalization (d78a9cb) update std-uritemplate to v2.0.0 (cf12831) 1.0.0-preview.77 (2024-11-22) Miscellaneous Chores **@microsoft/kiota-abstractions:** Synchronize microsoft-kiota versions 1.0.0-preview.76 (2024-11-21) Features abstractions: create empty guid (ebc1e39) 1.0.0-preview.75 (2024-11-11) Bug Fixes removed export for guid part generation (#1481) (e13ebd7) 1.0.0-preview.74 (2024-11-07) Bug Fixes getting rid of unnecessary guid-typescript dependency (ced60d1) getting rid of unnecessary guid-typescript dependency (706ce3c) using parseGuidString as validator function (7a7c9ed) 1.0.0-preview.73 (2024-11-05) Bug Fixes fix Eslint configuration to parse all files. (9a58d21) 1.0.0-preview.72 (2024-10-31) Bug Fixes resolve regression in serializeMultipartBody signature. (6434567) resolve regression in serializeMultipartBody signature. (507eff6) 1.0.0-preview.71 (2024-10-28) Miscellaneous Chores **@microsoft/kiota-abstractions:** Synchronize microsoft-kiota versions 1.0.0-preview.70 (2024-10-24) Features request body compression (#1358) (40440fb) 1.0.0-preview.69 (2024-10-22) Features request body compression (#1358) (40440fb) 1.0.0-preview.68 (2024-10-03) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151) 1.0.0-preview.67 (2024-10-03) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151)"
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-abstractions/README.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-abstractions/README.html",
    "title": "Microsoft Kiota Abstractions Library for TypeScript",
    "summary": "Microsoft Kiota Abstractions Library for TypeScript The Kiota abstractions Library is the TypeScript library defining the basic constructs the Kiota projects need once an SDK has been generated from an OpenAPI definition. A Kiota generated project will need a reference to the abstraction package to build and run. Read more about Kiota here. Using the abstractions In order to use this library, install the package by running: npm i @microsoft/kiota-abstractions Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Trademarks This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies."
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-authentication-azure/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-authentication-azure/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog 1.0.0-preview.92 (2025-03-24) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.91 to ^1.0.0-preview.92 1.0.0-preview.91 (2025-03-21) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.90 to ^1.0.0-preview.91 1.0.0-preview.90 (2025-03-21) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.89 to ^1.0.0-preview.90 1.0.0-preview.89 (2025-03-19) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.88 to ^1.0.0-preview.89 1.0.0-preview.88 (2025-03-19) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.87 to ^1.0.0-preview.88 1.0.0-preview.87 (2025-03-17) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.86 to ^1.0.0-preview.87 1.0.0-preview.86 (2025-03-12) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.85 to ^1.0.0-preview.86 1.0.0-preview.85 (2025-03-04) Bug Fixes adds missing observability options export (a544894) adds missing observability options export (87e76c9) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.84 to ^1.0.0-preview.85 1.0.0-preview.84 (2025-02-17) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.83 to ^1.0.0-preview.84 1.0.0-preview.83 (2025-02-13) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.82 to ^1.0.0-preview.83 1.0.0-preview.82 (2025-02-03) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.81 to ^1.0.0-preview.82 1.0.0-preview.81 (2025-01-31) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.80 to ^1.0.0-preview.81 1.0.0-preview.80 (2025-01-21) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.79 to ^1.0.0-preview.80 1.0.0-preview.79 (2025-01-09) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.78 to ^1.0.0-preview.79 1.0.0-preview.78 (2024-12-19) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.77 to ^1.0.0-preview.78 1.0.0-preview.77 (2024-11-22) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.76 to ^1.0.0-preview.77 1.0.0-preview.76 (2024-11-21) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.75 to ^1.0.0-preview.76 1.0.0-preview.75 (2024-11-11) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.74 to ^1.0.0-preview.75 1.0.0-preview.74 (2024-11-07) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.73 to ^1.0.0-preview.74 1.0.0-preview.73 (2024-11-05) Bug Fixes fix Eslint configuration to parse all files. (9a58d21) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.72 to ^1.0.0-preview.73 1.0.0-preview.72 (2024-10-31) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.71 to ^1.0.0-preview.72 1.0.0-preview.71 (2024-10-28) Bug Fixes set version in package files to be updated by release please (d33ddef) set version in package files to be updated by release please (4da42b6) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.70 to ^1.0.0-preview.71 1.0.0-preview.70 (2024-10-24) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions 1.0.0-preview.69 (2024-10-22) Miscellaneous Chores **@microsoft/kiota-authentication-azure:** Synchronize microsoft-kiota versions 1.0.0-preview.63 (2024-10-03) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151) 1.0.0-preview.62 (2024-10-03) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151)"
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-authentication-azure/README.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-authentication-azure/README.html",
    "title": "Microsoft Kiota Authentication Azure Library for TypeScript",
    "summary": "Microsoft Kiota Authentication Azure Library for TypeScript The Kiota Authentication Azure Library is an implementation to authenticate HTTP requests using @azure/identity. A Kiota generated project will need a reference to an authentication provider to make calls to an API endpoint. Read more about Kiota here. Using the Kiota Authentication Azure npm i @microsoft/kiota-authentication-azure -S. Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Trademarks This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies."
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-bundle/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-bundle/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog 1.0.0-preview.92 (2025-03-24) Bug Fixes Removes singleton registries (#1634) (8baf6e3) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.91 to ^1.0.0-preview.92 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.91 to ^1.0.0-preview.92 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.91 to ^1.0.0-preview.92 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.91 to ^1.0.0-preview.92 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.91 to ^1.0.0-preview.92 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.91 to ^1.0.0-preview.92 1.0.0-preview.91 (2025-03-21) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.90 to ^1.0.0-preview.91 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.90 to ^1.0.0-preview.91 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.90 to ^1.0.0-preview.91 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.90 to ^1.0.0-preview.91 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.90 to ^1.0.0-preview.91 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.90 to ^1.0.0-preview.91 1.0.0-preview.90 (2025-03-21) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.89 to ^1.0.0-preview.90 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.89 to ^1.0.0-preview.90 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.89 to ^1.0.0-preview.90 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.89 to ^1.0.0-preview.90 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.89 to ^1.0.0-preview.90 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.89 to ^1.0.0-preview.90 1.0.0-preview.89 (2025-03-19) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.88 to ^1.0.0-preview.89 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.88 to ^1.0.0-preview.89 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.88 to ^1.0.0-preview.89 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.88 to ^1.0.0-preview.89 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.88 to ^1.0.0-preview.89 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.88 to ^1.0.0-preview.89 1.0.0-preview.88 (2025-03-19) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.87 to ^1.0.0-preview.88 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.87 to ^1.0.0-preview.88 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.87 to ^1.0.0-preview.88 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.87 to ^1.0.0-preview.88 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.87 to ^1.0.0-preview.88 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.87 to ^1.0.0-preview.88 1.0.0-preview.87 (2025-03-17) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.86 to ^1.0.0-preview.87 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.86 to ^1.0.0-preview.87 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.86 to ^1.0.0-preview.87 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.86 to ^1.0.0-preview.87 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.86 to ^1.0.0-preview.87 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.86 to ^1.0.0-preview.87 1.0.0-preview.86 (2025-03-12) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.85 to ^1.0.0-preview.86 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.85 to ^1.0.0-preview.86 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.85 to ^1.0.0-preview.86 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.85 to ^1.0.0-preview.86 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.85 to ^1.0.0-preview.86 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.85 to ^1.0.0-preview.86 1.0.0-preview.85 (2025-03-04) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.84 to ^1.0.0-preview.85 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.84 to ^1.0.0-preview.85 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.84 to ^1.0.0-preview.85 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.84 to ^1.0.0-preview.85 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.84 to ^1.0.0-preview.85 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.84 to ^1.0.0-preview.85 1.0.0-preview.84 (2025-02-17) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.83 to ^1.0.0-preview.84 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.83 to ^1.0.0-preview.84 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.83 to ^1.0.0-preview.84 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.83 to ^1.0.0-preview.84 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.83 to ^1.0.0-preview.84 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.83 to ^1.0.0-preview.84 1.0.0-preview.83 (2025-02-13) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.82 to ^1.0.0-preview.83 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.82 to ^1.0.0-preview.83 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.82 to ^1.0.0-preview.83 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.82 to ^1.0.0-preview.83 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.82 to ^1.0.0-preview.83 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.82 to ^1.0.0-preview.83 1.0.0-preview.82 (2025-02-03) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.81 to ^1.0.0-preview.82 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.81 to ^1.0.0-preview.82 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.81 to ^1.0.0-preview.82 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.81 to ^1.0.0-preview.82 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.81 to ^1.0.0-preview.82 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.81 to ^1.0.0-preview.82 1.0.0-preview.81 (2025-01-31) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.80 to ^1.0.0-preview.81 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.80 to ^1.0.0-preview.81 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.80 to ^1.0.0-preview.81 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.80 to ^1.0.0-preview.81 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.80 to ^1.0.0-preview.81 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.80 to ^1.0.0-preview.81 1.0.0-preview.80 (2025-01-21) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.79 to ^1.0.0-preview.80 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.79 to ^1.0.0-preview.80 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.79 to ^1.0.0-preview.80 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.79 to ^1.0.0-preview.80 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.79 to ^1.0.0-preview.80 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.79 to ^1.0.0-preview.80 1.0.0-preview.79 (2025-01-09) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.78 to ^1.0.0-preview.79 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.78 to ^1.0.0-preview.79 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.78 to ^1.0.0-preview.79 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.78 to ^1.0.0-preview.79 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.78 to ^1.0.0-preview.79 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.78 to ^1.0.0-preview.79 1.0.0-preview.78 (2024-12-19) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.77 to ^1.0.0-preview.78 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.77 to ^1.0.0-preview.78 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.77 to ^1.0.0-preview.78 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.77 to ^1.0.0-preview.78 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.77 to ^1.0.0-preview.78 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.77 to ^1.0.0-preview.78 1.0.0-preview.77 (2024-11-22) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.76 to ^1.0.0-preview.77 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.76 to ^1.0.0-preview.77 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.76 to ^1.0.0-preview.77 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.76 to ^1.0.0-preview.77 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.76 to ^1.0.0-preview.77 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.76 to ^1.0.0-preview.77 1.0.0-preview.76 (2024-11-21) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.75 to ^1.0.0-preview.76 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.75 to ^1.0.0-preview.76 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.75 to ^1.0.0-preview.76 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.75 to ^1.0.0-preview.76 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.75 to ^1.0.0-preview.76 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.75 to ^1.0.0-preview.76 1.0.0-preview.75 (2024-11-11) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.74 to ^1.0.0-preview.75 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.74 to ^1.0.0-preview.75 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.74 to ^1.0.0-preview.75 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.74 to ^1.0.0-preview.75 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.74 to ^1.0.0-preview.75 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.74 to ^1.0.0-preview.75 1.0.0-preview.74 (2024-11-07) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.73 to ^1.0.0-preview.74 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.73 to ^1.0.0-preview.74 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.73 to ^1.0.0-preview.74 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.73 to ^1.0.0-preview.74 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.73 to ^1.0.0-preview.74 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.73 to ^1.0.0-preview.74 1.0.0-preview.73 (2024-11-05) Bug Fixes fix Eslint configuration to parse all files. (9a58d21) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.72 to ^1.0.0-preview.73 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.72 to ^1.0.0-preview.73 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.72 to ^1.0.0-preview.73 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.72 to ^1.0.0-preview.73 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.72 to ^1.0.0-preview.73 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.72 to ^1.0.0-preview.73 1.0.0-preview.72 (2024-10-31) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.71 to ^1.0.0-preview.72 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.71 to ^1.0.0-preview.72 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.71 to ^1.0.0-preview.72 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.71 to ^1.0.0-preview.72 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.71 to ^1.0.0-preview.72 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.71 to ^1.0.0-preview.72 1.0.0-preview.71 (2024-10-28) Bug Fixes set version in package files to be updated by release please (d33ddef) set version in package files to be updated by release please (4da42b6) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.70 to ^1.0.0-preview.71 @microsoft/kiota-http-fetchlibrary bumped from ^1.0.0-preview.70 to ^1.0.0-preview.71 @microsoft/kiota-serialization-form bumped from ^1.0.0-preview.70 to ^1.0.0-preview.71 @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.70 to ^1.0.0-preview.71 @microsoft/kiota-serialization-multipart bumped from ^1.0.0-preview.70 to ^1.0.0-preview.71 @microsoft/kiota-serialization-text bumped from ^1.0.0-preview.70 to ^1.0.0-preview.71 1.0.0-preview.70 (2024-10-24) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions 1.0.0-preview.69 (2024-10-22) Miscellaneous Chores **@microsoft/kiota-bundle:** Synchronize microsoft-kiota versions 1.0.0-preview.11 (2024-10-03) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151) 1.0.0-preview.10 (2024-10-03) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151)"
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-bundle/README.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-bundle/README.html",
    "title": "Microsoft Kiota Bundle library for TypeScript",
    "summary": "Microsoft Kiota Bundle library for TypeScript The Kiota Bundle Library provides default implementations for client setup. The package provides a request adapter implementation with defaults serialization libraries setup fo use with a generated Kiota client. Read more about Kiota here. Using the bundle npm i @microsoft/kiota-bundle Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Trademarks This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies."
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-http-fetchlibrary/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-http-fetchlibrary/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog 1.0.0-preview.92 (2025-03-24) Bug Fixes Removes singleton registries (#1634) (8baf6e3) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.91 to ^1.0.0-preview.92 1.0.0-preview.91 (2025-03-21) Miscellaneous Chores **@microsoft/kiota-http-fetchlibrary:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.90 to ^1.0.0-preview.91 1.0.0-preview.90 (2025-03-21) Miscellaneous Chores **@microsoft/kiota-http-fetchlibrary:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.89 to ^1.0.0-preview.90 1.0.0-preview.89 (2025-03-19) Miscellaneous Chores **@microsoft/kiota-http-fetchlibrary:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.88 to ^1.0.0-preview.89 1.0.0-preview.88 (2025-03-19) Bug Fixes error Operation attempted on ended Span (fc930f6) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.87 to ^1.0.0-preview.88 1.0.0-preview.87 (2025-03-17) Miscellaneous Chores **@microsoft/kiota-http-fetchlibrary:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.86 to ^1.0.0-preview.87 1.0.0-preview.86 (2025-03-12) Miscellaneous Chores **@microsoft/kiota-http-fetchlibrary:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.85 to ^1.0.0-preview.86 1.0.0-preview.85 (2025-03-04) Miscellaneous Chores **@microsoft/kiota-http-fetchlibrary:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.84 to ^1.0.0-preview.85 1.0.0-preview.84 (2025-02-17) Miscellaneous Chores **@microsoft/kiota-http-fetchlibrary:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.83 to ^1.0.0-preview.84 1.0.0-preview.83 (2025-02-13) Miscellaneous Chores **@microsoft/kiota-http-fetchlibrary:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.82 to ^1.0.0-preview.83 1.0.0-preview.82 (2025-02-03) Miscellaneous Chores **@microsoft/kiota-http-fetchlibrary:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.81 to ^1.0.0-preview.82 1.0.0-preview.81 (2025-01-31) Features adds authorization handler (#1575) (f9ff6ab) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.80 to ^1.0.0-preview.81 1.0.0-preview.80 (2025-01-21) Features disable default compression (72e7011) disable default compression (8ed62c2) Bug Fixes handle 3XX responses (5145d6a) handles 3xx responses with no header (856de64) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.79 to ^1.0.0-preview.80 1.0.0-preview.79 (2025-01-09) Features adds url replacement as a default (#1540) (acca423) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.78 to ^1.0.0-preview.79 1.0.0-preview.78 (2024-12-19) Miscellaneous Chores **@microsoft/kiota-http-fetchlibrary:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.77 to ^1.0.0-preview.78 1.0.0-preview.77 (2024-11-22) Bug Fixes remove zlib compression in node (e8ceb56) remove zlib compression in node (5a80e23) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.76 to ^1.0.0-preview.77 1.0.0-preview.76 (2024-11-21) Miscellaneous Chores **@microsoft/kiota-http-fetchlibrary:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.75 to ^1.0.0-preview.76 1.0.0-preview.75 (2024-11-11) Miscellaneous Chores **@microsoft/kiota-http-fetchlibrary:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.74 to ^1.0.0-preview.75 1.0.0-preview.74 (2024-11-07) Bug Fixes getting rid of unnecessary guid-typescript dependency (ced60d1) getting rid of unnecessary guid-typescript dependency (706ce3c) using parseGuidString as validator function (7a7c9ed) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.73 to ^1.0.0-preview.74 1.0.0-preview.73 (2024-11-05) Bug Fixes fix Eslint configuration to parse all files. (9a58d21) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.72 to ^1.0.0-preview.73 1.0.0-preview.72 (2024-10-31) Miscellaneous Chores **@microsoft/kiota-http-fetchlibrary:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.71 to ^1.0.0-preview.72 1.0.0-preview.71 (2024-10-28) Bug Fixes set version in package files to be updated by release please (d33ddef) set version in package files to be updated by release please (4da42b6) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.70 to ^1.0.0-preview.71 1.0.0-preview.70 (2024-10-24) Features request body compression (#1358) (40440fb) 1.0.0-preview.69 (2024-10-22) Features request body compression (#1358) (40440fb) 1.0.0-preview.67 (2024-10-03) Features add release please (#1366) (59d3177) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151) 1.0.0-preview.66 (2024-10-03) Features add release please (#1366) (59d3177) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151)"
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-http-fetchlibrary/README.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-http-fetchlibrary/README.html",
    "title": "Microsoft Kiota HTTP - Fetch library",
    "summary": "Microsoft Kiota HTTP - Fetch library The Kiota Http Fetch Library is an implementation using the Fetch API to make requests. A Kiota generated project will need a reference to an HTTP implementation to make calls to an API endpoint. Read more about Kiota here. Using the Kiota Fetch library implementations npm i @microsoft/kiota-http-fetchlibrary. Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Trademarks This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies."
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-form/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-form/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog 1.0.0-preview.92 (2025-03-24) Bug Fixes Removes singleton registries (#1634) (8baf6e3) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.91 to ^1.0.0-preview.92 1.0.0-preview.91 (2025-03-21) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.90 to ^1.0.0-preview.91 1.0.0-preview.90 (2025-03-21) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.89 to ^1.0.0-preview.90 1.0.0-preview.89 (2025-03-19) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.88 to ^1.0.0-preview.89 1.0.0-preview.88 (2025-03-19) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.87 to ^1.0.0-preview.88 1.0.0-preview.87 (2025-03-17) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.86 to ^1.0.0-preview.87 1.0.0-preview.86 (2025-03-12) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.85 to ^1.0.0-preview.86 1.0.0-preview.85 (2025-03-04) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.84 to ^1.0.0-preview.85 1.0.0-preview.84 (2025-02-17) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.83 to ^1.0.0-preview.84 1.0.0-preview.83 (2025-02-13) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.82 to ^1.0.0-preview.83 1.0.0-preview.82 (2025-02-03) Bug Fixes implements serialization of enum collections (0a09f5c) implements serialization of enum collections (#1578) (0a09f5c) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.81 to ^1.0.0-preview.82 1.0.0-preview.81 (2025-01-31) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.80 to ^1.0.0-preview.81 1.0.0-preview.80 (2025-01-21) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.79 to ^1.0.0-preview.80 1.0.0-preview.79 (2025-01-09) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.78 to ^1.0.0-preview.79 1.0.0-preview.78 (2024-12-19) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.77 to ^1.0.0-preview.78 1.0.0-preview.77 (2024-11-22) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.76 to ^1.0.0-preview.77 1.0.0-preview.76 (2024-11-21) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.75 to ^1.0.0-preview.76 1.0.0-preview.75 (2024-11-11) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.74 to ^1.0.0-preview.75 1.0.0-preview.74 (2024-11-07) Bug Fixes getting rid of unnecessary guid-typescript dependency (ced60d1) getting rid of unnecessary guid-typescript dependency (706ce3c) using parseGuidString as validator function (7a7c9ed) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.73 to ^1.0.0-preview.74 1.0.0-preview.73 (2024-11-05) Bug Fixes fix Eslint configuration to parse all files. (9a58d21) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.72 to ^1.0.0-preview.73 1.0.0-preview.72 (2024-10-31) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.71 to ^1.0.0-preview.72 1.0.0-preview.71 (2024-10-28) Bug Fixes set version in package files to be updated by release please (d33ddef) set version in package files to be updated by release please (4da42b6) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.70 to ^1.0.0-preview.71 1.0.0-preview.70 (2024-10-24) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions 1.0.0-preview.69 (2024-10-22) Miscellaneous Chores **@microsoft/kiota-serialization-form:** Synchronize microsoft-kiota versions 1.0.0-preview.56 (2024-10-03) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151) 1.0.0-preview.55 (2024-10-03) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151)"
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-form/README.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-form/README.html",
    "title": "Microsoft Kiota URI Form Encoded Serialization Library for TypeScript",
    "summary": "Microsoft Kiota URI Form Encoded Serialization Library for TypeScript The Form Serialization Library is an implementation to handle URI form encoded payloads. A Kiota generated project will need a reference to a form serialization package to handle URI form encoded payloads from an API endpoint. Read more about Kiota here. Using the Serialization Form implementations npm i @microsoft/kiota-serialization-form. Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Trademarks This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies."
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-json/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-json/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog 1.0.0-preview.92 (2025-03-24) Bug Fixes Removes singleton registries (#1634) (8baf6e3) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.91 to ^1.0.0-preview.92 1.0.0-preview.91 (2025-03-21) Bug Fixes prevent error on undefined byte array value in serialization writers (de80b9a) prevent error on undefined byte array value in serialization writers (cf96887) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.90 to ^1.0.0-preview.91 1.0.0-preview.90 (2025-03-21) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.89 to ^1.0.0-preview.90 1.0.0-preview.89 (2025-03-19) Bug Fixes json parser ArrayBuffer memory leak (968a4fa) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.88 to ^1.0.0-preview.89 1.0.0-preview.88 (2025-03-19) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.87 to ^1.0.0-preview.88 1.0.0-preview.87 (2025-03-17) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.86 to ^1.0.0-preview.87 1.0.0-preview.86 (2025-03-12) Bug Fixes a bug where additional data would not go to the dedicated property (145fc50) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.85 to ^1.0.0-preview.86 1.0.0-preview.85 (2025-03-04) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.84 to ^1.0.0-preview.85 1.0.0-preview.84 (2025-02-17) Bug Fixes corrects SerializationWriter.writeByteArrayValue to ensure consistency with other method writers (e895a13) SerializationWriter.writeByteArrayValue should accept a null value (91bec86) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.83 to ^1.0.0-preview.84 1.0.0-preview.83 (2025-02-13) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.82 to ^1.0.0-preview.83 1.0.0-preview.82 (2025-02-03) Bug Fixes implements serialization of enum collections (0a09f5c) implements serialization of enum collections (#1578) (0a09f5c) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.81 to ^1.0.0-preview.82 1.0.0-preview.81 (2025-01-31) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.80 to ^1.0.0-preview.81 1.0.0-preview.80 (2025-01-21) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.79 to ^1.0.0-preview.80 1.0.0-preview.79 (2025-01-09) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.78 to ^1.0.0-preview.79 1.0.0-preview.78 (2024-12-19) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.77 to ^1.0.0-preview.78 1.0.0-preview.77 (2024-11-22) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.76 to ^1.0.0-preview.77 1.0.0-preview.76 (2024-11-21) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.75 to ^1.0.0-preview.76 1.0.0-preview.75 (2024-11-11) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.74 to ^1.0.0-preview.75 1.0.0-preview.74 (2024-11-07) Bug Fixes getting rid of unnecessary guid-typescript dependency (ced60d1) getting rid of unnecessary guid-typescript dependency (706ce3c) using parseGuidString as validator function (7a7c9ed) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.73 to ^1.0.0-preview.74 1.0.0-preview.73 (2024-11-05) Bug Fixes fix Eslint configuration to parse all files. (9a58d21) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.72 to ^1.0.0-preview.73 1.0.0-preview.72 (2024-10-31) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.71 to ^1.0.0-preview.72 1.0.0-preview.71 (2024-10-28) Bug Fixes set version in package files to be updated by release please (d33ddef) set version in package files to be updated by release please (4da42b6) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.70 to ^1.0.0-preview.71 1.0.0-preview.70 (2024-10-24) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions 1.0.0-preview.69 (2024-10-22) Miscellaneous Chores **@microsoft/kiota-serialization-json:** Synchronize microsoft-kiota versions 1.0.0-preview.68 (2024-10-03) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151) 1.0.0-preview.67 (2024-10-03) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151)"
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-json/README.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-json/README.html",
    "title": "Microsoft Kiota JSON Serialization library for TypeScript",
    "summary": "Microsoft Kiota JSON Serialization library for TypeScript The JSON Serialization Library is an implementation to handle JSON payloads. A Kiota generated project will need a reference to a JSON serialization package to handle JSON payloads from an API endpoint. Read more about Kiota here. Using the Serialization JSON implementations npm i @microsoft/kiota-serialization-json. Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Trademarks This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies."
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-multipart/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-multipart/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog 1.0.0-preview.92 (2025-03-24) Bug Fixes Removes singleton registries (#1634) (8baf6e3) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.91 to ^1.0.0-preview.92 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.91 to ^1.0.0-preview.92 1.0.0-preview.91 (2025-03-21) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.90 to ^1.0.0-preview.91 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.90 to ^1.0.0-preview.91 1.0.0-preview.90 (2025-03-21) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.89 to ^1.0.0-preview.90 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.89 to ^1.0.0-preview.90 1.0.0-preview.89 (2025-03-19) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.88 to ^1.0.0-preview.89 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.88 to ^1.0.0-preview.89 1.0.0-preview.88 (2025-03-19) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.87 to ^1.0.0-preview.88 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.87 to ^1.0.0-preview.88 1.0.0-preview.87 (2025-03-17) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.86 to ^1.0.0-preview.87 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.86 to ^1.0.0-preview.87 1.0.0-preview.86 (2025-03-12) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.85 to ^1.0.0-preview.86 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.85 to ^1.0.0-preview.86 1.0.0-preview.85 (2025-03-04) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.84 to ^1.0.0-preview.85 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.84 to ^1.0.0-preview.85 1.0.0-preview.84 (2025-02-17) Features add support for filename in Content-Disposition header (29c4d09) Bug Fixes corrects SerializationWriter.writeByteArrayValue to ensure consistency with other method writers (e895a13) SerializationWriter.writeByteArrayValue should accept a null value (91bec86) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.83 to ^1.0.0-preview.84 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.83 to ^1.0.0-preview.84 1.0.0-preview.83 (2025-02-13) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.82 to ^1.0.0-preview.83 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.82 to ^1.0.0-preview.83 1.0.0-preview.82 (2025-02-03) Bug Fixes implements serialization of enum collections (0a09f5c) implements serialization of enum collections (#1578) (0a09f5c) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.81 to ^1.0.0-preview.82 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.81 to ^1.0.0-preview.82 1.0.0-preview.81 (2025-01-31) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.80 to ^1.0.0-preview.81 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.80 to ^1.0.0-preview.81 1.0.0-preview.80 (2025-01-21) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.79 to ^1.0.0-preview.80 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.79 to ^1.0.0-preview.80 1.0.0-preview.79 (2025-01-09) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.78 to ^1.0.0-preview.79 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.78 to ^1.0.0-preview.79 1.0.0-preview.78 (2024-12-19) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.77 to ^1.0.0-preview.78 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.77 to ^1.0.0-preview.78 1.0.0-preview.77 (2024-11-22) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.76 to ^1.0.0-preview.77 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.76 to ^1.0.0-preview.77 1.0.0-preview.76 (2024-11-21) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.75 to ^1.0.0-preview.76 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.75 to ^1.0.0-preview.76 1.0.0-preview.75 (2024-11-11) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.74 to ^1.0.0-preview.75 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.74 to ^1.0.0-preview.75 1.0.0-preview.74 (2024-11-07) Bug Fixes getting rid of unnecessary guid-typescript dependency (ced60d1) getting rid of unnecessary guid-typescript dependency (706ce3c) using parseGuidString as validator function (7a7c9ed) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.73 to ^1.0.0-preview.74 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.73 to ^1.0.0-preview.74 1.0.0-preview.73 (2024-11-05) Bug Fixes fix Eslint configuration to parse all files. (9a58d21) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.72 to ^1.0.0-preview.73 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.72 to ^1.0.0-preview.73 1.0.0-preview.72 (2024-10-31) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.71 to ^1.0.0-preview.72 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.71 to ^1.0.0-preview.72 1.0.0-preview.71 (2024-10-28) Bug Fixes set version in package files to be updated by release please (d33ddef) set version in package files to be updated by release please (4da42b6) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.70 to ^1.0.0-preview.71 devDependencies @microsoft/kiota-serialization-json bumped from ^1.0.0-preview.70 to ^1.0.0-preview.71 1.0.0-preview.70 (2024-10-24) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions 1.0.0-preview.69 (2024-10-22) Miscellaneous Chores **@microsoft/kiota-serialization-multipart:** Synchronize microsoft-kiota versions 1.0.0-preview.46 (2024-10-03) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151) 1.0.0-preview.45 (2024-10-03) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151)"
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-multipart/README.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-multipart/README.html",
    "title": "Microsoft Kiota Multipart Serialization Library for TypeScript",
    "summary": "Microsoft Kiota Multipart Serialization Library for TypeScript The Multipart Serialization Library is an implementation to handle multipart form data payloads. A Kiota generated project will need a reference to a form serialization package to handle multipart encoded payloads from an API endpoint. Read more about Kiota here. Using the Serialization Multipart implementations npm i @microsoft/kiota-serialization-multipart. Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Trademarks This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies."
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-text/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-text/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog 1.0.0-preview.92 (2025-03-24) Bug Fixes Removes singleton registries (#1634) (8baf6e3) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.91 to ^1.0.0-preview.92 1.0.0-preview.91 (2025-03-21) Bug Fixes prevent error on undefined byte array value in serialization writers (de80b9a) prevent error on undefined byte array value in serialization writers (cf96887) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.90 to ^1.0.0-preview.91 1.0.0-preview.90 (2025-03-21) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.89 to ^1.0.0-preview.90 1.0.0-preview.89 (2025-03-19) Bug Fixes json parser ArrayBuffer memory leak (968a4fa) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.88 to ^1.0.0-preview.89 1.0.0-preview.88 (2025-03-19) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.87 to ^1.0.0-preview.88 1.0.0-preview.87 (2025-03-17) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.86 to ^1.0.0-preview.87 1.0.0-preview.86 (2025-03-12) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.85 to ^1.0.0-preview.86 1.0.0-preview.85 (2025-03-04) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.84 to ^1.0.0-preview.85 1.0.0-preview.84 (2025-02-17) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.83 to ^1.0.0-preview.84 1.0.0-preview.83 (2025-02-13) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.82 to ^1.0.0-preview.83 1.0.0-preview.82 (2025-02-03) Bug Fixes implements serialization of enum collections (0a09f5c) implements serialization of enum collections (#1578) (0a09f5c) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.81 to ^1.0.0-preview.82 1.0.0-preview.81 (2025-01-31) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.80 to ^1.0.0-preview.81 1.0.0-preview.80 (2025-01-21) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.79 to ^1.0.0-preview.80 1.0.0-preview.79 (2025-01-09) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.78 to ^1.0.0-preview.79 1.0.0-preview.78 (2024-12-19) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.77 to ^1.0.0-preview.78 1.0.0-preview.77 (2024-11-22) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.76 to ^1.0.0-preview.77 1.0.0-preview.76 (2024-11-21) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.75 to ^1.0.0-preview.76 1.0.0-preview.75 (2024-11-11) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.74 to ^1.0.0-preview.75 1.0.0-preview.74 (2024-11-07) Bug Fixes getting rid of unnecessary guid-typescript dependency (ced60d1) getting rid of unnecessary guid-typescript dependency (706ce3c) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.73 to ^1.0.0-preview.74 1.0.0-preview.73 (2024-11-05) Bug Fixes fix Eslint configuration to parse all files. (9a58d21) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.72 to ^1.0.0-preview.73 1.0.0-preview.72 (2024-10-31) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.71 to ^1.0.0-preview.72 1.0.0-preview.71 (2024-10-28) Bug Fixes set version in package files to be updated by release please (d33ddef) set version in package files to be updated by release please (4da42b6) Dependencies The following workspace dependencies were updated dependencies @microsoft/kiota-abstractions bumped from ^1.0.0-preview.70 to ^1.0.0-preview.71 1.0.0-preview.70 (2024-10-24) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions 1.0.0-preview.69 (2024-10-22) Miscellaneous Chores **@microsoft/kiota-serialization-text:** Synchronize microsoft-kiota versions 1.0.0-preview.65 (2024-10-03) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151) 1.0.0-preview.64 (2024-10-03) Bug Fixes fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (f69c934) fixes serializeMultipartBody function to match the ModelSerializerFunction<Parsable> type after updates made in https://github.com/microsoft/kiota-typescript/pull/1248 (d58d949) release please configuration tag alignment (5d4f2ab) release please configuration tag alignment (4cc0151)"
  },
  "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-text/README.html": {
    "href": "src/frontend/app-client/node_modules/@microsoft/kiota-serialization-text/README.html",
    "title": "Microsoft Kiota Text Serialization Library for Python",
    "summary": "Microsoft Kiota Text Serialization Library for Python The Text Serialization Library is an implementation to handle text/plain payloads. A Kiota generated project will need a reference to a Text serialization package to handle text/plain payloads from an API endpoint. Read more about Kiota here. Using the Serialization text implementations npm i @microsoft/kiota-serialization-text. Contributing This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com. When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA. This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Trademarks This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies."
  },
  "src/frontend/app-client/node_modules/@mjackson/node-fetch-server/README.html": {
    "href": "src/frontend/app-client/node_modules/@mjackson/node-fetch-server/README.html",
    "title": "node-fetch-server",
    "summary": "node-fetch-server node-fetch-server allows you to build servers for Node.js that use the web Fetch API primitives (namely Request and Response) instead of the traditional req/res API used in libraries like Express. This web standard API is already used in many places across the JavaScript ecosystem: Bun.serve Cloudflare Workers Deno.serve Fastly Compute When you write servers using the Request and Response APIs, you maximize the chances that your code will be portable across these different JavaScript runtimes. Features Use web standard Request and Response APIs for building servers, instead of node-specific API Seamless integration with node:http and node:https modules Supports custom hostnames (e.g. using process.env.HOST on a VPS to set the host portion of incoming request URLs) Supports streaming responses using new Response(stream) Exposes remote client address info Installation npm install @mjackson/node-fetch-server Usage import * as http from 'node:http'; import { createRequestListener } from '@mjackson/node-fetch-server'; let handler = (request: Request) => { return new Response('Hello, world!'); }; let server = http.createServer(createRequestListener(handler)); server.listen(3000); By default request.url is derived from the value of the Host HTTP header and the connection protocol being used. To support custom hostnames using e.g. a HOST environment variable, you can use the host option: import * as assert from 'node:assert/strict'; import * as http from 'node:http'; import { createRequestListener } from '@mjackson/node-fetch-server'; let handler = (request: Request) => { // This is now true assert.equal(new URL(request.url).host, process.env.HOST); return new Response('Hello, world!'); }; let server = http.createServer(createRequestListener(handler, { host: process.env.HOST })); server.listen(3000); Information about the remote client IP and port is passed as the 2nd argument to your FetchHandler: import { type FetchHandler } from '@mjackson/node-fetch-server'; let handler: FetchHandler = (request, client) => { return new Response(`The client IP address is ${client.address}`); }; Related Packages fetch-proxy - Build HTTP proxy servers using the web fetch API Benchmark A basic \"hello world\" benchmark shows node-fetch-server introduces considerable overhead on top of a vanilla node:http server. However, it is still able to serve more requests per second (and has higher overall throughput) than Express v4, so the slowdown should be acceptable for most applications. > @mjackson/node-fetch-server@0.0.0 bench /Users/michael/Projects/remix-the-web/packages/node-fetch-server > bash ./bench/runner.sh Platform: Darwin (24.0.0) CPU: Apple M1 Pro Date: 11/14/2024, 2:30:22 PM Running benchmark for node:http@22.8.0 ... Running 30s test @ http://127.0.0.1:3000/ 12 threads and 400 connections Thread Stats Avg Stdev Max +/- Stdev Latency 9.97ms 31.92ms 786.67ms 99.09% Req/Sec 4.45k 268.33 6.38k 93.69% 1594257 requests in 30.02s, 326.89MB read Socket errors: connect 0, read 1317, write 6, timeout 0 Requests/sec: 53110.92 Transfer/sec: 10.89MB Running benchmark for node-fetch-server@0.1.0 ... Running 30s test @ http://127.0.0.1:3000/ 12 threads and 400 connections Thread Stats Avg Stdev Max +/- Stdev Latency 22.74ms 81.06ms 1.46s 98.22% Req/Sec 2.42k 185.82 4.30k 91.80% 866347 requests in 30.03s, 177.64MB read Socket errors: connect 0, read 1496, write 3, timeout 0 Requests/sec: 28849.46 Transfer/sec: 5.92MB Running benchmark for express@4.19.2 ... Running 30s test @ http://127.0.0.1:3000/ 12 threads and 400 connections Thread Stats Avg Stdev Max +/- Stdev Latency 36.46ms 125.89ms 1.99s 97.89% Req/Sec 1.56k 146.86 2.93k 88.25% 558504 requests in 30.06s, 134.76MB read Socket errors: connect 0, read 1261, write 11, timeout 36 Requests/sec: 18579.11 Transfer/sec: 4.48MB License See LICENSE"
  },
  "src/frontend/app-client/node_modules/@npmcli/git/node_modules/lru-cache/README.html": {
    "href": "src/frontend/app-client/node_modules/@npmcli/git/node_modules/lru-cache/README.html",
    "title": "lru-cache",
    "summary": "lru-cache A cache object that deletes the least-recently-used items. Specify a max number of the most recently used items that you want to keep, and this cache will keep that many of the most recently accessed items. This is not primarily a TTL cache, and does not make strong TTL guarantees. There is no preemptive pruning of expired items by default, but you may set a TTL on the cache or on a single set. If you do so, it will treat expired items as missing, and delete them when fetched. If you are more interested in TTL caching than LRU caching, check out @isaacs/ttlcache. As of version 7, this is one of the most performant LRU implementations available in JavaScript, and supports a wide diversity of use cases. However, note that using some of the features will necessarily impact performance, by causing the cache to have to do more work. See the \"Performance\" section below. Installation npm install lru-cache --save Usage // hybrid module, either works import LRUCache from 'lru-cache' // or: const LRUCache = require('lru-cache') // At least one of 'max', 'ttl', or 'maxSize' is required, to prevent // unsafe unbounded storage. // // In most cases, it's best to specify a max for performance, so all // the required memory allocation is done up-front. // // All the other options are optional, see the sections below for // documentation on what each one does. Most of them can be // overridden for specific items in get()/set() const options = { max: 500, // for use with tracking overall storage size maxSize: 5000, sizeCalculation: (value, key) => { return 1 }, // for use when you need to clean up something when objects // are evicted from the cache dispose: (value, key) => { freeFromMemoryOrWhatever(value) }, // how long to live in ms ttl: 1000 * 60 * 5, // return stale items before removing from cache? allowStale: false, updateAgeOnGet: false, updateAgeOnHas: false, // async method to use for cache.fetch(), for // stale-while-revalidate type of behavior fetchMethod: async (key, staleValue, { options, signal }) => {}, } const cache = new LRUCache(options) cache.set('key', 'value') cache.get('key') // \"value\" // non-string keys ARE fully supported // but note that it must be THE SAME object, not // just a JSON-equivalent object. var someObject = { a: 1 } cache.set(someObject, 'a value') // Object keys are not toString()-ed cache.set('[object Object]', 'a different value') assert.equal(cache.get(someObject), 'a value') // A similar object with same keys/values won't work, // because it's a different object identity assert.equal(cache.get({ a: 1 }), undefined) cache.clear() // empty the cache If you put more stuff in it, then items will fall out. Options max The maximum number of items that remain in the cache (assuming no TTL pruning or explicit deletions). Note that fewer items may be stored if size calculation is used, and maxSize is exceeded. This must be a positive finite intger. At least one of max, maxSize, or TTL is required. This must be a positive integer if set. It is strongly recommended to set a max to prevent unbounded growth of the cache. See \"Storage Bounds Safety\" below. maxSize Set to a positive integer to track the sizes of items added to the cache, and automatically evict items in order to stay below this size. Note that this may result in fewer than max items being stored. Attempting to add an item to the cache whose calculated size is greater that this amount will be a no-op. The item will not be cached, and no other items will be evicted. Optional, must be a positive integer if provided. Sets maxEntrySize to the same value, unless a different value is provided for maxEntrySize. At least one of max, maxSize, or TTL is required. This must be a positive integer if set. Even if size tracking is enabled, it is strongly recommended to set a max to prevent unbounded growth of the cache. See \"Storage Bounds Safety\" below. maxEntrySize Set to a positive integer to track the sizes of items added to the cache, and prevent caching any item over a given size. Attempting to add an item whose calculated size is greater than this amount will be a no-op. The item will not be cached, and no other items will be evicted. Optional, must be a positive integer if provided. Defaults to the value of maxSize if provided. sizeCalculation Function used to calculate the size of stored items. If you're storing strings or buffers, then you probably want to do something like n => n.length. The item is passed as the first argument, and the key is passed as the second argument. This may be overridden by passing an options object to cache.set(). Requires maxSize to be set. If the size (or return value of sizeCalculation) for a given entry is greater than maxEntrySize, then the item will not be added to the cache. Deprecated alias: length fetchMethod Function that is used to make background asynchronous fetches. Called with fetchMethod(key, staleValue, { signal, options, context }). May return a Promise. If fetchMethod is not provided, then cache.fetch(key) is equivalent to Promise.resolve(cache.get(key)). The signal object is an AbortSignal if that's available in the global object, otherwise it's a pretty close polyfill. If at any time, signal.aborted is set to true, or if the signal.onabort method is called, or if it emits an 'abort' event which you can listen to with addEventListener, then that means that the fetch should be abandoned. This may be passed along to async functions aware of AbortController/AbortSignal behavior. The fetchMethod should only return undefined or a Promise resolving to undefined if the AbortController signaled an abort event. In all other cases, it should return or resolve to a value suitable for adding to the cache. The options object is a union of the options that may be provided to set() and get(). If they are modified, then that will result in modifying the settings to cache.set() when the value is resolved, and in the case of noDeleteOnFetchRejection and allowStaleOnFetchRejection, the handling of fetchMethod failures. For example, a DNS cache may update the TTL based on the value returned from a remote DNS server by changing options.ttl in the fetchMethod. fetchContext Arbitrary data that can be passed to the fetchMethod as the context option. Note that this will only be relevant when the cache.fetch() call needs to call fetchMethod(). Thus, any data which will meaningfully vary the fetch response needs to be present in the key. This is primarily intended for including x-request-id headers and the like for debugging purposes, which do not affect the fetchMethod() response. noDeleteOnFetchRejection If a fetchMethod throws an error or returns a rejected promise, then by default, any existing stale value will be removed from the cache. If noDeleteOnFetchRejection is set to true, then this behavior is suppressed, and the stale value remains in the cache in the case of a rejected fetchMethod. This is important in cases where a fetchMethod is only called as a background update while the stale value is returned, when allowStale is used. This is implicitly in effect when allowStaleOnFetchRejection is set. This may be set in calls to fetch(), or defaulted on the constructor, or overridden by modifying the options object in the fetchMethod. allowStaleOnFetchRejection Set to true to return a stale value from the cache when a fetchMethod throws an error or returns a rejected Promise. If a fetchMethod fails, and there is no stale value available, the fetch() will resolve to undefined. Ie, all fetchMethod errors are suppressed. Implies noDeleteOnFetchRejection. This may be set in calls to fetch(), or defaulted on the constructor, or overridden by modifying the options object in the fetchMethod. allowStaleOnFetchAbort Set to true to return a stale value from the cache when the AbortSignal passed to the fetchMethod dispatches an 'abort' event, whether user-triggered, or due to internal cache behavior. Unless ignoreFetchAbort is also set, the underlying fetchMethod will still be considered canceled, and its return value will be ignored and not cached. ignoreFetchAbort Set to true to ignore the abort event emitted by the AbortSignal object passed to fetchMethod, and still cache the resulting resolution value, as long as it is not undefined. When used on its own, this means aborted fetch() calls are not immediately resolved or rejected when they are aborted, and instead take the full time to await. When used with allowStaleOnFetchAbort, aborted fetch() calls will resolve immediately to their stale cached value or undefined, and will continue to process and eventually update the cache when they resolve, as long as the resulting value is not undefined, thus supporting a \"return stale on timeout while refreshing\" mechanism by passing AbortSignal.timeout(n) as the signal. For example: const c = new LRUCache({ ttl: 100, ignoreFetchAbort: true, allowStaleOnFetchAbort: true, fetchMethod: async (key, oldValue, { signal }) => { // note: do NOT pass the signal to fetch()! // let's say this fetch can take a long time. const res = await fetch(`https://slow-backend-server/${key}`) return await res.json() }, }) // this will return the stale value after 100ms, while still // updating in the background for next time. const val = await c.fetch('key', { signal: AbortSignal.timeout(100) }) Note: regardless of this setting, an abort event is still emitted on the AbortSignal object, so may result in invalid results when passed to other underlying APIs that use AbortSignals. This may be overridden on the fetch() call or in the fetchMethod itself. dispose Function that is called on items when they are dropped from the cache, as this.dispose(value, key, reason). This can be handy if you want to close file descriptors or do other cleanup tasks when items are no longer stored in the cache. NOTE: It is called before the item has been fully removed from the cache, so if you want to put it right back in, you need to wait until the next tick. If you try to add it back in during the dispose() function call, it will break things in subtle and weird ways. Unlike several other options, this may not be overridden by passing an option to set(), for performance reasons. If disposal functions may vary between cache entries, then the entire list must be scanned on every cache swap, even if no disposal function is in use. The reason will be one of the following strings, corresponding to the reason for the item's deletion: evict Item was evicted to make space for a new addition set Item was overwritten by a new value delete Item was removed by explicit cache.delete(key) or by calling cache.clear(), which deletes everything. The dispose() method is not called for canceled calls to fetchMethod(). If you wish to handle evictions, overwrites, and deletes of in-flight asynchronous fetches, you must use the AbortSignal provided. Optional, must be a function. disposeAfter The same as dispose, but called after the entry is completely removed and the cache is once again in a clean state. It is safe to add an item right back into the cache at this point. However, note that it is very easy to inadvertently create infinite recursion in this way. The disposeAfter() method is not called for canceled calls to fetchMethod(). If you wish to handle evictions, overwrites, and deletes of in-flight asynchronous fetches, you must use the AbortSignal provided. noDisposeOnSet Set to true to suppress calling the dispose() function if the entry key is still accessible within the cache. This may be overridden by passing an options object to cache.set(). Boolean, default false. Only relevant if dispose or disposeAfter options are set. ttl Max time to live for items before they are considered stale. Note that stale items are NOT preemptively removed by default, and MAY live in the cache, contributing to its LRU max, long after they have expired. Also, as this cache is optimized for LRU/MRU operations, some of the staleness/TTL checks will reduce performance. This is not primarily a TTL cache, and does not make strong TTL guarantees. There is no pre-emptive pruning of expired items, but you may set a TTL on the cache, and it will treat expired items as missing when they are fetched, and delete them. Optional, but must be a positive integer in ms if specified. This may be overridden by passing an options object to cache.set(). At least one of max, maxSize, or TTL is required. This must be a positive integer if set. Even if ttl tracking is enabled, it is strongly recommended to set a max to prevent unbounded growth of the cache. See \"Storage Bounds Safety\" below. If ttl tracking is enabled, and max and maxSize are not set, and ttlAutopurge is not set, then a warning will be emitted cautioning about the potential for unbounded memory consumption. Deprecated alias: maxAge noUpdateTTL Boolean flag to tell the cache to not update the TTL when setting a new value for an existing key (ie, when updating a value rather than inserting a new value). Note that the TTL value is always set (if provided) when adding a new entry into the cache. This may be passed as an option to cache.set(). Boolean, default false. ttlResolution Minimum amount of time in ms in which to check for staleness. Defaults to 1, which means that the current time is checked at most once per millisecond. Set to 0 to check the current time every time staleness is tested. Note that setting this to a higher value will improve performance somewhat while using ttl tracking, albeit at the expense of keeping stale items around a bit longer than intended. ttlAutopurge Preemptively remove stale items from the cache. Note that this may significantly degrade performance, especially if the cache is storing a large number of items. It is almost always best to just leave the stale items in the cache, and let them fall out as new items are added. Note that this means that allowStale is a bit pointless, as stale items will be deleted almost as soon as they expire. Use with caution! Boolean, default false allowStale By default, if you set ttl, it'll only delete stale items from the cache when you get(key). That is, it's not preemptively pruning items. If you set allowStale:true, it'll return the stale value as well as deleting it. If you don't set this, then it'll return undefined when you try to get a stale entry. Note that when a stale entry is fetched, even if it is returned due to allowStale being set, it is removed from the cache immediately. You can immediately put it back in the cache if you wish, thus resetting the TTL. This may be overridden by passing an options object to cache.get(). The cache.has() method will always return false for stale items. Boolean, default false, only relevant if ttl is set. Deprecated alias: stale noDeleteOnStaleGet When using time-expiring entries with ttl, by default stale items will be removed from the cache when the key is accessed with cache.get(). Setting noDeleteOnStaleGet to true will cause stale items to remain in the cache, until they are explicitly deleted with cache.delete(key), or retrieved with noDeleteOnStaleGet set to false. This may be overridden by passing an options object to cache.get(). Boolean, default false, only relevant if ttl is set. updateAgeOnGet When using time-expiring entries with ttl, setting this to true will make each item's age reset to 0 whenever it is retrieved from cache with get(), causing it to not expire. (It can still fall out of cache based on recency of use, of course.) This may be overridden by passing an options object to cache.get(). Boolean, default false, only relevant if ttl is set. updateAgeOnHas When using time-expiring entries with ttl, setting this to true will make each item's age reset to 0 whenever its presence in the cache is checked with has(), causing it to not expire. (It can still fall out of cache based on recency of use, of course.) This may be overridden by passing an options object to cache.has(). Boolean, default false, only relevant if ttl is set. API new LRUCache(options) Create a new LRUCache. All options are documented above, and are on the cache as public members. cache.max, cache.maxSize, cache.allowStale, cache.noDisposeOnSet, cache.sizeCalculation, cache.dispose, cache.maxSize, cache.ttl, cache.updateAgeOnGet, cache.updateAgeOnHas All option names are exposed as public members on the cache object. These are intended for read access only. Changing them during program operation can cause undefined behavior. cache.size The total number of items held in the cache at the current moment. cache.calculatedSize The total size of items in cache when using size tracking. set(key, value, [{ size, sizeCalculation, ttl, noDisposeOnSet, start, status }]) Add a value to the cache. Optional options object may contain ttl and sizeCalculation as described above, which default to the settings on the cache object. If start is provided, then that will set the effective start time for the TTL calculation. Note that this must be a previous value of performance.now() if supported, or a previous value of Date.now() if not. Options object may also include size, which will prevent calling the sizeCalculation function and just use the specified number if it is a positive integer, and noDisposeOnSet which will prevent calling a dispose function in the case of overwrites. If the size (or return value of sizeCalculation) for a given entry is greater than maxEntrySize, then the item will not be added to the cache. Will update the recency of the entry. Returns the cache object. For the usage of the status option, see Status Tracking below. get(key, { updateAgeOnGet, allowStale, status } = {}) => value Return a value from the cache. Will update the recency of the cache entry found. If the key is not found, get() will return undefined. This can be confusing when setting values specifically to undefined, as in cache.set(key, undefined). Use cache.has() to determine whether a key is present in the cache at all. For the usage of the status option, see Status Tracking below. async fetch(key, options = {}) => Promise The following options are supported: updateAgeOnGet allowStale size sizeCalculation ttl noDisposeOnSet forceRefresh status - See Status Tracking below. signal - AbortSignal can be used to cancel the fetch(). Note that the signal option provided to the fetchMethod is a different object, because it must also respond to internal cache state changes, but aborting this signal will abort the one passed to fetchMethod as well. fetchContext - sets the context option passed to the underlying fetchMethod. If the value is in the cache and not stale, then the returned Promise resolves to the value. If not in the cache, or beyond its TTL staleness, then fetchMethod(key, staleValue, { options, signal, context }) is called, and the value returned will be added to the cache once resolved. If called with allowStale, and an asynchronous fetch is currently in progress to reload a stale value, then the former stale value will be returned. If called with forceRefresh, then the cached item will be re-fetched, even if it is not stale. However, if allowStale is set, then the old value will still be returned. This is useful in cases where you want to force a reload of a cached value. If a background fetch is already in progress, then forceRefresh has no effect. Multiple fetches for the same key will only call fetchMethod a single time, and all will be resolved when the value is resolved, even if different options are used. If fetchMethod is not specified, then this is effectively an alias for Promise.resolve(cache.get(key)). When the fetch method resolves to a value, if the fetch has not been aborted due to deletion, eviction, or being overwritten, then it is added to the cache using the options provided. If the key is evicted or deleted before the fetchMethod resolves, then the AbortSignal passed to the fetchMethod will receive an abort event, and the promise returned by fetch() will reject with the reason for the abort. If a signal is passed to the fetch() call, then aborting the signal will abort the fetch and cause the fetch() promise to reject with the reason provided. peek(key, { allowStale } = {}) => value Like get() but doesn't update recency or delete stale items. Returns undefined if the item is stale, unless allowStale is set either on the cache or in the options object. has(key, { updateAgeOnHas, status } = {}) => Boolean Check if a key is in the cache, without updating the recency of use. Age is updated if updateAgeOnHas is set to true in either the options or the constructor. Will return false if the item is stale, even though it is technically in the cache. The difference can be determined (if it matters) by using a status argument, and inspecting the has field. For the usage of the status option, see Status Tracking below. delete(key) Deletes a key out of the cache. Returns true if the key was deleted, false otherwise. clear() Clear the cache entirely, throwing away all values. Deprecated alias: reset() keys() Return a generator yielding the keys in the cache, in order from most recently used to least recently used. rkeys() Return a generator yielding the keys in the cache, in order from least recently used to most recently used. values() Return a generator yielding the values in the cache, in order from most recently used to least recently used. rvalues() Return a generator yielding the values in the cache, in order from least recently used to most recently used. entries() Return a generator yielding [key, value] pairs, in order from most recently used to least recently used. rentries() Return a generator yielding [key, value] pairs, in order from least recently used to most recently used. find(fn, [getOptions]) Find a value for which the supplied fn method returns a truthy value, similar to Array.find(). fn is called as fn(value, key, cache). The optional getOptions are applied to the resulting get() of the item found. dump() Return an array of [key, entry] objects which can be passed to cache.load() The start fields are calculated relative to a portable Date.now() timestamp, even if performance.now() is available. Stale entries are always included in the dump, even if allowStale is false. Note: this returns an actual array, not a generator, so it can be more easily passed around. load(entries) Reset the cache and load in the items in entries in the order listed. Note that the shape of the resulting cache may be different if the same options are not used in both caches. The start fields are assumed to be calculated relative to a portable Date.now() timestamp, even if performance.now() is available. purgeStale() Delete any stale entries. Returns true if anything was removed, false otherwise. Deprecated alias: prune getRemainingTTL(key) Return the number of ms left in the item's TTL. If item is not in cache, returns 0. Returns Infinity if item is in cache without a defined TTL. forEach(fn, [thisp]) Call the fn function with each set of fn(value, key, cache) in the LRU cache, from most recent to least recently used. Does not affect recency of use. If thisp is provided, function will be called in the this-context of the provided object. rforEach(fn, [thisp]) Same as cache.forEach(fn, thisp), but in order from least recently used to most recently used. pop() Evict the least recently used item, returning its value. Returns undefined if cache is empty. Internal Methods and Properties In order to optimize performance as much as possible, \"private\" members and methods are exposed on the object as normal properties, rather than being accessed via Symbols, private members, or closure variables. Do not use or rely on these. They will change or be removed without notice. They will cause undefined behavior if used inappropriately. There is no need or reason to ever call them directly. This documentation is here so that it is especially clear that this not \"undocumented\" because someone forgot; it is documented, and the documentation is telling you not to do it. Do not report bugs that stem from using these properties. They will be ignored. initializeTTLTracking() Set up the cache for tracking TTLs updateItemAge(index) Called when an item age is updated, by internal ID setItemTTL(index) Called when an item ttl is updated, by internal ID isStale(index) Called to check an item's staleness, by internal ID initializeSizeTracking() Set up the cache for tracking item size. Called automatically when a size is specified. removeItemSize(index) Updates the internal size calculation when an item is removed or modified, by internal ID addItemSize(index) Updates the internal size calculation when an item is added or modified, by internal ID indexes() An iterator over the non-stale internal IDs, from most recently to least recently used. rindexes() An iterator over the non-stale internal IDs, from least recently to most recently used. newIndex() Create a new internal ID, either reusing a deleted ID, evicting the least recently used ID, or walking to the end of the allotted space. evict() Evict the least recently used internal ID, returning its ID. Does not do any bounds checking. connect(p, n) Connect the p and n internal IDs in the linked list. moveToTail(index) Move the specified internal ID to the most recently used position. keyMap Map of keys to internal IDs keyList List of keys by internal ID valList List of values by internal ID sizes List of calculated sizes by internal ID ttls List of TTL values by internal ID starts List of start time values by internal ID next Array of \"next\" pointers by internal ID prev Array of \"previous\" pointers by internal ID head Internal ID of least recently used item tail Internal ID of most recently used item free Stack of deleted internal IDs Status Tracking Occasionally, it may be useful to track the internal behavior of the cache, particularly for logging, debugging, or for behavior within the fetchMethod. To do this, you can pass a status object to the get(), set(), has(), and fetch() methods. The status option should be a plain JavaScript object. The following fields will be set appropriately: interface Status<V> { /** * The status of a set() operation. * * - add: the item was not found in the cache, and was added * - update: the item was in the cache, with the same value provided * - replace: the item was in the cache, and replaced * - miss: the item was not added to the cache for some reason */ set?: 'add' | 'update' | 'replace' | 'miss' /** * the ttl stored for the item, or undefined if ttls are not used. */ ttl?: LRUMilliseconds /** * the start time for the item, or undefined if ttls are not used. */ start?: LRUMilliseconds /** * The timestamp used for TTL calculation */ now?: LRUMilliseconds /** * the remaining ttl for the item, or undefined if ttls are not used. */ remainingTTL?: LRUMilliseconds /** * The calculated size for the item, if sizes are used. */ size?: LRUSize /** * A flag indicating that the item was not stored, due to exceeding the * {@link maxEntrySize} */ maxEntrySizeExceeded?: true /** * The old value, specified in the case of `set:'update'` or * `set:'replace'` */ oldValue?: V /** * The results of a {@link has} operation * * - hit: the item was found in the cache * - stale: the item was found in the cache, but is stale * - miss: the item was not found in the cache */ has?: 'hit' | 'stale' | 'miss' /** * The status of a {@link fetch} operation. * Note that this can change as the underlying fetch() moves through * various states. * * - inflight: there is another fetch() for this key which is in process * - get: there is no fetchMethod, so {@link get} was called. * - miss: the item is not in cache, and will be fetched. * - hit: the item is in the cache, and was resolved immediately. * - stale: the item is in the cache, but stale. * - refresh: the item is in the cache, and not stale, but * {@link forceRefresh} was specified. */ fetch?: 'get' | 'inflight' | 'miss' | 'hit' | 'stale' | 'refresh' /** * The {@link fetchMethod} was called */ fetchDispatched?: true /** * The cached value was updated after a successful call to fetchMethod */ fetchUpdated?: true /** * The reason for a fetch() rejection. Either the error raised by the * {@link fetchMethod}, or the reason for an AbortSignal. */ fetchError?: Error /** * The fetch received an abort signal */ fetchAborted?: true /** * The abort signal received was ignored, and the fetch was allowed to * continue. */ fetchAbortIgnored?: true /** * The fetchMethod promise resolved successfully */ fetchResolved?: true /** * The results of the fetchMethod promise were stored in the cache */ fetchUpdated?: true /** * The fetchMethod promise was rejected */ fetchRejected?: true /** * The status of a {@link get} operation. * * - fetching: The item is currently being fetched. If a previous value is * present and allowed, that will be returned. * - stale: The item is in the cache, and is stale. * - hit: the item is in the cache * - miss: the item is not in the cache */ get?: 'stale' | 'hit' | 'miss' /** * A fetch or get operation returned a stale value. */ returnedStale?: true } Storage Bounds Safety This implementation aims to be as flexible as possible, within the limits of safe memory consumption and optimal performance. At initial object creation, storage is allocated for max items. If max is set to zero, then some performance is lost, and item count is unbounded. Either maxSize or ttl must be set if max is not specified. If maxSize is set, then this creates a safe limit on the maximum storage consumed, but without the performance benefits of pre-allocation. When maxSize is set, every item must provide a size, either via the sizeCalculation method provided to the constructor, or via a size or sizeCalculation option provided to cache.set(). The size of every item must be a positive integer. If neither max nor maxSize are set, then ttl tracking must be enabled. Note that, even when tracking item ttl, items are not preemptively deleted when they become stale, unless ttlAutopurge is enabled. Instead, they are only purged the next time the key is requested. Thus, if ttlAutopurge, max, and maxSize are all not set, then the cache will potentially grow unbounded. In this case, a warning is printed to standard error. Future versions may require the use of ttlAutopurge if max and maxSize are not specified. If you truly wish to use a cache that is bound only by TTL expiration, consider using a Map object, and calling setTimeout to delete entries when they expire. It will perform much better than an LRU cache. Here is an implementation you may use, under the same license as this package: // a storage-unbounded ttl cache that is not an lru-cache const cache = { data: new Map(), timers: new Map(), set: (k, v, ttl) => { if (cache.timers.has(k)) { clearTimeout(cache.timers.get(k)) } cache.timers.set( k, setTimeout(() => cache.delete(k), ttl) ) cache.data.set(k, v) }, get: k => cache.data.get(k), has: k => cache.data.has(k), delete: k => { if (cache.timers.has(k)) { clearTimeout(cache.timers.get(k)) } cache.timers.delete(k) return cache.data.delete(k) }, clear: () => { cache.data.clear() for (const v of cache.timers.values()) { clearTimeout(v) } cache.timers.clear() }, } If that isn't to your liking, check out @isaacs/ttlcache. Performance As of January 2022, version 7 of this library is one of the most performant LRU cache implementations in JavaScript. Benchmarks can be extremely difficult to get right. In particular, the performance of set/get/delete operations on objects will vary wildly depending on the type of key used. V8 is highly optimized for objects with keys that are short strings, especially integer numeric strings. Thus any benchmark which tests solely using numbers as keys will tend to find that an object-based approach performs the best. Note that coercing anything to strings to use as object keys is unsafe, unless you can be 100% certain that no other type of value will be used. For example: const myCache = {} const set = (k, v) => (myCache[k] = v) const get = k => myCache[k] set({}, 'please hang onto this for me') set('[object Object]', 'oopsie') Also beware of \"Just So\" stories regarding performance. Garbage collection of large (especially: deep) object graphs can be incredibly costly, with several \"tipping points\" where it increases exponentially. As a result, putting that off until later can make it much worse, and less predictable. If a library performs well, but only in a scenario where the object graph is kept shallow, then that won't help you if you are using large objects as keys. In general, when attempting to use a library to improve performance (such as a cache like this one), it's best to choose an option that will perform well in the sorts of scenarios where you'll actually use it. This library is optimized for repeated gets and minimizing eviction time, since that is the expected need of a LRU. Set operations are somewhat slower on average than a few other options, in part because of that optimization. It is assumed that you'll be caching some costly operation, ideally as rarely as possible, so optimizing set over get would be unwise. If performance matters to you: If it's at all possible to use small integer values as keys, and you can guarantee that no other types of values will be used as keys, then do that, and use a cache such as lru-fast, or mnemonist's LRUCache which uses an Object as its data store. Failing that, if at all possible, use short non-numeric strings (ie, less than 256 characters) as your keys, and use mnemonist's LRUCache. If the types of your keys will be long strings, strings that look like floats, null, objects, or some mix of types, or if you aren't sure, then this library will work well for you. Do not use a dispose function, size tracking, or especially ttl behavior, unless absolutely needed. These features are convenient, and necessary in some use cases, and every attempt has been made to make the performance impact minimal, but it isn't nothing. Breaking Changes in Version 7 This library changed to a different algorithm and internal data structure in version 7, yielding significantly better performance, albeit with some subtle changes as a result. If you were relying on the internals of LRUCache in version 6 or before, it probably will not work in version 7 and above. For more info, see the change log."
  },
  "src/frontend/app-client/node_modules/@npmcli/git/README.html": {
    "href": "src/frontend/app-client/node_modules/@npmcli/git/README.html",
    "title": "",
    "summary": "@npmcli/git A utility for spawning git from npm CLI contexts. This is not an implementation of git itself, it's just a thing that spawns child processes to tell the system git CLI implementation to do stuff. USAGE const git = require('@npmcli/git') git.clone('git://foo/bar.git', 'some-branch', 'some-path', opts) // clone a repo .then(() => git.spawn(['checkout', 'some-branch'], {cwd: 'bar'})) .then(() => git.spawn(['you get the idea'])) API Most methods take an options object. Options are described below. git.spawn(args, opts = {}) Launch a git subprocess with the arguments specified. All the other functions call this one at some point. Processes are launched using @npmcli/promise-spawn, with the stdioString: true option enabled by default, since git output is generally in readable string format. Return value is a Promise that resolves to a result object with {cmd, args, code, signal, stdout, stderr} members, or rejects with an error with the same fields, passed back from @npmcli/promise-spawn. git.clone(repo, ref = 'HEAD', target = null, opts = {}) -> Promise<sha String> Clone the repository into target path (or the default path for the name of the repository), checking out ref. Return value is the sha of the current HEAD in the locally cloned repository. In lieu of a specific ref, you may also pass in a spec option, which is a npm-package-arg object for a git package dependency reference. In this way, you can select SemVer tags within a range, or any git committish value. For example: const npa = require('npm-package-arg') git.clone('git@github.com:npm/git.git', '', null, { spec: npa('github:npm/git#semver:1.x'), }) // only gitRange and gitCommittish are relevant, so this works, too git.clone('git@github.com:npm/git.git', null, null, { spec: { gitRange: '1.x' } }) This will automatically do a shallow --depth=1 clone on any hosts that are known to support it. To force a shallow or deep clone, you can set the gitShallow option to true or false respectively. git.revs(repo, opts = {}) -> Promise<rev doc Object> Fetch a representation of all of the named references in a given repository. The resulting doc is intentionally somewhat packument-like, so that git semver ranges can be applied using the same npm-pick-manifest logic. The resulting object looks like: revs = { versions: { // all semver-looking tags go in here... // version: { sha, ref, rawRef, type } '1.0.0': { sha: '1bc5fba3353f8e1b56493b266bc459276ab23139', ref: 'v1.0.0', rawRef: 'refs/tags/v1.0.0', type: 'tag', }, }, 'dist-tags': { HEAD: '1.0.0', latest: '1.0.0', }, refs: { // all the advertised refs that can be cloned down remotely HEAD: { sha, ref, rawRef, type: 'head' }, master: { ... }, 'v1.0.0': { ... }, 'refs/tags/v1.0.0': { ... }, }, shas: { // all named shas referenced above // sha: [list, of, refs] '6b2501f9183a1753027a9bf89a184b7d3d4602c7': [ 'HEAD', 'master', 'refs/heads/master', ], '1bc5fba3353f8e1b56493b266bc459276ab23139': [ 'v1.0.0', 'refs/tags/v1.0.0' ], }, } git.is(opts) -> Promise<Boolean> Resolve to true if the path argument refers to the root of a git repository. It does this by looking for a file in ${path}/.git/index, which is not an airtight indicator, but at least avoids being fooled by an empty directory or a file named .git. git.find(opts) -> Promise<String | null> Given a path, walk up the file system tree until a git repo working directory is found. Since this calls stat a bunch of times, it's probably best to only call it if you're reasonably sure you're likely to be in a git project somewhere. Pass in opts.root to stop checking at that directory. Resolves to null if not in a git project. git.isClean(opts = {}) -> Promise<Boolean> Return true if in a git dir, and that git dir is free of changes. This will resolve true if the git working dir is clean, or false if not, and reject if the path is not within a git directory or some other error occurs. OPTIONS retry An object to configure retry behavior for transient network errors with exponential backoff. retries: Defaults to opts.fetchRetries or 2 factor: Defaults to opts.fetchRetryFactor or 10 maxTimeout: Defaults to opts.fetchRetryMaxtimeout or 60000 minTimeout: Defaults to opts.fetchRetryMintimeout or 1000 git Path to the git binary to use. Will look up the first git in the PATH if not specified. spec The npm-package-arg specifier object for the thing being fetched (if relevant). fakePlatform set to a fake value of process.platform to use. (Just for testing win32 behavior on Unix, and vice versa.) cwd The current working dir for the git command. Particularly for find and is and isClean, it's good to know that this defaults to process.cwd(), as one might expect. Any other options that can be passed to @npmcli/promise-spawn, or child_process.spawn()."
  },
  "src/frontend/app-client/node_modules/@npmcli/package-json/README.html": {
    "href": "src/frontend/app-client/node_modules/@npmcli/package-json/README.html",
    "title": "",
    "summary": "@npmcli/package-json Programmatic API to update package.json files. Updates and saves files the same way the npm cli handles them. Install npm install @npmcli/package-json Usage: const PackageJson = require('@npmcli/package-json') const pkgJson = await PackageJson.load(path) // $ cat package.json // { // \"name\": \"foo\", // \"version\": \"1.0.0\", // \"dependencies\": { // \"a\": \"^1.0.0\", // \"abbrev\": \"^1.1.1\" // } // } pkgJson.update({ dependencies: { a: '^1.0.0', b: '^1.2.3', }, workspaces: [ './new-workspace', ], }) await pkgJson.save() // $ cat package.json // { // \"name\": \"foo\", // \"version\": \"1.0.0\", // \"dependencies\": { // \"a\": \"^1.0.0\", // \"b\": \"^1.2.3\" // }, // \"workspaces\": [ // \"./new-workspace\" // ] // } API: constructor() Creates a new empty instance of PackageJson. async PackageJson.create(path) Creates an empty package.json at the given path. If one already exists it will be overwritten. async PackageJson.load(path, opts = {}) Loads a package.json at the given path. opts: Object can contain: create: Boolean if true, a new package.json will be created if one does not already exist. Will not clobber ane existing package.json that can not be parsed. Example: Loads contents of a package.json file located at ./: const PackageJson = require('@npmcli/package-json') const pkgJson = new PackageJson() await pkgJson.load('./') Throws an error in case a package.json file is missing or has invalid contents. static async PackageJson.load(path) Convenience static method that returns a new instance and loads the contents of a package.json file from that location. path: String that points to the folder from where to read the package.json from Example: Loads contents of a package.json file located at ./: const PackageJson = require('@npmcli/package-json') const pkgJson = await PackageJson.load('./') async PackageJson.normalize() Intended for normalizing package.json files in a node_modules tree. Some light normalization is done to ensure that it is ready for use in @npmcli/arborist path: String that points to the folder from where to read the package.json from opts: Object can contain: strict: Boolean enables optional strict mode when applying the normalizeData step steps: Array optional normalization steps that will be applied to the package.json file, replacing the default steps root: Path optional git root to provide when applying the gitHead step changes: Array if provided, a message about each change that was made to the packument will be added to this array static async PackageJson.normalize(path, opts = {}) Convenience static that calls load before calling normalize path: String that points to the folder from where to read the package.json from opts: Object can contain: strict: Boolean enables optional strict mode when applying the normalizeData step steps: Array optional normalization steps that will be applied to the package.json file, replacing the default steps root: Path optional git root to provide when applying the gitHead step changes: Array if provided, a message about each change that was made to the packument will be added to this array async PackageJson.prepare() Like normalize but intended for preparing package.json files for publish. static async PackageJson.prepare(path, opts = {}) Convenience static that calls load before calling prepare path: String that points to the folder from where to read the package.json from opts: Object can contain: strict: Boolean enables optional strict mode when applying the normalizeData step steps: Array optional normalization steps that will be applied to the package.json file, replacing the default steps root: Path optional git root to provide when applying the gitHead step changes: Array if provided, a message about each change that was made to the packument will be added to this array async PackageJson.fix() Like normalize but intended for the npm pkg fix command. PackageJson.update(content) Updates the contents of a package.json with the content provided. content: Object containing the properties to be updated/replaced in the package.json file. Special properties like dependencies, devDependencies, optionalDependencies, peerDependencies will have special logic to handle the update of these options, such as sorting and deduplication. Example: Adds a new script named new-script to your package.json scripts property: const PackageJson = require('@npmcli/package-json') const pkgJson = await PackageJson.load('./') pkgJson.update({ scripts: { ...pkgJson.content.scripts, 'new-script': 'echo \"Bom dia!\"' } }) NOTE: When working with dependencies, it's important to provide values for all known dependency types as the update logic has some interdependence in between these properties. Example: A safe way to add a devDependency AND remove all peer dependencies of an existing package.json: const PackageJson = require('@npmcli/package-json') const pkgJson = await PackageJson.load('./') pkgJson.update({ dependencies: pkgJson.content.dependencies, devDependencies: { ...pkgJson.content.devDependencies, foo: '^foo@1.0.0', }, peerDependencies: {}, optionalDependencies: pkgJson.content.optionalDependencies, }) get PackageJson.content Getter that retrieves the normalized Object read from the loaded package.json file. Example: const PackageJson = require('@npmcli/package-json') const pkgJson = await PackageJson.load('./') pkgJson.content // -> { // name: 'foo', // version: '1.0.0' // } async PackageJson.save() Saves the current content to the same location used when calling load(). LICENSE ISC"
  },
  "src/frontend/app-client/node_modules/@npmcli/promise-spawn/README.html": {
    "href": "src/frontend/app-client/node_modules/@npmcli/promise-spawn/README.html",
    "title": "",
    "summary": "@npmcli/promise-spawn Spawn processes the way the npm cli likes to do. Give it some options, it'll give you a Promise that resolves or rejects based on the results of the execution. USAGE const promiseSpawn = require('@npmcli/promise-spawn') promiseSpawn('ls', [ '-laF', 'some/dir/*.js' ], { cwd: '/tmp/some/path', // defaults to process.cwd() stdioString: true, // stdout/stderr as strings rather than buffers stdio: 'pipe', // any node spawn stdio arg is valid here // any other arguments to node child_process.spawn can go here as well, }, { extra: 'things', to: 'decorate', the: 'result', }).then(result => { // {code === 0, signal === null, stdout, stderr, and all the extras} console.log('ok!', result) }).catch(er => { // er has all the same properties as the result, set appropriately console.error('failed!', er) }) API promiseSpawn(cmd, args, opts, extra) -> Promise Run the command, return a Promise that resolves/rejects based on the process result. Result or error will be decorated with the properties in the extra object. You can use this to attach some helpful info about why the command is being run, if it makes sense for your use case. If stdio is set to anything other than 'inherit', then the result/error will be decorated with stdout and stderr values. If stdioString is set to true, these will be strings. Otherwise they will be Buffer objects. Returned promise is decorated with the stdin stream if the process is set to pipe from stdin. Writing to this stream writes to the stdin of the spawned process. Options stdioString Boolean, default true. Return stdout/stderr output as strings rather than buffers. cwd String, default process.cwd(). Current working directory for running the script. Also the argument to infer-owner to determine effective uid/gid when run as root on Unix systems. shell Boolean or String. If false, no shell is used during spawn. If true, the system default shell is used. If a String, that specific shell is used. When a shell is used, the given command runs from within that shell by concatenating the command and its escaped arguments and running the result. This option is not passed through to child_process.spawn. Any other options for child_process.spawn can be passed as well. promiseSpawn.open(arg, opts, extra) -> Promise Use the operating system to open arg with a default program. This is useful for things like opening the user's default browser to a specific URL. Depending on the platform in use this will use start (win32), open (darwin) or xdg-open (everything else). In the case of Windows Subsystem for Linux we use the default win32 behavior as it is much more predictable to open the arg using the host operating system. Options Options are identical to promiseSpawn except for the following: command String, the command to use to open the file in question. Default is one of start, open or xdg-open depending on platform in use."
  },
  "src/frontend/app-client/node_modules/@one-ini/wasm/README.html": {
    "href": "src/frontend/app-client/node_modules/@one-ini/wasm/README.html",
    "title": "One INI",
    "summary": "One INI The core implementation of an AST based, idiomatic INI parser which aims to provide an easy to implement and consistent INI-standard. This reference implementation is provided as Rust-library and WASM-package. The work on this project started with the search for an universal parser for the EditorConfig INI file format specification. WASM To use from Web Assembly, compile with: wasm-pack build --release --target nodejs and run the (limited) WASM tests with: wasm-pack test --node You can call the genereted JS wrapper with either: import { parse_to_json } from './pkg/editorconfig_ini.js' const results = parse_to_json(` root = true [*] # always use unix line endings end_of_line = lf `) // { // \"version\": \"0.1.0\", // \"body\": [ // { \"type\": \"Pair\", \"key\": \"root\", \"value\": \"true\" }, // { // \"type\": \"Section\", // \"name\": \"*\", // \"body\": [ // { \"type\": \"Comment\", \"indicator\": \"#\", \"value\": \"always use unix line endings\" }, // { \"type\": \"Pair\", \"key\": \"end_of_line\", \"value\": \"lf\" } // ] // } // ] // } or: import { parse_to_uint32array, TokenTypes } from './pkg/editorconfig_ini.js' const buf = Buffer.from(` root = true [*] # always use unix line endings end_of_line = lf `, 'utf8') const ary = parse_to_uint32array(buf) // Array with token type, start byte offset, end byte offset for each token // Uint32Array(21) [ // TokenTypes.Key, 1, 5, // TokenTypes.Value, 8, 12, // TokenTypes.Section, 15, 16, // TokenTypes.CommentIndicator, 18, 19, // TokenTypes.CommentValue, 20, 48, // TokenTypes.Key, 49, 60, // TokenTypes.Value, 63, 65 // ]"
  },
  "src/frontend/app-client/node_modules/@opentelemetry/api/README.html": {
    "href": "src/frontend/app-client/node_modules/@opentelemetry/api/README.html",
    "title": "OpenTelemetry API for JavaScript",
    "summary": "OpenTelemetry API for JavaScript API Reference • Documentation This package provides everything needed to interact with the OpenTelemetry API, including all TypeScript interfaces, enums, and no-op implementations. It is intended for use both on the server and in the browser. The methods in this package perform no operations by default. This means they can be safely called by a library or end-user application whether there is an SDK registered or not. In order to generate and export telemetry data, you will also need an SDK such as the OpenTelemetry JS SDK. Tracing Quick Start You Will Need An application you wish to instrument OpenTelemetry JS SDK Node.js >=8.5.0 (14+ is preferred) or an ECMAScript 5+ compatible browser Note: ECMAScript 5+ compatibility is for this package only. Please refer to the documentation for the SDK you are using to determine its minimum ECMAScript version. Note for library authors: Only your end users will need an OpenTelemetry SDK. If you wish to support OpenTelemetry in your library, you only need to use the OpenTelemetry API. For more information, please read the tracing documentation. Install Dependencies npm install @opentelemetry/api @opentelemetry/sdk-trace-base Trace Your Application In order to get started with tracing, you will need to first register an SDK. The SDK you are using may provide a convenience method which calls the registration methods for you, but if you would like to call them directly they are documented here: SDK registration methods. Once you have registered an SDK, you can start and end spans. A simple example of basic SDK registration and tracing a simple operation is below. The example should export spans to the console once per second. For more information, see the tracing documentation. const { trace } = require(\"@opentelemetry/api\"); const { BasicTracerProvider, ConsoleSpanExporter, SimpleSpanProcessor } = require(\"@opentelemetry/sdk-trace-base\"); // Create and register an SDK const provider = new BasicTracerProvider(); provider.addSpanProcessor(new SimpleSpanProcessor(new ConsoleSpanExporter())); trace.setGlobalTracerProvider(provider); // Acquire a tracer from the global tracer provider which will be used to trace the application const name = 'my-application-name'; const version = '0.1.0'; const tracer = trace.getTracer(name, version); // Trace your application by creating spans async function operation() { const span = tracer.startSpan(\"do operation\"); // mock some work by sleeping 1 second await new Promise((resolve, reject) => { setTimeout(resolve, 1000); }) span.end(); } async function main() { while (true) { await operation(); } } main(); Version Compatibility Because the npm installer and node module resolution algorithm could potentially allow two or more copies of any given package to exist within the same node_modules structure, the OpenTelemetry API takes advantage of a variable on the global object to store the global API. When an API method in the API package is called, it checks if this global API exists and proxies calls to it if and only if it is a compatible API version. This means if a package has a dependency on an OpenTelemetry API version which is not compatible with the API used by the end user, the package will receive a no-op implementation of the API. Upgrade Guidelines 0.21.0 to 1.0.0 No breaking changes 0.20.0 to 0.21.0 #78 api.context.bind arguments reversed and context is now a required argument. #46 Noop classes and singletons are no longer exported. To create a noop span it is recommended to use api.trace.wrapSpanContext with INVALID_SPAN_CONTEXT instead of using the NOOP_TRACER. 1.0.0-rc.3 to 0.20.0 Removing TimedEvent which was not part of spec HttpBaggage renamed to HttpBaggagePropagator #45 Span#context renamed to Span#spanContext #47 getSpan/setSpan/getSpanContext/setSpanContext moved to trace namespace #55 getBaggage/setBaggage/createBaggage moved to propagation namespace Useful links For more information on OpenTelemetry, visit: https://opentelemetry.io/ For more about OpenTelemetry JavaScript: https://github.com/open-telemetry/opentelemetry-js For help or feedback on this project, join us in GitHub Discussions License Apache 2.0 - See LICENSE for more information."
  },
  "src/frontend/app-client/node_modules/@pkgjs/parseargs/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/@pkgjs/parseargs/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog 0.11.0 (2022-10-08) Features add default option parameter (#142) (cd20847) 0.10.0 (2022-07-21) Features add parsed meta-data to returned properties (#129) (91bfb4d) 0.9.1 (2022-06-20) Bug Fixes runtime: support node 14+ (#135) (6a1c5a6) 0.9.0 (2022-05-23) ⚠ BREAKING CHANGES drop handling of electron arguments (#121) Code Refactoring drop handling of electron arguments (#121) (a2ffd53) 0.8.0 (2022-05-16) ⚠ BREAKING CHANGES switch type:string option arguments to greedy, but with error for suspect cases in strict mode (#88) positionals now opt-in when strict:true (#116) create result.values with null prototype (#111) Features create result.values with null prototype (#111) (9d539c3) positionals now opt-in when strict:true (#116) (3643338) switch type:string option arguments to greedy, but with error for suspect cases in strict mode (#88) (c2b5e72) 0.7.1 (2022-04-15) Bug Fixes resist pollution (#106) (ecf2dec) 0.7.0 (2022-04-13) Features Add strict mode to parser (#74) (8267d02) 0.6.0 (2022-04-11) ⚠ BREAKING CHANGES rework results to remove redundant flags property and store value true for boolean options (#83) switch to existing ERR_INVALID_ARG_VALUE (#97) Code Refactoring rework results to remove redundant flags property and store value true for boolean options (#83) (be153db) switch to existing ERR_INVALID_ARG_VALUE (#97) (084a23f) 0.5.0 (2022-04-10) ⚠ BREAKING CHANGES Require type to be specified for each supplied option (#95) Features Require type to be specified for each supplied option (#95) (02cd018) 0.4.0 (2022-03-12) ⚠ BREAKING CHANGES parsing, revisit short option groups, add support for combined short and value (#75) restructure configuration to take options bag (#63) Code Refactoring parsing, revisit short option groups, add support for combined short and value (#75) (a92600f) restructure configuration to take options bag (#63) (b412095) 0.3.0 (2022-02-06) Features parser: support short-option groups (#59) (882067b) 0.2.0 (2022-02-05) Features basic support for shorts (#50) (a2f36d7) Bug Fixes always store value for a=b (#43) (a85e8dc) support single dash as positional (#49) (d795bf8) 0.1.1 (2022-01-25) Bug Fixes only use arrays in results for multiples (#42) (c357584) 0.1.0 (2022-01-22) Features expand scenarios covered by default arguments for environments (#20) (582ada7) update readme and include contributing guidelines (8edd6fc) Bug Fixes do not strip excess leading dashes on long option names (#21) (f848590) name & readme (3f057c1) package.json values (9bac300) update readme name (957d8d9) Build System first release as minor (421c6e2)"
  },
  "src/frontend/app-client/node_modules/@pkgjs/parseargs/README.html": {
    "href": "src/frontend/app-client/node_modules/@pkgjs/parseargs/README.html",
    "title": "parseArgs",
    "summary": "parseArgs Polyfill of util.parseArgs() util.parseArgs([config]) Stability: 1 - Experimental config {Object} Used to provide arguments for parsing and to configure the parser. config supports the following properties: args {string[]} array of argument strings. Default: process.argv with execPath and filename removed. options {Object} Used to describe arguments known to the parser. Keys of options are the long names of options and values are an {Object} accepting the following properties: type {string} Type of argument, which must be either boolean or string. multiple {boolean} Whether this option can be provided multiple times. If true, all values will be collected in an array. If false, values for the option are last-wins. Default: false. short {string} A single character alias for the option. default {string | boolean | string[] | boolean[]} The default option value when it is not set by args. It must be of the same type as the the type property. When multiple is true, it must be an array. strict {boolean} Should an error be thrown when unknown arguments are encountered, or when arguments are passed that do not match the type configured in options. Default: true. allowPositionals {boolean} Whether this command accepts positional arguments. Default: false if strict is true, otherwise true. tokens {boolean} Return the parsed tokens. This is useful for extending the built-in behavior, from adding additional checks through to reprocessing the tokens in different ways. Default: false. Returns: {Object} The parsed command line arguments: values {Object} A mapping of parsed option names with their {string} or {boolean} values. positionals {string[]} Positional arguments. tokens {Object[] | undefined} See parseArgs tokens section. Only returned if config includes tokens: true. Provides a higher level API for command-line argument parsing than interacting with process.argv directly. Takes a specification for the expected arguments and returns a structured object with the parsed options and positionals. import { parseArgs } from 'node:util'; const args = ['-f', '--bar', 'b']; const options = { foo: { type: 'boolean', short: 'f' }, bar: { type: 'string' } }; const { values, positionals } = parseArgs({ args, options }); console.log(values, positionals); // Prints: [Object: null prototype] { foo: true, bar: 'b' } [] const { parseArgs } = require('node:util'); const args = ['-f', '--bar', 'b']; const options = { foo: { type: 'boolean', short: 'f' }, bar: { type: 'string' } }; const { values, positionals } = parseArgs({ args, options }); console.log(values, positionals); // Prints: [Object: null prototype] { foo: true, bar: 'b' } [] util.parseArgs is experimental and behavior may change. Join the conversation in pkgjs/parseargs to contribute to the design. parseArgs tokens Detailed parse information is available for adding custom behaviours by specifying tokens: true in the configuration. The returned tokens have properties describing: all tokens kind {string} One of 'option', 'positional', or 'option-terminator'. index {number} Index of element in args containing token. So the source argument for a token is args[token.index]. option tokens name {string} Long name of option. rawName {string} How option used in args, like -f of --foo. value {string | undefined} Option value specified in args. Undefined for boolean options. inlineValue {boolean | undefined} Whether option value specified inline, like --foo=bar. positional tokens value {string} The value of the positional argument in args (i.e. args[index]). option-terminator token The returned tokens are in the order encountered in the input args. Options that appear more than once in args produce a token for each use. Short option groups like -xy expand to a token for each option. So -xxx produces three tokens. For example to use the returned tokens to add support for a negated option like --no-color, the tokens can be reprocessed to change the value stored for the negated option. import { parseArgs } from 'node:util'; const options = { 'color': { type: 'boolean' }, 'no-color': { type: 'boolean' }, 'logfile': { type: 'string' }, 'no-logfile': { type: 'boolean' }, }; const { values, tokens } = parseArgs({ options, tokens: true }); // Reprocess the option tokens and overwrite the returned values. tokens .filter((token) => token.kind === 'option') .forEach((token) => { if (token.name.startsWith('no-')) { // Store foo:false for --no-foo const positiveName = token.name.slice(3); values[positiveName] = false; delete values[token.name]; } else { // Resave value so last one wins if both --foo and --no-foo. values[token.name] = token.value ?? true; } }); const color = values.color; const logfile = values.logfile ?? 'default.log'; console.log({ logfile, color }); const { parseArgs } = require('node:util'); const options = { 'color': { type: 'boolean' }, 'no-color': { type: 'boolean' }, 'logfile': { type: 'string' }, 'no-logfile': { type: 'boolean' }, }; const { values, tokens } = parseArgs({ options, tokens: true }); // Reprocess the option tokens and overwrite the returned values. tokens .filter((token) => token.kind === 'option') .forEach((token) => { if (token.name.startsWith('no-')) { // Store foo:false for --no-foo const positiveName = token.name.slice(3); values[positiveName] = false; delete values[token.name]; } else { // Resave value so last one wins if both --foo and --no-foo. values[token.name] = token.value ?? true; } }); const color = values.color; const logfile = values.logfile ?? 'default.log'; console.log({ logfile, color }); Example usage showing negated options, and when an option is used multiple ways then last one wins. $ node negate.js { logfile: 'default.log', color: undefined } $ node negate.js --no-logfile --no-color { logfile: false, color: false } $ node negate.js --logfile=test.log --color { logfile: 'test.log', color: true } $ node negate.js --no-logfile --logfile=test.log --color --no-color { logfile: 'test.log', color: false } Table of Contents util.parseArgs([config]) Scope Version Matchups \uD83D\uDE80 Getting Started \uD83D\uDE4C Contributing \uD83D\uDCA1 process.mainArgs Proposal Implementation: \uD83D\uDCC3 Examples F.A.Qs Links & Resources Scope It is already possible to build great arg parsing modules on top of what Node.js provides; the prickly API is abstracted away by these modules. Thus, process.parseArgs() is not necessarily intended for library authors; it is intended for developers of simple CLI tools, ad-hoc scripts, deployed Node.js applications, and learning materials. It is exceedingly difficult to provide an API which would both be friendly to these Node.js users while being extensible enough for libraries to build upon. We chose to prioritize these use cases because these are currently not well-served by Node.js' API. Version Matchups Node.js @pkgjs/parseArgs v18.3.0 v0.9.1 v16.17.0, v18.7.0 0.10.0 \uD83D\uDE80 Getting Started Install dependencies. npm install Open the index.js file and start editing! Test your code by calling parseArgs through our test file npm test \uD83D\uDE4C Contributing Any person who wants to contribute to the initiative is welcome! Please first read the Contributing Guide Additionally, reading the Examples w/ Output section of this document will be the best way to familiarize yourself with the target expected behavior for parseArgs() once it is fully implemented. This package was implemented using tape as its test harness. \uD83D\uDCA1 process.mainArgs Proposal Note: This can be moved forward independently of the util.parseArgs() proposal/work. Implementation: process.mainArgs = process.argv.slice(process._exec ? 1 : 2) \uD83D\uDCC3 Examples const { parseArgs } = require('@pkgjs/parseargs'); const { parseArgs } = require('@pkgjs/parseargs'); // specify the options that may be used const options = { foo: { type: 'string'}, bar: { type: 'boolean' }, }; const args = ['--foo=a', '--bar']; const { values, positionals } = parseArgs({ args, options }); // values = { foo: 'a', bar: true } // positionals = [] const { parseArgs } = require('@pkgjs/parseargs'); // type:string & multiple const options = { foo: { type: 'string', multiple: true, }, }; const args = ['--foo=a', '--foo', 'b']; const { values, positionals } = parseArgs({ args, options }); // values = { foo: [ 'a', 'b' ] } // positionals = [] const { parseArgs } = require('@pkgjs/parseargs'); // shorts const options = { foo: { short: 'f', type: 'boolean' }, }; const args = ['-f', 'b']; const { values, positionals } = parseArgs({ args, options, allowPositionals: true }); // values = { foo: true } // positionals = ['b'] const { parseArgs } = require('@pkgjs/parseargs'); // unconfigured const options = {}; const args = ['-f', '--foo=a', '--bar', 'b']; const { values, positionals } = parseArgs({ strict: false, args, options, allowPositionals: true }); // values = { f: true, foo: 'a', bar: true } // positionals = ['b'] F.A.Qs Is cmd --foo=bar baz the same as cmd baz --foo=bar? yes Does the parser execute a function? no Does the parser execute one of several functions, depending on input? no Can subcommands take options that are distinct from the main command? no Does it output generated help when no options match? no Does it generated short usage? Like: usage: ls [-ABCFGHLOPRSTUWabcdefghiklmnopqrstuwx1] [file ...] no (no usage/help at all) Does the user provide the long usage text? For each option? For the whole command? no Do subcommands (if implemented) have their own usage output? no Does usage print if the user runs cmd --help? no Does it set process.exitCode? no Does usage print to stderr or stdout? N/A Does it check types? (Say, specify that an option is a boolean, number, etc.) no Can an option have more than one type? (string or false, for example) no Can the user define a type? (Say, type: path to call path.resolve() on the argument.) no Does a --foo=0o22 mean 0, 22, 18, or \"0o22\"? \"0o22\" Does it coerce types? no Does --no-foo coerce to --foo=false? For all options? Only boolean options? no, it sets {values:{'no-foo': true}} Is --foo the same as --foo=true? Only for known booleans? Only at the end? no, they are not the same. There is no special handling of true as a value so it is just another string. Does it read environment variables? Ie, is FOO=1 cmd the same as cmd --foo=1? no Do unknown arguments raise an error? Are they parsed? Are they treated as positional arguments? no, they are parsed, not treated as positionals Does -- signal the end of options? yes Is -- included as a positional? no Is program -- foo the same as program foo? yes, both store {positionals:['foo']} Does the API specify whether a -- was present/relevant? no Is -bar the same as --bar? no, -bar is a short option or options, with expansion logic that follows the Utility Syntax Guidelines in POSIX.1-2017. -bar expands to -b, -a, -r. Is ---foo the same as --foo? no the first is a long option named '-foo' the second is a long option named 'foo' Is - a positional? ie, bash some-test.sh | tap - yes Links & Resources Initial Tooling Issue Initial Proposal parseArgs Proposal"
  },
  "src/frontend/app-client/node_modules/@radix-ui/number/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/number/README.html",
    "title": "number",
    "summary": "number Installation $ yarn add @radix-ui/number # or $ npm install @radix-ui/number Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/primitive/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/primitive/README.html",
    "title": "primitive",
    "summary": "primitive Installation $ yarn add @radix-ui/primitive # or $ npm install @radix-ui/primitive Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-accordion/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-accordion/README.html",
    "title": "react-accordion",
    "summary": "react-accordion Installation $ yarn add @radix-ui/react-accordion # or $ npm install @radix-ui/react-accordion Usage View docs here."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-arrow/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-arrow/README.html",
    "title": "react-arrow",
    "summary": "react-arrow Installation $ yarn add @radix-ui/react-arrow # or $ npm install @radix-ui/react-arrow Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-collapsible/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-collapsible/README.html",
    "title": "react-collapsible",
    "summary": "react-collapsible Installation $ yarn add @radix-ui/react-collapsible # or $ npm install @radix-ui/react-collapsible Usage View docs here."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-collection/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-collection/README.html",
    "title": "react-collection",
    "summary": "react-collection Installation $ yarn add @radix-ui/react-collection # or $ npm install @radix-ui/react-collection Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-compose-refs/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-compose-refs/README.html",
    "title": "react-compose-refs",
    "summary": "react-compose-refs Installation $ yarn add @radix-ui/react-compose-refs # or $ npm install @radix-ui/react-compose-refs Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-context/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-context/README.html",
    "title": "react-context",
    "summary": "react-context Installation $ yarn add @radix-ui/react-context # or $ npm install @radix-ui/react-context Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-direction/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-direction/README.html",
    "title": "react-direction",
    "summary": "react-direction Installation $ yarn add @radix-ui/react-direction # or $ npm install @radix-ui/react-direction Usage View docs here."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-dismissable-layer/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-dismissable-layer/README.html",
    "title": "react-dismissable-layer",
    "summary": "react-dismissable-layer Installation $ yarn add @radix-ui/react-dismissable-layer # or $ npm install @radix-ui/react-dismissable-layer Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-focus-guards/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-focus-guards/README.html",
    "title": "react-focus-guards",
    "summary": "react-focus-guards Installation $ yarn add @radix-ui/react-focus-guards # or $ npm install @radix-ui/react-focus-guards Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-focus-scope/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-focus-scope/README.html",
    "title": "react-focus-scope",
    "summary": "react-focus-scope Installation $ yarn add @radix-ui/react-focus-scope # or $ npm install @radix-ui/react-focus-scope Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-id/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-id/README.html",
    "title": "react-id",
    "summary": "react-id Installation $ yarn add @radix-ui/react-id # or $ npm install @radix-ui/react-id Usage View docs here."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-popper/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-popper/README.html",
    "title": "react-popper",
    "summary": "react-popper Installation $ yarn add @radix-ui/react-popper # or $ npm install @radix-ui/react-popper Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-portal/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-portal/README.html",
    "title": "react-portal",
    "summary": "react-portal Installation $ yarn add @radix-ui/react-portal # or $ npm install @radix-ui/react-portal Usage View docs here."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-presence/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-presence/README.html",
    "title": "react-presence",
    "summary": "react-presence Installation $ yarn add @radix-ui/react-presence # or $ npm install @radix-ui/react-presence Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-primitive/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-primitive/README.html",
    "title": "react-primitive",
    "summary": "react-primitive Installation $ yarn add @radix-ui/react-primitive # or $ npm install @radix-ui/react-primitive Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-select/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-select/README.html",
    "title": "react-select",
    "summary": "react-select Installation $ yarn add @radix-ui/react-select # or $ npm install @radix-ui/react-select Usage View docs here."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-slot/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-slot/README.html",
    "title": "react-slot",
    "summary": "react-slot Installation $ yarn add @radix-ui/react-slot # or $ npm install @radix-ui/react-slot Usage View docs here."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-use-callback-ref/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-use-callback-ref/README.html",
    "title": "react-use-callback-ref",
    "summary": "react-use-callback-ref Installation $ yarn add @radix-ui/react-use-callback-ref # or $ npm install @radix-ui/react-use-callback-ref Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-use-controllable-state/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-use-controllable-state/README.html",
    "title": "react-use-controllable-state",
    "summary": "react-use-controllable-state Installation $ yarn add @radix-ui/react-use-controllable-state # or $ npm install @radix-ui/react-use-controllable-state Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-use-escape-keydown/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-use-escape-keydown/README.html",
    "title": "react-use-escape-keydown",
    "summary": "react-use-escape-keydown Installation $ yarn add @radix-ui/react-use-escape-keydown # or $ npm install @radix-ui/react-use-escape-keydown Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-use-layout-effect/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-use-layout-effect/README.html",
    "title": "react-use-layout-effect",
    "summary": "react-use-layout-effect Installation $ yarn add @radix-ui/react-use-layout-effect # or $ npm install @radix-ui/react-use-layout-effect Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-use-previous/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-use-previous/README.html",
    "title": "react-use-previous",
    "summary": "react-use-previous Installation $ yarn add @radix-ui/react-use-previous # or $ npm install @radix-ui/react-use-previous Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-use-rect/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-use-rect/README.html",
    "title": "react-use-rect",
    "summary": "react-use-rect Installation $ yarn add @radix-ui/react-use-rect # or $ npm install @radix-ui/react-use-rect Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-use-size/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-use-size/README.html",
    "title": "react-use-size",
    "summary": "react-use-size Installation $ yarn add @radix-ui/react-use-size # or $ npm install @radix-ui/react-use-size Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@radix-ui/react-visually-hidden/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/react-visually-hidden/README.html",
    "title": "react-visually-hidden",
    "summary": "react-visually-hidden Installation $ yarn add @radix-ui/react-visually-hidden # or $ npm install @radix-ui/react-visually-hidden Usage View docs here."
  },
  "src/frontend/app-client/node_modules/@radix-ui/rect/README.html": {
    "href": "src/frontend/app-client/node_modules/@radix-ui/rect/README.html",
    "title": "rect",
    "summary": "rect Installation $ yarn add @radix-ui/rect # or $ npm install @radix-ui/rect Usage This is an internal utility, not intended for public usage."
  },
  "src/frontend/app-client/node_modules/@react-router/dev/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/@react-router/dev/CHANGELOG.html",
    "title": "@react-router/dev",
    "summary": "@react-router/dev 7.5.0 Patch Changes Introduce unstable_subResourceIntegrity future flag that enables generation of an importmap with integrity for the scripts that will be loaded by the browser. (#13163) Update optional Wrangler peer dependency range to support Wrangler v4 (#13258) When future.unstable_viteEnvironmentApi is enabled, ensure critical CSS in development works when using a custom Vite base has been configured (#13305) Reinstate dependency optimization in the child compiler to fix depsOptimizer is required in dev mode errors when using vite-plugin-cloudflare and importing Node.js builtins (#13317) Updated dependencies: react-router@7.5.0 @react-router/node@7.5.0 @react-router/serve@7.5.0 7.4.1 Patch Changes Fix path in prerender error messages (#13257) Fix typegen for virtual modules when moduleDetection is set to force (#13267) When both future.unstable_middleware and future.unstable_splitRouteModules are enabled, split unstable_clientMiddleware route exports into separate chunks when possible (#13210) Improve performance of future.unstable_middleware by ensuring that route modules are only blocking during the middleware phase when the unstable_clientMiddleware has been defined (#13210) Updated dependencies: react-router@7.4.1 @react-router/node@7.4.1 @react-router/serve@7.4.1 7.4.0 Minor Changes Generate types for virtual:react-router/server-build module (#13152) Patch Changes When future.unstable_splitRouteModules is set to \"enforce\", allow both splittable and unsplittable root route exports since it's always in a single chunk. (#13238) When future.unstable_viteEnvironmentApi is enabled, allow plugins that override the default SSR environment (such as @cloudflare/vite-plugin) to be placed before or after the React Router plugin. (#13183) Fix conflicts with other Vite plugins that use the configureServer and/or configurePreviewServer hooks (#13184) Updated dependencies: react-router@7.4.0 @react-router/node@7.4.0 @react-router/serve@7.4.0 7.3.0 Patch Changes Fix support for custom client build.rollupOptions.output.entryFileNames (#13098) Fix usage of prerender option when serverBundles option has been configured or provided by a preset, e.g. vercelPreset from @vercel/react-router (#13082) Fix support for custom build.assetsDir (#13077) Remove unused dependencies (#13134) Stub all routes except root in \"SPA Mode\" server builds to avoid issues when route modules or their dependencies import non-SSR-friendly modules (#13023) Fix errors with future.unstable_viteEnvironmentApi when the ssr environment has been configured by another plugin to be a custom Vite.DevEnvironment rather than the default Vite.RunnableDevEnvironment (#13008) Remove unused Vite file system watcher (#13133) Fix support for custom SSR build input when serverBundles option has been configured (#13107) Note that for consumers using the future.unstable_viteEnvironmentApi and serverBundles options together, hyphens are no longer supported in server bundle IDs since they also need to be valid Vite environment names. Fix dev server when using HTTPS by stripping HTTP/2 pseudo headers from dev server requests (#12830) Lazy load Cloudflare platform proxy on first dev server request when using the cloudflareDevProxy Vite plugin to avoid creating unnecessary workerd processes (#13016) When future.unstable_viteEnvironmentApi is enabled and the ssr environment has optimizeDeps.noDiscovery disabled, define optimizeDeps.entries and optimizeDeps.include (#13007) Fix duplicated entries in typegen for layout routes and their corresponding index route (#13140) Updated dependencies: react-router@7.3.0 @react-router/node@7.3.0 @react-router/serve@7.3.0 7.2.0 Minor Changes Generate a \"SPA fallback\" HTML file for scenarios where applications are prerendering the / route with ssr:false (#12948) If you specify ssr:false without a prerender config, this is considered \"SPA Mode\" and the generated index.html file will only render down to the root route and will be able to hydrate for any valid application path If you specify ssr:false with a prerender config but do not include the / path (i.e., prerender: ['/blog/post']), then we still generate a \"SPA Mode\" index.html file that can hydrate for any path in the application However, previously if you specified ssr:false and included the / path in your prerender config, we would prerender the / route into index.html as a non-SPA page The generated HTML would include the root index route which prevented hydration for any other paths With this change, we now generate a \"SPA Mode\" file in __spa-fallback.html that will allow you to hydrate for any non-prerendered paths You can serve this file from your static file server for any paths that would otherwise 404 if you only want to pre-render some routes in your ssr:false app and serve the others as a SPA npx sirv-cli build/client --single __spa-fallback.html Allow a loader in the root route in SPA mode because it can be called/server-rendered at build time (#12948) Route.HydrateFallbackProps now also receives loaderData This will be defined so long as the HydrateFallback is rendering while children routes are loading This will be undefined if the HydrateFallback is rendering because the route has it's own hydrating clientLoader In SPA mode, this will allow you to render loader root data into the SPA index.html New type-safe href utility that guarantees links point to actual paths in your app (#13012) import { href } from \"react-router\"; export default function Component() { const link = href(\"/blog/:slug\", { slug: \"my-first-post\" }); return ( <main> <Link to={href(\"/products/:id\", { id: \"asdf\" })} /> <NavLink to={href(\"/:lang?/about\", { lang: \"en\" })} /> </main> ); } Patch Changes Handle custom envDir in Vite config (#12969) Fix typegen for repeated params (#13012) In React Router, path parameters are keyed by their name. So for a path pattern like /a/:id/b/:id?/c/:id, the last :id will set the value for id in useParams and the params prop. For example, /a/1/b/2/c/3 will result in the value { id: 3 } at runtime. Previously, generated types for params incorrectly modeled repeated params with an array. So /a/1/b/2/c/3 generated a type like { id: [1,2,3] }. To be consistent with runtime behavior, the generated types now correctly model the \"last one wins\" semantics of path parameters. So /a/1/b/2/c/3 now generates a type like { id: 3 }. Fix CLI parsing to allow argumentless npx react-router usage (#12925) Fix ArgError: unknown or unexpected option: --version when running react-router --version (#13012) Skip action-only resource routes when using prerender:true (#13004) Enhance invalid export detection when using ssr:false (#12948) headers/action are prohibited in all routes with ssr:false because there will be no runtime server on which to run them loader functions are more nuanced and depend on whether a given route is prerendered When using ssr:false without a prerender config, only the root route can have a loader This is \"SPA mode\" which generates a single index.html file with the root route HydrateFallback so it is capable of hydrating for any path in your application - therefore we can only call a root route loader at build time When using ssr:false with a prerender config, you can export a loader from routes matched by one of the prerender paths because those routes will be server rendered at build time Exporting a loader from a route that is never matched by a prerender path will throw a build time error because there will be no runtime server to ever run the loader Limit prerendered resource route .data files to only the target route (#13004) Add unstable support for splitting route modules in framework mode via future.unstable_splitRouteModules (#11871) Fix prerendering of binary files (#13039) Add future.unstable_viteEnvironmentApi flag to enable experimental Vite Environment API support (#12936) Disable Lazy Route Discovery for all ssr:false apps and not just \"SPA Mode\" because there is no runtime server to serve the search-param-configured __manifest requests (#12894) We previously only disabled this for \"SPA Mode\" which is ssr:false and no prerender config but we realized it should apply to all ssr:false apps, including those prerendering multiple pages In those prerender scenarios we would prerender the /__manifest file assuming the static file server would serve it but that makes some unneccesary assumptions about the static file server behaviors Updated dependencies: react-router@7.2.0 @react-router/node@7.2.0 @react-router/serve@7.2.0 7.1.5 Patch Changes Updated dependencies: react-router@7.1.5 @react-router/node@7.1.5 @react-router/serve@7.1.5 7.1.4 Patch Changes Properly resolve Windows file paths to scan for Vite's dependency optimization when using the unstable_optimizeDeps future flag. (#12637) Fix prerendering when using a custom server - previously we ended up trying to import the users custom server when we actually want to import the virtual server build module (#12759) Updated dependencies: react-router@7.1.4 @react-router/node@7.1.4 @react-router/serve@7.1.4 7.1.3 Patch Changes Fix reveal and routes CLI commands (#12745) Updated dependencies: react-router@7.1.3 @react-router/node@7.1.3 @react-router/serve@7.1.3 7.1.2 Patch Changes Fix default external conditions in Vite v6. This fixes resolution issues with certain npm packages. (#12644) Fix mismatch in prerendering html/data files when path is missing a leading slash (#12684) Use module-sync server condition when enabled in the runtime. This fixes React context mismatches (e.g. useHref() may be used only in the context of a <Router> component.) during development on Node 22.10.0+ when using libraries that have a peer dependency on React Router. (#12729) Fix react-refresh source maps (#12686) Updated dependencies: react-router@7.1.2 @react-router/node@7.1.2 @react-router/serve@7.1.2 7.1.1 Patch Changes Fix for a crash when optional args are passed to the CLI (5b1ca202f) Updated dependencies: react-router@7.1.1 @react-router/node@7.1.1 @react-router/serve@7.1.1 7.1.0 Minor Changes Add support for Vite v6 (#12469) Patch Changes Properly initialize NODE_ENV if not already set for compatibility with React 19 (#12578) Remove the leftover/unused abortDelay prop from ServerRouter and update the default entry.server.tsx to use the new streamTimeout value for Single Fetch (#12478) The abortDelay functionality was removed in v7 as it was coupled to the defer implementation from Remix v2, but this removal of this prop was missed If you were still using this prop in your entry.server file, it's likely your app is not aborting streams as you would expect and you will need to adopt the new streamTimeout value introduced with Single Fetch Updated dependencies: react-router@7.1.0 @react-router/node@7.1.0 @react-router/serve@7.1.0 7.0.2 Patch Changes Support moduleResolution Node16 and NodeNext (#12440) Generate wide matches and params types for current route and child routes (#12397) At runtime, matches includes child route matches and params include child route path parameters. But previously, we only generated types for parent routes in matches; for params, we only considered the parent routes and the current route. To align our generated types more closely to the runtime behavior, we now generate more permissive, wider types when accessing child route information. Updated dependencies: react-router@7.0.2 @react-router/node@7.0.2 @react-router/serve@7.0.2 7.0.1 Patch Changes Pass route error to ErrorBoundary as a prop (#12338) Ensure typegen file watcher is cleaned up when Vite dev server restarts (#12331) Updated dependencies: react-router@7.0.1 @react-router/node@7.0.1 @react-router/serve@7.0.1 7.0.0 Major Changes For Remix consumers migrating to React Router, the vitePlugin and cloudflareDevProxyVitePlugin exports have been renamed and moved. (#11904) -import { - vitePlugin as remix, - cloudflareDevProxyVitePlugin, -} from \"@remix/dev\"; +import { reactRouter } from \"@react-router/dev/vite\"; +import { cloudflareDevProxy } from \"@react-router/dev/vite/cloudflare\"; Remove single fetch future flag. (#11522) update minimum node version to 18 (#11690) Add exports field to all packages (#11675) node package no longer re-exports from react-router (#11702) For Remix consumers migrating to React Router who used the Vite plugin's buildEnd hook, the resolved reactRouterConfig object no longer contains a publicPath property since this belongs to Vite, not React Router. (#11575) For Remix consumers migrating to React Router, the Vite plugin's manifest option has been removed. (#11573) The manifest option been superseded by the more powerful buildEnd hook since it's passed the buildManifest argument. You can still write the build manifest to disk if needed, but you'll most likely find it more convenient to write any logic depending on the build manifest within the buildEnd hook itself. If you were using the manifest option, you can replace it with a buildEnd hook that writes the manifest to disk like this: // react-router.config.ts import type { Config } from \"@react-router/dev/config\"; import { writeFile } from \"node:fs/promises\"; export default { async buildEnd({ buildManifest }) { await writeFile( \"build/manifest.json\", JSON.stringify(buildManifest, null, 2), \"utf-8\" ); }, } satisfies Config; Consolidate types previously duplicated across @remix-run/router, @remix-run/server-runtime, and @remix-run/react now that they all live in react-router (#12177) Examples: LoaderFunction, LoaderFunctionArgs, ActionFunction, ActionFunctionArgs, DataFunctionArgs, RouteManifest, LinksFunction, Route, EntryRoute The RouteManifest type used by the \"remix\" code is now slightly stricter because it is using the former @remix-run/router RouteManifest Record<string, Route> -> Record<string, Route | undefined> Removed AppData type in favor of inlining unknown in the few locations it was used Removed ServerRuntimeMeta* types in favor of the Meta* types they were duplicated from Update default isbot version to v5 and drop support for isbot@3 (#11770) If you have isbot@4 or isbot@5 in your package.json: You do not need to make any changes If you have isbot@3 in your package.json and you have your own entry.server.tsx file in your repo You do not need to make any changes You can upgrade to isbot@5 independent of the React Router v7 upgrade If you have isbot@3 in your package.json and you do not have your own entry.server.tsx file in your repo You are using the internal default entry provided by React Router v7 and you will need to upgrade to isbot@5 in your package.json Drop support for Node 18, update minimum Node vestion to 20 (#12171) Remove installGlobals() as this should no longer be necessary For Remix consumers migrating to React Router, Vite manifests (i.e. .vite/manifest.json) are now written within each build subdirectory, e.g. build/client/.vite/manifest.json and build/server/.vite/manifest.json instead of build/.vite/client-manifest.json and build/.vite/server-manifest.json. This means that the build output is now much closer to what you'd expect from a typical Vite project. (#11573) Originally the Remix Vite plugin moved all Vite manifests to a root-level build/.vite directory to avoid accidentally serving them in production, particularly from the client build. This was later improved with additional logic that deleted these Vite manifest files at the end of the build process unless Vite's build.manifest had been enabled within the app's Vite config. This greatly reduced the risk of accidentally serving the Vite manifests in production since they're only present when explicitly asked for. As a result, we can now assume that consumers will know that they need to manage these additional files themselves, and React Router can safely generate a more standard Vite build output. Minor Changes Params, loader data, and action data as props for route component exports (#11961) export default function Component({ params, loaderData, actionData }) {} export function HydrateFallback({ params }) {} export function ErrorBoundary({ params, loaderData, actionData }) {} Remove internal entry.server.spa.tsx implementation (#11681) Add prefix route config helper to @react-router/dev/routes (#12094) Typesafety improvements (#12019) React Router now generates types for each of your route modules. You can access those types by importing them from ./+types.<route filename without extension>. For example: // app/routes/product.tsx import type * as Route from \"./+types.product\"; export function loader({ params }: Route.LoaderArgs) {} export default function Component({ loaderData }: Route.ComponentProps) {} This initial implementation targets type inference for: Params : Path parameters from your routing config in routes.ts including file-based routing LoaderData : Loader data from loader and/or clientLoader within your route module ActionData : Action data from action and/or clientAction within your route module In the future, we plan to add types for the rest of the route module exports: meta, links, headers, shouldRevalidate, etc. We also plan to generate types for typesafe Links: <Link to=\"/products/:id\" params={{ id: 1 }} /> // ^^^^^^^^^^^^^ ^^^^^^^^^ // typesafe `to` and `params` based on the available routes in your app Check out our docs for more: Explanations > Type Safety How-To > Setting up type safety Patch Changes Enable prerendering for resource routes (#12200) chore: warn instead of error for min node version in CLI (#12270) chore: re-enable development warnings through a development exports condition. (#12269) include root \"react-dom\" module for optimization (#12060) resolve config directory relative to flat output file structure (#12187) if we are in SAP mode, always render the index.html for hydration (#12268) fix(react-router): (v7) fix static prerender of non-ascii characters (#12161) Updated dependencies: react-router@7.0.0 @react-router/serve@7.0.0 @react-router/node@7.0.0 2.9.0 Minor Changes New future.unstable_singleFetch flag (#8773) Naked objects returned from loaders/actions are no longer automatically converted to JSON responses. They'll be streamed as-is via turbo-stream so Date's will become Date through useLoaderData() You can return naked objects with Promise's without needing to use defer() - including nested Promise's If you need to return a custom status code or custom response headers, you can still use the defer utility <RemixServer abortDelay> is no longer used. Instead, you should export const streamTimeout from entry.server.tsx and the remix server runtime will use that as the delay to abort the streamed response If you export your own streamTimeout, you should decouple that from aborting the react renderToPipeableStream. You should always ensure that react is aborted afer the stream is aborted so that abort rejections can be flushed down Actions no longer automatically revalidate on 4xx/5xx responses (via RR future.unstable_skipActionErrorRevalidation flag) - you can return a 2xx to opt-into revalidation or use shouldRevalidate Patch Changes Improve getDependenciesToBundle resolution in monorepos (#8848) Fix SPA mode when single fetch is enabled by using streaming entry.server (#9063) Vite: added sourcemap support for transformed routes (#8970) Update links printed to the console by the Remix CLI/Dev Server to point to updated docs locations (#9176) Updated dependencies: @remix-run/node@2.9.0 @remix-run/server-runtime@2.9.0 2.8.1 Patch Changes Support reading from Vite config when running remix reveal and remix routes CLI commands (#8916) Add Vite commands to Remix CLI --help output (#8939) Vite: Fix support for build.sourcemap option in Vite config (#8965) Clean up redundant client route query strings on route JavaScript files in production builds (#8969) Vite: Fix error when using Vite's server.fs.allow option without a client entry file (#8966) Updated dependencies: @remix-run/node@2.8.1 @remix-run/server-runtime@2.8.1 2.8.0 Minor Changes Pass resolved viteConfig to Remix Vite plugin's buildEnd hook (#8885) Patch Changes Mark Layout as browser safe route export in esbuild compiler (#8842) Vite: Silence build warnings when dependencies include \"use client\" directives (#8897) Vite: Fix serverBundles issue where multiple browser manifests are generated (#8864) Support custom Vite build.assetsDir option (#8843) Updated dependencies: @remix-run/node@2.8.0 @remix-run/server-runtime@2.8.0 2.7.2 Patch Changes Vite: Fix error when building projects with .css?url imports (#8829) Updated dependencies: @remix-run/node@2.7.2 @remix-run/server-runtime@2.7.2 2.7.1 Patch Changes Updated dependencies: @remix-run/node@2.7.1 @remix-run/server-runtime@2.7.1 2.7.0 Minor Changes Allow an optional Layout export from the root route (#8709) Vite: Cloudflare Proxy as a Vite plugin (#8749) This is a breaking change for projects relying on Cloudflare support from the unstable Vite plugin The Cloudflare preset (unstable_cloudflarePreset) as been removed and replaced with a new Vite plugin: import { unstable_vitePlugin as remix, - unstable_cloudflarePreset as cloudflare, + cloudflareDevProxyVitePlugin as remixCloudflareDevProxy, } from \"@remix-run/dev\"; import { defineConfig } from \"vite\"; export default defineConfig({ plugins: [ + remixCloudflareDevProxy(), + remix(), - remix({ - presets: [cloudflare()], - }), ], - ssr: { - resolve: { - externalConditions: [\"workerd\", \"worker\"], - }, - }, }); remixCloudflareDevProxy must come before the remix plugin so that it can override Vite's dev server middleware to be compatible with Cloudflare's proxied environment. Because it is a Vite plugin, remixCloudflareDevProxy can set ssr.resolve.externalConditions to be workerd-compatible for you. remixCloudflareDevProxy accepts a getLoadContext function that replaces the old getRemixDevLoadContext. If you were using a nightly version that required getBindingsProxy or getPlatformProxy, that is no longer required. Any options you were passing to getBindingsProxy or getPlatformProxy should now be passed to remixCloudflareDevProxy instead. This API also better aligns with future plans to support Cloudflare with a framework-agnostic Vite plugin that makes use of Vite's (experimental) Runtime API. Vite: Stabilize the Remix Vite plugin, Cloudflare preset, and all related types by removing all unstable_ / Unstable_ prefixes. (#8713) While this is a breaking change for existing Remix Vite plugin consumers, now that the plugin has stabilized, there will no longer be any breaking changes outside of a major release. Thank you to all of our early adopters and community contributors for helping us get here! \uD83D\uDE4F Vite: Stabilize \"SPA Mode\" by renaming the Remix vite plugin config from unstable_ssr -> ssr (#8692) Vite: Add a new basename option to the Vite plugin, allowing users to set the internal React Router basename in order to to serve their applications underneath a subpath (#8145) Patch Changes Vite: fix server exports dead-code elimination for routes outside of app directory (#8795) Always prepend DOCTYPE in SPA mode entry.server.tsx, can opt out via remix reveal (#8725) Fix build issue in SPA mode when using a basename (#8720) Vite: Validate that the MDX Rollup plugin, if present, is placed before Remix in Vite config (#8690) Vite: reliably detect non-root routes in Windows (#8806) Sometimes route file will be unnormalized Windows path with \\ instead of /. Vite: Pass remixUserConfig to preset remixConfig hook (#8797) Vite: Fix issue resolving critical CSS during development when the current working directory differs from the project root (#8752) Vite: Ensure CSS file URLs that are only referenced in the server build are available on the client (#8796) Vite: Require version 5.1.0 to support .css?url imports (#8723) Fix type error in Remix config for synchronous routes function (#8745) Vite: Support Vite v5.1.0's .css?url imports (#8684) Always ignore route files starting with . (#8801) Vite: Enable use of vite preview to preview Remix SPA applications (#8624) In the SPA template, npm run start has been renamed to npm run preview which uses vite preview instead of a standalone HTTP server such as http-server or serv-cli Vite: Remove the ability to pass publicPath as an option to the Remix vite plugin (#8145) ⚠️ This is a breaking change for projects using the unstable Vite plugin with a publicPath This is already handled in Vite via the base config so we now set the Remix publicPath from the Vite base config Vite: Fix issue where client route file requests fail if search params have been parsed and serialized before reaching the Remix Vite plugin (#8740) Vite: Enable HMR for .md and .mdx files (#8711) Updated dependencies: @remix-run/server-runtime@2.7.0 @remix-run/node@2.7.0 2.6.0 Minor Changes Add future.v3_throwAbortReason flag to throw request.signal.reason when a request is aborted instead of an Error such as new Error(\"query() call aborted: GET /path\") (#8251) Patch Changes Vite: Add manifest option to Vite plugin to enable writing a .remix/manifest.json file to the build directory (#8575) This is a breaking change for consumers of the Vite plugin's \"server bundles\" feature. The build/server/bundles.json file has been superseded by the more general build/.remix/manifest.json. While the old server bundles manifest was always written to disk when generating server bundles, the build manifest file must be explicitly enabled via the manifest option. Vite: Provide Unstable_ServerBundlesFunction and Unstable_VitePluginConfig types (#8654) Vite: add --sourcemapClient and --sourcemapServer flags to remix vite:build (#8613) --sourcemapClient --sourcemapClient=inline --sourcemapClient=hidden --sourcemapServer --sourcemapServer=inline --sourcemapServer=hidden See https://vitejs.dev/config/build-options.html#build-sourcemap Vite: Validate IDs returned from the serverBundles function to ensure they only contain alphanumeric characters, hyphens and underscores (#8598) Vite: fix \"could not fast refresh\" false alarm (#8580) HMR is already functioning correctly but was incorrectly logging that it \"could not fast refresh\" on internal client routes. Now internal client routes correctly register Remix exports like meta for fast refresh, which removes the false alarm. Vite: Cloudflare Pages support (#8531) To get started with Cloudflare, you can use the [unstable-vite-cloudflare][template-vite-cloudflare] template: npx create-remix@latest --template remix-run/remix/templates/unstable-vite-cloudflare Or read the new docs at Future > Vite > Cloudflare and Future > Vite > Migrating > Migrating Cloudflare Functions. Vite: Remove undocumented backwards compatibility layer for Vite v4 (#8581) Vite: rely on Vite plugin ordering (#8627) This is a breaking change for projects using the unstable Vite plugin. The Remix plugin expects to process JavaScript or TypeScript files, so any transpilation from other languages must be done first. For example, that means putting the MDX plugin before the Remix plugin: import mdx from \"@mdx-js/rollup\"; import { unstable_vitePlugin as remix } from \"@remix-run/dev\"; import { defineConfig } from \"vite\"; export default defineConfig({ plugins: [ + mdx(), remix() - mdx(), ], }); Previously, the Remix plugin misused enforce: \"post\" from Vite's plugin API to ensure that it ran last. However, this caused other unforeseen issues. Instead, we now rely on standard Vite semantics for plugin ordering. The official Vite React SWC plugin also relies on plugin ordering for MDX. Vite: Add presets option to ease integration with different platforms and tools. (#8514) Vite: Remove interop with <LiveReload />, rely on <Scripts /> instead (#8636) This is a breaking change for projects using the unstable Vite plugin. Vite provides a robust client-side runtime for development features like HMR, making the <LiveReload /> component obsolete. In fact, having a separate dev scripts component was causing issues with script execution order. To work around this, the Remix Vite plugin used to override <LiveReload /> into a bespoke implementation that was compatible with Vite. Instead of all this indirection, now the Remix Vite plugin instructs the <Scripts /> component to automatically include Vite's client-side runtime and other dev-only scripts. import { - LiveReload, Outlet, Scripts, } export default function App() { return ( <html> <head> </head> <body> <Outlet /> <Scripts /> - <LiveReload /> </body> </html> ) } Vite: Add buildEnd hook (#8620) Vite: add dev load context option to Cloudflare preset (#8649) Vite: Add mode field into generated server build (#8539) Vite: Only write Vite manifest files if build.manifest is enabled within the Vite config (#8599) This is a breaking change for consumers of Vite's manifest.json files. To explicitly enable generation of Vite manifest files, you must set build.manifest to true in your Vite config. export default defineConfig({ build: { manifest: true }, // ... }); Vite: reduce network calls for route modules during HMR (#8591) Vite: Add new buildDirectory option with a default value of \"build\". This replaces the old assetsBuildDirectory and serverBuildDirectory options which defaulted to \"build/client\" and \"build/server\" respectively. (#8575) This is a breaking change for consumers of the Vite plugin that were using the assetsBuildDirectory and serverBuildDirectory options. The Remix Vite plugin now builds into a single directory containing client and server directories. If you've customized your build output directories, you'll need to migrate to the new buildDirectory option, e.g. import { unstable_vitePlugin as remix } from \"@remix-run/dev\"; import { defineConfig } from \"vite\"; export default defineConfig({ plugins: [ remix({ - serverBuildDirectory: \"dist/server\", - assetsBuildDirectory: \"dist/client\", + buildDirectory: \"dist\", }) ], }); Vite: Remove unstable prefix from serverBundles option. (#8596) Vite: Write Vite manifest files to build/.vite directory rather than being nested within build/client and build/server directories. (#8599) This is a breaking change for consumers of Vite's manifest.json files. Vite manifest files are now written to the Remix build directory. Since all Vite manifests are now in the same directory, they're no longer named manifest.json. Instead, they're named build/.vite/client-manifest.json and build/.vite/server-manifest.json, or build/.vite/server-{BUNDLE_ID}-manifest.json when using server bundles. Updated dependencies: @remix-run/server-runtime@2.6.0 @remix-run/node@2.6.0 2.5.1 Patch Changes Add isSpaMode to @remix-run/dev/server-build virtual module (#8492) Automatically prepend <!DOCTYPE html> if not present to fix quirks mode warnings for SPA template (#8495) Vite: Errors for server-only code point to new docs (#8488) Vite: Fix HMR race condition when reading changed file contents (#8479) Vite: Tree-shake unused route exports in the client build (#8468) Vite: Performance profiling (#8493) Run remix vite:build --profile to generate a .cpuprofile that can be shared or uploaded to speedscope.app In dev, press p + enter to start a new profiling session or stop the current session If you need to profile dev server startup, run remix vite:dev --profile to initialize the dev server with a running profiling session For more, see the new docs: Vite > Performance Vite: Improve performance of dev server requests by invalidating Remix's virtual modules on relevant file changes rather than on every request (#8164) Updated dependencies: @remix-run/node@2.5.1 @remix-run/server-runtime@2.5.1 2.5.0 Minor Changes Add unstable support for \"SPA Mode\" (#8457) You can opt into SPA Mode by setting unstable_ssr: false in your Remix Vite plugin config: // vite.config.ts import { unstable_vitePlugin as remix } from \"@remix-run/dev\"; import { defineConfig } from \"vite\"; export default defineConfig({ plugins: [remix({ unstable_ssr: false })], }); Development in SPA Mode is just like a normal Remix app, and still uses the Remix dev server for HMR/HDR: remix vite:dev Building in SPA Mode will generate an index.html file in your client assets directory: remix vite:build To run your SPA, you serve your client assets directory via an HTTP server: npx http-server build/client For more information, please refer to the SPA Mode docs. Add unstable_serverBundles option to Vite plugin to support splitting server code into multiple request handlers. (#8332) This is an advanced feature designed for hosting provider integrations. When compiling your app into multiple server bundles, there will need to be a custom routing layer in front of your app directing requests to the correct bundle. This feature is currently unstable and only designed to gather early feedback. Example usage: import { unstable_vitePlugin as remix } from \"@remix-run/dev\"; import { defineConfig } from \"vite\"; export default defineConfig({ plugins: [ remix({ unstable_serverBundles: ({ branch }) => { const isAuthenticatedRoute = branch.some( (route) => route.id === \"routes/_authenticated\" ); return isAuthenticatedRoute ? \"authenticated\" : \"unauthenticated\"; }, }), ], }); Patch Changes Fix issue with isbot v4 released on 1/1/2024 (#8415) remix dev will now add \"isbot\": \"^4\" to package.json instead of using latest Update built-in entry.server files to work with both isbot@3 and isbot@4 for backwards-compatibility with Remix apps that have pinned isbot to v3 Templates are updated to use isbot@4 moving forward via create-remix Vite: Fix HMR issues when altering exports for non-rendered routes (#8157) Vite: Default NODE_ENV to \"production\" when running remix vite:build command (#8405) Vite: Remove Vite plugin config option serverBuildPath in favor of separate serverBuildDirectory and serverBuildFile options (#8332) Vite: Loosen strict route exports restriction, reinstating support for non-Remix route exports (#8420) Updated dependencies: @remix-run/server-runtime@2.5.0 @remix-run/node@2.5.0 2.4.1 Patch Changes Vite: Error messages when .server files are referenced by client (#8267) Previously, referencing a .server module from client code resulted in an error message like: The requested module '/app/models/answer.server.ts' does not provide an export named 'isDateType' This was confusing because answer.server.ts does provide the isDateType export, but Remix was replacing .server modules with empty modules (export {}) for the client build Now, Remix explicitly fails at compile time when a .server module is referenced from client code and includes dedicated error messages depending on whether the import occurs in a route or a non-route module The error messages also include links to relevant documentation Remove unstable_viteServerBuildModuleId in favor of manually referencing virtual module name \"virtual:remix/server-build\". (#8264) This is a breaking change for projects using the unstable Vite plugin with a custom server. This change was made to avoid issues where @remix-run/dev could be inadvertently required in your server's production dependencies. Instead, you should manually write the virtual module name \"virtual:remix/server-build\" when calling ssrLoadModule in development. -import { unstable_viteServerBuildModuleId } from \"@remix-run/dev\"; // ... app.all( \"*\", createRequestHandler({ build: vite - ? () => vite.ssrLoadModule(unstable_viteServerBuildModuleId) + ? () => vite.ssrLoadModule(\"virtual:remix/server-build\") : await import(\"./build/server/index.js\"), }) ); Vite: Fix errors for non-existent index.html importer (#8353) Add vite:dev and vite:build commands to the Remix CLI. (#8211) In order to handle upcoming Remix features where your plugin options can impact the number of Vite builds required, you should now run your Vite dev and build processes via the Remix CLI. { \"scripts\": { - \"dev\": \"vite dev\", - \"build\": \"vite build && vite build --ssr\" + \"dev\": \"remix vite:dev\", + \"build\": \"remix vite:build\" } } Vite: Preserve names for exports from .client modules (#8200) Unlike .server modules, the main idea is not to prevent code from leaking into the server build since the client build is already public. Rather, the goal is to isolate the SSR render from client-only code. Routes need to import code from .client modules without compilation failing and then rely on runtime checks or otherwise ensure that execution only happens within a client-only context (e.g. event handlers, useEffect). Replacing .client modules with empty modules would cause the build to fail as ESM named imports are statically analyzed. So instead, we preserve the named export but replace each exported value with undefined. That way, the import is valid at build time and standard runtime checks can be used to determine if the code is running on the server or client. Disable watch mode in Vite child compiler during build (#8342) Vite: Show warning when source maps are enabled in production build (#8222) Updated dependencies: @remix-run/server-runtime@2.4.1 @remix-run/node@2.4.1 2.4.0 Minor Changes Vite: exclude modules within .server directories from client build (#8154) Add support for clientLoader/clientAction/HydrateFallback route exports (RFC) (#8173) Remix now supports loaders/actions that run on the client (in addition to, or instead of the loader/action that runs on the server). While we still recommend server loaders/actions for the majority of your data needs in a Remix app - these provide some levers you can pull for more advanced use-cases such as: Leveraging a data source local to the browser (i.e., localStorage) Managing a client-side cache of server data (like IndexedDB) Bypassing the Remix server in a BFF setup and hitting your API directly from the browser Migrating a React Router SPA to a Remix application By default, clientLoader will not run on hydration, and will only run on subsequent client side navigations. If you wish to run your client loader on hydration, you can set clientLoader.hydrate=true to force Remix to execute it on initial page load. Keep in mind that Remix will still SSR your route component so you should ensure that there is no new required data being added by your clientLoader. If your clientLoader needs to run on hydration and adds data you require to render the route component, you can export a HydrateFallback component that will render during SSR, and then your route component will not render until the clientLoader has executed on hydration. clientAction is simpler than clientLoader because it has no hydration use-cases. clientAction will only run on client-side navigations. For more information, please refer to the clientLoader and clientAction documentation. Vite: Strict route exports (#8171) With Vite, Remix gets stricter about which exports are allowed from your route modules. Previously, the Remix compiler would allow any export from routes. While this was convenient, it was also a common source of bugs that were hard to track down because they only surfaced at runtime. For more, see https://remix.run/docs/en/main/future/vite#strict-route-exports Add a new future.v3_relativeSplatPath flag to implement a breaking bug fix to relative routing when inside a splat route. For more information, please see the React Router 6.21.0 Release Notes and the useResolvedPath docs. (#8216) Patch Changes Upgrade Vite peer dependency range to v5 (#8172) Support HMR for routes with handle export in Vite dev (#8022) Fix flash of unstyled content for non-Express custom servers in Vite dev (#8076) Bundle CSS imported in client entry file in Vite plugin (#8143) Change Vite build output paths to fix a conflict between how Vite and the Remix compiler each manage the public directory. (#8077) This is a breaking change for projects using the unstable Vite plugin. The server is now compiled into build/server rather than build, and the client is now compiled into build/client rather than public. For more information on the changes and guidance on how to migrate your project, refer to the updated Remix Vite documentation. Remove undocumented legacyCssImports option from Vite plugin due to issues with ?url imports of CSS files not being processed correctly in Vite (#8096) Vite: fix access to default entry.{client,server}.tsx within pnpm workspace on Windows (#8057) Remove unstable_createViteServer and unstable_loadViteServerBuild which were only minimal wrappers around Vite's createServer and ssrLoadModule functions when using a custom server. (#8120) This is a breaking change for projects using the unstable Vite plugin with a custom server. Instead, we now provide unstable_viteServerBuildModuleId so that custom servers interact with Vite directly rather than via Remix APIs, for example: -import { - unstable_createViteServer, - unstable_loadViteServerBuild, -} from \"@remix-run/dev\"; +import { unstable_viteServerBuildModuleId } from \"@remix-run/dev\"; Creating the Vite server in middleware mode: const vite = process.env.NODE_ENV === \"production\" ? undefined - : await unstable_createViteServer(); + : await import(\"vite\").then(({ createServer }) => + createServer({ + server: { + middlewareMode: true, + }, + }) + ); Loading the Vite server build in the request handler: app.all( \"*\", createRequestHandler({ build: vite - ? () => unstable_loadViteServerBuild(vite) + ? () => vite.ssrLoadModule(unstable_viteServerBuildModuleId) : await import(\"./build/server/index.js\"), }) ); Pass request handler errors to vite.ssrFixStacktrace in Vite dev to ensure stack traces correctly map to the original source code (#8066) Vite: Preserve names for exports from .client imports (#8200) Unlike .server modules, the main idea is not to prevent code from leaking into the server build since the client build is already public. Rather, the goal is to isolate the SSR render from client-only code. Routes need to import code from .client modules without compilation failing and then rely on runtime checks to determine if the code is running on the server or client. Replacing .client modules with empty modules would cause the build to fail as ESM named imports are statically analyzed. So instead, we preserve the named export but replace each exported value with an empty object. That way, the import is valid at build time and the standard runtime checks can be used to determine if then code is running on the server or client. Add @remix-run/node to Vite's optimizeDeps.include array (#8177) Improve Vite plugin performance (#8121) Parallelize detection of route module exports Disable server.preTransformRequests in Vite child compiler since it's only used to process route modules Remove automatic global Node polyfill installation from the built-in Vite dev server and instead allow explicit opt-in. (#8119) This is a breaking change for projects using the unstable Vite plugin without a custom server. If you're not using a custom server, you should call installGlobals in your Vite config instead. import { unstable_vitePlugin as remix } from \"@remix-run/dev\"; +import { installGlobals } from \"@remix-run/node\"; import { defineConfig } from \"vite\"; +installGlobals(); export default defineConfig({ plugins: [remix()], }); Vite: Errors at build-time when client imports .server default export (#8184) Remix already stripped .server file code before ensuring that server code never makes it into the client. That results in errors when client code tries to import server code, which is exactly what we want! But those errors were happening at runtime for default imports. A better experience is to have those errors happen at build-time so that you guarantee that your users won't hit them. Fix request instanceof Request checks when using Vite dev server (#8062) Updated dependencies: @remix-run/server-runtime@2.4.0 @remix-run/node@2.4.0 2.3.1 Patch Changes Support nonce prop on LiveReload component in Vite dev (#8014) Ensure code-split JS files in the server build's assets directory aren't cleaned up after Vite build (#8042) Fix redundant copying of assets from public directory in Vite build (#8039) This ensures that static assets aren't duplicated in the server build directory This also fixes an issue where the build would break if assetsBuildDirectory was deeply nested within the public directory Updated dependencies: @remix-run/node@2.3.1 @remix-run/server-runtime@2.3.1 2.3.0 Patch Changes Support rendering of LiveReload component after Scripts in Vite dev (#7919) fix(vite): fix \"react-refresh/babel\" resolution for custom server with pnpm (#7904) Support JSX usage in .jsx files without manual React import in Vite (#7888) Support optional rendering of LiveReload component in Vite dev (#7919) Fix Vite production builds when plugins that have different local state between development and production modes are present, e.g. @mdx-js/rollup. (#7911) Cache resolution of Remix Vite plugin options (#7908) Support Vite 5 (#7846) Allow process.env.NODE_ENV values other than \"development\" in Vite dev (#7980) Attach CSS from shared chunks to routes in Vite build (#7952) fix(vite): Let Vite handle serving files outside of project root via /@fs (#7913) This fixes errors when using default client entry or server entry in a pnpm project where those files may be outside of the project root, but within the workspace root. By default, Vite prevents access to files outside the workspace root (when using workspaces) or outside of the project root (when not using workspaces) unless user explicitly opts into it via Vite's server.fs.allow. Improve performance of LiveReload proxy in Vite dev (#7883) fix(vite): deduplicate @remix-run/react (#7926) Pre-bundle Remix dependencies to avoid Remix router duplicates. Our remix-react-proxy plugin does not process default client and server entry files since those come from within node_modules. That means that before Vite pre-bundles dependencies (e.g. first time dev server is run) mismatching Remix routers cause Error: You must render this element inside a <Remix> element. Fix React Fast Refresh error on load when using defer in Vite dev server (#7842) Handle multiple \"Set-Cookie\" headers in Vite dev server (#7843) Fix flash of unstyled content on initial page load in Vite dev when using a custom Express server (#7937) Emit assets that were only referenced in the server build into the client assets directory in Vite build (#7892, cherry-picked in 8cd31d65) Populate process.env from .env files on the server in Vite dev (#7958) Fix FutureConfig type (#7895) Updated dependencies: @remix-run/server-runtime@2.3.0 @remix-run/node@2.3.0 2.2.0 Minor Changes Unstable Vite support for Node-based Remix apps (#7590) remix build \uD83D\uDC49 vite build && vite build --ssr remix dev \uD83D\uDC49 vite dev Other runtimes (e.g. Deno, Cloudflare) not yet supported. See \"Future > Vite\" in the Remix Docs for details Add a new future.v3_fetcherPersist flag to change the persistence behavior of fetchers. Instead of being immediately cleaned up when unmounted in the UI, fetchers will persist until they return to an idle state (RFC) (#7704) For more details, please refer to the React Router 6.18.0 release notes Patch Changes Updated dependencies: @remix-run/server-runtime@2.2.0 @remix-run/node@2.2.0 2.1.0 Patch Changes Sourcemap takes into account special chars in output file (#7574) Updated dependencies: @remix-run/server-runtime@2.1.0 2.0.1 Patch Changes Fix types for MDX files when using pnpm (#7491) Update getDependenciesToBundle to handle ESM packages without main exports (#7272) Note that these packages must expose package.json in their exports field so that their path can be resolved Fix server builds where serverBuildPath extension is .cjs (#7180) Updated dependencies: @remix-run/server-runtime@2.0.1 2.0.0 Major Changes The create-remix CLI has been rewritten to feature a cleaner interface, Git repo initialization and optional remix.init script execution. The interactive template prompt and official Remix stack/template shorthands have also been removed so that community/third-party templates are now on a more equal footing. (#6887) The code for create-remix has been moved out of the Remix CLI since it's not intended for use within an existing Remix application This means that the remix create command is no longer available. Enable built-in PostCSS and Tailwind support by default. (#6909) These tools are now automatically used within the Remix compiler if PostCSS and/or Tailwind configuration files are present in your project. If you have a custom PostCSS and/or Tailwind setup outside of Remix, you can disable these features in your remix.config.js via the postcss:false and/or tailwind:false flags Drop React 17 support (#7121) Require Node >=18.0.0 (#6939) Compile server build to Node 18 (#7292) This allows features like top-level await to be used within a Remix app Remove default Node.js polyfills - you must now opt-into polyfills via the serverNodeBuiltinsPolyfill and browserNodeBuiltinsPolyfill configs (#7269) Remove v2_errorBoundary flag and CatchBoundary implementation (#6906) Remove v2_normalizeFormMethod future flag - all formMethod values will be normalized in v2 (#6875) Remove v2_routeConvention flag - the flat route file convention is now standard (#6969) Remove v2_headers flag - it is now the default behavior to use the deepest headers function in the route tree (#6979) The route meta API now defaults to the new \"V2 Meta\" API (#6958) Please refer to the (docs and Preparing for V2 guide for more information. Default to serverModuleFormat: \"esm\" and update remix-serve to use dynamic import to support ESM and CJS build outputs (#6949) Remove serverBuildTarget config option (#6896) Remove deprecated REMIX_DEV_HTTP_ORIGIN env var - use REMIX_DEV_ORIGIN instead (#6963) Remove devServerBroadcastDelay config option (#7063) Remove deprecated devServerPort option - use --port / dev.port instead (#7078) Remove deprecated REMIX_DEV_SERVER_WS_PORT env var - use remix dev's '--port / port option instead (#6965) Stop passing isTypeScript to remix.init script (#7099) Remove replace-remix-magic-imports codemod (#6899) Remove deprecated --no-restart/restart cli args/flags - use --manual/manual instead (#6962) Remove deprecated --scheme/scheme and --host/host cli args/flags - use REMIX_DEV_ORIGIN instead (#6962) Promote the future.v2_dev flag in remix.config.js to a root level dev config (#7002) Remove browserBuildDirectory config option (#6900) Remove serverBuildDirectory config option ([#6897](https://github.com/remix-run/remix/pull/- Remove codemod command (#6918) 6897)) Removed support for \"magic exports\" from the remix package. This package can be removed from your package.json and you should update all imports to use the source @remix-run/* packages: (#6895) - import type { ActionArgs } from \"remix\"; - import { json, useLoaderData } from \"remix\"; + import type { ActionArgs } from \"@remix-run/node\"; + import { json } from \"@remix-run/node\"; + import { useLoaderData } from \"@remix-run/react\"; Minor Changes Warn users about obsolete future flags in remix.config.js (#7048) Detect built mode via build.mode (#6964) Prevents mode mismatch between built Remix server entry and user-land server Additionally, all runtimes (including non-Node runtimes) can use build.mode to determine if HMR should be performed Support bun package manager (#7074) The serverNodeBuiltinsPolyfill option (along with the newly added browserNodeBuiltinsPolyfill) now supports defining global polyfills in addition to module polyfills (#7269) For example, to polyfill Node's Buffer global: module.exports = { serverNodeBuiltinsPolyfill: { globals: { Buffer: true, }, // You'll probably need to polyfill the \"buffer\" module // too since the global polyfill imports this: modules: { buffer: true, }, }, }; Patch Changes Fix importing of PNGs, SVGs, and other assets from packages in node_modules (#6813, #7182) Decouple the @remix-run/dev package from the contents of the @remix-run/css-bundle package. (#6982) The contents of the @remix-run/css-bundle package are now entirely managed by the Remix compiler Even though it's still recommended that your Remix dependencies all share the same version, this change ensures that there are no runtime errors when upgrading @remix-run/dev without upgrading @remix-run/css-bundle Allow non-development modes for remix watch (#7117) Stop remix dev when esbuild is not running (#7158) Do not interpret JSX in .ts files (#7306) While JSX is supported in .js files for compatibility with existing apps and libraries, .ts files should not contain JSX. By not interpreting .ts files as JSX, .ts files can contain single-argument type generics without needing a comma to disambiguate from JSX: // this works in .ts files const id = <T>(x: T) => x; // ^ single-argument type generic // this doesn't work in .tsx files const id = <T,>(x: T) => x; // ^ is this a JSX element? or a single-argument type generic? // this works in .tsx files const id = <T,>(x: T) => x; // ^ comma: this is a generic, not a JSX element const component = <h1>hello</h1>; // ^ no comma: this is a JSX element Enhance obsolete flag warning for future.v2_dev if it was an object, and prompt users to lift it to the root dev config (#7427) Allow decorators in app code (#7176) Allow JSX in .js files during HMR (#7112) Kill app server when remix dev terminates (#7280) Support dependencies that import polyfill packages for Node built-ins via a trailing slash (e.g. importing the buffer package with var Buffer = require('buffer/').Buffer as recommended in their README) (#7198) These imports were previously marked as external This meant that they were left as dynamic imports in the client bundle and would throw a runtime error in the browser (e.g. Dynamic require of \"buffer/\" is not supported) Surface errors when PostCSS config is invalid (#7391) Restart dev server when Remix config changes (#7269) Remove outdated ESM import warnings (#6916) Most of the time these warnings were false positives. Instead, we now rely on built-in Node warnings for ESM imports. Do not trigger rebuilds when .DS_Store changes (#7172) Remove warnings for stabilized flags: (#6905) unstable_cssSideEffectImports unstable_cssModules unstable_vanillaExtract Allow any mode (NODE_ENV) (#7113) Replace the deprecated xdm package with @mdx-js/mdx (#4054) Write a version.txt sentinel file after server build is completely written (#7299) Updated dependencies: @remix-run/server-runtime@2.0.0 1.19.3 Patch Changes Show deprecation warning when using devServerBroadcastDelay and devServerPort config options (#7064) Updated dependencies: @remix-run/server-runtime@1.19.3 1.19.2 Patch Changes Update proxy-agent to resolve npm audit security vulnerability (#7027) Updated dependencies: @remix-run/server-runtime@1.19.2 1.19.1 Patch Changes Add a heartbeat ping to prevent the WebSocket connection from being closed due to inactivity when using a proxy like Cloudflare (#6904, #6927) Treeshake out HMR code from production builds (#6894) Updated dependencies: @remix-run/server-runtime@1.19.1 1.19.0 Minor Changes improved networking options for v2_dev (#6724) deprecate the --scheme and --host options and replace them with the REMIX_DEV_ORIGIN environment variable Output esbuild metafiles for bundle analysis (#6772) Written to server build directory (build/ by default): metafile.css.json metafile.js.json (browser JS) metafile.server.json (server JS) Metafiles can be uploaded to https://esbuild.github.io/analyze/ for analysis. Add serverNodeBuiltinsPolyfill config option. In remix.config.js you can now disable polyfills of Node.js built-in modules for non-Node.js server platforms, or opt into a subset of polyfills. (#6814, #6859, #6877) // Disable all polyfills exports.serverNodeBuiltinsPolyfill = { modules: {} }; // Enable specific polyfills exports.serverNodeBuiltinsPolyfill = { modules: { crypto: true, // Provide a JSPM polyfill fs: \"empty\", // Provide an empty polyfill }, }; Patch Changes ignore missing react-dom/client for react 17 (#6725) Warn if not using v2_dev (#6818) Also, rename --no-restart to --manual to match intention and documentation. --no-restart remains an alias for --manual in v1 for backwards compatibility. ignore errors when killing already dead processes (#6773) Always rewrite css-derived assets during builds (#6837) fix sourcemaps for v2_dev (#6762) Do not clear screen when dev server starts (#6719) On some terminal emulators, \"clearing\" only scrolls the next line to the top. on others, it erases the scrollback. Instead, let users call clear themselves (clear && remix dev) if they want to clear. Updated dependencies: @remix-run/server-runtime@1.19.0 1.18.1 Patch Changes Ignore missing react-dom/client for React 17 (#6725) Updated dependencies: @remix-run/server-runtime@1.18.1 1.18.0 Minor Changes stabilize v2 dev server (#6615) improved logging for remix build and remix dev (#6596) Patch Changes fix docs links for msw and mkcert (#6672) fix remix dev -c: kill all descendant processes of specified command when restarting (#6663) Add caching to regular stylesheet compilation (#6638) Rename Architect (AWS Lambda) -> Architect in the create-remix CLI to avoid confusion for other methods of deploying to AWS (i.e., SST) (#6484) Improve CSS bundle build performance by skipping unused Node polyfills (#6639) Improve performance of CSS bundle build by skipping compilation of Remix/React packages that are known not to contain CSS imports (#6654) Cache CSS side-effect imports transform when using HMR (#6622) Fix bug with pathless layout routes beneath nested path segments (#6649) Add caching to PostCSS for CSS Modules (#6604) Add caching to PostCSS for side-effect imports (#6554) cache getRouteModuleExports calls to significantly speed up build and HMR rebuild times (#6629) group rebuild logs with surrounding whitespace (#6607) instructions for integrating with msw (#6669) Update minimum version of esbuild-plugins-node-modules-polyfill to 1.0.16 to ensure that the plugin is cached (#6652) Updated dependencies: @remix-run/server-runtime@1.18.0 1.17.1 Patch Changes Replace esbuild-plugin-polyfill-node with esbuild-plugins-node-modules-polyfill (#6562) Lazily generate CSS bundle when import of @remix-run/css-bundle is detected (#6535) Updated dependencies: @remix-run/server-runtime@1.17.1 1.17.0 Minor Changes built-in tls support (#6483) New options: --tls-key / tlsKey: TLS key --tls-cert / tlsCert: TLS Certificate If both TLS options are set, scheme defaults to https Example Install mkcert and create a local CA: brew install mkcert mkcert -install Then make sure you inform node about your CA certs: export NODE_EXTRA_CA_CERTS=\"$(mkcert -CAROOT)/rootCA.pem\" \uD83D\uDC46 You'll probably want to put that env var in your scripts or .bashrc/.zshrc Now create key.pem and cert.pem: mkcert -key-file key.pem -cert-file cert.pem localhost See mkcert docs for more details. Finally, pass in the paths to the key and cert via flags: remix dev --tls-key=key.pem --tls-cert=cert.pem or via config: module.exports = { future: { unstable_dev: { tlsKey: \"key.pem\", tlsCert: \"cert.pem\", }, }, }; That's all that's needed to set up the Remix Dev Server with TLS. \uD83D\uDEA8 Make sure to update your app server for TLS as well. For example, with express: import fs from \"node:fs\"; import https from \"node:https\"; import express from \"express\"; const app = express(); // ...code setting up your express app... const appServer = https.createServer( { key: fs.readFileSync(\"key.pem\"), cert: fs.readFileSync(\"cert.pem\"), }, app ); appServer.listen(3000, () => { console.log(\"Ready on https://localhost:3000\"); }); Known limitations remix-serve does not yet support TLS. That means this only works for custom app server using the -c flag for now. Reuse dev server port for WebSocket (Live Reload,HMR,HDR) (#6476) As a result the webSocketPort/--websocket-port option has been obsoleted. Additionally, scheme/host/port options for the dev server have been renamed. Available options are: Option flag config default Command -c / --command command remix-serve <server build path> Scheme --scheme scheme http Host --host host localhost Port --port port Dynamically chosen open port No restart --no-restart restart: false restart: true Note that scheme/host/port options are for the dev server, not your app server. You probably don't need to use scheme/host/port option if you aren't configuring networking (e.g. for Docker or SSL). Patch Changes Add caching to PostCSS for regular stylesheets (#6505) Fix warnings when importing CSS files with future.unstable_dev enabled (#6506) Fix Tailwind performance issue when postcss.config.js contains plugins: { tailwindcss: {} } and remix.config.js contains both tailwind: true and postcss: true. (#6468) Note that this was not an issue when the plugin function had been explicitly called, i.e. plugins: [tailwindcss()]. Remix avoids adding the Tailwind plugin to PostCSS if it's already present but we were failing to detect when the plugin function hadn't been called — either because the plugin function itself had been passed, i.e. plugins: [require('tailwindcss')], or the plugin config object syntax had been used, i.e. plugins: { tailwindcss: {} }. Faster server export removal for routes when unstable_dev is enabled. (#6455) Also, only render modulepreloads on SSR. Do not render modulepreloads when hydrated. Add HeadersArgs type to be consistent with loaders/actions/meta and allows for using a function declaration in addition to an arrow function expression (#6247) import type { HeadersArgs } from \"@remix-run/node\"; // or cloudflare/deno export function headers({ loaderHeaders }: HeadersArgs) { return { \"x-my-custom-thing\": loaderHeaders.get(\"x-my-custom-thing\") || \"fallback\", }; } better error message when remix-serve is not found (#6477) restore color for app server output (#6485) Fix route ranking bug with pathless layout route next to a sibling index route (#4421) Under the hood this is done by removing the trailing slash from all generated path values since the number of slash-delimited segments counts towards route ranking so the trailing slash incorrectly increases the score for routes Support sibling pathless layout routes by removing pathless layout routes from the unique route path checks in conventional route generation since they inherently trigger duplicate paths (#4421) fix dev server crashes caused by ungraceful hdr error handling (#6467) Updated dependencies: @remix-run/server-runtime@1.17.0 1.16.1 Patch Changes Cross-module loader change detection for HDR (#6299) Normalize path for dev server PATH envvar so that it works cross-platform (e.g. Windows) (#6310) Fix CSS imports in JS files that use JSX (#6309) Kill app server when dev server exits (#6395) Wait until app server is killed before starting a new app server (#6289) Ensure CSS bundle changes result in a new manifest hash (#6374) Normalize file paths before testing if a changed file is a route entry (#6293) Fix race where app server responds with updated manifest version before dev server is listening for it (#6294) dev server now listens for updated versions before writing the server changes, guaranteeing that it is listening before the app server gets a chance to send its 'ready' message Only process .css.ts/.css.js files with Vanilla Extract if @vanilla-extract/css is installed (#6345) Stop modifying a user's tsconfig.json when running using getConfig (remix dev, remix routes, remix build, etc) (#6156) Cancel previous build when rebuild is kicked off to prevent rebuilds from hanging (#6295) Update minimum version of Babel dependencies to avoid errors parsing decorators (#6390) Support asset imports when detecting loader changes for HDR (#6396) Updated dependencies: @remix-run/server-runtime@1.16.1 1.16.0 Minor Changes Enable support for CSS Modules, Vanilla Extract and CSS side-effect imports (#6046) These CSS bundling features were previously only available via future.unstable_cssModules, future.unstable_vanillaExtract and future.unstable_cssSideEffectImports options in remix.config.js, but they have now been stabilized. In order to use these features, check out our guide to CSS bundling in your project. Stabilize built-in PostCSS support via the new postcss option in remix.config.js. As a result, the future.unstable_postcss option has also been deprecated. (#5960) The postcss option is false by default, but when set to true will enable processing of all CSS files using PostCSS if postcss.config.js is present. If you followed the original PostCSS setup guide for Remix, you may have a folder structure that looks like this, separating your source files from its processed output: . ├── app │ └── styles (processed files) │ ├── app.css │ └── routes │ └── index.css └── styles (source files) ├── app.css └── routes └── index.css After you've enabled the new postcss option, you can delete the processed files from app/styles folder and move your source files from styles to app/styles: . ├── app │ └── styles (source files) │ ├── app.css │ └── routes │ └── index.css You should then remove app/styles from your .gitignore file since it now contains source files rather than processed output. You can then update your package.json scripts to remove any usage of postcss since Remix handles this automatically. For example, if you had followed the original setup guide: { \"scripts\": { - \"dev:css\": \"postcss styles --base styles --dir app/styles -w\", - \"build:css\": \"postcss styles --base styles --dir app/styles --env production\", - \"dev\": \"concurrently \\\"npm run dev:css\\\" \\\"remix dev\\\"\" + \"dev\": \"remix dev\" } } Stabilize built-in Tailwind support via the new tailwind option in remix.config.js. As a result, the future.unstable_tailwind option has also been deprecated. (#5960) The tailwind option is false by default, but when set to true will enable built-in support for Tailwind functions and directives in your CSS files if tailwindcss is installed. If you followed the original Tailwind setup guide for Remix and want to make use of this feature, you should first delete the generated app/tailwind.css. Then, if you have a styles/tailwind.css file, you should move it to app/tailwind.css. rm app/tailwind.css mv styles/tailwind.css app/tailwind.css Otherwise, if you don't already have an app/tailwind.css file, you should create one with the following contents: @tailwind base; @tailwind components; @tailwind utilities; You should then remove /app/tailwind.css from your .gitignore file since it now contains source code rather than processed output. You can then update your package.json scripts to remove any usage of tailwindcss since Remix handles this automatically. For example, if you had followed the original setup guide: { // ... \"scripts\": { - \"build\": \"run-s \\\"build:*\\\"\", + \"build\": \"remix build\", - \"build:css\": \"npm run generate:css -- --minify\", - \"build:remix\": \"remix build\", - \"dev\": \"run-p \\\"dev:*\\\"\", + \"dev\": \"remix dev\", - \"dev:css\": \"npm run generate:css -- --watch\", - \"dev:remix\": \"remix dev\", - \"generate:css\": \"npx tailwindcss -o ./app/tailwind.css\", \"start\": \"remix-serve build\" } // ... } The Remix dev server spins up your app server as a managed subprocess. (#6133) This keeps your development environment as close to production as possible. It also means that the Remix dev server is compatible with any app server. By default, the dev server will use the Remix App Server, but you opt to use your own app server by specifying the command to run it via the -c/--command flag: remix dev # uses `remix-serve <serve build path>` as the app server remix dev -c \"node ./server.js\" # uses your custom app server at `./server.js` The dev server will: force NODE_ENV=development and warn you if it was previously set to something else rebuild your app whenever your Remix app code changes restart your app server whenever rebuilds succeed handle live reload and HMR + Hot Data Revalidation App server coordination In order to manage your app server, the dev server needs to be told what server build is currently being used by your app server. This works by having the app server send a \"I'm ready!\" message with the Remix server build hash as the payload. This is handled automatically in Remix App Server and is set up for you via calls to broadcastDevReady or logDevReady in the official Remix templates. If you are not using Remix App Server and your server doesn't call broadcastDevReady, you'll need to call it in your app server after it is up and running. For example, in an Express server: // server.js // <other imports> import { broadcastDevReady } from \"@remix-run/node\"; // Path to Remix's server build directory ('build/' by default) const BUILD_DIR = path.join(process.cwd(), \"build\"); // <code setting up your express server> app.listen(3000, () => { const build = require(BUILD_DIR); console.log(\"Ready: http://localhost:\" + port); // in development, call `broadcastDevReady` _after_ your server is up and running if (process.env.NODE_ENV === \"development\") { broadcastDevReady(build); } }); Options Options priority order is: 1. flags, 2. config, 3. defaults. Option flag config default Command -c / --command command remix-serve <server build path> HTTP(S) scheme --http-scheme httpScheme http HTTP(S) host --http-host httpHost localhost HTTP(S) port --http-port httpPort Dynamically chosen open port Websocket port --websocket-port websocketPort Dynamically chosen open port No restart --no-restart restart: false restart: true \uD83D\uDEA8 The --http-* flags are only used for internal dev server <-> app server communication. Your app will run on your app server's normal URL. To set unstable_dev configuration, replace unstable_dev: true with unstable_dev: { <options> }. For example, to set the HTTP(S) port statically: // remix.config.js module.exports = { future: { unstable_dev: { httpPort: 8001, }, }, }; SSL and custom hosts You should only need to use the --http-* flags and --websocket-port flag if you need fine-grain control of what scheme/host/port for the dev server. If you are setting up SSL or Docker networking, these are the flags you'll want to use. \uD83D\uDEA8 Remix will not set up SSL and custom host for you. The --http-scheme and --http-host flag are for you to tell Remix how you've set things up. It is your task to set up SSL certificates and host files if you want those features. --no-restart and require cache purging If you want to manage server changes yourself, you can use the --no-restart flag to tell the dev server to refrain from restarting your app server when builds succeed: remix dev -c \"node ./server.js\" --no-restart For example, you could purge the require cache of your app server to keep it running while picking up server changes. If you do so, you should watch the server build path (build/ by default) for changes and only purge the require cache when changes are detected. \uD83D\uDEA8 If you use --no-restart, it is your responsibility to call broadcastDevReady when your app server has picked up server changes. For example, with chokidar: // server.dev.js const BUILD_PATH = path.resolve(__dirname, \"build\"); const watcher = chokidar.watch(BUILD_PATH); watcher.on(\"change\", () => { // 1. purge require cache purgeRequireCache(); // 2. load updated server build const build = require(BUILD_PATH); // 3. tell dev server that this app server is now ready broadcastDevReady(build); }); Patch Changes Fix absolute paths in CSS url() rules when using CSS Modules, Vanilla Extract and CSS side-effect imports (#5788) look for @remix-run/serve in devDependencies when running remix dev (#6228) add warning for v2 \"cjs\"->\"esm\" serverModuleFormat default change (#6154) write mjs server output files (#6225) fix(react,dev): dev chunking and refresh race condition (#6201) Use correct require context in bareImports plugin. (#6181) use minimatch for regex instead of glob-to-regexp (#6017) add logDevReady as replacement for platforms that can't initialize async I/O outside of the request response lifecycle. (#6204) Use the \"automatic\" JSX runtime when processing MDX files. (#6098) forcibly kill app server during dev (#6197) show first compilation error instead of cancelation errors (#6202) Resolve imports from route modules across the graph back to the virtual module created by the v2 routes plugin. This fixes issues where we would duplicate portions of route modules that were imported. (#6098) Updated dependencies: @remix-run/server-runtime@1.16.0 1.15.0 Minor Changes Added deprecation warning for v2_normalizeFormMethod (#5863) Added a new future.v2_normalizeFormMethod flag to normalize the exposed useNavigation().formMethod as an uppercase HTTP method to align with the previous useTransition behavior as well as the fetch() behavior of normalizing to uppercase HTTP methods. (#5815) When future.v2_normalizeFormMethod === false, useNavigation().formMethod is lowercase useFetcher().formMethod is uppercase When future.v2_normalizeFormMethod === true: useNavigation().formMethod is uppercase useFetcher().formMethod is uppercase Added deprecation warning for browserBuildDirectory in remix.config (#5702) Added deprecation warning for CatchBoundary in favor of future.v2_errorBoundary (#5718) Added experimental support for Vanilla Extract caching, which can be enabled by setting future.unstable_vanillaExtract: { cache: true } in remix.config. This is considered experimental due to the use of a brand new Vanilla Extract compiler under the hood. In order to use this feature, you must be using at least v1.10.0 of @vanilla-extract/css. (#5735) Added deprecation warning for serverBuildDirectory in remix.config (#5704) Patch Changes Fixed issue to ensure changes to CSS inserted via @remix-run/css-bundle are picked up during HMR (#5823) We now use path.resolve when re-exporting entry.client (#5707) Added support for .mjs and .cjs extensions when detecting CSS side-effect imports (#5564) Fixed resolution issues for pnpm users installing react-refresh (#5637) Added deprecation warning for future.v2_meta (#5878) Added optional entry file support for React 17 (#5681) Updated dependencies: @remix-run/server-runtime@1.15.0 1.14.3 Patch Changes dev server is resilient to build failures (#5795) Updated dependencies: @remix-run/server-runtime@1.14.3 1.14.2 Patch Changes remove premature deprecation warnings (#5790) Updated dependencies: @remix-run/server-runtime@1.14.2 1.14.1 Patch Changes Add types for importing *.ico files (#5430) Allow moduleResolution: \"bundler\" in tsconfig.json (#5576) Fix issue with x-route imports creating multiple entries in the module graph (#5721) Add serverBuildTarget deprecation warning (#5624) Updated dependencies: @remix-run/server-runtime@1.14.1 1.14.0 Minor Changes Hot Module Replacement and Hot Data Revalidation (#5259) Requires unstable_dev future flag to be enabled HMR provided through React Refresh Features: HMR for component and style changes HDR when loaders for current route change Known limitations for MVP: Only implemented for React via React Refresh No import.meta.hot API exposed yet Revalidates all loaders on route when loader changes are detected Loader changes do not account for imported dependencies changing Make entry.client and entry.server files optional (#4600) we'll use a bundled version of each unless you provide your own Patch Changes Fixes flat route inconsistencies where route.{ext} wasn't always being treated like index.{ext} when used in a folder (#5459) Route conflict no longer throw errors and instead display a helpful warning that we're using the first one we found. ⚠️ Route Path Collision: \"/dashboard\" The following routes all define the same URL, only the first one will be used \uD83D\uDFE2️️ routes/dashboard/route.tsx ⭕️️ routes/dashboard.tsx ⚠️ Route Path Collision: \"/\" The following routes all define the same URL, only the first one will be used \uD83D\uDFE2️️ routes/_landing._index.tsx ⭕️️ routes/_dashboard._index.tsx ⭕️ routes/_index.tsx Log errors thrown during initial build in development. (#5441) Sync FutureConfig interface between packages (#5398) Add file loader for importing .csv files (#3920) Updated dependencies: @remix-run/server-runtime@1.14.0 1.13.0 Minor Changes We are deprecating serverBuildTarget in remix.config. See the release notes for v1.13.0 for more information. (#5354) Add built-in support for PostCSS via the future.unstable_postcss feature flag (#5229) Add built-in support for Tailwind via the future.unstable_tailwind feature flag (#5229) Patch Changes Mark Vanilla Extract files as side effects to ensure that files only containing global styles aren't tree-shaken (#5246) Support decorators in files using CSS side-effect imports (#5305) We made several Flat route fixes and enhancements. See the release notes for v1.13.0 for more information. (#5228) Updated dependencies: @remix-run/server-runtime@1.13.0 1.12.0 Minor Changes Added a new development server available in the Remix config under the unstable_dev flag. See the release notes for a full description. (#5133) Patch Changes Fixed issues with v2_routeConvention on Windows so that new and renamed files are properly included (#5266) Server build should not be removed in remix watch and remix dev (#5228) The dev server will now clean up build directories whenever a rebuild starts (#5223) Updated dependencies: @remix-run/server-runtime@1.12.0 1.11.1 Patch Changes Fixed a bug with v2_routeConvention that prevented index modules from being recognized for route paths (195291a3d) Updated dependencies: @remix-run/server-runtime@1.11.1 1.11.0 Minor Changes Specify file loader for .fbx, .glb, .gltf, .hdr, and .mov files (#5030) Added support for Vanilla Extract via the unstable_vanillaExtract future flag. IMPORTANT: Features marked with unstable are … unstable. While we're confident in the use cases they solve, the API and implementation may change without a major version bump. (#5040) Add support for CSS side-effect imports via the unstable_cssSideEffectImports future flag. IMPORTANT: Features marked with unstable are … unstable. While we're confident in the use cases they solve, the API and implementation may change without a major version bump. (#4919) Add support for CSS Modules via the unstable_cssModules future flag. IMPORTANT: Features marked with unstable are … unstable. While we're confident in the use cases they solve, the API and implementation may change without a major version bump. (#4852) Patch Changes Add new \"flat\" routing conventions. This convention will be the default in v2 but is available now under the v2_routeConvention future flag. (#4880) Added support for handle in MDX frontmatter (#4865) Updated dependencies: @remix-run/server-runtime@1.11.0 1.10.1 Patch Changes Update babel config to transpile down to node 14 (#5047) Updated dependencies: @remix-run/server-runtime@1.10.1 1.10.0 Patch Changes Fixed several issues with TypeScript to JavaScript conversion when running create-remix (#4891) Resolve asset entry full path to support monorepo import of styles (#4855) Updated dependencies: @remix-run/server-runtime@1.10.0 1.9.0 Minor Changes Allow defining multiple routes for the same route module file (#3970) Added support and conventions for optional route segments (#4706) Patch Changes The Remix compiler now supports new Typescript 4.9 syntax (like the satisfies keyword) (#4754) Optimize parentRouteId lookup in defineConventionalRoutes. (#4800) Fixed a bug in .ts -> .js conversion on Windows by using a relative unix-style path (#4718) Updated dependencies: @remix-run/server-runtime@1.9.0 1.8.2 Patch Changes Updated dependencies: @remix-run/server-runtime@1.8.2 @remix-run/serve@1.8.2 1.8.1 Patch Changes Added a missing type definition for the Remix config future option to the @remix-run/dev/server-build virtual module (#4771) Updated dependencies: @remix-run/serve@1.8.1 @remix-run/server-runtime@1.8.1 1.8.0 Minor Changes Added support for a new route meta API to handle arrays of tags instead of an object. For details, check out the RFC. (#4610) Patch Changes Importing functions and types from the remix package is deprecated, and all exported modules will be removed in the next major release. For more details,see the release notes for 1.4.0 where these changes were first announced. (#4661) Updated dependencies: @remix-run/server-runtime@1.8.0 @remix-run/serve@1.8.0 1.7.6 Patch Changes Updated dependencies: @remix-run/serve@1.7.6 @remix-run/server-runtime@1.7.6 Patch Changes Updated dependencies: @remix-run/serve@1.7.6-pre.0 @remix-run/server-runtime@1.7.6-pre.0 1.7.5 Patch Changes Updated dependencies: @remix-run/serve@1.7.5 @remix-run/server-runtime@1.7.5 1.7.4 Patch Changes Updated dependencies: @remix-run/server-runtime@1.7.4 @remix-run/serve@1.7.4 1.7.3 Patch Changes Update create-remix to use the new examples repository when using --template example/<name> (#4208) Add support for setting moduleResolution to node, node16 or nodenext in tsconfig.json. (#4034) Add resources imported only by resource routes to assetsBuildDirectory (#3841) Ensure that any assets referenced in CSS files are hashed and copied to the assetsBuildDirectory. (#4130) Updated dependencies: @remix-run/serve@1.7.3 @remix-run/server-runtime@1.7.3 1.7.2 Patch Changes Updated dependencies: @remix-run/server-runtime@1.7.2 @remix-run/serve@1.7.2 1.7.1 Patch Changes Updated dependencies: @remix-run/server-runtime@1.7.1 @remix-run/serve@1.7.1 1.7.0 Minor Changes Added support for importing .gql and .graphql files as plain text (#3923) Added support for importing .zip and .avif files as resource URLs (#3985) Patch Changes Removed our compiler's React shim in favor of esbuild's new automatic JSX transform (#3860) Updated dependencies: @remix-run/server-runtime@1.7.0 @remix-run/serve@1.7.0 1.6.8 Patch Changes Added support for .mjs and .cjs file extensions for remix.config (#3675) Added support for importing .sql files as text content (#3190) Updated the compiler to make MDX builds deterministic (and a little faster!) (#3966) Updated dependencies: @remix-run/server-runtime@1.6.8 @remix-run/serve@1.6.8 1.6.7 Patch Changes Remove logical nullish assignment, which is incompatible with Node v14. (#3880) Don't show ESM warnings when consumed via dynamic import. (#3872) Updated dependencies: @remix-run/serve@1.6.7 @remix-run/server-runtime@1.6.7 1.6.6 Patch Changes Write server build output files so that only assets imported from resource routes are written to disk (#3817) Add support for exporting links in .mdx files (#3801) Ensure that build hashing is deterministic (#2027) Fix types for @remix-run/dev/server-build virtual module (#3743) Updated dependencies: @remix-run/serve@1.6.6 @remix-run/server-runtime@1.6.6 1.6.5 Patch Changes Update serverBareModulesPlugin warning to use full import path (#3656) Fix broken --port flag in create-remix (#3694) Updated dependencies @remix-run/server-runtime @remix-run/serve"
  },
  "src/frontend/app-client/node_modules/@react-router/dev/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/@react-router/dev/LICENSE.html",
    "title": "",
    "summary": "MIT License Copyright (c) React Training LLC 2015-2019 Copyright (c) Remix Software Inc. 2020-2021 Copyright (c) Shopify Inc. 2022-2023 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/@react-router/dev/README.html": {
    "href": "src/frontend/app-client/node_modules/@react-router/dev/README.html",
    "title": "",
    "summary": "Dev tools and CLI for React Router that enables framework features through bundler integration like server rendering, code splitting, HMR, etc. npm install @react-router/dev --save-dev"
  },
  "src/frontend/app-client/node_modules/@react-router/express/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/@react-router/express/CHANGELOG.html",
    "title": "@react-router/express",
    "summary": "@react-router/express 7.5.0 Patch Changes Updated dependencies: react-router@7.5.0 @react-router/node@7.5.0 7.4.1 Patch Changes Better validation of x-forwarded-host header to preent potential security issues. (#13309) Updated dependencies: react-router@7.4.1 @react-router/node@7.4.1 7.4.0 Patch Changes Updated dependencies: react-router@7.4.0 @react-router/node@7.4.0 7.3.0 Patch Changes Update express peerDependency to include v5 (https://github.com/remix-run/react-router/pull/13064) (#12961) Updated dependencies: react-router@7.3.0 @react-router/node@7.3.0 7.2.0 Patch Changes Updated dependencies: react-router@7.2.0 @react-router/node@7.2.0 7.1.5 Patch Changes Updated dependencies: react-router@7.1.5 @react-router/node@7.1.5 7.1.4 Patch Changes Updated dependencies: react-router@7.1.4 @react-router/node@7.1.4 7.1.3 Patch Changes Updated dependencies: react-router@7.1.3 @react-router/node@7.1.3 7.1.2 Patch Changes Updated dependencies: react-router@7.1.2 @react-router/node@7.1.2 7.1.1 Patch Changes Updated dependencies: react-router@7.1.1 @react-router/node@7.1.1 7.1.0 Patch Changes Updated dependencies: react-router@7.1.0 @react-router/node@7.1.0 7.0.2 Patch Changes Updated dependencies: react-router@7.0.2 @react-router/node@7.0.2 7.0.1 Patch Changes Updated dependencies: react-router@7.0.1 @react-router/node@7.0.1 7.0.0 Major Changes Remove single fetch future flag. (#11522) update minimum node version to 18 (#11690) Add exports field to all packages (#11675) node package no longer re-exports from react-router (#11702) Drop support for Node 18, update minimum Node vestion to 20 (#12171) Remove installGlobals() as this should no longer be necessary Patch Changes Updated dependencies: react-router@7.0.0 @react-router/node@7.0.0 2.9.0 Patch Changes Updated dependencies: @remix-run/node@2.9.0 2.8.1 Patch Changes Updated dependencies: @remix-run/node@2.8.1 2.8.0 Patch Changes Updated dependencies: @remix-run/node@2.8.0 2.7.2 Patch Changes Updated dependencies: @remix-run/node@2.7.2 2.7.1 Patch Changes Updated dependencies: @remix-run/node@2.7.1 2.7.0 Minor Changes Vite: Add a new basename option to the Vite plugin, allowing users to set the internal React Router basename in order to to serve their applications underneath a subpath (#8145) Patch Changes Use req.originalUrl instead of req.url so that Remix sees the full URL (#8145) Remix relies on the knowing the full URL to ensure that server and client code can function together, and does not support URL rewriting prior to the Remix handler Updated dependencies: @remix-run/node@2.7.0 2.6.0 Patch Changes Updated dependencies: @remix-run/node@2.6.0 2.5.1 Patch Changes Updated dependencies: @remix-run/node@2.5.1 2.5.0 Patch Changes Updated dependencies: @remix-run/node@2.5.0 2.4.1 Patch Changes Updated dependencies: @remix-run/node@2.4.1 2.4.0 Patch Changes Updated dependencies: @remix-run/node@2.4.0 2.3.1 Patch Changes Updated dependencies: @remix-run/node@2.3.1 2.3.0 Patch Changes Fix flash of unstyled content on initial page load in Vite dev when using a custom Express server (#7937) Updated dependencies: @remix-run/node@2.3.0 2.2.0 Patch Changes Allow the @remix-run/express adapter to work behind a proxy when using app.enable('trust proxy') (#7323) Previously, this used req.get('host') to construct the Remix Request, but that does not respect X-Forwarded-Host This now uses req.hostname which will respect X-Forwarded-Host Updated dependencies: @remix-run/node@2.2.0 2.1.0 Patch Changes Flush headers for text/event-stream responses (#7619) Updated dependencies: @remix-run/node@2.1.0 2.0.1 Patch Changes Updated dependencies: @remix-run/node@2.0.1 2.0.0 Major Changes Require Node >=18.0.0 (#6939) For preparation of using Node's built in fetch implementation, installing the fetch globals is now a responsibility of the app server (#7009) If you are using remix-serve, nothing is required If you are using your own app server, you will need to install the globals yourself import { installGlobals } from \"@remix-run/node\"; installGlobals(); source-map-support is now a responsibility of the app server (#7009) If you are using remix-serve, nothing is required If you are using your own app server, you will need to install source-map-support yourself. npm i source-map-support import sourceMapSupport from \"source-map-support\"; sourceMapSupport.install(); Patch Changes Switch to headers.entries() instead of non-spec-compliant headers.raw() in sendRemixResponse (#7150) Remove references to fetch polyfills in node and arc adapters (#7230) Updated dependencies: @remix-run/node@2.0.0 @remix-run/web-fetch@4.4.0 @remix-run/web-file@3.1.0 @remix-run/web-stream@1.1.0 1.19.3 Patch Changes Updated dependencies: @remix-run/node@1.19.3 1.19.2 Patch Changes Updated dependencies: @remix-run/node@1.19.2 1.19.1 Patch Changes Updated dependencies: @remix-run/node@1.19.1 1.19.0 Patch Changes Updated dependencies: @remix-run/node@1.19.0 1.18.1 Patch Changes Updated dependencies: @remix-run/node@1.18.1 1.18.0 Patch Changes Updated dependencies: @remix-run/node@1.18.0 1.17.1 Patch Changes Updated dependencies: @remix-run/node@1.17.1 1.17.0 Patch Changes Updated dependencies: @remix-run/node@1.17.0 1.16.1 Patch Changes Updated dependencies: @remix-run/node@1.16.1 1.16.0 Patch Changes feat: support async getLoadContext in all adapters (#6170) Updated dependencies: @remix-run/node@1.16.0 1.15.0 Patch Changes Updated dependencies: @remix-run/node@1.15.0 1.14.3 Patch Changes Updated dependencies: @remix-run/node@1.14.3 1.14.2 Patch Changes Updated dependencies: @remix-run/node@1.14.2 1.14.1 Patch Changes Updated dependencies: @remix-run/node@1.14.1 1.14.0 Patch Changes Updated dependencies: @remix-run/node@1.14.0 1.13.0 Patch Changes Fix fetch Request creation for incoming URLs with double slashes (#5336) Updated dependencies: @remix-run/node@1.13.0 1.12.0 Patch Changes Updated dependencies: @remix-run/node@1.12.0 1.11.1 Patch Changes Updated dependencies: @remix-run/node@1.11.1 1.11.0 Patch Changes Updated dependencies: @remix-run/node@1.11.0 1.10.1 Patch Changes Updated dependencies: @remix-run/node@1.10.1 1.10.0 Patch Changes Updated dependencies: @remix-run/node@1.10.0 1.9.0 Patch Changes Updated dependencies: @remix-run/node@1.9.0 1.8.2 Patch Changes Updated dependencies: @remix-run/node@1.8.2 1.8.1 Patch Changes Updated dependencies: @remix-run/node@1.8.1 1.8.0 Patch Changes Updated dependencies: @remix-run/node@1.8.0 1.7.6 Patch Changes Updated dependencies: @remix-run/node@1.7.6 1.7.5 Patch Changes Updated dependencies: @remix-run/node@1.7.5 1.7.4 Patch Changes Updated dependencies: @remix-run/node@1.7.4 1.7.3 Patch Changes Updated dependencies: @remix-run/node@1.7.3 1.7.2 Patch Changes Updated dependencies: @remix-run/node@1.7.2 1.7.1 Patch Changes Ensured that requests are properly aborted on closing of a Response instead of Request (#3626) Updated dependencies: @remix-run/node@1.7.1 1.7.0 Patch Changes Updated dependencies: @remix-run/node@1.7.0 1.6.8 Patch Changes Updated dependencies: @remix-run/node@1.6.8 1.6.7 Patch Changes Updated dependencies: @remix-run/node@1.6.7 1.6.6 Patch Changes Updated dependencies: @remix-run/node@1.6.6 1.6.5 Patch Changes Updated dependencies @remix-run/node@1.6.5"
  },
  "src/frontend/app-client/node_modules/@react-router/express/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/@react-router/express/LICENSE.html",
    "title": "",
    "summary": "MIT License Copyright (c) React Training LLC 2015-2019 Copyright (c) Remix Software Inc. 2020-2021 Copyright (c) Shopify Inc. 2022-2023 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/@react-router/express/README.html": {
    "href": "src/frontend/app-client/node_modules/@react-router/express/README.html",
    "title": "",
    "summary": "Express server request handler for React Router. npm install @react-router/express"
  },
  "src/frontend/app-client/node_modules/@react-router/node/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/@react-router/node/CHANGELOG.html",
    "title": "@react-router/node",
    "summary": "@react-router/node 7.5.0 Patch Changes Updated dependencies: react-router@7.5.0 7.4.1 Patch Changes Updated dependencies: react-router@7.4.1 7.4.0 Patch Changes Updated dependencies: react-router@7.4.0 7.3.0 Patch Changes Updated dependencies: react-router@7.3.0 7.2.0 Patch Changes Updated dependencies: react-router@7.2.0 7.1.5 Patch Changes Updated dependencies: react-router@7.1.5 7.1.4 Patch Changes Updated dependencies: react-router@7.1.4 7.1.3 Patch Changes Updated dependencies: react-router@7.1.3 7.1.2 Patch Changes Updated dependencies: react-router@7.1.2 7.1.1 Patch Changes Updated dependencies: react-router@7.1.1 7.1.0 Patch Changes Updated dependencies: react-router@7.1.0 7.0.2 Patch Changes Updated dependencies: react-router@7.0.2 7.0.1 Patch Changes Updated dependencies: react-router@7.0.1 7.0.0 Major Changes Remove single fetch future flag. (#11522) For Remix consumers migrating to React Router, the crypto global from the Web Crypto API is now required when using cookie and session APIs. This means that the following APIs are provided from react-router rather than platform-specific packages: (#11837) createCookie createCookieSessionStorage createMemorySessionStorage createSessionStorage For consumers running older versions of Node, the installGlobals function from @remix-run/node has been updated to define globalThis.crypto, using Node's require('node:crypto').webcrypto implementation. Since platform-specific packages no longer need to implement this API, the following low-level APIs have been removed: createCookieFactory createSessionStorageFactory createCookieSessionStorageFactory createMemorySessionStorageFactory update minimum node version to 18 (#11690) Add exports field to all packages (#11675) node package no longer re-exports from react-router (#11702) Drop support for Node 18, update minimum Node vestion to 20 (#12171) Remove installGlobals() as this should no longer be necessary Patch Changes Add createRequestListener to @react-router/node (#12319) Remove unstable upload handler. (#12015) Remove unneeded dependency on @web3-storage/multipart-parser (#12274) Updated dependencies: react-router@7.0.0 2.9.0 Minor Changes Use undici as our fetch polyfill going forward (#9106, #9111) Put undici fetch polyfill behind a new installGlobals({ nativeFetch: true }) parameter (#9198) remix-serve will default to using undici for the fetch polyfill if future._unstable_singleFetch is enabled because the single fetch implementation relies on the undici polyfill Any users opting into Single Fetch and managing their own polfill will need to pass the flag to installGlobals on their own to avoid runtime errors with Single Fetch Patch Changes Updated dependencies: @remix-run/server-runtime@2.9.0 2.8.1 Patch Changes Updated dependencies: @remix-run/server-runtime@2.8.1 2.8.0 Patch Changes Updated dependencies: @remix-run/server-runtime@2.8.0 2.7.2 Patch Changes Updated dependencies: @remix-run/server-runtime@2.7.2 2.7.1 Patch Changes Updated dependencies: @remix-run/server-runtime@2.7.1 2.7.0 Patch Changes Updated dependencies: @remix-run/server-runtime@2.7.0 2.6.0 Patch Changes Updated dependencies: @remix-run/server-runtime@2.6.0 2.5.1 Patch Changes Updated dependencies: @remix-run/server-runtime@2.5.1 2.5.0 Patch Changes Updated dependencies: @remix-run/server-runtime@2.5.0 2.4.1 Patch Changes Updated dependencies: @remix-run/server-runtime@2.4.1 2.4.0 Minor Changes Deprecate DataFunctionArgs in favor of LoaderFunctionArgs/ActionFunctionArgs. This is aimed at keeping the types aligned across server/client loaders/actions now that clientLoader/clientActon functions have serverLoader/serverAction parameters which differentiate ClientLoaderFunctionArgs/ClientActionFunctionArgs. (#8173) Patch Changes Update to @remix-run/web-fetch@4.4.2 (#8231) Updated dependencies: @remix-run/server-runtime@2.4.0 2.3.1 Patch Changes Updated dependencies: @remix-run/server-runtime@2.3.1 2.3.0 Patch Changes Updated dependencies: @remix-run/server-runtime@2.3.0 2.2.0 Patch Changes Updated dependencies: @remix-run/server-runtime@2.2.0 2.1.0 Patch Changes Updated dependencies: @remix-run/server-runtime@2.1.0 2.0.1 Patch Changes Switch from crypto.randomBytes to crypto.webcrypto.getRandomValues for file session storage ID generation (#7203) Use native Blob class instead of polyfill (#7217) Updated dependencies: @remix-run/server-runtime@2.0.1 @remix-run/web-fetch@4.4.1 2.0.0 Major Changes Require Node >=18.0.0 (#6939) Stop exporting the fetch API in favor of using the version in the global scope - which can be polyfilled via installGlobals (#7293) Removed/adjusted types to prefer unknown over any and to align with underlying React Router types (#7319, #7354): Renamed the useMatches() return type from RouteMatch to UIMatch Renamed LoaderArgs/ActionArgs to LoaderFunctionArgs/ActionFunctionArgs AppData changed from any to unknown Location[\"state\"] (useLocation.state) changed from any to unknown UIMatch[\"data\"] (useMatches()[i].data) changed from any to unknown UIMatch[\"handle\"] (useMatches()[i].handle) changed from { [k: string]: any } to unknown Fetcher[\"data\"] (useFetcher().data) changed from any to unknown MetaMatch.handle (used in meta()) changed from any to unknown AppData/RouteHandle are no longer exported as they are just aliases for unknown The route meta API now defaults to the new \"V2 Meta\" API (#6958) Please refer to the (docs and Preparing for V2 guide for more information. For preparation of using Node's built in fetch implementation, installing the fetch globals is now a responsibility of the app server (#7009) If you are using remix-serve, nothing is required If you are using your own app server, you will need to install the globals yourself import { installGlobals } from \"@remix-run/node\"; installGlobals(); source-map-support is now a responsibility of the app server (#7009) If you are using remix-serve, nothing is required If you are using your own app server, you will need to install source-map-support yourself. npm i source-map-support import sourceMapSupport from \"source-map-support\"; sourceMapSupport.install(); Removed support for \"magic exports\" from the remix package. This package can be removed from your package.json and you should update all imports to use the source @remix-run/* packages: (#6895) - import type { ActionArgs } from \"remix\"; - import { json, useLoaderData } from \"remix\"; + import type { ActionArgs } from \"@remix-run/node\"; + import { json } from \"@remix-run/node\"; + import { useLoaderData } from \"@remix-run/react\"; Minor Changes Re-export the new redirectDocument method from React Router (#7040, #6842) (#7040) Patch Changes Remove atob/btoa polyfills in favor of built-in versions (#7206) Export proper ErrorResponse type for usage alongside isRouteErrorResponse (#7244) Add the rest of the Web Streams API to installGlobals (#7321) Ensures fetch() return is instanceof global Response by removing extended classes for NodeRequest and NodeResponse in favor of custom interface type cast (#7109) Remove recursion from stream utilities (#7245) Updated dependencies: @remix-run/server-runtime@2.0.0 @remix-run/web-fetch@4.4.0 @remix-run/web-file@3.1.0 @remix-run/web-stream@1.1.0 1.19.3 Patch Changes Updated dependencies: @remix-run/server-runtime@1.19.3 1.19.2 Patch Changes Update to latest @remix-run/web-* packages (#7026) Updated dependencies: @remix-run/server-runtime@1.19.2 1.19.1 Patch Changes Updated dependencies: @remix-run/server-runtime@1.19.1 1.19.0 Patch Changes Upgrade to @remix-run/web-fetch@4.3.5. Submitted empty file inputs are now correctly parsed out as empty File instances instead of being surfaced as an empty string via request.formData() (#6816) Updated dependencies: @remix-run/server-runtime@1.19.0 1.18.1 Patch Changes Updated dependencies: @remix-run/server-runtime@1.18.1 1.18.0 Patch Changes Updated dependencies: @remix-run/server-runtime@1.18.0 1.17.1 Patch Changes Updated dependencies: @remix-run/server-runtime@1.17.1 1.17.0 Patch Changes Add HeadersArgs type to be consistent with loaders/actions/meta and allows for using a function declaration in addition to an arrow function expression (#6247) import type { HeadersArgs } from \"@remix-run/node\"; // or cloudflare/deno export function headers({ loaderHeaders }: HeadersArgs) { return { \"x-my-custom-thing\": loaderHeaders.get(\"x-my-custom-thing\") || \"fallback\", }; } Fix request.clone() instanceof Request returning false. (#6512) Updated dependencies: @remix-run/server-runtime@1.17.0 1.16.1 Patch Changes Updated dependencies: @remix-run/server-runtime@1.16.1 1.16.0 Patch Changes add @remix-run/node/install side-effect to allow node --require @remix-run/node/install (#6132) add logDevReady as replacement for platforms that can't initialize async I/O outside of the request response lifecycle. (#6204) add missing files to published package (#6179) Updated dependencies: @remix-run/server-runtime@1.16.0 1.15.0 Minor Changes We have made a few changes to the API for route module meta functions when using the future.v2_meta flag. These changes are only breaking for users who have opted in. (#5746) V2_HtmlMetaDescriptor has been renamed to V2_MetaDescriptor The meta function's arguments have been simplified parentsData has been removed, as each route's loader data is available on the data property of its respective match object // before export function meta({ parentsData }) { return [{ title: parentsData[\"routes/some-route\"].title }]; } // after export function meta({ matches }) { return [ { title: matches.find((match) => match.id === \"routes/some-route\") .data.title, }, ]; } The route property on route matches has been removed, as relevant match data is attached directly to the match object // before export function meta({ matches }) { const rootModule = matches.find((match) => match.route.id === \"root\"); } // after export function meta({ matches }) { const rootModule = matches.find((match) => match.id === \"root\"); } Added support for generating <script type='application/ld+json' /> and meta-related <link /> tags to document head via the route meta function when using the v2_meta future flag Patch Changes Updated dependencies: @remix-run/server-runtime@1.15.0 1.14.3 Patch Changes Updated dependencies: @remix-run/server-runtime@1.14.3 1.14.2 Patch Changes Updated dependencies: @remix-run/server-runtime@1.14.2 1.14.1 Patch Changes Updated dependencies: @remix-run/server-runtime@1.14.1 1.14.0 Patch Changes Updated dependencies: @remix-run/server-runtime@1.14.0 1.13.0 Patch Changes Updated dependencies: @remix-run/server-runtime@1.13.0 1.12.0 Patch Changes Updated dependencies: @remix-run/server-runtime@1.12.0 1.11.1 Patch Changes Updated dependencies: @remix-run/server-runtime@1.11.1 1.11.0 Patch Changes Introduces the defer() API from @remix-run/router with support for server-rendering and HTTP streaming. This utility allows you to defer values returned from loader functions by returning promises instead of resolved values. This has been refered to as \"sending a promise over the wire\". (#4920) Informational Resources: https://gist.github.com/jacob-ebey/9bde9546c1aafaa6bc8c242054b1be26 https://github.com/remix-run/remix/blob/main/decisions/0004-streaming-apis.md Documentation Resources (better docs specific to Remix are in the works): https://reactrouter.com/en/main/utils/defer https://reactrouter.com/en/main/components/await https://reactrouter.com/en/main/hooks/use-async-value https://reactrouter.com/en/main/hooks/use-async-error Updated dependencies: @remix-run/server-runtime@1.11.0 1.10.1 Patch Changes Updated dependencies: @remix-run/server-runtime@1.10.1 1.10.0 Patch Changes Export V2_HtmlMetaDescriptor and V2_MetaFunction types from runtime packages (#4943) Updated dependencies: @remix-run/server-runtime@1.10.0 1.9.0 Patch Changes Updated dependencies: @remix-run/server-runtime@1.9.0 1.8.2 Patch Changes Updated dependencies: @remix-run/server-runtime@1.8.2 1.8.1 Patch Changes Updated dependencies: @remix-run/server-runtime@1.8.1 1.8.0 Minor Changes Importing functions and types from the remix package is deprecated, and all (#3284) exported modules will be removed in the next major release. For more details, see the release notes for 1.4.0 where these changes were first announced. Patch Changes Update @remix-run/web-fetch. This addresses two bugs: (#4644) It fixes a memory leak caused by unregistered listeners It adds support for custom \"credentials\" values (Remix does nothing with these at the moment, but they pass through for the consumer of the request to access if needed) Updated dependencies: @remix-run/server-runtime@1.8.0 1.7.6 Patch Changes Updated dependencies: @remix-run/server-runtime@1.7.6 1.7.5 Patch Changes Updated dependencies: @remix-run/server-runtime@1.7.5 1.7.4 Patch Changes Updated dependencies: @remix-run/server-runtime@1.7.4 1.7.3 Patch Changes Updated dependencies: @remix-run/server-runtime@1.7.3 @remix-run/web-fetch@4.3.1 1.7.2 Patch Changes Flush Node streams to address issues with libraries like compression that rely on chunk flushing (#4235) Updated dependencies: @remix-run/server-runtime@1.7.2 1.7.1 Patch Changes Updated dependencies: @remix-run/server-runtime@1.7.1 1.7.0 Minor Changes We've added a new type: SerializeFrom. This is used to infer the (#4013) JSON-serialized return type of loaders and actions. Patch Changes Fixed a bug when destroying fileStorage sessions to prevent deleting entire session directories Updated dependencies: @remix-run/server-runtime@1.7.0 1.6.8 Patch Changes Updated dependencies: @remix-run/server-runtime@1.6.8 1.6.7 Patch Changes Updated dependencies: @remix-run/server-runtime@1.6.7 1.6.6 Patch Changes Updated dependencies: @remix-run/server-runtime@1.6.6 1.6.5 Patch Changes We enhanced the type signatures of loader/action and useLoaderData/useActionData to make it possible to infer the data type from return type of its related server function. To enable this feature, you will need to use the LoaderArgs type from @remix-run/node instead of typing the function directly: - import type { LoaderFunction } from \"@remix-run/node\"; + import type { LoaderArgs } from \"@remix-run/node\"; - export const loader: LoaderFunction = async (args) => { - return json<LoaderData>(data); - } + export async function loader(args: LoaderArgs) { + return json(data); + } Then you can infer the loader data by using typeof loader as the type variable in useLoaderData: - let data = useLoaderData() as LoaderData; + let data = useLoaderData<typeof loader>(); The API above is exactly the same for your route action and useActionData via the ActionArgs type. With this change you no longer need to manually define a LoaderData type (huge time and typo saver!), and we serialize all values so that useLoaderData can't return types that are impossible over the network, such as Date objects or functions. See the discussions in #1254 and #3276 for more context. Updated dependencies @remix-run/server-runtime"
  },
  "src/frontend/app-client/node_modules/@react-router/node/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/@react-router/node/LICENSE.html",
    "title": "",
    "summary": "MIT License Copyright (c) React Training LLC 2015-2019 Copyright (c) Remix Software Inc. 2020-2021 Copyright (c) Shopify Inc. 2022-2023 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/@react-router/node/README.html": {
    "href": "src/frontend/app-client/node_modules/@react-router/node/README.html",
    "title": "",
    "summary": "Node.js platform abstractions for React Router npm install @react-router/node"
  },
  "src/frontend/app-client/node_modules/@react-router/serve/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/@react-router/serve/CHANGELOG.html",
    "title": "@react-router/serve",
    "summary": "@react-router/serve 7.5.0 Patch Changes Updated dependencies: react-router@7.5.0 @react-router/node@7.5.0 @react-router/express@7.5.0 7.4.1 Patch Changes Updated dependencies: react-router@7.4.1 @react-router/express@7.4.1 @react-router/node@7.4.1 7.4.0 Patch Changes Updated dependencies: react-router@7.4.0 @react-router/node@7.4.0 @react-router/express@7.4.0 7.3.0 Patch Changes Updated dependencies: react-router@7.3.0 @react-router/express@7.3.0 @react-router/node@7.3.0 7.2.0 Patch Changes Updated dependencies: react-router@7.2.0 @react-router/node@7.2.0 @react-router/express@7.2.0 7.1.5 Patch Changes Updated dependencies: react-router@7.1.5 @react-router/node@7.1.5 @react-router/express@7.1.5 7.1.4 Patch Changes Updated dependencies: react-router@7.1.4 @react-router/node@7.1.4 @react-router/express@7.1.4 7.1.3 Patch Changes Updated dependencies: react-router@7.1.3 @react-router/express@7.1.3 @react-router/node@7.1.3 7.1.2 Patch Changes Updated dependencies: react-router@7.1.2 @react-router/node@7.1.2 @react-router/express@7.1.2 7.1.1 Patch Changes Updated dependencies: react-router@7.1.1 @react-router/express@7.1.1 @react-router/node@7.1.1 7.1.0 Patch Changes Updated dependencies: react-router@7.1.0 @react-router/node@7.1.0 @react-router/express@7.1.0 7.0.2 Patch Changes Updated dependencies: react-router@7.0.2 @react-router/node@7.0.2 @react-router/express@7.0.2 7.0.1 Patch Changes Updated dependencies: react-router@7.0.1 @react-router/express@7.0.1 @react-router/node@7.0.1 7.0.0 Major Changes Remove single fetch future flag. (#11522) update minimum node version to 18 (#11690) Add exports field to all packages (#11675) node package no longer re-exports from react-router (#11702) Patch Changes Update express.static configurations to support prerendering (#11547) Assets in the build/client/assets folder are served as before, with a 1-year immutable Cache-Control header Static files outside of assets, such as pre-rendered .html and .data files are not served with a specific Cache-Control header .data files are served with Content-Type: text/x-turbo For some reason, when adding this via express.static, it seems to also add a Cache-Control: public, max-age=0 to .data files Updated dependencies: react-router@7.0.0 @react-router/express@7.0.0 @react-router/node@7.0.0 2.9.0 Minor Changes Put undici fetch polyfill behind a new installGlobals({ nativeFetch: true }) parameter (#9198) remix-serve will default to using undici for the fetch polyfill if future.unstable_singleFetch is enabled because the single fetch implementation relies on the undici polyfill Any users opting into Single Fetch and managing their own polyfill will need to pass the flag to installGlobals on their own to avoid runtime errors with Single Fetch Patch Changes Updated dependencies: @remix-run/node@2.9.0 @remix-run/express@2.9.0 2.8.1 Patch Changes Updated dependencies: @remix-run/express@2.8.1 @remix-run/node@2.8.1 2.8.0 Patch Changes Updated dependencies: @remix-run/express@2.8.0 @remix-run/node@2.8.0 2.7.2 Patch Changes Updated dependencies: @remix-run/express@2.7.2 @remix-run/node@2.7.2 2.7.1 Patch Changes Updated dependencies: @remix-run/express@2.7.1 @remix-run/node@2.7.1 2.7.0 Patch Changes Updated dependencies: @remix-run/express@2.7.0 @remix-run/node@2.7.0 2.6.0 Patch Changes Updated dependencies: @remix-run/node@2.6.0 @remix-run/express@2.6.0 2.5.1 Patch Changes Updated dependencies: @remix-run/express@2.5.1 @remix-run/node@2.5.1 2.5.0 Patch Changes Don't try to load sourcemaps if they don't exist on disk (#8446) Updated dependencies: @remix-run/node@2.5.0 @remix-run/express@2.5.0 2.4.1 Patch Changes Use node fileURLToPath to convert source map URL to path (#8321) Updated dependencies: @remix-run/node@2.4.1 @remix-run/express@2.4.1 2.4.0 Patch Changes Fix source map loading when file has ?t=timestamp suffix (rebuilds) (#8174) Updated dependencies: @remix-run/node@2.4.0 @remix-run/express@2.4.0 2.3.1 Patch Changes Updated dependencies: @remix-run/express@2.3.1 @remix-run/node@2.3.1 2.3.0 Patch Changes Updated dependencies: @remix-run/express@2.3.0 @remix-run/node@2.3.0 2.2.0 Patch Changes Updated dependencies: @remix-run/express@2.2.0 @remix-run/node@2.2.0 2.1.0 Patch Changes Updated dependencies: @remix-run/express@2.1.0 @remix-run/node@2.1.0 2.0.1 Patch Changes Fix HMR for CJS projects using remix-serve and manual mode (remix dev --manual) (#7487) By explicitly busting the require cache, remix-serve now correctly re-imports new server changes in CJS ESM projects were already working correctly and are not affected by this. Fix error caused by partially written server build (#7470) Previously, it was possible to trigger a reimport of the app server code before the new server build had completely been written. Reimporting the partially written server build caused issues related to build.assets being undefined and crashing when reading build.assets.version Updated dependencies: @remix-run/node@2.0.1 @remix-run/express@2.0.1 2.0.0 Major Changes remix-serve now picks an open port if 3000 is taken (#7278) If PORT env var is set, remix-serve will use that port Otherwise, remix-serve picks an open port (3000 unless that is already taken) Integrate manual mode in remix-serve (#7231) Remove undocumented createApp Node API (#7229) remix-serve is a CLI, not a library Require Node >=18.0.0 (#6939) Promote the future.v2_dev flag in remix.config.js to a root level dev config (#7002) Default to serverModuleFormat: \"esm\" and update remix-serve to use dynamic import to support ESM and CJS build outputs (#6949) Preserve dynamic imports in remix-serve for external bundle (#7173) For preparation of using Node's built in fetch implementation, installing the fetch globals is now a responsibility of the app server (#7009) If you are using remix-serve, nothing is required If you are using your own app server, you will need to install the globals yourself import { installGlobals } from \"@remix-run/node\"; installGlobals(); source-map-support is now a responsibility of the app server (#7009) If you are using remix-serve, nothing is required If you are using your own app server, you will need to install source-map-support yourself. npm i source-map-support import sourceMapSupport from \"source-map-support\"; sourceMapSupport.install(); Patch Changes Update remix-serve usage error message to support ESM projects (#7400) Updated dependencies: @remix-run/node@2.0.0 @remix-run/express@2.0.0 1.19.3 Patch Changes Updated dependencies: @remix-run/express@1.19.3 @remix-run/node@1.19.3 1.19.2 Patch Changes Install source-map-support (#7039) Updated dependencies: @remix-run/node@1.19.2 @remix-run/express@1.19.2 1.19.1 Patch Changes Updated dependencies: @remix-run/express@1.19.1 @remix-run/node@1.19.1 1.19.0 Patch Changes Updated dependencies: @remix-run/node@1.19.0 @remix-run/express@1.19.0 1.18.1 Patch Changes Updated dependencies: @remix-run/node@1.18.1 @remix-run/express@1.18.1 1.18.0 Minor Changes stabilize v2 dev server (#6615) Patch Changes fix(types): better tuple serialization types (#6616) Updated dependencies: @remix-run/node@1.18.0 @remix-run/express@1.18.0 1.17.1 Patch Changes Updated dependencies: @remix-run/express@1.17.1 @remix-run/node@1.17.1 1.17.0 Patch Changes Add HeadersArgs type to be consistent with loaders/actions/meta and allows for using a function declaration in addition to an arrow function expression (#6247) import type { HeadersArgs } from \"@remix-run/node\"; // or cloudflare/deno export function headers({ loaderHeaders }: HeadersArgs) { return { \"x-my-custom-thing\": loaderHeaders.get(\"x-my-custom-thing\") || \"fallback\", }; } Updated dependencies: @remix-run/node@1.17.0 @remix-run/express@1.17.0 1.16.1 Patch Changes Updated dependencies: @remix-run/node@1.16.1 @remix-run/express@1.16.1 1.16.0 Patch Changes add @remix-run/node/install side-effect to allow node --require @remix-run/node/install (#6132) Updated dependencies: @remix-run/express@1.16.0 @remix-run/node@1.16.0 1.15.0 Patch Changes Updated dependencies: @remix-run/express@1.15.0 1.14.3 Patch Changes Updated dependencies: @remix-run/express@1.14.3 1.14.2 Patch Changes Updated dependencies: @remix-run/express@1.14.2 1.14.1 Patch Changes Updated dependencies: @remix-run/express@1.14.1 1.14.0 Patch Changes Allow configurable NODE_ENV with remix-serve (#5540) Sync FutureConfig interface between packages (#5398) Updated dependencies: @remix-run/express@1.14.0 1.13.0 Patch Changes Updated dependencies: @remix-run/express@1.13.0 1.12.0 Minor Changes Added a new development server available in the Remix config under the unstable_dev flag. See the release notes for a full description. (#5133) Patch Changes Updated dependencies: @remix-run/express@1.12.0 1.11.1 Patch Changes Updated dependencies: @remix-run/express@1.11.1 1.11.0 Patch Changes Introduces the defer() API from @remix-run/router with support for server-rendering and HTTP streaming. This utility allows you to defer values returned from loader functions by returning promises instead of resolved values. This has been refered to as \"sending a promise over the wire\". (#4920) Informational Resources: https://gist.github.com/jacob-ebey/9bde9546c1aafaa6bc8c242054b1be26 https://github.com/remix-run/remix/blob/main/decisions/0004-streaming-apis.md Documentation Resources (better docs specific to Remix are in the works): https://reactrouter.com/en/main/utils/defer https://reactrouter.com/en/main/components/await https://reactrouter.com/en/main/hooks/use-async-value https://reactrouter.com/en/main/hooks/use-async-error Updated dependencies: @remix-run/express@1.11.0 1.10.1 Patch Changes Updated dependencies: @remix-run/express@1.10.1 1.10.0 Patch Changes Updated dependencies: @remix-run/express@1.10.0 1.9.0 Patch Changes Fix TypedResponse so that Typescript correctly shows errors for incompatible types in loader and action functions. (#4734) Updated dependencies: @remix-run/express@1.9.0 1.8.2 Patch Changes Updated dependencies: @remix-run/express@1.8.2 1.8.1 Patch Changes Updated dependencies: @remix-run/express@1.8.1 1.8.0 Patch Changes Updated dependencies: @remix-run/express@1.8.0 1.7.6 Patch Changes Updated dependencies: @remix-run/express@1.7.6 1.7.5 Patch Changes Updated dependencies: @remix-run/express@1.7.5 1.7.4 Patch Changes Updated dependencies: @remix-run/express@1.7.4 1.7.3 Patch Changes Updated dependencies: @remix-run/express@1.7.3 1.7.2 Patch Changes Updated dependencies: @remix-run/express@1.7.2 1.7.1 Patch Changes Updated dependencies: @remix-run/express@1.7.1 1.7.0 Minor Changes We've added a new type: SerializeFrom. This is used to infer the (#4013) JSON-serialized return type of loaders and actions. MetaFunction type can now infer data and parentsData types from route loaders (#4022) Patch Changes Updated dependencies: @remix-run/express@1.7.0 1.6.8 Patch Changes Updated dependencies: @remix-run/express@1.6.8 1.6.7 Patch Changes Updated dependencies: @remix-run/express@1.6.7 1.6.6 Patch Changes Updated dependencies: @remix-run/express@1.6.6 1.6.5 Patch Changes Updated dependencies @remix-run/express@1.6.5"
  },
  "src/frontend/app-client/node_modules/@react-router/serve/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/@react-router/serve/LICENSE.html",
    "title": "",
    "summary": "MIT License Copyright (c) React Training LLC 2015-2019 Copyright (c) Remix Software Inc. 2020-2021 Copyright (c) Shopify Inc. 2022-2023 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/@react-router/serve/README.html": {
    "href": "src/frontend/app-client/node_modules/@react-router/serve/README.html",
    "title": "",
    "summary": "Node.js application server for React Router npm install @react-router/serve"
  },
  "src/frontend/app-client/node_modules/@rollup/rollup-win32-x64-msvc/README.html": {
    "href": "src/frontend/app-client/node_modules/@rollup/rollup-win32-x64-msvc/README.html",
    "title": "@rollup/rollup-win32-x64-msvc",
    "summary": "@rollup/rollup-win32-x64-msvc This is the x86_64-pc-windows-msvc binary for rollup"
  },
  "src/frontend/app-client/node_modules/@std-uritemplate/std-uritemplate/Readme.html": {
    "href": "src/frontend/app-client/node_modules/@std-uritemplate/std-uritemplate/Readme.html",
    "title": "std-uritemplate",
    "summary": "std-uritemplate This is a complete and maintained cross-language implementation of the Uri Template specification RFC 6570 Level 4. Note Low activity is this repository is expected as long as there are no outstanding bug reports the implementations are considered stable and mature. Available implementations Language Complete Reviewed Published Java ✅ ✅ ✅ Python ✅ ❌ ✅ Typescript ✅ ✅ ✅ Go ✅ ✅ ✅ C# ✅ ✅ ✅ Ruby ✅ ❌ ✅ PHP ✅ ✅ ✅ Swift ✅ ❌ ✅ Dart ✅ ✅ ✅ Usage Java You can use the library as a Maven dependency: <dependency> <groupId>io.github.std-uritemplate</groupId> <artifactId>std-uritemplate</artifactId> <version>REPLACE-ME</version> </dependency> in Gradle: implementation 'io.github.std-uritemplate:std-uritemplate:REPLACE-ME' and use it in your project: import io.github.stduritemplate.StdUriTemplate; ... StdUriTemplate.expand(template, substitutions); Python Install the package with pip (or any alternative): pip install std-uritemplate Use the library in your project: from stduritemplate import StdUriTemplate ... StdUriTemplate.expand(template, substitutions) Typescript/Javascript Install the package using npm: npm i @std-uritemplate/std-uritemplate Use the package: const { StdUriTemplate } = require('@std-uritemplate/std-uritemplate'); ... StdUriTemplate.expand(template, substitutions); Go Install the package: go get github.com/std-uritemplate/std-uritemplate/go/v2 and use it: import stduritemplate \"github.com/std-uritemplate/std-uritemplate/go/v2\" ... stduritemplate.Expand(template, substitutions) C# Install the package: dotnet add package Std.UriTemplate and use it: Std.UriTemplate.Expand(template, substitutions); Ruby Install the package: gem install stduritemplate and use it: require 'stduritemplate' ... StdUriTemplate.expand(template, substitutions) PHP Install the package: composer require stduritemplate/stduritemplate and use it: use StdUriTemplate\\StdUriTemplate; ... StdUriTemplate::expand($template, $substitutions); Swift Install the package, adding to Package.swift: let package = Package( ... dependencies: [ ... .package( url: \"https://github.com/std-uritemplate/std-uritemplate-swift.git\", from: \"<version>\" ) ], targets: [ .executableTarget( ... dependencies: [ ... .product(name: \"stduritemplate\", package: \"std-uritemplate-swift\") ] ... ), ] ) and use it: import stduritemplate ... StdUriTemplate.expand(template, substitutions: substs) Dart Install the package: dart pub add std_uritemplate for flutter: flutter pub add std_uritemplate and use it: import 'package:std_uritemplate/std_uritemplate.dart'; ... print(StdUriTemplate.expand(template, substitutions)); Design decisions We have a set of design decisions to guide: zero dependencies no usage of regexp no options/configurations only single expansion will be supported single method public API no language idiomatic API, only 1 low level primitive - we do encourage language-specific wrapper/alternative libraries portable implementation across languages based on widely available patterns target Level support is 4 (should pass all the canonical tests) favor maintenance and readability performance until they compromise readability one implementation per ecosystem/runtime (e.g. 1 implementation in Java and no Kotlin/Scala/Closure, 1 in TS that will serve JS as well etc.) substitutions will be performed only for primitive types API The public API is composed by a single method(in Java for simplicity): String expand(String template, Map<String, Object> substitutions) all the rest, should not be directly accessible. Motivation In the Kiota project they are using Uri Templates to build URLs, and we have already spent enough life-time dealing with: unmaintained projects scarce feedback from maintainers long release cycles different nuances in different implementations quirks and integration issues frameworks and additional dependencies diamond transitive dependencies We aim to do it differently, by reducing maintenance to a minimum by automating it, and sharing responsibilities to reduce the bus/truck factor: single repository multiple implementations fully automated testing standardized fully automated releases on tag same tradeoffs across languages familiar implementation across languages multiple maintainers in an independent organization Uri Template is(likely) going to be included in the next OpenAPI specification and we need to rely on a (more) solid foundation to prevent our selves to spend long, tedious hours and days chasing hidden bugs, verifying compatibilities and waiting for unresponsive maintainers."
  },
  "src/frontend/app-client/node_modules/@tailwindcss/node/README.html": {
    "href": "src/frontend/app-client/node_modules/@tailwindcss/node/README.html",
    "title": "",
    "summary": "A utility-first CSS framework for rapidly building custom user interfaces. Documentation For full documentation, visit tailwindcss.com. Community For help, discussion about best practices, or any other conversation that would benefit from being searchable: Discuss Tailwind CSS on GitHub For chatting with others using the framework: Join the Tailwind CSS Discord Server Contributing If you're interested in contributing to Tailwind CSS, please read our contributing docs before submitting a pull request."
  },
  "src/frontend/app-client/node_modules/@tailwindcss/oxide-win32-x64-msvc/README.html": {
    "href": "src/frontend/app-client/node_modules/@tailwindcss/oxide-win32-x64-msvc/README.html",
    "title": "@tailwindcss/oxide-win32-x64-msvc",
    "summary": "@tailwindcss/oxide-win32-x64-msvc This is the x86_64-pc-windows-msvc binary for @tailwindcss/oxide"
  },
  "src/frontend/app-client/node_modules/@tailwindcss/vite/README.html": {
    "href": "src/frontend/app-client/node_modules/@tailwindcss/vite/README.html",
    "title": "",
    "summary": "A utility-first CSS framework for rapidly building custom user interfaces. Documentation For full documentation, visit tailwindcss.com. Community For help, discussion about best practices, or any other conversation that would benefit from being searchable: Discuss Tailwind CSS on GitHub For chatting with others using the framework: Join the Tailwind CSS Discord Server Contributing If you're interested in contributing to Tailwind CSS, please read our contributing docs before submitting a pull request."
  },
  "src/frontend/app-client/node_modules/@types/cookie/README.html": {
    "href": "src/frontend/app-client/node_modules/@types/cookie/README.html",
    "title": "Installation",
    "summary": "Installation npm install --save @types/cookie Summary This package contains type definitions for cookie (https://github.com/jshttp/cookie). Details Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/cookie. Additional Details Last updated: Sun, 26 Nov 2023 22:07:01 GMT Dependencies: none Credits These definitions were written by Pine Mizune, and Piotr Błażejewicz."
  },
  "src/frontend/app-client/node_modules/@types/d3-hierarchy/README.html": {
    "href": "src/frontend/app-client/node_modules/@types/d3-hierarchy/README.html",
    "title": "Installation",
    "summary": "Installation npm install --save @types/d3-hierarchy Summary This package contains type definitions for d3-hierarchy (https://github.com/d3/d3-hierarchy/). Details Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/d3-hierarchy/v1. Additional Details Last updated: Tue, 07 Nov 2023 15:11:37 GMT Dependencies: none Credits These definitions were written by Tom Wanzek, Alex Ford, Boris Yankov, denisname, and Nathan Bierema."
  },
  "src/frontend/app-client/node_modules/@types/estree/README.html": {
    "href": "src/frontend/app-client/node_modules/@types/estree/README.html",
    "title": "Installation",
    "summary": "Installation npm install --save @types/estree Summary This package contains type definitions for estree (https://github.com/estree/estree). Details Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/estree. Additional Details Last updated: Mon, 24 Mar 2025 07:34:10 GMT Dependencies: none Credits These definitions were written by RReverser."
  },
  "src/frontend/app-client/node_modules/@types/node/README.html": {
    "href": "src/frontend/app-client/node_modules/@types/node/README.html",
    "title": "Installation",
    "summary": "Installation npm install --save @types/node Summary This package contains type definitions for node (https://nodejs.org/). Details Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/node/v20. Additional Details Last updated: Tue, 01 Apr 2025 16:38:24 GMT Dependencies: undici-types Credits These definitions were written by Microsoft TypeScript, Alberto Schiabel, Alvis HT Tang, Andrew Makarov, Benjamin Toueg, Chigozirim C., David Junger, Deividas Bakanas, Eugene Y. Q. Shen, Hannes Magnusson, Huw, Kelvin Jin, Klaus Meinhardt, Lishude, Mariusz Wiktorczyk, Mohsen Azimi, Nikita Galkin, Parambir Singh, Sebastian Silbermann, Thomas den Hollander, Wilco Bakker, wwwy3y3, Samuel Ainsworth, Kyle Uehlein, Thanik Bhongbhibhat, Marcin Kopacz, Trivikram Kamat, Junxiao Shi, Ilia Baryshnikov, ExE Boss, Piotr Błażejewicz, Anna Henningsen, Victor Perin, NodeJS Contributors, Linus Unnebäck, wafuwafu13, Matteo Collina, and Dmitry Semigradsky."
  },
  "src/frontend/app-client/node_modules/@types/parse-json/README.html": {
    "href": "src/frontend/app-client/node_modules/@types/parse-json/README.html",
    "title": "Installation",
    "summary": "Installation npm install --save @types/parse-json Summary This package contains type definitions for parse-json (https://github.com/sindresorhus/parse-json). Details Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/parse-json. index.d.ts declare function parseJson(input: string | null, filepath?: string): any; declare function parseJson(input: string | null, reviver: (key: any, value: any) => any, filepath?: string): any; export = parseJson; Additional Details Last updated: Tue, 07 Nov 2023 09:09:39 GMT Dependencies: none Credits These definitions were written by mrmlnc."
  },
  "src/frontend/app-client/node_modules/@types/react-dom/README.html": {
    "href": "src/frontend/app-client/node_modules/@types/react-dom/README.html",
    "title": "Installation",
    "summary": "Installation npm install --save @types/react-dom Summary This package contains type definitions for react-dom (https://react.dev/). Details Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/react-dom. Additional Details Last updated: Wed, 02 Apr 2025 09:02:14 GMT Dependencies: none Peer dependencies: @types/react Credits These definitions were written by Asana, AssureSign, Microsoft, MartynasZilinskas, Josh Rutherford, Jessica Franco, and Sebastian Silbermann."
  },
  "src/frontend/app-client/node_modules/@types/react-reconciler/README.html": {
    "href": "src/frontend/app-client/node_modules/@types/react-reconciler/README.html",
    "title": "Installation",
    "summary": "Installation npm install --save @types/react-reconciler Summary This package contains type definitions for react-reconciler (https://reactjs.org/). Details Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/react-reconciler. Additional Details Last updated: Wed, 11 Dec 2024 14:36:56 GMT Dependencies: none Peer dependencies: @types/react Credits These definitions were written by Nathan Bierema, Zhang Haocong, and Mathieu Dutour."
  },
  "src/frontend/app-client/node_modules/@types/react/README.html": {
    "href": "src/frontend/app-client/node_modules/@types/react/README.html",
    "title": "Installation",
    "summary": "Installation npm install --save @types/react Summary This package contains type definitions for react (https://react.dev/). Details Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/react. Additional Details Last updated: Wed, 02 Apr 2025 07:33:00 GMT Dependencies: csstype Credits These definitions were written by Asana, AssureSign, Microsoft, John Reilly, Benoit Benezech, Patricio Zavolinsky, Eric Anderson, Dovydas Navickas, Josh Rutherford, Guilherme Hübner, Ferdy Budhidharma, Johann Rakotoharisoa, Olivier Pascal, Martin Hochel, Frank Li, Jessica Franco, Saransh Kataria, Kanitkorn Sujautra, Sebastian Silbermann, Kyle Scully, Cong Zhang, Dimitri Mitropoulos, JongChan Choi, Victor Magalhães, Priyanshu Rav, Dmitry Semigradsky, and Matt Pocock."
  },
  "src/frontend/app-client/node_modules/abbrev/README.html": {
    "href": "src/frontend/app-client/node_modules/abbrev/README.html",
    "title": "abbrev-js",
    "summary": "abbrev-js Just like ruby's Abbrev. Usage: var abbrev = require(\"abbrev\"); abbrev(\"foo\", \"fool\", \"folding\", \"flop\"); // returns: { fl: 'flop' , flo: 'flop' , flop: 'flop' , fol: 'folding' , fold: 'folding' , foldi: 'folding' , foldin: 'folding' , folding: 'folding' , foo: 'foo' , fool: 'fool' } This is handy for command-line scripts, or other cases where you want to be able to accept shorthands."
  },
  "src/frontend/app-client/node_modules/accepts/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/accepts/HISTORY.html",
    "title": "1.3.8 / 2022-02-02",
    "summary": "1.3.8 / 2022-02-02 deps: mime-types@~2.1.34 deps: mime-db@~1.51.0 deps: negotiator@0.6.3 1.3.7 / 2019-04-29 deps: negotiator@0.6.2 Fix sorting charset, encoding, and language with extra parameters 1.3.6 / 2019-04-28 deps: mime-types@~2.1.24 deps: mime-db@~1.40.0 1.3.5 / 2018-02-28 deps: mime-types@~2.1.18 deps: mime-db@~1.33.0 1.3.4 / 2017-08-22 deps: mime-types@~2.1.16 deps: mime-db@~1.29.0 1.3.3 / 2016-05-02 deps: mime-types@~2.1.11 deps: mime-db@~1.23.0 deps: negotiator@0.6.1 perf: improve Accept parsing speed perf: improve Accept-Charset parsing speed perf: improve Accept-Encoding parsing speed perf: improve Accept-Language parsing speed 1.3.2 / 2016-03-08 deps: mime-types@~2.1.10 Fix extension of application/dash+xml Update primary extension for audio/mp4 deps: mime-db@~1.22.0 1.3.1 / 2016-01-19 deps: mime-types@~2.1.9 deps: mime-db@~1.21.0 1.3.0 / 2015-09-29 deps: mime-types@~2.1.7 deps: mime-db@~1.19.0 deps: negotiator@0.6.0 Fix including type extensions in parameters in Accept parsing Fix parsing Accept parameters with quoted equals Fix parsing Accept parameters with quoted semicolons Lazy-load modules from main entry point perf: delay type concatenation until needed perf: enable strict mode perf: hoist regular expressions perf: remove closures getting spec properties perf: remove a closure from media type parsing perf: remove property delete from media type parsing 1.2.13 / 2015-09-06 deps: mime-types@~2.1.6 deps: mime-db@~1.18.0 1.2.12 / 2015-07-30 deps: mime-types@~2.1.4 deps: mime-db@~1.16.0 1.2.11 / 2015-07-16 deps: mime-types@~2.1.3 deps: mime-db@~1.15.0 1.2.10 / 2015-07-01 deps: mime-types@~2.1.2 deps: mime-db@~1.14.0 1.2.9 / 2015-06-08 deps: mime-types@~2.1.1 perf: fix deopt during mapping 1.2.8 / 2015-06-07 deps: mime-types@~2.1.0 deps: mime-db@~1.13.0 perf: avoid argument reassignment & argument slice perf: avoid negotiator recursive construction perf: enable strict mode perf: remove unnecessary bitwise operator 1.2.7 / 2015-05-10 deps: negotiator@0.5.3 Fix media type parameter matching to be case-insensitive 1.2.6 / 2015-05-07 deps: mime-types@~2.0.11 deps: mime-db@~1.9.1 deps: negotiator@0.5.2 Fix comparing media types with quoted values Fix splitting media types with quoted commas 1.2.5 / 2015-03-13 deps: mime-types@~2.0.10 deps: mime-db@~1.8.0 1.2.4 / 2015-02-14 Support Node.js 0.6 deps: mime-types@~2.0.9 deps: mime-db@~1.7.0 deps: negotiator@0.5.1 Fix preference sorting to be stable for long acceptable lists 1.2.3 / 2015-01-31 deps: mime-types@~2.0.8 deps: mime-db@~1.6.0 1.2.2 / 2014-12-30 deps: mime-types@~2.0.7 deps: mime-db@~1.5.0 1.2.1 / 2014-12-30 deps: mime-types@~2.0.5 deps: mime-db@~1.3.1 1.2.0 / 2014-12-19 deps: negotiator@0.5.0 Fix list return order when large accepted list Fix missing identity encoding when q=0 exists Remove dynamic building of Negotiator class 1.1.4 / 2014-12-10 deps: mime-types@~2.0.4 deps: mime-db@~1.3.0 1.1.3 / 2014-11-09 deps: mime-types@~2.0.3 deps: mime-db@~1.2.0 1.1.2 / 2014-10-14 deps: negotiator@0.4.9 Fix error when media type has invalid parameter 1.1.1 / 2014-09-28 deps: mime-types@~2.0.2 deps: mime-db@~1.1.0 deps: negotiator@0.4.8 Fix all negotiations to be case-insensitive Stable sort preferences of same quality according to client order 1.1.0 / 2014-09-02 update mime-types 1.0.7 / 2014-07-04 Fix wrong type returned from type when match after unknown extension 1.0.6 / 2014-06-24 deps: negotiator@0.4.7 1.0.5 / 2014-06-20 fix crash when unknown extension given 1.0.4 / 2014-06-19 use mime-types 1.0.3 / 2014-06-11 deps: negotiator@0.4.6 Order by specificity when quality is the same 1.0.2 / 2014-05-29 Fix interpretation when header not in request deps: pin negotiator@0.4.5 1.0.1 / 2014-01-18 Identity encoding isn't always acceptable deps: negotiator@~0.4.0 1.0.0 / 2013-12-27 Genesis"
  },
  "src/frontend/app-client/node_modules/accepts/node_modules/negotiator/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/accepts/node_modules/negotiator/HISTORY.html",
    "title": "0.6.3 / 2022-01-22",
    "summary": "0.6.3 / 2022-01-22 Revert \"Lazy-load modules from main entry point\" 0.6.2 / 2019-04-29 Fix sorting charset, encoding, and language with extra parameters 0.6.1 / 2016-05-02 perf: improve Accept parsing speed perf: improve Accept-Charset parsing speed perf: improve Accept-Encoding parsing speed perf: improve Accept-Language parsing speed 0.6.0 / 2015-09-29 Fix including type extensions in parameters in Accept parsing Fix parsing Accept parameters with quoted equals Fix parsing Accept parameters with quoted semicolons Lazy-load modules from main entry point perf: delay type concatenation until needed perf: enable strict mode perf: hoist regular expressions perf: remove closures getting spec properties perf: remove a closure from media type parsing perf: remove property delete from media type parsing 0.5.3 / 2015-05-10 Fix media type parameter matching to be case-insensitive 0.5.2 / 2015-05-06 Fix comparing media types with quoted values Fix splitting media types with quoted commas 0.5.1 / 2015-02-14 Fix preference sorting to be stable for long acceptable lists 0.5.0 / 2014-12-18 Fix list return order when large accepted list Fix missing identity encoding when q=0 exists Remove dynamic building of Negotiator class 0.4.9 / 2014-10-14 Fix error when media type has invalid parameter 0.4.8 / 2014-09-28 Fix all negotiations to be case-insensitive Stable sort preferences of same quality according to client order Support Node.js 0.6 0.4.7 / 2014-06-24 Handle invalid provided languages Handle invalid provided media types 0.4.6 / 2014-06-11 Order by specificity when quality is the same 0.4.5 / 2014-05-29 Fix regression in empty header handling 0.4.4 / 2014-05-29 Fix behaviors when headers are not present 0.4.3 / 2014-04-16 Handle slashes on media params correctly 0.4.2 / 2014-02-28 Fix media type sorting Handle media types params strictly 0.4.1 / 2014-01-16 Use most specific matches 0.4.0 / 2014-01-09 Remove preferred prefix from methods"
  },
  "src/frontend/app-client/node_modules/accepts/node_modules/negotiator/README.html": {
    "href": "src/frontend/app-client/node_modules/accepts/node_modules/negotiator/README.html",
    "title": "negotiator",
    "summary": "negotiator An HTTP content negotiator for Node.js Installation $ npm install negotiator API var Negotiator = require('negotiator') Accept Negotiation availableMediaTypes = ['text/html', 'text/plain', 'application/json'] // The negotiator constructor receives a request object negotiator = new Negotiator(request) // Let's say Accept header is 'text/html, application/*;q=0.2, image/jpeg;q=0.8' negotiator.mediaTypes() // -> ['text/html', 'image/jpeg', 'application/*'] negotiator.mediaTypes(availableMediaTypes) // -> ['text/html', 'application/json'] negotiator.mediaType(availableMediaTypes) // -> 'text/html' You can check a working example at examples/accept.js. Methods mediaType() Returns the most preferred media type from the client. mediaType(availableMediaType) Returns the most preferred media type from a list of available media types. mediaTypes() Returns an array of preferred media types ordered by the client preference. mediaTypes(availableMediaTypes) Returns an array of preferred media types ordered by priority from a list of available media types. Accept-Language Negotiation negotiator = new Negotiator(request) availableLanguages = ['en', 'es', 'fr'] // Let's say Accept-Language header is 'en;q=0.8, es, pt' negotiator.languages() // -> ['es', 'pt', 'en'] negotiator.languages(availableLanguages) // -> ['es', 'en'] language = negotiator.language(availableLanguages) // -> 'es' You can check a working example at examples/language.js. Methods language() Returns the most preferred language from the client. language(availableLanguages) Returns the most preferred language from a list of available languages. languages() Returns an array of preferred languages ordered by the client preference. languages(availableLanguages) Returns an array of preferred languages ordered by priority from a list of available languages. Accept-Charset Negotiation availableCharsets = ['utf-8', 'iso-8859-1', 'iso-8859-5'] negotiator = new Negotiator(request) // Let's say Accept-Charset header is 'utf-8, iso-8859-1;q=0.8, utf-7;q=0.2' negotiator.charsets() // -> ['utf-8', 'iso-8859-1', 'utf-7'] negotiator.charsets(availableCharsets) // -> ['utf-8', 'iso-8859-1'] negotiator.charset(availableCharsets) // -> 'utf-8' You can check a working example at examples/charset.js. Methods charset() Returns the most preferred charset from the client. charset(availableCharsets) Returns the most preferred charset from a list of available charsets. charsets() Returns an array of preferred charsets ordered by the client preference. charsets(availableCharsets) Returns an array of preferred charsets ordered by priority from a list of available charsets. Accept-Encoding Negotiation availableEncodings = ['identity', 'gzip'] negotiator = new Negotiator(request) // Let's say Accept-Encoding header is 'gzip, compress;q=0.2, identity;q=0.5' negotiator.encodings() // -> ['gzip', 'identity', 'compress'] negotiator.encodings(availableEncodings) // -> ['gzip', 'identity'] negotiator.encoding(availableEncodings) // -> 'gzip' You can check a working example at examples/encoding.js. Methods encoding() Returns the most preferred encoding from the client. encoding(availableEncodings) Returns the most preferred encoding from a list of available encodings. encodings() Returns an array of preferred encodings ordered by the client preference. encodings(availableEncodings) Returns an array of preferred encodings ordered by priority from a list of available encodings. See Also The accepts module builds on this module and provides an alternative interface, mime type validation, and more. License MIT"
  },
  "src/frontend/app-client/node_modules/accepts/README.html": {
    "href": "src/frontend/app-client/node_modules/accepts/README.html",
    "title": "accepts",
    "summary": "accepts Higher level content negotiation based on negotiator. Extracted from koa for general use. In addition to negotiator, it allows: Allows types as an array or arguments list, ie (['text/html', 'application/json']) as well as ('text/html', 'application/json'). Allows type shorthands such as json. Returns false when no types match Treats non-existent headers as * Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install accepts API var accepts = require('accepts') accepts(req) Create a new Accepts object for the given req. .charset(charsets) Return the first accepted charset. If nothing in charsets is accepted, then false is returned. .charsets() Return the charsets that the request accepts, in the order of the client's preference (most preferred first). .encoding(encodings) Return the first accepted encoding. If nothing in encodings is accepted, then false is returned. .encodings() Return the encodings that the request accepts, in the order of the client's preference (most preferred first). .language(languages) Return the first accepted language. If nothing in languages is accepted, then false is returned. .languages() Return the languages that the request accepts, in the order of the client's preference (most preferred first). .type(types) Return the first accepted type (and it is returned as the same text as what appears in the types array). If nothing in types is accepted, then false is returned. The types array can contain full MIME types or file extensions. Any value that is not a full MIME types is passed to require('mime-types').lookup. .types() Return the types that the request accepts, in the order of the client's preference (most preferred first). Examples Simple type negotiation This simple example shows how to use accepts to return a different typed respond body based on what the client wants to accept. The server lists it's preferences in order and will get back the best match between the client and server. var accepts = require('accepts') var http = require('http') function app (req, res) { var accept = accepts(req) // the order of this list is significant; should be server preferred order switch (accept.type(['json', 'html'])) { case 'json': res.setHeader('Content-Type', 'application/json') res.write('{\"hello\":\"world!\"}') break case 'html': res.setHeader('Content-Type', 'text/html') res.write('<b>hello, world!</b>') break default: // the fallback is text/plain, so no need to specify it above res.setHeader('Content-Type', 'text/plain') res.write('hello, world!') break } res.end() } http.createServer(app).listen(3000) You can test this out with the cURL program: curl -I -H'Accept: text/html' http://localhost:3000/ License MIT"
  },
  "src/frontend/app-client/node_modules/ansi-regex/readme.html": {
    "href": "src/frontend/app-client/node_modules/ansi-regex/readme.html",
    "title": "ansi-regex",
    "summary": "ansi-regex Regular expression for matching ANSI escape codes Install npm install ansi-regex Usage import ansiRegex from 'ansi-regex'; ansiRegex().test('\\u001B[4mcake\\u001B[0m'); //=> true ansiRegex().test('cake'); //=> false '\\u001B[4mcake\\u001B[0m'.match(ansiRegex()); //=> ['\\u001B[4m', '\\u001B[0m'] '\\u001B[4mcake\\u001B[0m'.match(ansiRegex({onlyFirst: true})); //=> ['\\u001B[4m'] '\\u001B]8;;https://github.com\\u0007click\\u001B]8;;\\u0007'.match(ansiRegex()); //=> ['\\u001B]8;;https://github.com\\u0007', '\\u001B]8;;\\u0007'] API ansiRegex(options?) Returns a regex for matching ANSI escape codes. options Type: object onlyFirst Type: boolean Default: false (Matches any ANSI escape codes in a string) Match only the first ANSI escape. FAQ Why do you test for codes not in the ECMA 48 standard? Some of the codes we run as a test are codes that we acquired finding various lists of non-standard or manufacturer specific codes. We test for both standard and non-standard codes, as most of them follow the same or similar format and can be safely matched in strings without the risk of removing actual string content. There are a few non-standard control codes that do not follow the traditional format (i.e. they end in numbers) thus forcing us to exclude them from the test because we cannot reliably match them. On the historical side, those ECMA standards were established in the early 90's whereas the VT100, for example, was designed in the mid/late 70's. At that point in time, control codes were still pretty ungoverned and engineers used them for a multitude of things, namely to activate hardware ports that may have been proprietary. Somewhere else you see a similar 'anarchy' of codes is in the x86 architecture for processors; there are a ton of \"interrupts\" that can mean different things on certain brands of processors, most of which have been phased out. Maintainers Sindre Sorhus Josh Junon"
  },
  "src/frontend/app-client/node_modules/ansi-styles/readme.html": {
    "href": "src/frontend/app-client/node_modules/ansi-styles/readme.html",
    "title": "ansi-styles",
    "summary": "ansi-styles ANSI escape codes for styling strings in the terminal You probably want the higher-level chalk module for styling your strings. Install npm install ansi-styles Usage import styles from 'ansi-styles'; console.log(`${styles.green.open}Hello world!${styles.green.close}`); // Color conversion between 256/truecolor // NOTE: When converting from truecolor to 256 colors, the original color // may be degraded to fit the new color palette. This means terminals // that do not support 16 million colors will best-match the // original color. console.log(`${styles.color.ansi(styles.rgbToAnsi(199, 20, 250))}Hello World${styles.color.close}`) console.log(`${styles.color.ansi256(styles.rgbToAnsi256(199, 20, 250))}Hello World${styles.color.close}`) console.log(`${styles.color.ansi16m(...styles.hexToRgb('#abcdef'))}Hello World${styles.color.close}`) API open and close Each style has an open and close property. modifierNames, foregroundColorNames, backgroundColorNames, and colorNames All supported style strings are exposed as an array of strings for convenience. colorNames is the combination of foregroundColorNames and backgroundColorNames. This can be useful if you need to validate input: import {modifierNames, foregroundColorNames} from 'ansi-styles'; console.log(modifierNames.includes('bold')); //=> true console.log(foregroundColorNames.includes('pink')); //=> false Styles Modifiers reset bold dim italic (Not widely supported) underline overline Supported on VTE-based terminals, the GNOME terminal, mintty, and Git Bash. inverse hidden strikethrough (Not widely supported) Colors black red green yellow blue magenta cyan white blackBright (alias: gray, grey) redBright greenBright yellowBright blueBright magentaBright cyanBright whiteBright Background colors bgBlack bgRed bgGreen bgYellow bgBlue bgMagenta bgCyan bgWhite bgBlackBright (alias: bgGray, bgGrey) bgRedBright bgGreenBright bgYellowBright bgBlueBright bgMagentaBright bgCyanBright bgWhiteBright Advanced usage By default, you get a map of styles, but the styles are also available as groups. They are non-enumerable so they don't show up unless you access them explicitly. This makes it easier to expose only a subset in a higher-level module. styles.modifier styles.color styles.bgColor Example import styles from 'ansi-styles'; console.log(styles.color.green.open); Raw escape codes (i.e. without the CSI escape prefix \\u001B[ and render mode postfix m) are available under styles.codes, which returns a Map with the open codes as keys and close codes as values. Example import styles from 'ansi-styles'; console.log(styles.codes.get(36)); //=> 39 16 / 256 / 16 million (TrueColor) support ansi-styles allows converting between various color formats and ANSI escapes, with support for 16, 256 and 16 million colors. The following color spaces are supported: rgb hex ansi256 ansi To use these, call the associated conversion function with the intended output, for example: import styles from 'ansi-styles'; styles.color.ansi(styles.rgbToAnsi(100, 200, 15)); // RGB to 16 color ansi foreground code styles.bgColor.ansi(styles.hexToAnsi('#C0FFEE')); // HEX to 16 color ansi foreground code styles.color.ansi256(styles.rgbToAnsi256(100, 200, 15)); // RGB to 256 color ansi foreground code styles.bgColor.ansi256(styles.hexToAnsi256('#C0FFEE')); // HEX to 256 color ansi foreground code styles.color.ansi16m(100, 200, 15); // RGB to 16 million color foreground code styles.bgColor.ansi16m(...styles.hexToRgb('#C0FFEE')); // Hex (RGB) to 16 million color foreground code Related ansi-escapes - ANSI escape codes for manipulating the terminal Maintainers Sindre Sorhus Josh Junon For enterprise Available as part of the Tidelift Subscription. The maintainers of ansi-styles and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "src/frontend/app-client/node_modules/arg/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/arg/LICENSE.html",
    "title": "",
    "summary": "The MIT License (MIT) Copyright (c) 2021 Vercel, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/arg/README.html": {
    "href": "src/frontend/app-client/node_modules/arg/README.html",
    "title": "Arg",
    "summary": "Arg arg is an unopinionated, no-frills CLI argument parser. Installation npm install arg Usage arg() takes either 1 or 2 arguments: Command line specification object (see below) Parse options (Optional, defaults to {permissive: false, argv: process.argv.slice(2), stopAtPositional: false}) It returns an object with any values present on the command-line (missing options are thus missing from the resulting object). Arg performs no validation/requirement checking - we leave that up to the application. All parameters that aren't consumed by options (commonly referred to as \"extra\" parameters) are added to result._, which is always an array (even if no extra parameters are passed, in which case an empty array is returned). const arg = require('arg'); // `options` is an optional parameter const args = arg( spec, (options = { permissive: false, argv: process.argv.slice(2) }) ); For example: $ node ./hello.js --verbose -vvv --port=1234 -n 'My name' foo bar --tag qux --tag=qix -- --foobar // hello.js const arg = require('arg'); const args = arg({ // Types '--help': Boolean, '--version': Boolean, '--verbose': arg.COUNT, // Counts the number of times --verbose is passed '--port': Number, // --port <number> or --port=<number> '--name': String, // --name <string> or --name=<string> '--tag': [String], // --tag <string> or --tag=<string> // Aliases '-v': '--verbose', '-n': '--name', // -n <string>; result is stored in --name '--label': '--name' // --label <string> or --label=<string>; // result is stored in --name }); console.log(args); /* { _: [\"foo\", \"bar\", \"--foobar\"], '--port': 1234, '--verbose': 4, '--name': \"My name\", '--tag': [\"qux\", \"qix\"] } */ The values for each key=>value pair is either a type (function or [function]) or a string (indicating an alias). In the case of a function, the string value of the argument's value is passed to it, and the return value is used as the ultimate value. In the case of an array, the only element must be a type function. Array types indicate that the argument may be passed multiple times, and as such the resulting value in the returned object is an array with all of the values that were passed using the specified flag. In the case of a string, an alias is established. If a flag is passed that matches the key, then the value is substituted in its place. Type functions are passed three arguments: The parameter value (always a string) The parameter name (e.g. --label) The previous value for the destination (useful for reduce-like operations or for supporting -v multiple times, etc.) This means the built-in String, Number, and Boolean type constructors \"just work\" as type functions. Note that Boolean and [Boolean] have special treatment - an option argument is not consumed or passed, but instead true is returned. These options are called \"flags\". For custom handlers that wish to behave as flags, you may pass the function through arg.flag(): const arg = require('arg'); const argv = [ '--foo', 'bar', '-ff', 'baz', '--foo', '--foo', 'qux', '-fff', 'qix' ]; function myHandler(value, argName, previousValue) { /* `value` is always `true` */ return 'na ' + (previousValue || 'batman!'); } const args = arg( { '--foo': arg.flag(myHandler), '-f': '--foo' }, { argv } ); console.log(args); /* { _: ['bar', 'baz', 'qux', 'qix'], '--foo': 'na na na na na na na na batman!' } */ As well, arg supplies a helper argument handler called arg.COUNT, which equivalent to a [Boolean] argument's .length property - effectively counting the number of times the boolean flag, denoted by the key, is passed on the command line.. For example, this is how you could implement ssh's multiple levels of verbosity (-vvvv being the most verbose). const arg = require('arg'); const argv = ['-AAAA', '-BBBB']; const args = arg( { '-A': arg.COUNT, '-B': [Boolean] }, { argv } ); console.log(args); /* { _: [], '-A': 4, '-B': [true, true, true, true] } */ Options If a second parameter is specified and is an object, it specifies parsing options to modify the behavior of arg(). argv If you have already sliced or generated a number of raw arguments to be parsed (as opposed to letting arg slice them from process.argv) you may specify them in the argv option. For example: const args = arg( { '--foo': String }, { argv: ['hello', '--foo', 'world'] } ); results in: const args = { _: ['hello'], '--foo': 'world' }; permissive When permissive set to true, arg will push any unknown arguments onto the \"extra\" argument array (result._) instead of throwing an error about an unknown flag. For example: const arg = require('arg'); const argv = [ '--foo', 'hello', '--qux', 'qix', '--bar', '12345', 'hello again' ]; const args = arg( { '--foo': String, '--bar': Number }, { argv, permissive: true } ); results in: const args = { _: ['--qux', 'qix', 'hello again'], '--foo': 'hello', '--bar': 12345 }; stopAtPositional When stopAtPositional is set to true, arg will halt parsing at the first positional argument. For example: const arg = require('arg'); const argv = ['--foo', 'hello', '--bar']; const args = arg( { '--foo': Boolean, '--bar': Boolean }, { argv, stopAtPositional: true } ); results in: const args = { _: ['hello', '--bar'], '--foo': true }; Errors Some errors that arg throws provide a .code property in order to aid in recovering from user error, or to differentiate between user error and developer error (bug). ARG_UNKNOWN_OPTION If an unknown option (not defined in the spec object) is passed, an error with code ARG_UNKNOWN_OPTION will be thrown: // cli.js try { require('arg')({ '--hi': String }); } catch (err) { if (err.code === 'ARG_UNKNOWN_OPTION') { console.log(err.message); } else { throw err; } } node cli.js --extraneous true Unknown or unexpected option: --extraneous FAQ A few questions and answers that have been asked before: How do I require an argument with arg? Do the assertion yourself, such as: const args = arg({ '--name': String }); if (!args['--name']) throw new Error('missing required argument: --name'); License Released under the MIT License."
  },
  "src/frontend/app-client/node_modules/aria-hidden/README.html": {
    "href": "src/frontend/app-client/node_modules/aria-hidden/README.html",
    "title": "aria-hidden",
    "summary": "aria-hidden Hides from ARIA everything, except provided node(s). Helps to isolate modal dialogs and focused task - the content will be not accessible using accessible tools. Now with HTML inert support API Just call hideOthers with DOM-node you want to keep, and it will hide everything else. targetNode could be placed anywhere - its siblings would be hidden, but it and its parents - not. \"hidden\" in terms or aria-hidden import { hideOthers } from 'aria-hidden'; const undo = hideOthers(exceptThisDOMnode); // everything else is \"aria-hidden\" // undo changes undo(); you also may limit the effect spread by providing top level node as a second parameter // keep only `anotherNode` node visible in #app // the rest of document will be untouched hideOthers(anotherNode, document.getElementById('app')); parentNode defaults to document.body Inert While aria-hidden played important role in the past and will play in the future - the main use case always was around isolating content and making elements \"transparent\" not only for aria, but for user interaction as well. This is why you might consider using inertOthers import { hideOthers, inertOthers, supportsInert } from 'aria-hidden'; // focus on element mean \"hide others\". Ideally disable interactions const focusOnElement = (node) => (supportsInert() ? inertOthers(node) : hideOthers(node)); the same function as above is already contructed and exported as import { suppressOthers } from 'aria-hidden'; suppressOthers([keepThisNode, andThis]); ⚠️ Note - inert will disable any interactions with suppressed elements ⚠️ Suppressing interactivity without inert One can marker, the third argument to a function, to mark hidden elements. Later one can create a style matching given marker to apply pointer-events:none [hidden-node] { pointer-events: none; } hideOthers(notThisOne, undefined /*parent = document*/, 'hidden-node'); Generally speaking the same can be achieved by addressing [aria-hidden] nodes, but not all aria-hidden nodes are expected to be non-interactive. Hence, it's better to separate concerns. Inspiration Based on smooth-ui modal dialogs. See also inert - The HTML attribute/property to mark parts of the DOM tree as \"inert\". react-focus-lock to lock Focus inside modal. react-scroll-lock to disable page scroll while modal is opened. Size Code is 30 lines long Licence MIT"
  },
  "src/frontend/app-client/node_modules/array-flatten/README.html": {
    "href": "src/frontend/app-client/node_modules/array-flatten/README.html",
    "title": "Array Flatten",
    "summary": "Array Flatten Flatten an array of nested arrays into a single flat array. Accepts an optional depth. Installation npm install array-flatten --save Usage var flatten = require('array-flatten') flatten([1, [2, [3, [4, [5], 6], 7], 8], 9]) //=> [1, 2, 3, 4, 5, 6, 7, 8, 9] flatten([1, [2, [3, [4, [5], 6], 7], 8], 9], 2) //=> [1, 2, 3, [4, [5], 6], 7, 8, 9] (function () { flatten(arguments) //=> [1, 2, 3] })(1, [2, 3]) License MIT"
  },
  "src/frontend/app-client/node_modules/babel-dead-code-elimination/README.html": {
    "href": "src/frontend/app-client/node_modules/babel-dead-code-elimination/README.html",
    "title": "babel-dead-code-elimination",
    "summary": "babel-dead-code-elimination Composable primitives for dead code elimination in Babel This package is not a Babel plugin, but rather a set of composable primitives to author your own Babel transforms and plugins. Install npm install babel-dead-code-elimination deadCodeElimination Eliminates unused code from the Babel AST by repeatedly removing unreferenced identifiers. import { parse } from \"@babel/parser\" import generate from \"@babel/generator\" import { deadCodeElimination } from \"babel-dead-code-elimination\" let source = \"...\" let ast = parse(source, { sourceType: \"module\" }) deadCodeElimination(ast) let result = generate(ast).code findReferencedIdentifiers Find identifiers that are currently referenced in the Babel AST. Useful for limiting deadCodeElimination to only eliminate newly unreferenced identifiers, as a best effort to preserve any intentional side-effects in the source. import { parse } from \"@babel/parser\" import generate from \"@babel/generator\" import traverse from \"@babel/traverse\" import { deadCodeElimination, findReferencedIdentifiers, } from \"babel-dead-code-elimination\" let source = \"...\" let ast = parse(source, { sourceType: \"module\" }) let referenced = findReferencedIdentifiers(ast) traverse(ast, { /* ... your custom transform goes here ... */ }) deadCodeElimination(ast, referenced) let result = generate(ast).code Prior art Credit to Jason Miller for the initial implementation. Thanks to these projects for exploring dead code elimination: Next.js babel-plugin-eliminator bling"
  },
  "src/frontend/app-client/node_modules/babel-plugin-macros/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/babel-plugin-macros/CHANGELOG.html",
    "title": "CHANGELOG",
    "summary": "CHANGELOG The changelog is automatically updated using semantic-release. You can see it on the releases page."
  },
  "src/frontend/app-client/node_modules/babel-plugin-macros/README.html": {
    "href": "src/frontend/app-client/node_modules/babel-plugin-macros/README.html",
    "title": "babel-plugin-macros \uD83C\uDFA3",
    "summary": "babel-plugin-macros \uD83C\uDFA3 Allows you to build simple compile-time libraries The problem Check out this guest post on the Babel.js blog for a complete write up on the problem, motivation, and solution. Currently, each babel plugin in the babel ecosystem requires that you configure it individually. This is fine for things like language features, but can be frustrating overhead for libraries that allow for compile-time code transformation as an optimization. This solution babel-plugin-macros defines a standard interface for libraries that want to use compile-time code transformation without requiring the user to add a babel plugin to their build system (other than babel-plugin-macros, which is ideally already in place). Expand for more details on the motivation For instance, many css-in-js libraries have a css tagged template string function: const styles = css` .red { color: red; } ` The function compiles your css into (for example) an object with generated class names for each of the classes you defined in your css: console.log(styles) // { red: \"1f-d34j8rn43y587t\" } This class name can be generated at runtime (in the browser), but this has some disadvantages: There is cpu usage/time overhead; the client needs to run the code to generate these classes every time the page loads There is code bundle size overhead; the client needs to receive a CSS parser in order to generate these class names, and shipping this makes the amount of js the client needs to parse larger. To help solve those issues, many css-in-js libraries write their own babel plugin that generates the class names at compile-time instead of runtime: // Before running through babel: const styles = css` .red { color: red; } ` // After running through babel, with the library-specific plugin: const styles = {red: '1f-d34j8rn43y587t'} If the css-in-js library supported babel-plugin-macros instead, then they wouldn't need their own babel plugin to compile these out; they could instead rely on babel-plugin-macros to do it for them. So if a user already had babel-plugin-macros installed and configured with babel, then they wouldn't need to change their babel configuration to get the compile-time benefits of the library. This would be most useful if the boilerplate they were using came with babel-plugin-macros out of the box, which is true for create-react-app. Although css-in-js is the most common example, there are lots of other things you could use babel-plugin-macros for, like: Compiling GraphQL fragments into objects so that the client doesn't need a GraphQL parser Eval-ing out code at compile time that will be baked into the runtime code, for instance to get a list of directories in the filesystem (see preval) Table of Contents Installation Usage User docs Author docs Caveats FAQ How do I find available macros? What's the difference between babel plugins and macros? In what order are macros executed? Does it work with function calls only? How about implicit optimizations at compile time? Inspiration Other Solutions Issues \uD83D\uDC1B Bugs \uD83D\uDCA1 Feature Requests Contributors ✨ LICENSE Installation This module is distributed via npm which is bundled with node and should be installed as one of your project's devDependencies: npm install --save-dev babel-plugin-macros Usage You may like to watch this YouTube video to get an idea of what macros is and how it can be used. User docs Are you trying to use babel-plugin-macros? Go to other/docs/user.md. Author docs Are you trying to make your own macros that works with babel-plugin-macros? Go to other/docs/author.md. (you should probably read the user docs too). Caveats Babel cache problem Note: This issue is not present when used in Create React App. Most of the time you'll probably be using this with the babel cache enabled in webpack to rebuild faster. If your macro function is not pure which gets different output with same code (e.g., IO side effects) it will cause recompile mechanism fail. Unfortunately you'll also experience this problem while developing your macro as well. If there's not a change to the source code that's being transpiled, then babel will use the cache rather than running your macro again. For now, to force recompile the code you can simply add a cache busting comment in the file: import macro from 'non-pure.macro'; -// Do some changes of your code or +// add a cache busting comment to force recompile. macro('parameters'); This problem is still being worked on and is not unique to babel-plugin-macros. For more details and workarounds, please check related issues below: babel-plugin-preval: How to force recompile? #19 graphql.macro: Recompile problem (babel cache) #6 twin.macro: Can't change taliwind config #37 FAQ How do I find available macros? You can write your own without publishing them to npm, but if you'd like to see existing macros you can add to your project, then take a look at the Awesome babel macros repository. Please add any you don't see listed! What's the difference between babel plugins and macros? Let's use babel-plugin-console as an example. If we used babel-plugin-console, it would look like this: Add babel-plugin-console to .babelrc Use it in a code: function add100(a) { const oneHundred = 100 console.scope('Add 100 to another number') return add(a, oneHundred) } function add(a, b) { return a + b } When that code is run, the scope function does some pretty nifty things: Browser: Node: Instead, let's use the macro it's shipped with like this: Add babel-plugin-macros to .babelrc (only once for all macros) Use it in a code: import scope from 'babel-plugin-console/scope.macro' function add100(a) { const oneHundred = 100 scope('Add 100 to another number') return add(a, oneHundred) } function add(a, b) { return a + b } The result is exactly the same, but this approach has a few advantages: Advantages: requires only one entry in .babelrc for all macros used in project. Add that once and you can use all the macros you want toolkits (like create-react-app) may already support babel-plugin-macros, so no configuration is needed at all it's explicit. With console.scope people may be fooled that it's just a normal console API when there's really a babel transpilation going on. When you import scope, it's obvious that it's macro and does something with the code at compile time. Some ESLint rules may also have issues with plugins that look for \"global\" variables macros are safer and easier to write, because they receive exactly the AST node to process If you misconfigure babel-plugin-console you wont find out until you run the code. If you misconfigure babel-plugin-macros you'll get a compile-time error. Drawbacks: Cannot (should not) be used for implicit transpilations (like syntax plugins) Explicitness is more verbose. Which some people might consider a drawback... In what order are macros executed? This is another advantage of babel-plugin-macros over regular plugins. The user of the macro is in control of the ordering! The order of execution is the same order as imported. The order of execution is clear, explicit and in full control of the user: import preval from 'preval.macro' import idx from 'idx.macro' // preval macro is evaluated first, then idx This differs from the current situation with babel plugins where it's prohibitively difficult to control the order plugins run in a particular file. Does it work with function calls only? No! Any AST node type is supported. It can be tagged template literal: import eval from 'eval.macro' const val = eval`7 * 6` A function: import eval from 'eval.macro' const val = eval('7 * 6') JSX Element: import Eval from 'eval.macro' const val = <Eval>7 * 6</Eval> Really, anything... See the testing snapshot for more examples. How about implicit optimizations at compile time? All examples above were explicit - a macro was imported and then evaluated with a specific AST node. Completely different story are implicit babel plugins, like transform-react-constant-elements, which process whole AST tree. Explicit is often a better pattern than implicit because it requires others to understand how things are globally configured. This is in this spirit are babel-plugin-macros designed. However, some things do need to be implicit, and those kinds of babel plugins can't be turned into macros. Inspiration threepointone/babel-plugin-macros facebookincubator/create-react-app#2730 Thank you to @phpnode for donating the npm package babel-plugin-macros. Other Solutions sweetjs Issues Looking to contribute? Look for the Good First Issue label. \uD83D\uDC1B Bugs Please file an issue for bugs, missing documentation, or unexpected behavior. See Bugs \uD83D\uDCA1 Feature Requests Please file an issue to suggest new features. Vote on feature requests by adding a \uD83D\uDC4D. This helps maintainers prioritize what to work on. See Feature Requests Contributors ✨ Thanks goes to these people (emoji key): Kent C. Dodds \uD83D\uDCBB \uD83D\uDCD6 \uD83D\uDE87 ⚠️ Sunil Pai \uD83E\uDD14 Lily Scott \uD83D\uDCAC \uD83D\uDCD6 Michiel Dral \uD83E\uDD14 Kye Hohenberger \uD83E\uDD14 Mitchell Hamilton \uD83D\uDCBB ⚠️ Justin Hall \uD83D\uDCD6 Brian Pedersen \uD83D\uDCBB \uD83D\uDCD6 Andrew Palm \uD83D\uDCBB Michael Hsu \uD83D\uDCD6 \uD83D\uDD0C Bo Lingen \uD83D\uDCBB Tyler Haas \uD83D\uDCD6 FWeinb \uD83D\uDCBB Tomáš Ehrlich \uD83D\uDC1B \uD83D\uDCBB Jonas Gierer \uD83D\uDCD6 Loïc Padier \uD83D\uDCBB Paul Sherman \uD83D\uDCBB Conrad Buck \uD83D\uDCBB ⚠️ \uD83D\uDCD6 InvictusMB ⚠️ Eric Berry \uD83D\uDD0D Futago-za Ryuu \uD83D\uDCBB ⚠️ Luc \uD83D\uDCBB Victor Vincent \uD83D\uDCBB я котик пур-пур \uD83D\uDCD6 Armando Sosa \uD83D\uDCD6 Matthias \uD83D\uDCBB Jovi De Croock \uD83D\uDCBB ⚠️ Victor Arowo \uD83D\uDCD6 Alex Chan \uD83D\uDCD6 Evan Jacobs \uD83D\uDCBB This project follows the all-contributors specification. Contributions of any kind welcome! LICENSE MIT"
  },
  "src/frontend/app-client/node_modules/balanced-match/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/balanced-match/LICENSE.html",
    "title": "",
    "summary": "(MIT) Copyright (c) 2013 Julian Gruber <julian@juliangruber.com&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/balanced-match/README.html": {
    "href": "src/frontend/app-client/node_modules/balanced-match/README.html",
    "title": "balanced-match",
    "summary": "balanced-match Match balanced string pairs, like { and } or <b> and </b>. Supports regular expressions as well! Example Get the first matching pair of braces: var balanced = require('balanced-match'); console.log(balanced('{', '}', 'pre{in{nested}}post')); console.log(balanced('{', '}', 'pre{first}between{second}post')); console.log(balanced(/\\s+\\{\\s+/, /\\s+\\}\\s+/, 'pre { in{nest} } post')); The matches are: $ node example.js { start: 3, end: 14, pre: 'pre', body: 'in{nested}', post: 'post' } { start: 3, end: 9, pre: 'pre', body: 'first', post: 'between{second}post' } { start: 3, end: 17, pre: 'pre', body: 'in{nest}', post: 'post' } API var m = balanced(a, b, str) For the first non-nested matching pair of a and b in str, return an object with those keys: start the index of the first match of a end the index of the matching b pre the preamble, a and b not included body the match, a and b not included post the postscript, a and b not included If there's no match, undefined will be returned. If the str contains more a than b / there are unmatched pairs, the first match that was closed will be used. For example, {{a} will match ['{', 'a', ''] and {a}} will match ['', 'a', '}']. var r = balanced.range(a, b, str) For the first non-nested matching pair of a and b in str, return an array with indexes: [ <a index>, <b index> ]. If there's no match, undefined will be returned. If the str contains more a than b / there are unmatched pairs, the first match that was closed will be used. For example, {{a} will match [ 1, 3 ] and {a}} will match [0, 2]. Installation With npm do: npm install balanced-match Security contact information To report a security vulnerability, please use the Tidelift security contact. Tidelift will coordinate the fix and disclosure. License (MIT) Copyright (c) 2013 Julian Gruber <julian@juliangruber.com&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/basic-auth/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/basic-auth/HISTORY.html",
    "title": "2.0.1 / 2018-09-19",
    "summary": "2.0.1 / 2018-09-19 deps: safe-buffer@5.1.2 2.0.0 / 2017-09-12 Drop support for Node.js below 0.8 Remove auth(ctx) signature -- pass in header or auth(ctx.req) Use safe-buffer for improved Buffer API 1.1.0 / 2016-11-18 Add auth.parse for low-level string parsing 1.0.4 / 2016-05-10 Improve error message when req argument is not an object Improve error message when req missing headers property 1.0.3 / 2015-07-01 Fix regression accepting a Koa context 1.0.2 / 2015-06-12 Improve error message when req argument missing perf: enable strict mode perf: hoist regular expression perf: parse with regular expressions perf: remove argument reassignment 1.0.1 / 2015-05-04 Update readme 1.0.0 / 2014-07-01 Support empty password Support empty username 0.0.1 / 2013-11-30 Initial release"
  },
  "src/frontend/app-client/node_modules/basic-auth/node_modules/safe-buffer/README.html": {
    "href": "src/frontend/app-client/node_modules/basic-auth/node_modules/safe-buffer/README.html",
    "title": "safe-buffer",
    "summary": "safe-buffer Safer Node.js Buffer API Use the new Node.js Buffer APIs (Buffer.from, Buffer.alloc, Buffer.allocUnsafe, Buffer.allocUnsafeSlow) in all versions of Node.js. Uses the built-in implementation when available. install npm install safe-buffer usage The goal of this package is to provide a safe replacement for the node.js Buffer. It's a drop-in replacement for Buffer. You can use it by adding one require line to the top of your node.js modules: var Buffer = require('safe-buffer').Buffer // Existing buffer code will continue to work without issues: new Buffer('hey', 'utf8') new Buffer([1, 2, 3], 'utf8') new Buffer(obj) new Buffer(16) // create an uninitialized buffer (potentially unsafe) // But you can use these new explicit APIs to make clear what you want: Buffer.from('hey', 'utf8') // convert from many types to a Buffer Buffer.alloc(16) // create a zero-filled buffer (safe) Buffer.allocUnsafe(16) // create an uninitialized buffer (potentially unsafe) api Class Method: Buffer.from(array) array {Array} Allocates a new Buffer using an array of octets. const buf = Buffer.from([0x62,0x75,0x66,0x66,0x65,0x72]); // creates a new Buffer containing ASCII bytes // ['b','u','f','f','e','r'] A TypeError will be thrown if array is not an Array. Class Method: Buffer.from(arrayBuffer[, byteOffset[, length]]) arrayBuffer {ArrayBuffer} The .buffer property of a TypedArray or a new ArrayBuffer() byteOffset {Number} Default: 0 length {Number} Default: arrayBuffer.length - byteOffset When passed a reference to the .buffer property of a TypedArray instance, the newly created Buffer will share the same allocated memory as the TypedArray. const arr = new Uint16Array(2); arr[0] = 5000; arr[1] = 4000; const buf = Buffer.from(arr.buffer); // shares the memory with arr; console.log(buf); // Prints: <Buffer 88 13 a0 0f> // changing the TypedArray changes the Buffer also arr[1] = 6000; console.log(buf); // Prints: <Buffer 88 13 70 17> The optional byteOffset and length arguments specify a memory range within the arrayBuffer that will be shared by the Buffer. const ab = new ArrayBuffer(10); const buf = Buffer.from(ab, 0, 2); console.log(buf.length); // Prints: 2 A TypeError will be thrown if arrayBuffer is not an ArrayBuffer. Class Method: Buffer.from(buffer) buffer {Buffer} Copies the passed buffer data onto a new Buffer instance. const buf1 = Buffer.from('buffer'); const buf2 = Buffer.from(buf1); buf1[0] = 0x61; console.log(buf1.toString()); // 'auffer' console.log(buf2.toString()); // 'buffer' (copy is not changed) A TypeError will be thrown if buffer is not a Buffer. Class Method: Buffer.from(str[, encoding]) str {String} String to encode. encoding {String} Encoding to use, Default: 'utf8' Creates a new Buffer containing the given JavaScript string str. If provided, the encoding parameter identifies the character encoding. If not provided, encoding defaults to 'utf8'. const buf1 = Buffer.from('this is a tést'); console.log(buf1.toString()); // prints: this is a tést console.log(buf1.toString('ascii')); // prints: this is a tC)st const buf2 = Buffer.from('7468697320697320612074c3a97374', 'hex'); console.log(buf2.toString()); // prints: this is a tést A TypeError will be thrown if str is not a string. Class Method: Buffer.alloc(size[, fill[, encoding]]) size {Number} fill {Value} Default: undefined encoding {String} Default: utf8 Allocates a new Buffer of size bytes. If fill is undefined, the Buffer will be zero-filled. const buf = Buffer.alloc(5); console.log(buf); // <Buffer 00 00 00 00 00> The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. If fill is specified, the allocated Buffer will be initialized by calling buf.fill(fill). See [buf.fill()][] for more information. const buf = Buffer.alloc(5, 'a'); console.log(buf); // <Buffer 61 61 61 61 61> If both fill and encoding are specified, the allocated Buffer will be initialized by calling buf.fill(fill, encoding). For example: const buf = Buffer.alloc(11, 'aGVsbG8gd29ybGQ=', 'base64'); console.log(buf); // <Buffer 68 65 6c 6c 6f 20 77 6f 72 6c 64> Calling Buffer.alloc(size) can be significantly slower than the alternative Buffer.allocUnsafe(size) but ensures that the newly created Buffer instance contents will never contain sensitive data. A TypeError will be thrown if size is not a number. Class Method: Buffer.allocUnsafe(size) size {Number} Allocates a new non-zero-filled Buffer of size bytes. The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. The underlying memory for Buffer instances created in this way is not initialized. The contents of the newly created Buffer are unknown and may contain sensitive data. Use [buf.fill(0)][] to initialize such Buffer instances to zeroes. const buf = Buffer.allocUnsafe(5); console.log(buf); // <Buffer 78 e0 82 02 01> // (octets will be different, every time) buf.fill(0); console.log(buf); // <Buffer 00 00 00 00 00> A TypeError will be thrown if size is not a number. Note that the Buffer module pre-allocates an internal Buffer instance of size Buffer.poolSize that is used as a pool for the fast allocation of new Buffer instances created using Buffer.allocUnsafe(size) (and the deprecated new Buffer(size) constructor) only when size is less than or equal to Buffer.poolSize >> 1 (floor of Buffer.poolSize divided by two). The default value of Buffer.poolSize is 8192 but can be modified. Use of this pre-allocated internal memory pool is a key difference between calling Buffer.alloc(size, fill) vs. Buffer.allocUnsafe(size).fill(fill). Specifically, Buffer.alloc(size, fill) will never use the internal Buffer pool, while Buffer.allocUnsafe(size).fill(fill) will use the internal Buffer pool if size is less than or equal to half Buffer.poolSize. The difference is subtle but can be important when an application requires the additional performance that Buffer.allocUnsafe(size) provides. Class Method: Buffer.allocUnsafeSlow(size) size {Number} Allocates a new non-zero-filled and non-pooled Buffer of size bytes. The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. The underlying memory for Buffer instances created in this way is not initialized. The contents of the newly created Buffer are unknown and may contain sensitive data. Use [buf.fill(0)][] to initialize such Buffer instances to zeroes. When using Buffer.allocUnsafe() to allocate new Buffer instances, allocations under 4KB are, by default, sliced from a single pre-allocated Buffer. This allows applications to avoid the garbage collection overhead of creating many individually allocated Buffers. This approach improves both performance and memory usage by eliminating the need to track and cleanup as many Persistent objects. However, in the case where a developer may need to retain a small chunk of memory from a pool for an indeterminate amount of time, it may be appropriate to create an un-pooled Buffer instance using Buffer.allocUnsafeSlow() then copy out the relevant bits. // need to keep around a few small chunks of memory const store = []; socket.on('readable', () => { const data = socket.read(); // allocate for retained data const sb = Buffer.allocUnsafeSlow(10); // copy the data into the new allocation data.copy(sb, 0, 0, 10); store.push(sb); }); Use of Buffer.allocUnsafeSlow() should be used only as a last resort after a developer has observed undue memory retention in their applications. A TypeError will be thrown if size is not a number. All the Rest The rest of the Buffer API is exactly the same as in node.js. See the docs. Related links Node.js issue: Buffer(number) is unsafe Node.js Enhancement Proposal: Buffer.from/Buffer.alloc/Buffer.zalloc/Buffer() soft-deprecate Why is Buffer unsafe? Today, the node.js Buffer constructor is overloaded to handle many different argument types like String, Array, Object, TypedArrayView (Uint8Array, etc.), ArrayBuffer, and also Number. The API is optimized for convenience: you can throw any type at it, and it will try to do what you want. Because the Buffer constructor is so powerful, you often see code like this: // Convert UTF-8 strings to hex function toHex (str) { return new Buffer(str).toString('hex') } But what happens if toHex is called with a Number argument? Remote Memory Disclosure If an attacker can make your program call the Buffer constructor with a Number argument, then they can make it allocate uninitialized memory from the node.js process. This could potentially disclose TLS private keys, user data, or database passwords. When the Buffer constructor is passed a Number argument, it returns an UNINITIALIZED block of memory of the specified size. When you create a Buffer like this, you MUST overwrite the contents before returning it to the user. From the node.js docs: new Buffer(size) size Number The underlying memory for Buffer instances created in this way is not initialized. The contents of a newly created Buffer are unknown and could contain sensitive data. Use buf.fill(0) to initialize a Buffer to zeroes. (Emphasis our own.) Whenever the programmer intended to create an uninitialized Buffer you often see code like this: var buf = new Buffer(16) // Immediately overwrite the uninitialized buffer with data from another buffer for (var i = 0; i < buf.length; i++) { buf[i] = otherBuf[i] } Would this ever be a problem in real code? Yes. It's surprisingly common to forget to check the type of your variables in a dynamically-typed language like JavaScript. Usually the consequences of assuming the wrong type is that your program crashes with an uncaught exception. But the failure mode for forgetting to check the type of arguments to the Buffer constructor is more catastrophic. Here's an example of a vulnerable service that takes a JSON payload and converts it to hex: // Take a JSON payload {str: \"some string\"} and convert it to hex var server = http.createServer(function (req, res) { var data = '' req.setEncoding('utf8') req.on('data', function (chunk) { data += chunk }) req.on('end', function () { var body = JSON.parse(data) res.end(new Buffer(body.str).toString('hex')) }) }) server.listen(8080) In this example, an http client just has to send: { \"str\": 1000 } and it will get back 1,000 bytes of uninitialized memory from the server. This is a very serious bug. It's similar in severity to the the Heartbleed bug that allowed disclosure of OpenSSL process memory by remote attackers. Which real-world packages were vulnerable? bittorrent-dht Mathias Buus and I (Feross Aboukhadijeh) found this issue in one of our own packages, bittorrent-dht. The bug would allow anyone on the internet to send a series of messages to a user of bittorrent-dht and get them to reveal 20 bytes at a time of uninitialized memory from the node.js process. Here's the commit that fixed it. We released a new fixed version, created a Node Security Project disclosure, and deprecated all vulnerable versions on npm so users will get a warning to upgrade to a newer version. ws That got us wondering if there were other vulnerable packages. Sure enough, within a short period of time, we found the same issue in ws, the most popular WebSocket implementation in node.js. If certain APIs were called with Number parameters instead of String or Buffer as expected, then uninitialized server memory would be disclosed to the remote peer. These were the vulnerable methods: socket.send(number) socket.ping(number) socket.pong(number) Here's a vulnerable socket server with some echo functionality: server.on('connection', function (socket) { socket.on('message', function (message) { message = JSON.parse(message) if (message.type === 'echo') { socket.send(message.data) // send back the user's message } }) }) socket.send(number) called on the server, will disclose server memory. Here's the release where the issue was fixed, with a more detailed explanation. Props to Arnout Kazemier for the quick fix. Here's the Node Security Project disclosure. What's the solution? It's important that node.js offers a fast way to get memory otherwise performance-critical applications would needlessly get a lot slower. But we need a better way to signal our intent as programmers. When we want uninitialized memory, we should request it explicitly. Sensitive functionality should not be packed into a developer-friendly API that loosely accepts many different types. This type of API encourages the lazy practice of passing variables in without checking the type very carefully. A new API: Buffer.allocUnsafe(number) The functionality of creating buffers with uninitialized memory should be part of another API. We propose Buffer.allocUnsafe(number). This way, it's not part of an API that frequently gets user input of all sorts of different types passed into it. var buf = Buffer.allocUnsafe(16) // careful, uninitialized memory! // Immediately overwrite the uninitialized buffer with data from another buffer for (var i = 0; i < buf.length; i++) { buf[i] = otherBuf[i] } How do we fix node.js core? We sent a PR to node.js core (merged as semver-major) which defends against one case: var str = 16 new Buffer(str, 'utf8') In this situation, it's implied that the programmer intended the first argument to be a string, since they passed an encoding as a second argument. Today, node.js will allocate uninitialized memory in the case of new Buffer(number, encoding), which is probably not what the programmer intended. But this is only a partial solution, since if the programmer does new Buffer(variable) (without an encoding parameter) there's no way to know what they intended. If variable is sometimes a number, then uninitialized memory will sometimes be returned. What's the real long-term fix? We could deprecate and remove new Buffer(number) and use Buffer.allocUnsafe(number) when we need uninitialized memory. But that would break 1000s of packages. We believe the best solution is to: 1. Change new Buffer(number) to return safe, zeroed-out memory 2. Create a new API for creating uninitialized Buffers. We propose: Buffer.allocUnsafe(number) Update We now support adding three new APIs: Buffer.from(value) - convert from any type to a buffer Buffer.alloc(size) - create a zero-filled buffer Buffer.allocUnsafe(size) - create an uninitialized buffer with given size This solves the core problem that affected ws and bittorrent-dht which is Buffer(variable) getting tricked into taking a number argument. This way, existing code continues working and the impact on the npm ecosystem will be minimal. Over time, npm maintainers can migrate performance-critical code to use Buffer.allocUnsafe(number) instead of new Buffer(number). Conclusion We think there's a serious design issue with the Buffer API as it exists today. It promotes insecure software by putting high-risk functionality into a convenient API with friendly \"developer ergonomics\". This wasn't merely a theoretical exercise because we found the issue in some of the most popular npm packages. Fortunately, there's an easy fix that can be applied today. Use safe-buffer in place of buffer. var Buffer = require('safe-buffer').Buffer Eventually, we hope that node.js core can switch to this new, safer behavior. We believe the impact on the ecosystem would be minimal since it's not a breaking change. Well-maintained, popular packages would be updated to use Buffer.alloc quickly, while older, insecure packages would magically become safe from this attack vector. links Node.js PR: buffer: throw if both length and enc are passed Node Security Project disclosure for ws Node Security Project disclosure forbittorrent-dht credit The original issues in bittorrent-dht (disclosure) and ws (disclosure) were discovered by Mathias Buus and Feross Aboukhadijeh. Thanks to Adam Baldwin for helping disclose these issues and for his work running the Node Security Project. Thanks to John Hiesey for proofreading this README and auditing the code. license MIT. Copyright (C) Feross Aboukhadijeh"
  },
  "src/frontend/app-client/node_modules/basic-auth/README.html": {
    "href": "src/frontend/app-client/node_modules/basic-auth/README.html",
    "title": "basic-auth",
    "summary": "basic-auth Generic basic auth Authorization header field parser for whatever. Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install basic-auth API var auth = require('basic-auth') auth(req) Get the basic auth credentials from the given request. The Authorization header is parsed and if the header is invalid, undefined is returned, otherwise an object with name and pass properties. auth.parse(string) Parse a basic auth authorization header string. This will return an object with name and pass properties, or undefined if the string is invalid. Example Pass a Node.js request object to the module export. If parsing fails undefined is returned, otherwise an object with .name and .pass. var auth = require('basic-auth') var user = auth(req) // => { name: 'something', pass: 'whatever' } A header string from any other location can also be parsed with auth.parse, for example a Proxy-Authorization header: var auth = require('basic-auth') var user = auth.parse(req.getHeader('Proxy-Authorization')) With vanilla node.js http server var http = require('http') var auth = require('basic-auth') var compare = require('tsscmp') // Create server var server = http.createServer(function (req, res) { var credentials = auth(req) // Check credentials // The \"check\" function will typically be against your user store if (!credentials || !check(credentials.name, credentials.pass)) { res.statusCode = 401 res.setHeader('WWW-Authenticate', 'Basic realm=\"example\"') res.end('Access denied') } else { res.end('Access granted') } }) // Basic function to validate credentials for example function check (name, pass) { var valid = true // Simple method to prevent short-circut and use timing-safe compare valid = compare(name, 'john') && valid valid = compare(pass, 'secret') && valid return valid } // Listen server.listen(3000) License MIT"
  },
  "src/frontend/app-client/node_modules/beautify/README.html": {
    "href": "src/frontend/app-client/node_modules/beautify/README.html",
    "title": "Beautify",
    "summary": "Beautify Beautify CSS/JS/JSON/HTML/XML formats Installation npm i beautify -g Usage beautify [options]: -h, --help output usage information -V, --version output the version number -f, --format input format.(optional) json/xml/html/js/css -o, --output output file or folder examles: beautify -o output.html ./test.html curl -L https://raw.githubusercontent.com/gko/beautify/master/test/mock/test1.json | beautify echo 'body{width: \"200px\"}' | beautify -f css You can also use it from node: const beautify = require('beautify'); beautify(`{\"a\":1}`, {format: 'json'}) Tests To run tests you simply need to do: npm run test License MIT Copyright (c) 2016 Konstantin Gorodinskiy"
  },
  "src/frontend/app-client/node_modules/bippy/README.html": {
    "href": "src/frontend/app-client/node_modules/bippy/README.html",
    "title": "bippy",
    "summary": "Warning ⚠️⚠️⚠️ this project may break production apps and cause unexpected behavior ⚠️⚠️⚠️ this project uses react internals, which can change at any time. it is not recommended to depend on internals unless you really, really have to. by proceeding, you acknowledge the risk of breaking your own code or apps that use your code. bippy bippy is a toolkit to hack into react internals by default, you cannot access react internals. bippy bypasses this by \"pretending\" to be react devtools, giving you access to the fiber tree and other internals. works outside of react – no react code modification needed utility functions that work across modern react (v17-19) no prior react source code knowledge required import { onCommitFiberRoot, traverseFiber } from 'bippy'; onCommitFiberRoot((root) => { traverseFiber(root.current, (fiber) => { // prints every fiber in the current React tree console.log('fiber:', fiber); }); }); how it works & motivation bippy allows you to access and use react fibers outside of react components. a react fiber is a \"unit of execution.\" this means react will do something based on the data in a fiber. each fiber either represents a composite (function/class component) or a host (dom element). here is a live visualization of what the fiber tree looks like, and here is a deep dive article. fibers are useful because they contain information about the react app (component props, state, contexts, etc.). a simplified version of a fiber looks roughly like this: interface Fiber { // component type (function/class) type: any; child: Fiber | null; sibling: Fiber | null; // stateNode is the host fiber (e.g. DOM element) stateNode: Node | null; // parent fiber return: Fiber | null; // the previous or current version of the fiber alternate: Fiber | null; // saved props input memoizedProps: any; // state (useState, useReducer, useSES, etc.) memoizedState: any; // contexts (useContext) dependencies: Dependencies | null; // effects (useEffect, useLayoutEffect, etc.) updateQueue: any; } here, the child, sibling, and return properties are pointers to other fibers in the tree. additionally, memoizedProps, memoizedState, and dependencies are the fiber's props, state, and contexts. while all of the information is there, it's not super easy to work with, and changes frequently across different versions of react. bippy simplifies this by providing utility functions like: traverseRenderedFibers to detect renders and traverseFiber to traverse the overall fiber tree (instead of child, sibling, and return pointers) traverseProps, traverseState, and traverseContexts to traverse the fiber's props, state, and contexts (instead of memoizedProps, memoizedState, and dependencies) however, fibers aren't directly accessible by the user. so, we have to hack our way around to accessing it. luckily, react reads from a property in the window object: window.__REACT_DEVTOOLS_GLOBAL_HOOK__ and runs handlers on it when certain events happen. this property must exist before react's bundle is executed. this is intended for react devtools, but we can use it to our advantage. here's what it roughly looks like: interface __REACT_DEVTOOLS_GLOBAL_HOOK__ { // list of renderers (react-dom, react-native, etc.) renderers: Map<RendererID, reactRenderer>; // called when react has rendered everything for an update and the fiber tree is fully built and ready to // apply changes to the host tree (e.g. DOM mutations) onCommitFiberRoot: ( rendererID: RendererID, root: FiberRoot, commitPriority?: number ) => void; // called when effects run onPostCommitFiberRoot: (rendererID: RendererID, root: FiberRoot) => void; // called when a specific fiber unmounts onCommitFiberUnmount: (rendererID: RendererID, fiber: Fiber) => void; } bippy works by monkey-patching window.__REACT_DEVTOOLS_GLOBAL_HOOK__ with our own custom handlers. bippy simplifies this by providing utility functions like: instrument to safely patch window.__REACT_DEVTOOLS_GLOBAL_HOOK__ (instead of directly mutating onCommitFiberRoot, ...) secure to wrap your handlers in a try/catch and determine if handlers are safe to run (instead of rawdogging window.__REACT_DEVTOOLS_GLOBAL_HOOK__ handlers, which may crash your app) traverseRenderedFibers to traverse the fiber tree and determine which fibers have actually rendered (instead of child, sibling, and return pointers) traverseFiber to traverse the fiber tree, regardless of whether it has rendered (instead of child, sibling, and return pointers) setFiberId / getFiberId to set and get a fiber's id (instead of anonymous fibers with no identity) how to use you can either install via a npm (recommended) or a script tag. this package should be imported before a React app runs. this will add a special object to the global which is used by React for providing its internals to the tool for analysis (React Devtools does the same). as soon as React library is loaded and attached to the tool, bippy starts collecting data about what is going on in React's internals. npm install bippy or, use via script tag: <script src=\"https://unpkg.com/bippy\"></script> this will cause bippy to be accessible under a window.Bippy global. next, you can use the api to get data about the fiber tree. below is a (useful) subset of the api. for the full api, read the source code. onCommitFiberRoot a utility function that wraps the instrument function and sets the onCommitFiberRoot hook. import { onCommitFiberRoot } from 'bippy'; onCommitFiberRoot((root) => { console.log('root ready to commit', root); }); instrument the underlying implementation for the onCommitFiberRoot() function. this is optional, unless you want to plug into more less common, advanced functionality. patches window.__REACT_DEVTOOLS_GLOBAL_HOOK__ with your handlers. must be imported before react, and must be initialized to properly run any other methods. use with the secure function to prevent uncaught errors from crashing your app. import { instrument, secure } from 'bippy'; // must be imported BEFORE react import * as React from 'react'; instrument( secure({ onCommitFiberRoot(rendererID, root) { console.log('root ready to commit', root); }, onPostCommitFiberRoot(rendererID, root) { console.log('root with effects committed', root); }, onCommitFiberUnmount(rendererID, fiber) { console.log('fiber unmounted', fiber); }, }) ); getRDTHook returns the window.__REACT_DEVTOOLS_GLOBAL_HOOK__ object. great for advanced use cases, such as accessing or modifying the renderers property. import { getRDTHook } from 'bippy'; const hook = getRDTHook(); console.log(hook); traverseRenderedFibers not every fiber in the fiber tree renders. traverseRenderedFibers allows you to traverse the fiber tree and determine which fibers have actually rendered. import { instrument, secure, traverseRenderedFibers } from 'bippy'; // must be imported BEFORE react import * as React from 'react'; instrument( secure({ onCommitFiberRoot(rendererID, root) { traverseRenderedFibers(root, (fiber) => { console.log('fiber rendered', fiber); }); }, }) ); traverseFiber calls a callback on every fiber in the fiber tree. import { instrument, secure, traverseFiber } from 'bippy'; // must be imported BEFORE react import * as React from 'react'; instrument( secure({ onCommitFiberRoot(rendererID, root) { traverseFiber(root.current, (fiber) => { console.log(fiber); }); }, }) ); traverseProps traverses the props of a fiber. import { traverseProps } from 'bippy'; // ... traverseProps(fiber, (propName, next, prev) => { console.log(propName, next, prev); }); traverseState traverses the state (useState, useReducer, etc.) and effects that set state of a fiber. import { traverseState } from 'bippy'; // ... traverseState(fiber, (next, prev) => { console.log(next, prev); }); traverseContexts traverses the contexts (useContext) of a fiber. import { traverseContexts } from 'bippy'; // ... traverseContexts(fiber, (next, prev) => { console.log(next, prev); }); setFiberId / getFiberId set and get a persistent identity for a fiber. by default, fibers are anonymous and have no identity. import { setFiberId, getFiberId } from 'bippy'; // ... setFiberId(fiber); console.log('unique id for fiber:', getFiberId(fiber)); isHostFiber returns true if the fiber is a host fiber (e.g., a DOM node in react-dom). import { isHostFiber } from 'bippy'; if (isHostFiber(fiber)) { console.log('fiber is a host fiber'); } isCompositeFiber returns true if the fiber is a composite fiber. composite fibers represent class components, function components, memoized components, and so on (anything that can actually render output). import { isCompositeFiber } from 'bippy'; if (isCompositeFiber(fiber)) { console.log('fiber is a composite fiber'); } getDisplayName returns the display name of the fiber's component, falling back to the component's function or class name if available. import { getDisplayName } from 'bippy'; console.log(getDisplayName(fiber)); getType returns the underlying type (the component definition) for a given fiber. for example, this could be a function component or class component. import { getType } from 'bippy'; import { memo } from 'react'; const RealComponent = () => { return <div>hello</div>; }; const MemoizedComponent = memo(() => { return <div>hello</div>; }); console.log(getType(fiberForMemoizedComponent) === RealComponent); getNearestHostFiber / getNearestHostFibers getNearestHostFiber returns the closest host fiber above or below a given fiber. getNearestHostFibers(fiber) returns all host fibers associated with the provided fiber and its subtree. import { getNearestHostFiber, getNearestHostFibers } from 'bippy'; // ... function Component() { return ( <> <div>hello</div> <div>world</div> </> ); } console.log(getNearestHostFiber(fiberForComponent)); // <div>hello</div> console.log(getNearestHostFibers(fiberForComponent)); // [<div>hello</div>, <div>world</div>] getTimings returns the self and total render times for the fiber. // timings don't exist in react production builds if (fiber.actualDuration !== undefined) { const { selfTime, totalTime } = getTimings(fiber); console.log(selfTime, totalTime); } getFiberStack returns an array representing the stack of fibers from the current fiber up to the root. [fiber, fiber.return, fiber.return.return, ...] getMutatedHostFibers returns an array of all host fibers that have committed and rendered in the provided fiber's subtree. import { getMutatedHostFibers } from 'bippy'; console.log(getMutatedHostFibers(fiber)); isValidFiber returns true if the given object is a valid React Fiber (i.e., has a tag, stateNode, return, child, sibling, etc.). import { isValidFiber } from 'bippy'; console.log(isValidFiber(fiber)); getFiberFromHostInstance returns the fiber associated with a given host instance (e.g., a DOM element). import { getFiberFromHostInstance } from 'bippy'; const fiber = getFiberFromHostInstance(document.querySelector('div')); console.log(fiber); getLatestFiber returns the latest fiber (since it may be double-buffered). usually use this in combination with getFiberFromHostInstance. import { getLatestFiber } from 'bippy'; const latestFiber = getLatestFiber( getFiberFromHostInstance(document.querySelector('div')) ); console.log(latestFiber); examples the best way to understand bippy is to read the source code. here are some examples of how you can use it: a mini react-scan here's a mini toy version of react-scan that highlights renders in your app. import { instrument, isHostFiber, getNearestHostFiber, traverseRenderedFibers, } from 'bippy'; // must be imported BEFORE react const highlightFiber = (fiber) => { if (!(fiber.stateNode instanceof HTMLElement)) return; // fiber.stateNode is a DOM element const rect = fiber.stateNode.getBoundingClientRect(); const highlight = document.createElement('div'); highlight.style.border = '1px solid red'; highlight.style.position = 'fixed'; highlight.style.top = `${rect.top}px`; highlight.style.left = `${rect.left}px`; highlight.style.width = `${rect.width}px`; highlight.style.height = `${rect.height}px`; highlight.style.zIndex = 999999999; document.documentElement.appendChild(highlight); setTimeout(() => { document.documentElement.removeChild(highlight); }, 100); }; /** * `instrument` is a function that installs the react DevTools global * hook and allows you to set up custom handlers for react fiber events. */ instrument( /** * `secure` is a function that wraps your handlers in a try/catch * and prevents it from crashing the app. it also prevents it from * running on unsupported react versions and during production. * * this is not required but highly recommended to provide \"safeguards\" * in case something breaks. */ secure({ /** * `onCommitFiberRoot` is a handler that is called when react is * ready to commit a fiber root. this means that react is has * rendered your entire app and is ready to apply changes to * the host tree (e.g. via DOM mutations). */ onCommitFiberRoot(rendererID, root) { /** * `traverseRenderedFibers` traverses the fiber tree and determines which * fibers have actually rendered. * * A fiber tree contains many fibers that may have not rendered. this * can be because it bailed out (e.g. `useMemo`) or because it wasn't * actually rendered (if <Child> re-rendered, then <Parent> didn't * actually render, but exists in the fiber tree). */ traverseRenderedFibers(root, (fiber) => { /** * `getNearestHostFiber` is a utility function that finds the * nearest host fiber to a given fiber. * * a host fiber for `react-dom` is a fiber that has a DOM element * as its `stateNode`. */ const hostFiber = getNearestHostFiber(fiber); highlightFiber(hostFiber); }); }, }) ); a mini why-did-you-render here's a mini toy version of why-did-you-render that logs why components re-render. import { instrument, isHostFiber, traverseRenderedFibers, isCompositeFiber, getDisplayName, traverseProps, traverseContexts, traverseState, } from 'bippy'; // must be imported BEFORE react instrument( secure({ onCommitFiberRoot(rendererID, root) { traverseRenderedFibers(root, (fiber) => { /** * `isCompositeFiber` is a utility function that checks if a fiber is a composite fiber. * a composite fiber is a fiber that represents a function or class component. */ if (!isCompositeFiber(fiber)) return; /** * `getDisplayName` is a utility function that gets the display name of a fiber. */ const displayName = getDisplayName(fiber); if (!displayName) return; const changes = []; /** * `traverseProps` is a utility function that traverses the props of a fiber. */ traverseProps(fiber, (propName, next, prev) => { if (next !== prev) { changes.push({ name: `prop ${propName}`, prev, next, }); } }); let contextId = 0; /** * `traverseContexts` is a utility function that traverses the contexts of a fiber. * Contexts don't have a \"name\" like props, so we use an id to identify them. */ traverseContexts(fiber, (next, prev) => { if (next !== prev) { changes.push({ name: `context ${contextId}`, prev, next, contextId, }); } contextId++; }); let stateId = 0; /** * `traverseState` is a utility function that traverses the state of a fiber. * * State don't have a \"name\" like props, so we use an id to identify them. */ traverseState(fiber, (value, prevValue) => { if (next !== prev) { changes.push({ name: `state ${stateId}`, prev, next, }); } stateId++; }); console.group( `%c${displayName}`, 'background: hsla(0,0%,70%,.3); border-radius:3px; padding: 0 2px;' ); for (const { name, prev, next } of changes) { console.log(`${name}:`, prev, '!==', next); } console.groupEnd(); }); }, }) ); glossary fiber: a \"unit of execution\" in react, representing a component or dom element commit: the process of applying changes to the host tree (e.g. DOM mutations) render: the process of building the fiber tree by executing component function/classes host tree: the tree of UI elements that react mutates (e.g. DOM elements) reconciler (or \"renderer\"): custom bindings for react, e.g. react-dom, react-native, react-three-fiber, etc to mutate the host tree rendererID: the id of the reconciler, starting at 1 (can be from multiple reconciler instances) root: a special FiberRoot type that contains the container fiber (the one you pass to ReactDOM.createRoot) in the current property onCommitFiberRoot: called when react is ready to commit a fiber root onPostCommitFiberRoot: called when react has committed a fiber root and effects have run onCommitFiberUnmount: called when a fiber unmounts development pre-requisite: you should understand how react works internally. if you don't, please give this series of articles a read. we use a pnpm monorepo, get started by running: pnpm install # create dev builds pnpm run dev # run unit tests pnpm run test you can ad-hoc test by running pnpm run dev in the /kitchen-sink directory. cd kitchen-sink pnpm run dev misc we use this project internally in react-scan, which is deployed with proper safeguards to ensure it's only used in development or error-guarded in production. while i maintain this specifically for react-scan, those seeking more robust solutions might consider its-fine for accessing fibers within react using hooks, or react-devtools-inline for a headful interface. if you plan to use this project beyond experimentation, please review react-scan's source code to understand our safeguarding practices. the original bippy character is owned and created by @dairyfreerice. this project is not related to the bippy brand, i just think the character is cute."
  },
  "src/frontend/app-client/node_modules/body-parser/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/body-parser/HISTORY.html",
    "title": "1.20.3 / 2024-09-10",
    "summary": "1.20.3 / 2024-09-10 deps: qs@6.13.0 add depth option to customize the depth level in the parser IMPORTANT: The default depth level for parsing URL-encoded data is now 32 (previously was Infinity) 1.20.2 / 2023-02-21 Fix strict json error message on Node.js 19+ deps: content-type@~1.0.5 perf: skip value escaping when unnecessary deps: raw-body@2.5.2 1.20.1 / 2022-10-06 deps: qs@6.11.0 perf: remove unnecessary object clone 1.20.0 / 2022-04-02 Fix error message for json parse whitespace in strict Fix internal error when inflated body exceeds limit Prevent loss of async hooks context Prevent hanging when request already read deps: depd@2.0.0 Replace internal eval usage with Function constructor Use instance methods on process to check for listeners deps: http-errors@2.0.0 deps: depd@2.0.0 deps: statuses@2.0.1 deps: on-finished@2.4.1 deps: qs@6.10.3 deps: raw-body@2.5.1 deps: http-errors@2.0.0 1.19.2 / 2022-02-15 deps: bytes@3.1.2 deps: qs@6.9.7 Fix handling of __proto__ keys deps: raw-body@2.4.3 deps: bytes@3.1.2 1.19.1 / 2021-12-10 deps: bytes@3.1.1 deps: http-errors@1.8.1 deps: inherits@2.0.4 deps: toidentifier@1.0.1 deps: setprototypeof@1.2.0 deps: qs@6.9.6 deps: raw-body@2.4.2 deps: bytes@3.1.1 deps: http-errors@1.8.1 deps: safe-buffer@5.2.1 deps: type-is@~1.6.18 1.19.0 / 2019-04-25 deps: bytes@3.1.0 Add petabyte (pb) support deps: http-errors@1.7.2 Set constructor name when possible deps: setprototypeof@1.1.1 deps: statuses@'>= 1.5.0 < 2' deps: iconv-lite@0.4.24 Added encoding MIK deps: qs@6.7.0 Fix parsing array brackets after index deps: raw-body@2.4.0 deps: bytes@3.1.0 deps: http-errors@1.7.2 deps: iconv-lite@0.4.24 deps: type-is@~1.6.17 deps: mime-types@~2.1.24 perf: prevent internal throw on invalid type 1.18.3 / 2018-05-14 Fix stack trace for strict json parse error deps: depd@~1.1.2 perf: remove argument reassignment deps: http-errors@~1.6.3 deps: depd@~1.1.2 deps: setprototypeof@1.1.0 deps: statuses@'>= 1.3.1 < 2' deps: iconv-lite@0.4.23 Fix loading encoding with year appended Fix deprecation warnings on Node.js 10+ deps: qs@6.5.2 deps: raw-body@2.3.3 deps: http-errors@1.6.3 deps: iconv-lite@0.4.23 deps: type-is@~1.6.16 deps: mime-types@~2.1.18 1.18.2 / 2017-09-22 deps: debug@2.6.9 perf: remove argument reassignment 1.18.1 / 2017-09-12 deps: content-type@~1.0.4 perf: remove argument reassignment perf: skip parameter parsing when no parameters deps: iconv-lite@0.4.19 Fix ISO-8859-1 regression Update Windows-1255 deps: qs@6.5.1 Fix parsing & compacting very deep objects deps: raw-body@2.3.2 deps: iconv-lite@0.4.19 1.18.0 / 2017-09-08 Fix JSON strict violation error to match native parse error Include the body property on verify errors Include the type property on all generated errors Use http-errors to set status code on errors deps: bytes@3.0.0 deps: debug@2.6.8 deps: depd@~1.1.1 Remove unnecessary Buffer loading deps: http-errors@~1.6.2 deps: depd@1.1.1 deps: iconv-lite@0.4.18 Add support for React Native Add a warning if not loaded as utf-8 Fix CESU-8 decoding in Node.js 8 Improve speed of ISO-8859-1 encoding deps: qs@6.5.0 deps: raw-body@2.3.1 Use http-errors for standard emitted errors deps: bytes@3.0.0 deps: iconv-lite@0.4.18 perf: skip buffer decoding on overage chunk perf: prevent internal throw when missing charset 1.17.2 / 2017-05-17 deps: debug@2.6.7 Fix DEBUG_MAX_ARRAY_LENGTH deps: ms@2.0.0 deps: type-is@~1.6.15 deps: mime-types@~2.1.15 1.17.1 / 2017-03-06 deps: qs@6.4.0 Fix regression parsing keys starting with [ 1.17.0 / 2017-03-01 deps: http-errors@~1.6.1 Make message property enumerable for HttpErrors deps: setprototypeof@1.0.3 deps: qs@6.3.1 Fix compacting nested arrays 1.16.1 / 2017-02-10 deps: debug@2.6.1 Fix deprecation messages in WebStorm and other editors Undeprecate DEBUG_FD set to 1 or 2 1.16.0 / 2017-01-17 deps: debug@2.6.0 Allow colors in workers Deprecated DEBUG_FD environment variable Fix error when running under React Native Use same color for same namespace deps: ms@0.7.2 deps: http-errors@~1.5.1 deps: inherits@2.0.3 deps: setprototypeof@1.0.2 deps: statuses@'>= 1.3.1 < 2' deps: iconv-lite@0.4.15 Added encoding MS-31J Added encoding MS-932 Added encoding MS-936 Added encoding MS-949 Added encoding MS-950 Fix GBK/GB18030 handling of Euro character deps: qs@6.2.1 Fix array parsing from skipping empty values deps: raw-body@~2.2.0 deps: iconv-lite@0.4.15 deps: type-is@~1.6.14 deps: mime-types@~2.1.13 1.15.2 / 2016-06-19 deps: bytes@2.4.0 deps: content-type@~1.0.2 perf: enable strict mode deps: http-errors@~1.5.0 Use setprototypeof module to replace __proto__ setting deps: statuses@'>= 1.3.0 < 2' perf: enable strict mode deps: qs@6.2.0 deps: raw-body@~2.1.7 deps: bytes@2.4.0 perf: remove double-cleanup on happy path deps: type-is@~1.6.13 deps: mime-types@~2.1.11 1.15.1 / 2016-05-05 deps: bytes@2.3.0 Drop partial bytes on all parsed units Fix parsing byte string that looks like hex deps: raw-body@~2.1.6 deps: bytes@2.3.0 deps: type-is@~1.6.12 deps: mime-types@~2.1.10 1.15.0 / 2016-02-10 deps: http-errors@~1.4.0 Add HttpError export, for err instanceof createError.HttpError deps: inherits@2.0.1 deps: statuses@'>= 1.2.1 < 2' deps: qs@6.1.0 deps: type-is@~1.6.11 deps: mime-types@~2.1.9 1.14.2 / 2015-12-16 deps: bytes@2.2.0 deps: iconv-lite@0.4.13 deps: qs@5.2.0 deps: raw-body@~2.1.5 deps: bytes@2.2.0 deps: iconv-lite@0.4.13 deps: type-is@~1.6.10 deps: mime-types@~2.1.8 1.14.1 / 2015-09-27 Fix issue where invalid charset results in 400 when verify used deps: iconv-lite@0.4.12 Fix CESU-8 decoding in Node.js 4.x deps: raw-body@~2.1.4 Fix masking critical errors from iconv-lite deps: iconv-lite@0.4.12 deps: type-is@~1.6.9 deps: mime-types@~2.1.7 1.14.0 / 2015-09-16 Fix JSON strict parse error to match syntax errors Provide static require analysis in urlencoded parser deps: depd@~1.1.0 Support web browser loading deps: qs@5.1.0 deps: raw-body@~2.1.3 Fix sync callback when attaching data listener causes sync read deps: type-is@~1.6.8 Fix type error when given invalid type to match against deps: mime-types@~2.1.6 1.13.3 / 2015-07-31 deps: type-is@~1.6.6 deps: mime-types@~2.1.4 1.13.2 / 2015-07-05 deps: iconv-lite@0.4.11 deps: qs@4.0.0 Fix dropping parameters like hasOwnProperty Fix user-visible incompatibilities from 3.1.0 Fix various parsing edge cases deps: raw-body@~2.1.2 Fix error stack traces to skip makeError deps: iconv-lite@0.4.11 deps: type-is@~1.6.4 deps: mime-types@~2.1.2 perf: enable strict mode perf: remove argument reassignment 1.13.1 / 2015-06-16 deps: qs@2.4.2 Downgraded from 3.1.0 because of user-visible incompatibilities 1.13.0 / 2015-06-14 Add statusCode property on Errors, in addition to status Change type default to application/json for JSON parser Change type default to application/x-www-form-urlencoded for urlencoded parser Provide static require analysis Use the http-errors module to generate errors deps: bytes@2.1.0 Slight optimizations deps: iconv-lite@0.4.10 The encoding UTF-16 without BOM now defaults to UTF-16LE when detection fails Leading BOM is now removed when decoding deps: on-finished@~2.3.0 Add defined behavior for HTTP CONNECT requests Add defined behavior for HTTP Upgrade requests deps: ee-first@1.1.1 deps: qs@3.1.0 Fix dropping parameters like hasOwnProperty Fix various parsing edge cases Parsed object now has null prototype deps: raw-body@~2.1.1 Use unpipe module for unpiping requests deps: iconv-lite@0.4.10 deps: type-is@~1.6.3 deps: mime-types@~2.1.1 perf: reduce try block size perf: remove bitwise operations perf: enable strict mode perf: remove argument reassignment perf: remove delete call 1.12.4 / 2015-05-10 deps: debug@~2.2.0 deps: qs@2.4.2 Fix allowing parameters like constructor deps: on-finished@~2.2.1 deps: raw-body@~2.0.1 Fix a false-positive when unpiping in Node.js 0.8 deps: bytes@2.0.1 deps: type-is@~1.6.2 deps: mime-types@~2.0.11 1.12.3 / 2015-04-15 Slight efficiency improvement when not debugging deps: depd@~1.0.1 deps: iconv-lite@0.4.8 Add encoding alias UNICODE-1-1-UTF-7 deps: raw-body@1.3.4 Fix hanging callback if request aborts during read deps: iconv-lite@0.4.8 1.12.2 / 2015-03-16 deps: qs@2.4.1 Fix error when parameter hasOwnProperty is present 1.12.1 / 2015-03-15 deps: debug@~2.1.3 Fix high intensity foreground color for bold deps: ms@0.7.0 deps: type-is@~1.6.1 deps: mime-types@~2.0.10 1.12.0 / 2015-02-13 add debug messages accept a function for the type option use content-type to parse Content-Type headers deps: iconv-lite@0.4.7 Gracefully support enumerables on Object.prototype deps: raw-body@1.3.3 deps: iconv-lite@0.4.7 deps: type-is@~1.6.0 fix argument reassignment fix false-positives in hasBody Transfer-Encoding check support wildcard for both type and subtype (*/*) deps: mime-types@~2.0.9 1.11.0 / 2015-01-30 make internal extended: true depth limit infinity deps: type-is@~1.5.6 deps: mime-types@~2.0.8 1.10.2 / 2015-01-20 deps: iconv-lite@0.4.6 Fix rare aliases of single-byte encodings deps: raw-body@1.3.2 deps: iconv-lite@0.4.6 1.10.1 / 2015-01-01 deps: on-finished@~2.2.0 deps: type-is@~1.5.5 deps: mime-types@~2.0.7 1.10.0 / 2014-12-02 make internal extended: true array limit dynamic 1.9.3 / 2014-11-21 deps: iconv-lite@0.4.5 Fix Windows-31J and X-SJIS encoding support deps: qs@2.3.3 Fix arrayLimit behavior deps: raw-body@1.3.1 deps: iconv-lite@0.4.5 deps: type-is@~1.5.3 deps: mime-types@~2.0.3 1.9.2 / 2014-10-27 deps: qs@2.3.2 Fix parsing of mixed objects and values 1.9.1 / 2014-10-22 deps: on-finished@~2.1.1 Fix handling of pipelined requests deps: qs@2.3.0 Fix parsing of mixed implicit and explicit arrays deps: type-is@~1.5.2 deps: mime-types@~2.0.2 1.9.0 / 2014-09-24 include the charset in \"unsupported charset\" error message include the encoding in \"unsupported content encoding\" error message deps: depd@~1.0.0 1.8.4 / 2014-09-23 fix content encoding to be case-insensitive 1.8.3 / 2014-09-19 deps: qs@2.2.4 Fix issue with object keys starting with numbers truncated 1.8.2 / 2014-09-15 deps: depd@0.4.5 1.8.1 / 2014-09-07 deps: media-typer@0.3.0 deps: type-is@~1.5.1 1.8.0 / 2014-09-05 make empty-body-handling consistent between chunked requests empty json produces {} empty raw produces new Buffer(0) empty text produces '' empty urlencoded produces {} deps: qs@2.2.3 Fix issue where first empty value in array is discarded deps: type-is@~1.5.0 fix hasbody to be true for content-length: 0 1.7.0 / 2014-09-01 add parameterLimit option to urlencoded parser change urlencoded extended array limit to 100 respond with 413 when over parameterLimit in urlencoded 1.6.7 / 2014-08-29 deps: qs@2.2.2 Remove unnecessary cloning 1.6.6 / 2014-08-27 deps: qs@2.2.0 Array parsing fix Performance improvements 1.6.5 / 2014-08-16 deps: on-finished@2.1.0 1.6.4 / 2014-08-14 deps: qs@1.2.2 1.6.3 / 2014-08-10 deps: qs@1.2.1 1.6.2 / 2014-08-07 deps: qs@1.2.0 Fix parsing array of objects 1.6.1 / 2014-08-06 deps: qs@1.1.0 Accept urlencoded square brackets Accept empty values in implicit array notation 1.6.0 / 2014-08-05 deps: qs@1.0.2 Complete rewrite Limits array length to 20 Limits object depth to 5 Limits parameters to 1,000 1.5.2 / 2014-07-27 deps: depd@0.4.4 Work-around v8 generating empty stack traces 1.5.1 / 2014-07-26 deps: depd@0.4.3 Fix exception when global Error.stackTraceLimit is too low 1.5.0 / 2014-07-20 deps: depd@0.4.2 Add TRACE_DEPRECATION environment variable Remove non-standard grey color from color output Support --no-deprecation argument Support --trace-deprecation argument deps: iconv-lite@0.4.4 Added encoding UTF-7 deps: raw-body@1.3.0 deps: iconv-lite@0.4.4 Added encoding UTF-7 Fix Cannot switch to old mode now error on Node.js 0.10+ deps: type-is@~1.3.2 1.4.3 / 2014-06-19 deps: type-is@1.3.1 fix global variable leak 1.4.2 / 2014-06-19 deps: type-is@1.3.0 improve type parsing 1.4.1 / 2014-06-19 fix urlencoded extended deprecation message 1.4.0 / 2014-06-19 add text parser add raw parser check accepted charset in content-type (accepts utf-8) check accepted encoding in content-encoding (accepts identity) deprecate bodyParser() middleware; use .json() and .urlencoded() as needed deprecate urlencoded() without provided extended option lazy-load urlencoded parsers parsers split into files for reduced mem usage support gzip and deflate bodies set inflate: false to turn off deps: raw-body@1.2.2 Support all encodings from iconv-lite 1.3.1 / 2014-06-11 deps: type-is@1.2.1 Switch dependency from mime to mime-types@1.0.0 1.3.0 / 2014-05-31 add extended option to urlencoded parser 1.2.2 / 2014-05-27 deps: raw-body@1.1.6 assert stream encoding on node.js 0.8 assert stream encoding on node.js < 0.10.6 deps: bytes@1 1.2.1 / 2014-05-26 invoke next(err) after request fully read prevents hung responses and socket hang ups 1.2.0 / 2014-05-11 add verify option deps: type-is@1.2.0 support suffix matching 1.1.2 / 2014-05-11 improve json parser speed 1.1.1 / 2014-05-11 fix repeated limit parsing with every request 1.1.0 / 2014-05-10 add type option deps: pin for safety and consistency 1.0.2 / 2014-04-14 use type-is module 1.0.1 / 2014-03-20 lower default limits to 100kb"
  },
  "src/frontend/app-client/node_modules/body-parser/node_modules/debug/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/body-parser/node_modules/debug/CHANGELOG.html",
    "title": "2.6.9 / 2017-09-22",
    "summary": "2.6.9 / 2017-09-22 remove ReDoS regexp in %o formatter (#504) 2.6.8 / 2017-05-18 Fix: Check for undefined on browser globals (#462, @marbemac) 2.6.7 / 2017-05-16 Fix: Update ms to 2.0.0 to fix regular expression denial of service vulnerability (#458, @hubdotcom) Fix: Inline extend function in node implementation (#452, @dougwilson) Docs: Fix typo (#455, @msasad) 2.6.5 / 2017-04-27 Fix: null reference check on window.documentElement.style.WebkitAppearance (#447, @thebigredgeek) Misc: clean up browser reference checks (#447, @thebigredgeek) Misc: add npm-debug.log to .gitignore (@thebigredgeek) 2.6.4 / 2017-04-20 Fix: bug that would occure if process.env.DEBUG is a non-string value. (#444, @LucianBuzzo) Chore: ignore bower.json in npm installations. (#437, @joaovieira) Misc: update \"ms\" to v0.7.3 (@tootallnate) 2.6.3 / 2017-03-13 Fix: Electron reference to process.env.DEBUG (#431, @paulcbetts) Docs: Changelog fix (@thebigredgeek) 2.6.2 / 2017-03-10 Fix: DEBUG_MAX_ARRAY_LENGTH (#420, @slavaGanzin) Docs: Add backers and sponsors from Open Collective (#422, @piamancini) Docs: Add Slackin invite badge (@tootallnate) 2.6.1 / 2017-02-10 Fix: Module's export default syntax fix for IE8 Expected identifier error Fix: Whitelist DEBUG_FD for values 1 and 2 only (#415, @pi0) Fix: IE8 \"Expected identifier\" error (#414, @vgoma) Fix: Namespaces would not disable once enabled (#409, @musikov) 2.6.0 / 2016-12-28 Fix: added better null pointer checks for browser useColors (@thebigredgeek) Improvement: removed explicit window.debug export (#404, @tootallnate) Improvement: deprecated DEBUG_FD environment variable (#405, @tootallnate) 2.5.2 / 2016-12-25 Fix: reference error on window within webworkers (#393, @KlausTrainer) Docs: fixed README typo (#391, @lurch) Docs: added notice about v3 api discussion (@thebigredgeek) 2.5.1 / 2016-12-20 Fix: babel-core compatibility 2.5.0 / 2016-12-20 Fix: wrong reference in bower file (@thebigredgeek) Fix: webworker compatibility (@thebigredgeek) Fix: output formatting issue (#388, @kribblo) Fix: babel-loader compatibility (#383, @escwald) Misc: removed built asset from repo and publications (@thebigredgeek) Misc: moved source files to /src (#378, @yamikuronue) Test: added karma integration and replaced babel with browserify for browser tests (#378, @yamikuronue) Test: coveralls integration (#378, @yamikuronue) Docs: simplified language in the opening paragraph (#373, @yamikuronue) 2.4.5 / 2016-12-17 Fix: navigator undefined in Rhino (#376, @jochenberger) Fix: custom log function (#379, @hsiliev) Improvement: bit of cleanup + linting fixes (@thebigredgeek) Improvement: rm non-maintainted dist/ dir (#375, @freewil) Docs: simplified language in the opening paragraph. (#373, @yamikuronue) 2.4.4 / 2016-12-14 Fix: work around debug being loaded in preload scripts for electron (#368, @paulcbetts) 2.4.3 / 2016-12-14 Fix: navigation.userAgent error for react native (#364, @escwald) 2.4.2 / 2016-12-14 Fix: browser colors (#367, @tootallnate) Misc: travis ci integration (@thebigredgeek) Misc: added linting and testing boilerplate with sanity check (@thebigredgeek) 2.4.1 / 2016-12-13 Fix: typo that broke the package (#356) 2.4.0 / 2016-12-13 Fix: bower.json references unbuilt src entry point (#342, @justmatt) Fix: revert \"handle regex special characters\" (@tootallnate) Feature: configurable util.inspect()`options for NodeJS (#327, @tootallnate) Feature: %O`(big O) pretty-prints objects (#322, @tootallnate) Improvement: allow colors in workers (#335, @botverse) Improvement: use same color for same namespace. (#338, @lchenay) 2.3.3 / 2016-11-09 Fix: Catch JSON.stringify() errors (#195, Jovan Alleyne) Fix: Returning localStorage saved values (#331, Levi Thomason) Improvement: Don't create an empty object when no process (Nathan Rajlich) 2.3.2 / 2016-11-09 Fix: be super-safe in index.js as well (@TooTallNate) Fix: should check whether process exists (Tom Newby) 2.3.1 / 2016-11-09 Fix: Added electron compatibility (#324, @paulcbetts) Improvement: Added performance optimizations (@tootallnate) Readme: Corrected PowerShell environment variable example (#252, @gimre) Misc: Removed yarn lock file from source control (#321, @fengmk2) 2.3.0 / 2016-11-07 Fix: Consistent placement of ms diff at end of output (#215, @gorangajic) Fix: Escaping of regex special characters in namespace strings (#250, @zacronos) Fix: Fixed bug causing crash on react-native (#282, @vkarpov15) Feature: Enabled ES6+ compatible import via default export (#212 @bucaran) Feature: Added %O formatter to reflect Chrome's console.log capability (#279, @oncletom) Package: Update \"ms\" to 0.7.2 (#315, @DevSide) Package: removed superfluous version property from bower.json (#207 @kkirsche) Readme: fix USE_COLORS to DEBUG_COLORS Readme: Doc fixes for format string sugar (#269, @mlucool) Readme: Updated docs for DEBUG_FD and DEBUG_COLORS environment variables (#232, @mattlyons0) Readme: doc fixes for PowerShell (#271 #243, @exoticknight @unreadable) Readme: better docs for browser support (#224, @matthewmueller) Tooling: Added yarn integration for development (#317, @thebigredgeek) Misc: Renamed History.md to CHANGELOG.md (@thebigredgeek) Misc: Added license file (#226 #274, @CantemoInternal @sdaitzman) Misc: Updated contributors (@thebigredgeek) 2.2.0 / 2015-05-09 package: update \"ms\" to v0.7.1 (#202, @dougwilson) README: add logging to file example (#193, @DanielOchoa) README: fixed a typo (#191, @amir-s) browser: expose storage (#190, @stephenmathieson) Makefile: add a distclean target (#189, @stephenmathieson) 2.1.3 / 2015-03-13 Updated stdout/stderr example (#186) Updated example/stdout.js to match debug current behaviour Renamed example/stderr.js to stdout.js Update Readme.md (#184) replace high intensity foreground color for bold (#182, #183) 2.1.2 / 2015-03-01 dist: recompile update \"ms\" to v0.7.0 package: update \"browserify\" to v9.0.3 component: fix \"ms.js\" repo location changed bower package name updated documentation about using debug in a browser fix: security error on safari (#167, #168, @yields) 2.1.1 / 2014-12-29 browser: use typeof to check for console existence browser: check for console.log truthiness (fix IE 8/9) browser: add support for Chrome apps Readme: added Windows usage remarks Add bower.json to properly support bower install 2.1.0 / 2014-10-15 node: implement DEBUG_FD env variable support package: update \"browserify\" to v6.1.0 package: add \"license\" field to package.json (#135, @panuhorsmalahti) 2.0.0 / 2014-09-01 package: update \"browserify\" to v5.11.0 node: use stderr rather than stdout for logging (#29, @stephenmathieson) 1.0.4 / 2014-07-15 dist: recompile example: remove console.info() log usage example: add \"Content-Type\" UTF-8 header to browser example browser: place %c marker after the space character browser: reset the \"content\" color via color: inherit browser: add colors support for Firefox >= v31 debug: prefer an instance log() function over the global one (#119) Readme: update documentation about styled console logs for FF v31 (#116, @wryk) 1.0.3 / 2014-07-09 Add support for multiple wildcards in namespaces (#122, @seegno) browser: fix lint 1.0.2 / 2014-06-10 browser: update color palette (#113, @gscottolson) common: make console logging function configurable (#108, @timoxley) node: fix %o colors on old node <= 0.8.x Makefile: find node path using shell/which (#109, @timoxley) 1.0.1 / 2014-06-06 browser: use removeItem() to clear localStorage browser, node: don't set DEBUG if namespaces is undefined (#107, @leedm777) package: add \"contributors\" section node: fix comment typo README: list authors 1.0.0 / 2014-06-04 make ms diff be global, not be scope debug: ignore empty strings in enable() node: make DEBUG_COLORS able to disable coloring *: export the colors array npmignore: don't publish the dist dir Makefile: refactor to use browserify package: add \"browserify\" as a dev dependency Readme: add Web Inspector Colors section node: reset terminal color for the debug content node: map \"%o\" to util.inspect() browser: map \"%j\" to JSON.stringify() debug: add custom \"formatters\" debug: use \"ms\" module for humanizing the diff Readme: add \"bash\" syntax highlighting browser: add Firebug color support browser: add colors for WebKit browsers node: apply log to console rewrite: abstract common logic for Node & browsers add .jshintrc file 0.8.1 / 2014-04-14 package: re-add the \"component\" section 0.8.0 / 2014-03-30 add enable() method for nodejs. Closes #27 change from stderr to stdout remove unnecessary index.js file 0.7.4 / 2013-11-13 remove \"browserify\" key from package.json (fixes something in browserify) 0.7.3 / 2013-10-30 fix: catch localStorage security error when cookies are blocked (Chrome) add debug(err) support. Closes #46 add .browser prop to package.json. Closes #42 0.7.2 / 2013-02-06 fix package.json fix: Mobile Safari (private mode) is broken with debug fix: Use unicode to send escape character to shell instead of octal to work with strict mode javascript 0.7.1 / 2013-02-05 add repository URL to package.json add DEBUG_COLORED to force colored output add browserify support fix component. Closes #24 0.7.0 / 2012-05-04 Added .component to package.json Added debug.component.js build 0.6.0 / 2012-03-16 Added support for \"-\" prefix in DEBUG [Vinay Pulim] Added .enabled flag to the node version [TooTallNate] 0.5.0 / 2012-02-02 Added: humanize diffs. Closes #8 Added debug.disable() to the CS variant Removed padding. Closes #10 Fixed: persist client-side variant again. Closes #9 0.4.0 / 2012-02-01 Added browser variant support for older browsers [TooTallNate] Added debug.enable('project:*') to browser variant [TooTallNate] Added padding to diff (moved it to the right) 0.3.0 / 2012-01-26 Added millisecond diff when isatty, otherwise UTC string 0.2.0 / 2012-01-22 Added wildcard support 0.1.0 / 2011-12-02 Added: remove colors unless stderr isatty [TooTallNate] 0.0.1 / 2010-01-03 Initial release"
  },
  "src/frontend/app-client/node_modules/body-parser/node_modules/debug/README.html": {
    "href": "src/frontend/app-client/node_modules/body-parser/node_modules/debug/README.html",
    "title": "debug",
    "summary": "debug A tiny node.js debugging utility modelled after node core's debugging technique. Discussion around the V3 API is under way here Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %s', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var debug = require('debug')('worker'); setInterval(function(){ debug('doing some work'); }, 1000); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows note On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Note that PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Then, run the program to be debugged as usual. Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toUTCString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); Web Inspector Colors Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Colored output looks something like: Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2016 TJ Holowaychuk <tj@vision-media.ca&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/body-parser/node_modules/ms/license.html": {
    "href": "src/frontend/app-client/node_modules/body-parser/node_modules/ms/license.html",
    "title": "",
    "summary": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/body-parser/node_modules/ms/readme.html": {
    "href": "src/frontend/app-client/node_modules/body-parser/node_modules/ms/readme.html",
    "title": "ms",
    "summary": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 Convert from milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(ms('10 hours')) // \"10h\" Time format written-out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in node and in the browser. If a number is supplied to ms, a string with a unit is returned. If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100'). If you pass a string with a number and a valid unit, the number of equivalent ms is returned. Caught a bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, node will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "src/frontend/app-client/node_modules/body-parser/README.html": {
    "href": "src/frontend/app-client/node_modules/body-parser/README.html",
    "title": "body-parser",
    "summary": "body-parser Node.js body parsing middleware. Parse incoming request bodies in a middleware before your handlers, available under the req.body property. Note As req.body's shape is based on user-controlled input, all properties and values in this object are untrusted and should be validated before trusting. For example, req.body.foo.toString() may fail in multiple ways, for example the foo property may not be there or may not be a string, and toString may not be a function and instead a string or other user input. Learn about the anatomy of an HTTP transaction in Node.js. This does not handle multipart bodies, due to their complex and typically large nature. For multipart bodies, you may be interested in the following modules: busboy and connect-busboy multiparty and connect-multiparty formidable multer This module provides the following parsers: JSON body parser Raw body parser Text body parser URL-encoded form body parser Other body parsers you might be interested in: body co-body Installation $ npm install body-parser API var bodyParser = require('body-parser') The bodyParser object exposes various factories to create middlewares. All middlewares will populate the req.body property with the parsed body when the Content-Type request header matches the type option, or an empty object ({}) if there was no body to parse, the Content-Type was not matched, or an error occurred. The various errors returned by this module are described in the errors section. bodyParser.json([options]) Returns middleware that only parses json and only looks at requests where the Content-Type header matches the type option. This parser accepts any Unicode encoding of the body and supports automatic inflation of gzip and deflate encodings. A new body object containing the parsed data is populated on the request object after the middleware (i.e. req.body). Options The json function takes an optional options object that may contain any of the following keys: inflate When set to true, then deflated (compressed) bodies will be inflated; when false, deflated bodies are rejected. Defaults to true. limit Controls the maximum request body size. If this is a number, then the value specifies the number of bytes; if it is a string, the value is passed to the bytes library for parsing. Defaults to '100kb'. reviver The reviver option is passed directly to JSON.parse as the second argument. You can find more information on this argument in the MDN documentation about JSON.parse. strict When set to true, will only accept arrays and objects; when false will accept anything JSON.parse accepts. Defaults to true. type The type option is used to determine what media type the middleware will parse. This option can be a string, array of strings, or a function. If not a function, type option is passed directly to the type-is library and this can be an extension name (like json), a mime type (like application/json), or a mime type with a wildcard (like */* or */json). If a function, the type option is called as fn(req) and the request is parsed if it returns a truthy value. Defaults to application/json. verify The verify option, if supplied, is called as verify(req, res, buf, encoding), where buf is a Buffer of the raw request body and encoding is the encoding of the request. The parsing can be aborted by throwing an error. bodyParser.raw([options]) Returns middleware that parses all bodies as a Buffer and only looks at requests where the Content-Type header matches the type option. This parser supports automatic inflation of gzip and deflate encodings. A new body object containing the parsed data is populated on the request object after the middleware (i.e. req.body). This will be a Buffer object of the body. Options The raw function takes an optional options object that may contain any of the following keys: inflate When set to true, then deflated (compressed) bodies will be inflated; when false, deflated bodies are rejected. Defaults to true. limit Controls the maximum request body size. If this is a number, then the value specifies the number of bytes; if it is a string, the value is passed to the bytes library for parsing. Defaults to '100kb'. type The type option is used to determine what media type the middleware will parse. This option can be a string, array of strings, or a function. If not a function, type option is passed directly to the type-is library and this can be an extension name (like bin), a mime type (like application/octet-stream), or a mime type with a wildcard (like */* or application/*). If a function, the type option is called as fn(req) and the request is parsed if it returns a truthy value. Defaults to application/octet-stream. verify The verify option, if supplied, is called as verify(req, res, buf, encoding), where buf is a Buffer of the raw request body and encoding is the encoding of the request. The parsing can be aborted by throwing an error. bodyParser.text([options]) Returns middleware that parses all bodies as a string and only looks at requests where the Content-Type header matches the type option. This parser supports automatic inflation of gzip and deflate encodings. A new body string containing the parsed data is populated on the request object after the middleware (i.e. req.body). This will be a string of the body. Options The text function takes an optional options object that may contain any of the following keys: defaultCharset Specify the default character set for the text content if the charset is not specified in the Content-Type header of the request. Defaults to utf-8. inflate When set to true, then deflated (compressed) bodies will be inflated; when false, deflated bodies are rejected. Defaults to true. limit Controls the maximum request body size. If this is a number, then the value specifies the number of bytes; if it is a string, the value is passed to the bytes library for parsing. Defaults to '100kb'. type The type option is used to determine what media type the middleware will parse. This option can be a string, array of strings, or a function. If not a function, type option is passed directly to the type-is library and this can be an extension name (like txt), a mime type (like text/plain), or a mime type with a wildcard (like */* or text/*). If a function, the type option is called as fn(req) and the request is parsed if it returns a truthy value. Defaults to text/plain. verify The verify option, if supplied, is called as verify(req, res, buf, encoding), where buf is a Buffer of the raw request body and encoding is the encoding of the request. The parsing can be aborted by throwing an error. bodyParser.urlencoded([options]) Returns middleware that only parses urlencoded bodies and only looks at requests where the Content-Type header matches the type option. This parser accepts only UTF-8 encoding of the body and supports automatic inflation of gzip and deflate encodings. A new body object containing the parsed data is populated on the request object after the middleware (i.e. req.body). This object will contain key-value pairs, where the value can be a string or array (when extended is false), or any type (when extended is true). Options The urlencoded function takes an optional options object that may contain any of the following keys: extended The extended option allows to choose between parsing the URL-encoded data with the querystring library (when false) or the qs library (when true). The \"extended\" syntax allows for rich objects and arrays to be encoded into the URL-encoded format, allowing for a JSON-like experience with URL-encoded. For more information, please see the qs library. Defaults to true, but using the default has been deprecated. Please research into the difference between qs and querystring and choose the appropriate setting. inflate When set to true, then deflated (compressed) bodies will be inflated; when false, deflated bodies are rejected. Defaults to true. limit Controls the maximum request body size. If this is a number, then the value specifies the number of bytes; if it is a string, the value is passed to the bytes library for parsing. Defaults to '100kb'. parameterLimit The parameterLimit option controls the maximum number of parameters that are allowed in the URL-encoded data. If a request contains more parameters than this value, a 413 will be returned to the client. Defaults to 1000. type The type option is used to determine what media type the middleware will parse. This option can be a string, array of strings, or a function. If not a function, type option is passed directly to the type-is library and this can be an extension name (like urlencoded), a mime type (like application/x-www-form-urlencoded), or a mime type with a wildcard (like */x-www-form-urlencoded). If a function, the type option is called as fn(req) and the request is parsed if it returns a truthy value. Defaults to application/x-www-form-urlencoded. verify The verify option, if supplied, is called as verify(req, res, buf, encoding), where buf is a Buffer of the raw request body and encoding is the encoding of the request. The parsing can be aborted by throwing an error. depth The depth option is used to configure the maximum depth of the qs library when extended is true. This allows you to limit the amount of keys that are parsed and can be useful to prevent certain types of abuse. Defaults to 32. It is recommended to keep this value as low as possible. Errors The middlewares provided by this module create errors using the http-errors module. The errors will typically have a status/statusCode property that contains the suggested HTTP response code, an expose property to determine if the message property should be displayed to the client, a type property to determine the type of error without matching against the message, and a body property containing the read body, if available. The following are the common errors created, though any error can come through for various reasons. content encoding unsupported This error will occur when the request had a Content-Encoding header that contained an encoding but the \"inflation\" option was set to false. The status property is set to 415, the type property is set to 'encoding.unsupported', and the charset property will be set to the encoding that is unsupported. entity parse failed This error will occur when the request contained an entity that could not be parsed by the middleware. The status property is set to 400, the type property is set to 'entity.parse.failed', and the body property is set to the entity value that failed parsing. entity verify failed This error will occur when the request contained an entity that could not be failed verification by the defined verify option. The status property is set to 403, the type property is set to 'entity.verify.failed', and the body property is set to the entity value that failed verification. request aborted This error will occur when the request is aborted by the client before reading the body has finished. The received property will be set to the number of bytes received before the request was aborted and the expected property is set to the number of expected bytes. The status property is set to 400 and type property is set to 'request.aborted'. request entity too large This error will occur when the request body's size is larger than the \"limit\" option. The limit property will be set to the byte limit and the length property will be set to the request body's length. The status property is set to 413 and the type property is set to 'entity.too.large'. request size did not match content length This error will occur when the request's length did not match the length from the Content-Length header. This typically occurs when the request is malformed, typically when the Content-Length header was calculated based on characters instead of bytes. The status property is set to 400 and the type property is set to 'request.size.invalid'. stream encoding should not be set This error will occur when something called the req.setEncoding method prior to this middleware. This module operates directly on bytes only and you cannot call req.setEncoding when using this module. The status property is set to 500 and the type property is set to 'stream.encoding.set'. stream is not readable This error will occur when the request is no longer readable when this middleware attempts to read it. This typically means something other than a middleware from this module read the request body already and the middleware was also configured to read the same request. The status property is set to 500 and the type property is set to 'stream.not.readable'. too many parameters This error will occur when the content of the request exceeds the configured parameterLimit for the urlencoded parser. The status property is set to 413 and the type property is set to 'parameters.too.many'. unsupported charset \"BOGUS\" This error will occur when the request had a charset parameter in the Content-Type header, but the iconv-lite module does not support it OR the parser does not support it. The charset is contained in the message as well as in the charset property. The status property is set to 415, the type property is set to 'charset.unsupported', and the charset property is set to the charset that is unsupported. unsupported content encoding \"bogus\" This error will occur when the request had a Content-Encoding header that contained an unsupported encoding. The encoding is contained in the message as well as in the encoding property. The status property is set to 415, the type property is set to 'encoding.unsupported', and the encoding property is set to the encoding that is unsupported. The input exceeded the depth This error occurs when using bodyParser.urlencoded with the extended property set to true and the input exceeds the configured depth option. The status property is set to 400. It is recommended to review the depth option and evaluate if it requires a higher value. When the depth option is set to 32 (default value), the error will not be thrown. Examples Express/Connect top-level generic This example demonstrates adding a generic JSON and URL-encoded parser as a top-level middleware, which will parse the bodies of all incoming requests. This is the simplest setup. var express = require('express') var bodyParser = require('body-parser') var app = express() // parse application/x-www-form-urlencoded app.use(bodyParser.urlencoded({ extended: false })) // parse application/json app.use(bodyParser.json()) app.use(function (req, res) { res.setHeader('Content-Type', 'text/plain') res.write('you posted:\\n') res.end(JSON.stringify(req.body, null, 2)) }) Express route-specific This example demonstrates adding body parsers specifically to the routes that need them. In general, this is the most recommended way to use body-parser with Express. var express = require('express') var bodyParser = require('body-parser') var app = express() // create application/json parser var jsonParser = bodyParser.json() // create application/x-www-form-urlencoded parser var urlencodedParser = bodyParser.urlencoded({ extended: false }) // POST /login gets urlencoded bodies app.post('/login', urlencodedParser, function (req, res) { res.send('welcome, ' + req.body.username) }) // POST /api/users gets JSON bodies app.post('/api/users', jsonParser, function (req, res) { // create user in req.body }) Change accepted type for parsers All the parsers accept a type option which allows you to change the Content-Type that the middleware will parse. var express = require('express') var bodyParser = require('body-parser') var app = express() // parse various different custom JSON types as JSON app.use(bodyParser.json({ type: 'application/*+json' })) // parse some custom thing into a Buffer app.use(bodyParser.raw({ type: 'application/vnd.custom-type' })) // parse an HTML body into a string app.use(bodyParser.text({ type: 'text/html' })) License MIT"
  },
  "src/frontend/app-client/node_modules/body-parser/SECURITY.html": {
    "href": "src/frontend/app-client/node_modules/body-parser/SECURITY.html",
    "title": "Security Policies and Procedures",
    "summary": "Security Policies and Procedures Reporting a Bug The Express team and community take all security bugs seriously. Thank you for improving the security of Express. We appreciate your efforts and responsible disclosure and will make every effort to acknowledge your contributions. Report security bugs by emailing the current owner(s) of body-parser. This information can be found in the npm registry using the command npm owner ls body-parser. If unsure or unable to get the information from the above, open an issue in the project issue tracker asking for the current contact information. To ensure the timely response to your report, please ensure that the entirety of the report is contained within the email body and not solely behind a web link or an attachment. At least one owner will acknowledge your email within 48 hours, and will send a more detailed response within 48 hours indicating the next steps in handling your report. After the initial reply to your report, the owners will endeavor to keep you informed of the progress towards a fix and full announcement, and may ask for additional information or guidance."
  },
  "src/frontend/app-client/node_modules/brace-expansion/README.html": {
    "href": "src/frontend/app-client/node_modules/brace-expansion/README.html",
    "title": "brace-expansion",
    "summary": "brace-expansion Brace expansion, as known from sh/bash, in JavaScript. Example var expand = require('brace-expansion'); expand('file-{a,b,c}.jpg') // => ['file-a.jpg', 'file-b.jpg', 'file-c.jpg'] expand('-v{,,}') // => ['-v', '-v', '-v'] expand('file{0..2}.jpg') // => ['file0.jpg', 'file1.jpg', 'file2.jpg'] expand('file-{a..c}.jpg') // => ['file-a.jpg', 'file-b.jpg', 'file-c.jpg'] expand('file{2..0}.jpg') // => ['file2.jpg', 'file1.jpg', 'file0.jpg'] expand('file{0..4..2}.jpg') // => ['file0.jpg', 'file2.jpg', 'file4.jpg'] expand('file-{a..e..2}.jpg') // => ['file-a.jpg', 'file-c.jpg', 'file-e.jpg'] expand('file{00..10..5}.jpg') // => ['file00.jpg', 'file05.jpg', 'file10.jpg'] expand('{{A..C},{a..c}}') // => ['A', 'B', 'C', 'a', 'b', 'c'] expand('ppp{,config,oe{,conf}}') // => ['ppp', 'pppconfig', 'pppoe', 'pppoeconf'] API var expand = require('brace-expansion'); var expanded = expand(str) Return an array of all possible and valid expansions of str. If none are found, [str] is returned. Valid expansions are: /^(.*,)+(.+)?$/ // {a,b,...} A comma separated list of options, like {a,b} or {a,{b,c}} or {,a,}. /^-?\\d+\\.\\.-?\\d+(\\.\\.-?\\d+)?$/ // {x..y[..incr]} A numeric sequence from x to y inclusive, with optional increment. If x or y start with a leading 0, all the numbers will be padded to have equal length. Negative numbers and backwards iteration work too. /^-?\\d+\\.\\.-?\\d+(\\.\\.-?\\d+)?$/ // {x..y[..incr]} An alphabetic sequence from x to y inclusive, with optional increment. x and y must be exactly one character, and if given, incr must be a number. For compatibility reasons, the string ${ is not eligible for brace expansion. Installation With npm do: npm install brace-expansion Contributors Julian Gruber Isaac Z. Schlueter Sponsors This module is proudly supported by my Sponsors! Do you want to support modules like this to improve their quality, stability and weigh in on new features? Then please consider donating to my Patreon. Not sure how much of my modules you're using? Try feross/thanks! Security contact information To report a security vulnerability, please use the Tidelift security contact. Tidelift will coordinate the fix and disclosure. License (MIT) Copyright (c) 2013 Julian Gruber <julian@juliangruber.com&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/browserslist/README.html": {
    "href": "src/frontend/app-client/node_modules/browserslist/README.html",
    "title": "Browserslist",
    "summary": "Browserslist The config to share target browsers and Node.js versions between different front-end tools. It is used in: Autoprefixer Babel postcss-preset-env eslint-plugin-compat stylelint-no-unsupported-browser-features postcss-normalize obsolete-webpack-plugin All tools will find target browsers automatically, when you add the following to package.json: \"browserslist\": [ \"defaults and fully supports es6-module\", \"maintained node versions\" ] Or in .browserslistrc config: # Browsers that we support defaults and fully supports es6-module maintained node versions Developers set their version lists using queries like last 2 versions to be free from updating versions manually. Browserslist will use caniuse-lite with Can I Use data for this queries. You can check how config works at our playground: browsersl.ist Docs Read full docs here."
  },
  "src/frontend/app-client/node_modules/buffer-from/readme.html": {
    "href": "src/frontend/app-client/node_modules/buffer-from/readme.html",
    "title": "Buffer From",
    "summary": "Buffer From A ponyfill for Buffer.from, uses native implementation if available. Installation npm install --save buffer-from Usage const bufferFrom = require('buffer-from') console.log(bufferFrom([1, 2, 3, 4])) //=> <Buffer 01 02 03 04> const arr = new Uint8Array([1, 2, 3, 4]) console.log(bufferFrom(arr.buffer, 1, 2)) //=> <Buffer 02 03> console.log(bufferFrom('test', 'utf8')) //=> <Buffer 74 65 73 74> const buf = bufferFrom('test') console.log(bufferFrom(buf)) //=> <Buffer 74 65 73 74> API bufferFrom(array) array <Array> Allocates a new Buffer using an array of octets. bufferFrom(arrayBuffer[, byteOffset[, length]]) arrayBuffer <ArrayBuffer> The .buffer property of a TypedArray or ArrayBuffer byteOffset <Integer> Where to start copying from arrayBuffer. Default: 0 length <Integer> How many bytes to copy from arrayBuffer. Default: arrayBuffer.length - byteOffset When passed a reference to the .buffer property of a TypedArray instance, the newly created Buffer will share the same allocated memory as the TypedArray. The optional byteOffset and length arguments specify a memory range within the arrayBuffer that will be shared by the Buffer. bufferFrom(buffer) buffer <Buffer> An existing Buffer to copy data from Copies the passed buffer data onto a new Buffer instance. bufferFrom(string[, encoding]) string <String> A string to encode. encoding <String> The encoding of string. Default: 'utf8' Creates a new Buffer containing the given JavaScript string string. If provided, the encoding parameter identifies the character encoding of string. See also buffer-alloc A ponyfill for Buffer.alloc buffer-alloc-unsafe A ponyfill for Buffer.allocUnsafe"
  },
  "src/frontend/app-client/node_modules/bytes/History.html": {
    "href": "src/frontend/app-client/node_modules/bytes/History.html",
    "title": "3.1.2 / 2022-01-27",
    "summary": "3.1.2 / 2022-01-27 Fix return value for un-parsable strings 3.1.1 / 2021-11-15 Fix \"thousandsSeparator\" incorrecting formatting fractional part 3.1.0 / 2019-01-22 Add petabyte (pb) support 3.0.0 / 2017-08-31 Change \"kB\" to \"KB\" in format output Remove support for Node.js 0.6 Remove support for ComponentJS 2.5.0 / 2017-03-24 Add option \"unit\" 2.4.0 / 2016-06-01 Add option \"unitSeparator\" 2.3.0 / 2016-02-15 Drop partial bytes on all parsed units Fix non-finite numbers to .format to return null Fix parsing byte string that looks like hex perf: hoist regular expressions 2.2.0 / 2015-11-13 add option \"decimalPlaces\" add option \"fixedDecimals\" 2.1.0 / 2015-05-21 add .format export add .parse export 2.0.2 / 2015-05-20 remove map recreation remove unnecessary object construction 2.0.1 / 2015-05-07 fix browserify require remove node.extend dependency 2.0.0 / 2015-04-12 add option \"case\" add option \"thousandsSeparator\" return \"null\" on invalid parse input support proper round-trip: bytes(bytes(num)) === num units no longer case sensitive when parsing 1.0.0 / 2014-05-05 add negative support. fixes #6 0.3.0 / 2014-03-19 added terabyte support 0.2.1 / 2013-04-01 add .component 0.2.0 / 2012-10-28 bytes(200).should.eql('200b') 0.1.0 / 2012-07-04 add bytes to string conversion [yields]"
  },
  "src/frontend/app-client/node_modules/bytes/Readme.html": {
    "href": "src/frontend/app-client/node_modules/bytes/Readme.html",
    "title": "Bytes utility",
    "summary": "Bytes utility Utility to parse a string bytes (ex: 1TB) to bytes (1099511627776) and vice-versa. Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install bytes Usage var bytes = require('bytes'); bytes(number｜string value, [options]): number｜string｜null Default export function. Delegates to either bytes.format or bytes.parse based on the type of value. Arguments Name Type Description value number｜string Number value to format or string value to parse options Object Conversion options for format Returns Name Type Description results string｜number｜null Return null upon error. Numeric value in bytes, or string value otherwise. Example bytes(1024); // output: '1KB' bytes('1KB'); // output: 1024 bytes.format(number value, [options]): string｜null Format the given value in bytes into a string. If the value is negative, it is kept as such. If it is a float, it is rounded. Arguments Name Type Description value number Value in bytes options Object Conversion options Options Property Type Description decimalPlaces number｜null Maximum number of decimal places to include in output. Default value to 2. fixedDecimals boolean｜null Whether to always display the maximum number of decimal places. Default value to false thousandsSeparator string｜null Example of values: ' ', ',' and '.'... Default value to ''. unit string｜null The unit in which the result will be returned (B/KB/MB/GB/TB). Default value to '' (which means auto detect). unitSeparator string｜null Separator to use between number and unit. Default value to ''. Returns Name Type Description results string｜null Return null upon error. String value otherwise. Example bytes.format(1024); // output: '1KB' bytes.format(1000); // output: '1000B' bytes.format(1000, {thousandsSeparator: ' '}); // output: '1 000B' bytes.format(1024 * 1.7, {decimalPlaces: 0}); // output: '2KB' bytes.format(1024, {unitSeparator: ' '}); // output: '1 KB' bytes.parse(string｜number value): number｜null Parse the string value into an integer in bytes. If no unit is given, or value is a number, it is assumed the value is in bytes. Supported units and abbreviations are as follows and are case-insensitive: b for bytes kb for kilobytes mb for megabytes gb for gigabytes tb for terabytes pb for petabytes The units are in powers of two, not ten. This means 1kb = 1024b according to this parser. Arguments Name Type Description value string｜number String to parse, or number in bytes. Returns Name Type Description results number｜null Return null upon error. Value in bytes otherwise. Example bytes.parse('1KB'); // output: 1024 bytes.parse('1024'); // output: 1024 bytes.parse(1024); // output: 1024 License MIT"
  },
  "src/frontend/app-client/node_modules/cac/README.html": {
    "href": "src/frontend/app-client/node_modules/cac/README.html",
    "title": "",
    "summary": "Introduction Command And Conquer is a JavaScript library for building CLI apps. Features Super light-weight: No dependency, just a single file. Easy to learn. There're only 4 APIs you need to learn for building simple CLIs: cli.option cli.version cli.help cli.parse. Yet so powerful. Enable features like default command, git-like subcommands, validation for required arguments and options, variadic arguments, dot-nested options, automated help message generation and so on. Developer friendly. Written in TypeScript. Table of Contents Install Usage Simple Parsing Display Help Message and Version Command-specific Options Dash in option names Brackets Negated Options Variadic Arguments Dot-nested Options Default Command Supply an array as option value Error Handling With TypeScript With Deno Projects Using CAC References CLI Instance cac(name?) cli.command(name, description, config?) cli.option(name, description, config?) cli.parse(argv?) cli.version(version, customFlags?) cli.help(callback?) cli.outputHelp() cli.usage(text) Command Instance command.option() command.action(callback) command.alias(name) command.allowUnknownOptions() command.example(example) command.usage(text) Events FAQ How is the name written and pronounced? Why not use Commander.js? Project Stats Contributing Author Install yarn add cac Usage Simple Parsing Use CAC as simple argument parser: // examples/basic-usage.js const cli = require('cac')() cli.option('--type <type>', 'Choose a project type', { default: 'node', }) const parsed = cli.parse() console.log(JSON.stringify(parsed, null, 2)) Display Help Message and Version // examples/help.js const cli = require('cac')() cli.option('--type [type]', 'Choose a project type', { default: 'node', }) cli.option('--name <name>', 'Provide your name') cli.command('lint [...files]', 'Lint files').action((files, options) => { console.log(files, options) }) // Display help message when `-h` or `--help` appears cli.help() // Display version number when `-v` or `--version` appears // It's also used in help message cli.version('0.0.0') cli.parse() Command-specific Options You can attach options to a command. const cli = require('cac')() cli .command('rm <dir>', 'Remove a dir') .option('-r, --recursive', 'Remove recursively') .action((dir, options) => { console.log('remove ' + dir + (options.recursive ? ' recursively' : '')) }) cli.help() cli.parse() A command's options are validated when the command is used. Any unknown options will be reported as an error. However, if an action-based command does not define an action, then the options are not validated. If you really want to use unknown options, use command.allowUnknownOptions. Dash in option names Options in kebab-case should be referenced in camelCase in your code: cli .command('dev', 'Start dev server') .option('--clear-screen', 'Clear screen') .action((options) => { console.log(options.clearScreen) }) In fact --clear-screen and --clearScreen are both mapped to options.clearScreen. Brackets When using brackets in command name, angled brackets indicate required command arguments, while square bracket indicate optional arguments. When using brackets in option name, angled brackets indicate that a string / number value is required, while square bracket indicate that the value can also be true. const cli = require('cac')() cli .command('deploy <folder>', 'Deploy a folder to AWS') .option('--scale [level]', 'Scaling level') .action((folder, options) => { // ... }) cli .command('build [project]', 'Build a project') .option('--out <dir>', 'Output directory') .action((folder, options) => { // ... }) cli.parse() Negated Options To allow an option whose value is false, you need to manually specify a negated option: cli .command('build [project]', 'Build a project') .option('--no-config', 'Disable config file') .option('--config <path>', 'Use a custom config file') This will let CAC set the default value of config to true, and you can use --no-config flag to set it to false. Variadic Arguments The last argument of a command can be variadic, and only the last argument. To make an argument variadic you have to add ... to the start of argument name, just like the rest operator in JavaScript. Here is an example: const cli = require('cac')() cli .command('build <entry> [...otherFiles]', 'Build your app') .option('--foo', 'Foo option') .action((entry, otherFiles, options) => { console.log(entry) console.log(otherFiles) console.log(options) }) cli.help() cli.parse() Dot-nested Options Dot-nested options will be merged into a single option. const cli = require('cac')() cli .command('build', 'desc') .option('--env <env>', 'Set envs') .example('--env.API_SECRET xxx') .action((options) => { console.log(options) }) cli.help() cli.parse() Default Command Register a command that will be used when no other command is matched. const cli = require('cac')() cli // Simply omit the command name, just brackets .command('[...files]', 'Build files') .option('--minimize', 'Minimize output') .action((files, options) => { console.log(files) console.log(options.minimize) }) cli.parse() Supply an array as option value node cli.js --include project-a # The parsed options will be: # { include: 'project-a' } node cli.js --include project-a --include project-b # The parsed options will be: # { include: ['project-a', 'project-b'] } Error Handling To handle command errors globally: try { // Parse CLI args without running the command cli.parse(process.argv, { run: false }) // Run the command yourself // You only need `await` when your command action returns a Promise await cli.runMatchedCommand() } catch (error) { // Handle error here.. // e.g. // console.error(error.stack) // process.exit(1) } With TypeScript First you need @types/node to be installed as a dev dependency in your project: yarn add @types/node --dev Then everything just works out of the box: const { cac } = require('cac') // OR ES modules import { cac } from 'cac' With Deno import { cac } from 'https://unpkg.com/cac/mod.ts' const cli = cac('my-program') Projects Using CAC Projects that use CAC: VuePress: \uD83D\uDCDD Minimalistic Vue-powered static site generator. SAO: ⚔️ Futuristic scaffolding tool. DocPad: \uD83C\uDFF9 Powerful Static Site Generator. Poi: ⚡️ Delightful web development. bili: \uD83E\uDD42 Schweizer Armeemesser for bundling JavaScript libraries. Lad: \uD83D\uDC66 Lad scaffolds a Koa webapp and API framework for Node.js. Lass: \uD83D\uDC81\uD83C\uDFFB Scaffold a modern package boilerplate for Node.js. Foy: \uD83C\uDFD7 A lightweight and modern task runner and build tool for general purpose. Vuese: \uD83E\uDD17 One-stop solution for vue component documentation. NUT: \uD83C\uDF30 A framework born for microfrontends Feel free to add yours here... References \uD83D\uDC81 Check out the generated docs from source code if you want a more in-depth API references. Below is a brief overview. CLI Instance CLI instance is created by invoking the cac function: const cac = require('cac') const cli = cac() cac(name?) Create a CLI instance, optionally specify the program name which will be used to display in help and version message. When not set we use the basename of argv[1]. cli.command(name, description, config?) Type: (name: string, description: string) => Command Create a command instance. The option also accepts a third argument config for additional command config: config.allowUnknownOptions: boolean Allow unknown options in this command. config.ignoreOptionDefaultValue: boolean Don't use the options's default value in parsed options, only display them in help message. cli.option(name, description, config?) Type: (name: string, description: string, config?: OptionConfig) => CLI Add a global option. The option also accepts a third argument config for additional option config: config.default: Default value for the option. config.type: any[] When set to [], the option value returns an array type. You can also use a conversion function such as [String], which will invoke the option value with String. cli.parse(argv?) Type: (argv = process.argv) => ParsedArgv interface ParsedArgv { args: string[] options: { [k: string]: any } } When this method is called, cli.rawArgs cli.args cli.options cli.matchedCommand will also be available. cli.version(version, customFlags?) Type: (version: string, customFlags = '-v, --version') => CLI Output version number when -v, --version flag appears. cli.help(callback?) Type: (callback?: HelpCallback) => CLI Output help message when -h, --help flag appears. Optional callback allows post-processing of help text before it is displayed: type HelpCallback = (sections: HelpSection[]) => void interface HelpSection { title?: string body: string } cli.outputHelp() Type: () => CLI Output help message. cli.usage(text) Type: (text: string) => CLI Add a global usage text. This is not used by sub-commands. Command Instance Command instance is created by invoking the cli.command method: const command = cli.command('build [...files]', 'Build given files') command.option() Basically the same as cli.option but this adds the option to specific command. command.action(callback) Type: (callback: ActionCallback) => Command Use a callback function as the command action when the command matches user inputs. type ActionCallback = ( // Parsed CLI args // The last arg will be an array if it's a variadic argument ...args: string | string[] | number | number[] // Parsed CLI options options: Options ) => any interface Options { [k: string]: any } command.alias(name) Type: (name: string) => Command Add an alias name to this command, the name here can't contain brackets. command.allowUnknownOptions() Type: () => Command Allow unknown options in this command, by default CAC will log an error when unknown options are used. command.example(example) Type: (example: CommandExample) => Command Add an example which will be displayed at the end of help message. type CommandExample = ((name: string) => string) | string command.usage(text) Type: (text: string) => Command Add a usage text for this command. Events Listen to commands: // Listen to the `foo` command cli.on('command:foo', () => { // Do something }) // Listen to the default command cli.on('command:!', () => { // Do something }) // Listen to unknown commands cli.on('command:*', () => { console.error('Invalid command: %s', cli.args.join(' ')) process.exit(1) }) FAQ How is the name written and pronounced? CAC, or cac, pronounced C-A-C. This project is dedicated to our lovely C.C. sama. Maybe CAC stands for C&C as well :P Why not use Commander.js? CAC is very similar to Commander.js, while the latter does not support dot nested options, i.e. something like --env.API_SECRET foo. Besides, you can't use unknown options in Commander.js either. And maybe more... Basically I made CAC to fulfill my own needs for building CLI apps like Poi, SAO and all my CLI apps. It's small, simple but powerful :P Project Stats Contributing Fork it! Create your feature branch: git checkout -b my-new-feature Commit your changes: git commit -am 'Add some feature' Push to the branch: git push origin my-new-feature Submit a pull request :D Author CAC © EGOIST, Released under the MIT License. Authored and maintained by egoist with help from contributors (list). Website · GitHub @egoist · Twitter @_egoistlily"
  },
  "src/frontend/app-client/node_modules/call-bind-apply-helpers/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/call-bind-apply-helpers/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.2 - 2025-02-12 Commits [types] improve inferred types e6f9586 [Dev Deps] update @arethetypeswrong/cli, @ljharb/tsconfig, @types/tape, es-value-fixtures, for-each, has-strict-mode, object-inspect e43d540 v1.0.1 - 2024-12-08 Commits [types] reflectApply: fix types 4efc396 [Fix] reflectApply: oops, Reflect is not a function 83cc739 [Dev Deps] update @arethetypeswrong/cli 80bd5d3 v1.0.0 - 2024-12-05 Commits Initial implementation, tests, readme 7879629 Initial commit 3f1dc16 npm init 081df04 Only apps should have lockfiles 5b9ca0f"
  },
  "src/frontend/app-client/node_modules/call-bind-apply-helpers/README.html": {
    "href": "src/frontend/app-client/node_modules/call-bind-apply-helpers/README.html",
    "title": "call-bind-apply-helpers",
    "summary": "call-bind-apply-helpers Helper functions around Function call/apply/bind, for use in call-bind. The only packages that should likely ever use this package directly are call-bind and get-intrinsic. Please use call-bind unless you have a very good reason not to. Getting started npm install --save call-bind-apply-helpers Usage/Examples const assert = require('assert'); const callBindBasic = require('call-bind-apply-helpers'); function f(a, b) { assert.equal(this, 1); assert.equal(a, 2); assert.equal(b, 3); assert.equal(arguments.length, 2); } const fBound = callBindBasic([f, 1]); delete Function.prototype.call; delete Function.prototype.bind; fBound(2, 3); Tests Clone the repo, npm install, and run npm test"
  },
  "src/frontend/app-client/node_modules/call-bound/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/call-bound/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.4 - 2025-03-03 Commits [types] improve types e648922 [Dev Deps] update @arethetypeswrong/cli, @ljharb/tsconfig, @types/tape, es-value-fixtures, for-each, has-strict-mode, object-inspect a42a5eb [Deps] update call-bind-apply-helpers, get-intrinsic f529eac v1.0.3 - 2024-12-15 Commits [Refactor] use call-bind-apply-helpers instead of call-bind 5e0b134 [Deps] update get-intrinsic 41fc967 [readme] fix example 79a0137 [meta] add sideEffects flag 08b07be v1.0.2 - 2024-12-10 Commits [Dev Deps] update @arethetypeswrong/cli, @ljharb/tsconfig, gopd e6a5ffe [Deps] update call-bind, get-intrinsic 2aeb5b5 [types] improve return type 1a0c9fe v1.0.1 - 2024-12-05 Commits Initial implementation, tests, readme, types 6d94121 Initial commit 0eae867 npm init 71b2479 Only apps should have lockfiles c3754a9 [actions] skip npm ls in node < 10 74275a5 [Dev Deps] add missing peer dep 1354de8"
  },
  "src/frontend/app-client/node_modules/call-bound/README.html": {
    "href": "src/frontend/app-client/node_modules/call-bound/README.html",
    "title": "call-bound",
    "summary": "call-bound Robust call-bound JavaScript intrinsics, using call-bind and get-intrinsic. Getting started npm install --save call-bound Usage/Examples const assert = require('assert'); const callBound = require('call-bound'); const slice = callBound('Array.prototype.slice'); delete Function.prototype.call; delete Function.prototype.bind; delete Array.prototype.slice; assert.deepEqual(slice([1, 2, 3, 4], 1, -1), [2, 3]); Tests Clone the repo, npm install, and run npm test"
  },
  "src/frontend/app-client/node_modules/callsites/readme.html": {
    "href": "src/frontend/app-client/node_modules/callsites/readme.html",
    "title": "callsites",
    "summary": "callsites Get callsites from the V8 stack trace API Install $ npm install callsites Usage const callsites = require('callsites'); function unicorn() { console.log(callsites()[0].getFileName()); //=> '/Users/sindresorhus/dev/callsites/test.js' } unicorn(); API Returns an array of callsite objects with the following methods: getThis: returns the value of this. getTypeName: returns the type of this as a string. This is the name of the function stored in the constructor field of this, if available, otherwise the object's [[Class]] internal property. getFunction: returns the current function. getFunctionName: returns the name of the current function, typically its name property. If a name property is not available an attempt will be made to try to infer a name from the function's context. getMethodName: returns the name of the property of this or one of its prototypes that holds the current function. getFileName: if this function was defined in a script returns the name of the script. getLineNumber: if this function was defined in a script returns the current line number. getColumnNumber: if this function was defined in a script returns the current column number getEvalOrigin: if this function was created using a call to eval returns a string representing the location where eval was called. isToplevel: is this a top-level invocation, that is, is this the global object? isEval: does this call take place in code defined by a call to eval? isNative: is this call in native V8 code? isConstructor: is this a constructor call? License MIT © Sindre Sorhus"
  },
  "src/frontend/app-client/node_modules/caniuse-lite/README.html": {
    "href": "src/frontend/app-client/node_modules/caniuse-lite/README.html",
    "title": "caniuse-lite",
    "summary": "caniuse-lite A smaller version of caniuse-db, with only the essentials! Docs Read full docs here."
  },
  "src/frontend/app-client/node_modules/chain-function/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/chain-function/LICENSE.html",
    "title": "",
    "summary": "The MIT License (MIT) Copyright (c) 2015 Jason Quense Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/chain-function/README.html": {
    "href": "src/frontend/app-client/node_modules/chain-function/README.html",
    "title": "chain-function",
    "summary": "chain-function chain a bunch of functions npm i chain-function function foo() { console.log('foo') } function baz() { console.log('bar') } var foobar = chain(foo, bar) foobar() // \"bar\" \"foo\" //handles empty values just fine foobar = chain(foo, null, bar, undefined) foobar() // \"bar\" \"foo\""
  },
  "src/frontend/app-client/node_modules/chalk/readme.html": {
    "href": "src/frontend/app-client/node_modules/chalk/readme.html",
    "title": "",
    "summary": "Terminal string styling done right Info Why not switch to a smaller coloring package? See yoctocolors for a smaller alternative Highlights Expressive API Highly performant No dependencies Ability to nest styles 256/Truecolor color support Auto-detects color support Doesn't extend String.prototype Clean and focused Actively maintained Used by ~115,000 packages as of July 4, 2024 Install npm install chalk IMPORTANT: Chalk 5 is ESM. If you want to use Chalk with TypeScript or a build tool, you will probably want to use Chalk 4 for now. Read more. Usage import chalk from 'chalk'; console.log(chalk.blue('Hello world!')); Chalk comes with an easy to use composable API where you just chain and nest the styles you want. import chalk from 'chalk'; const log = console.log; // Combine styled and normal strings log(chalk.blue('Hello') + ' World' + chalk.red('!')); // Compose multiple styles using the chainable API log(chalk.blue.bgRed.bold('Hello world!')); // Pass in multiple arguments log(chalk.blue('Hello', 'World!', 'Foo', 'bar', 'biz', 'baz')); // Nest styles log(chalk.red('Hello', chalk.underline.bgBlue('world') + '!')); // Nest styles of the same type even (color, underline, background) log(chalk.green( 'I am a green line ' + chalk.blue.underline.bold('with a blue substring') + ' that becomes green again!' )); // ES2015 template literal log(` CPU: ${chalk.red('90%')} RAM: ${chalk.green('40%')} DISK: ${chalk.yellow('70%')} `); // Use RGB colors in terminal emulators that support it. log(chalk.rgb(123, 45, 67).underline('Underlined reddish color')); log(chalk.hex('#DEADED').bold('Bold gray!')); Easily define your own themes: import chalk from 'chalk'; const error = chalk.bold.red; const warning = chalk.hex('#FFA500'); // Orange color console.log(error('Error!')); console.log(warning('Warning!')); Take advantage of console.log string substitution: import chalk from 'chalk'; const name = 'Sindre'; console.log(chalk.green('Hello %s'), name); //=> 'Hello Sindre' API chalk.<style>[.<style>...](string, [string...]) Example: chalk.red.bold.underline('Hello', 'world'); Chain styles and call the last one as a method with a string argument. Order doesn't matter, and later styles take precedent in case of a conflict. This simply means that chalk.red.yellow.green is equivalent to chalk.green. Multiple arguments will be separated by space. chalk.level Specifies the level of color support. Color support is automatically detected, but you can override it by setting the level property. You should however only do this in your own code as it applies globally to all Chalk consumers. If you need to change this in a reusable module, create a new instance: import {Chalk} from 'chalk'; const customChalk = new Chalk({level: 0}); Level Description 0 All colors disabled 1 Basic color support (16 colors) 2 256 color support 3 Truecolor support (16 million colors) supportsColor Detect whether the terminal supports color. Used internally and handled for you, but exposed for convenience. Can be overridden by the user with the flags --color and --no-color. For situations where using --color is not possible, use the environment variable FORCE_COLOR=1 (level 1), FORCE_COLOR=2 (level 2), or FORCE_COLOR=3 (level 3) to forcefully enable color, or FORCE_COLOR=0 to forcefully disable. The use of FORCE_COLOR overrides all other color support checks. Explicit 256/Truecolor mode can be enabled using the --color=256 and --color=16m flags, respectively. chalkStderr and supportsColorStderr chalkStderr contains a separate instance configured with color support detected for stderr stream instead of stdout. Override rules from supportsColor apply to this too. supportsColorStderr is exposed for convenience. modifierNames, foregroundColorNames, backgroundColorNames, and colorNames All supported style strings are exposed as an array of strings for convenience. colorNames is the combination of foregroundColorNames and backgroundColorNames. This can be useful if you wrap Chalk and need to validate input: import {modifierNames, foregroundColorNames} from 'chalk'; console.log(modifierNames.includes('bold')); //=> true console.log(foregroundColorNames.includes('pink')); //=> false Styles Modifiers reset - Reset the current style. bold - Make the text bold. dim - Make the text have lower opacity. italic - Make the text italic. (Not widely supported) underline - Put a horizontal line below the text. (Not widely supported) overline - Put a horizontal line above the text. (Not widely supported) inverse- Invert background and foreground colors. hidden - Print the text but make it invisible. strikethrough - Puts a horizontal line through the center of the text. (Not widely supported) visible- Print the text only when Chalk has a color level above zero. Can be useful for things that are purely cosmetic. Colors black red green yellow blue magenta cyan white blackBright (alias: gray, grey) redBright greenBright yellowBright blueBright magentaBright cyanBright whiteBright Background colors bgBlack bgRed bgGreen bgYellow bgBlue bgMagenta bgCyan bgWhite bgBlackBright (alias: bgGray, bgGrey) bgRedBright bgGreenBright bgYellowBright bgBlueBright bgMagentaBright bgCyanBright bgWhiteBright 256 and Truecolor color support Chalk supports 256 colors and Truecolor (16 million colors) on supported terminal apps. Colors are downsampled from 16 million RGB values to an ANSI color format that is supported by the terminal emulator (or by specifying {level: n} as a Chalk option). For example, Chalk configured to run at level 1 (basic color support) will downsample an RGB value of #FF0000 (red) to 31 (ANSI escape for red). Examples: chalk.hex('#DEADED').underline('Hello, world!') chalk.rgb(15, 100, 204).inverse('Hello!') Background versions of these models are prefixed with bg and the first level of the module capitalized (e.g. hex for foreground colors and bgHex for background colors). chalk.bgHex('#DEADED').underline('Hello, world!') chalk.bgRgb(15, 100, 204).inverse('Hello!') The following color models can be used: rgb - Example: chalk.rgb(255, 136, 0).bold('Orange!') hex - Example: chalk.hex('#FF8800').bold('Orange!') ansi256 - Example: chalk.bgAnsi256(194)('Honeydew, more or less') Browser support Since Chrome 69, ANSI escape codes are natively supported in the developer console. Windows If you're on Windows, do yourself a favor and use Windows Terminal instead of cmd.exe. FAQ Why not switch to a smaller coloring package? Chalk may be larger, but there is a reason for that. It offers a more user-friendly API, well-documented types, supports millions of colors, and covers edge cases that smaller alternatives miss. Chalk is mature, reliable, and built to last. But beyond the technical aspects, there's something more critical: trust and long-term maintenance. I have been active in open source for over a decade, and I'm committed to keeping Chalk maintained. Smaller packages might seem appealing now, but there's no guarantee they will be around for the long term, or that they won't become malicious over time. Chalk is also likely already in your dependency tree (since 100K+ packages depend on it), so switching won’t save space—in fact, it might increase it. npm deduplicates dependencies, so multiple Chalk instances turn into one, but adding another package alongside it will increase your overall size. If the goal is to clean up the ecosystem, switching away from Chalk won’t even make a dent. The real problem lies with packages that have very deep dependency trees (for example, those including a lot of polyfills). Chalk has no dependencies. It's better to focus on impactful changes rather than minor optimizations. If absolute package size is important to you, I also maintain yoctocolors, one of the smallest color packages out there. - Sindre But the smaller coloring package has benchmarks showing it is faster Micro-benchmarks are flawed because they measure performance in unrealistic, isolated scenarios, often giving a distorted view of real-world performance. Don't believe marketing fluff. All the coloring packages are more than fast enough. Related chalk-template - Tagged template literals support for this module chalk-cli - CLI for this module ansi-styles - ANSI escape codes for styling strings in the terminal supports-color - Detect whether a terminal supports color strip-ansi - Strip ANSI escape codes strip-ansi-stream - Strip ANSI escape codes from a stream has-ansi - Check if a string has ANSI escape codes ansi-regex - Regular expression for matching ANSI escape codes wrap-ansi - Wordwrap a string with ANSI escape codes slice-ansi - Slice a string with ANSI escape codes color-convert - Converts colors between different models chalk-animation - Animate strings in the terminal gradient-string - Apply color gradients to strings chalk-pipe - Create chalk style schemes with simpler style strings terminal-link - Create clickable links in the terminal (Not accepting additional entries) Maintainers Sindre Sorhus Josh Junon"
  },
  "src/frontend/app-client/node_modules/chokidar/README.html": {
    "href": "src/frontend/app-client/node_modules/chokidar/README.html",
    "title": "Chokidar",
    "summary": "Chokidar Minimal and efficient cross-platform file watching library Why? There are many reasons to prefer Chokidar to raw fs.watch / fs.watchFile in 2024: Events are properly reported macOS events report filenames events are not reported twice changes are reported as add / change / unlink instead of useless rename Atomic writes are supported, using atomic option Some file editors use them Chunked writes are supported, using awaitWriteFinish option Large files are commonly written in chunks File / dir filtering is supported Symbolic links are supported Recursive watching is always supported, instead of partial when using raw events Includes a way to limit recursion depth Chokidar relies on the Node.js core fs module, but when using fs.watch and fs.watchFile for watching, it normalizes the events it receives, often checking for truth by getting file stats and/or dir contents. The fs.watch-based implementation is the default, which avoids polling and keeps CPU usage down. Be advised that chokidar will initiate watchers recursively for everything within scope of the paths that have been specified, so be judicious about not wasting system resources by watching much more than needed. For some cases, fs.watchFile, which utilizes polling and uses more resources, is used. Made for Brunch in 2012, it is now used in ~30 million repositories and has proven itself in production environments. Sep 2024 update: v4 is out! It decreases dependency count from 13 to 1, removes support for globs, adds support for ESM / Common.js modules, and bumps minimum node.js version from v8 to v14. Check out upgrading. Getting started Install with npm: npm install chokidar Use it in your code: import chokidar from 'chokidar'; // One-liner for current directory chokidar.watch('.').on('all', (event, path) => { console.log(event, path); }); // Extended options // ---------------- // Initialize watcher. const watcher = chokidar.watch('file, dir, or array', { ignored: (path, stats) => stats?.isFile() && !path.endsWith('.js'), // only watch js files persistent: true }); // Something to use when events are received. const log = console.log.bind(console); // Add event listeners. watcher .on('add', path => log(`File ${path} has been added`)) .on('change', path => log(`File ${path} has been changed`)) .on('unlink', path => log(`File ${path} has been removed`)); // More possible events. watcher .on('addDir', path => log(`Directory ${path} has been added`)) .on('unlinkDir', path => log(`Directory ${path} has been removed`)) .on('error', error => log(`Watcher error: ${error}`)) .on('ready', () => log('Initial scan complete. Ready for changes')) .on('raw', (event, path, details) => { // internal log('Raw event info:', event, path, details); }); // 'add', 'addDir' and 'change' events also receive stat() results as second // argument when available: https://nodejs.org/api/fs.html#fs_class_fs_stats watcher.on('change', (path, stats) => { if (stats) console.log(`File ${path} changed size to ${stats.size}`); }); // Watch new files. watcher.add('new-file'); watcher.add(['new-file-2', 'new-file-3']); // Get list of actual paths being watched on the filesystem let watchedPaths = watcher.getWatched(); // Un-watch some files. await watcher.unwatch('new-file'); // Stop watching. The method is async! await watcher.close().then(() => console.log('closed')); // Full list of options. See below for descriptions. // Do not use this example! chokidar.watch('file', { persistent: true, // ignore .txt files ignored: (file) => file.endsWith('.txt'), // watch only .txt files // ignored: (file, _stats) => _stats?.isFile() && !file.endsWith('.txt'), awaitWriteFinish: true, // emit single event when chunked writes are completed atomic: true, // emit proper events when \"atomic writes\" (mv _tmp file) are used // The options also allow specifying custom intervals in ms // awaitWriteFinish: { // stabilityThreshold: 2000, // pollInterval: 100 // }, // atomic: 100, interval: 100, binaryInterval: 300, cwd: '.', depth: 99, followSymlinks: true, ignoreInitial: false, ignorePermissionErrors: false, usePolling: false, alwaysStat: false, }); chokidar.watch(paths, [options]) paths (string or array of strings). Paths to files, dirs to be watched recursively. options (object) Options object as defined below: Persistence persistent (default: true). Indicates whether the process should continue to run as long as files are being watched. Path filtering ignored function, regex, or path. Defines files/paths to be ignored. The whole relative or absolute path is tested, not just filename. If a function with two arguments is provided, it gets called twice per path - once with a single argument (the path), second time with two arguments (the path and the fs.Stats object of that path). ignoreInitial (default: false). If set to false then add/addDir events are also emitted for matching paths while instantiating the watching as chokidar discovers these file paths (before the ready event). followSymlinks (default: true). When false, only the symlinks themselves will be watched for changes instead of following the link references and bubbling events through the link's path. cwd (no default). The base directory from which watch paths are to be derived. Paths emitted with events will be relative to this. Performance usePolling (default: false). Whether to use fs.watchFile (backed by polling), or fs.watch. If polling leads to high CPU utilization, consider setting this to false. It is typically necessary to set this to true to successfully watch files over a network, and it may be necessary to successfully watch files in other non-standard situations. Setting to true explicitly on MacOS overrides the useFsEvents default. You may also set the CHOKIDAR_USEPOLLING env variable to true (1) or false (0) in order to override this option. Polling-specific settings (effective when usePolling: true) interval (default: 100). Interval of file system polling, in milliseconds. You may also set the CHOKIDAR_INTERVAL env variable to override this option. binaryInterval (default: 300). Interval of file system polling for binary files. (see list of binary extensions) alwaysStat (default: false). If relying upon the fs.Stats object that may get passed with add, addDir, and change events, set this to true to ensure it is provided even in cases where it wasn't already available from the underlying watch events. depth (default: undefined). If set, limits how many levels of subdirectories will be traversed. awaitWriteFinish (default: false). By default, the add event will fire when a file first appears on disk, before the entire file has been written. Furthermore, in some cases some change events will be emitted while the file is being written. In some cases, especially when watching for large files there will be a need to wait for the write operation to finish before responding to a file creation or modification. Setting awaitWriteFinish to true (or a truthy value) will poll file size, holding its add and change events until the size does not change for a configurable amount of time. The appropriate duration setting is heavily dependent on the OS and hardware. For accurate detection this parameter should be relatively high, making file watching much less responsive. Use with caution. options.awaitWriteFinish can be set to an object in order to adjust timing params: awaitWriteFinish.stabilityThreshold (default: 2000). Amount of time in milliseconds for a file size to remain constant before emitting its event. awaitWriteFinish.pollInterval (default: 100). File size polling interval, in milliseconds. Errors ignorePermissionErrors (default: false). Indicates whether to watch files that don't have read permissions if possible. If watching fails due to EPERM or EACCES with this set to true, the errors will be suppressed silently. atomic (default: true if useFsEvents and usePolling are false). Automatically filters out artifacts that occur when using editors that use \"atomic writes\" instead of writing directly to the source file. If a file is re-added within 100 ms of being deleted, Chokidar emits a change event rather than unlink then add. If the default of 100 ms does not work well for you, you can override it by setting atomic to a custom value, in milliseconds. Methods & Events chokidar.watch() produces an instance of FSWatcher. Methods of FSWatcher: .add(path / paths): Add files, directories for tracking. Takes an array of strings or just one string. .on(event, callback): Listen for an FS event. Available events: add, addDir, change, unlink, unlinkDir, ready, raw, error. Additionally all is available which gets emitted with the underlying event name and path for every event other than ready, raw, and error. raw is internal, use it carefully. .unwatch(path / paths): Stop watching files or directories. Takes an array of strings or just one string. .close(): async Removes all listeners from watched files. Asynchronous, returns Promise. Use with await to ensure bugs don't happen. .getWatched(): Returns an object representing all the paths on the file system being watched by this FSWatcher instance. The object's keys are all the directories (using absolute paths unless the cwd option was used), and the values are arrays of the names of the items contained in each directory. CLI Check out third party chokidar-cli, which allows to execute a command on each change, or get a stdio stream of change events. Troubleshooting Sometimes, Chokidar runs out of file handles, causing EMFILE and ENOSP errors: bash: cannot set terminal process group (-1): Inappropriate ioctl for device bash: no job control in this shell Error: watch /home/ ENOSPC There are two things that can cause it. Exhausted file handles for generic fs operations Can be solved by using graceful-fs, which can monkey-patch native fs module used by chokidar: let fs = require('fs'); let grfs = require('graceful-fs'); grfs.gracefulify(fs); Can also be solved by tuning OS: echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf && sudo sysctl -p. Exhausted file handles for fs.watch Can't seem to be solved by graceful-fs or OS tuning It's possible to start using usePolling: true, which will switch backend to resource-intensive fs.watchFile All fsevents-related issues (WARN optional dep failed, fsevents is not a constructor) are solved by upgrading to v4+. Changelog v4 (Sep 2024): remove glob support and bundled fsevents. Decrease dependency count from 13 to 1. Rewrite in typescript. Bumps minimum node.js requirement to v14+ v3 (Apr 2019): massive CPU & RAM consumption improvements; reduces deps / package size by a factor of 17x and bumps Node.js requirement to v8.16+. v2 (Dec 2017): globs are now posix-style-only. Tons of bugfixes. v1 (Apr 2015): glob support, symlink support, tons of bugfixes. Node 0.8+ is supported v0.1 (Apr 2012): Initial release, extracted from Brunch Upgrading If you've used globs before and want do replicate the functionality with v4: // v3 chok.watch('**/*.js'); chok.watch(\"./directory/**/*\"); // v4 chok.watch('.', { ignored: (path, stats) => stats?.isFile() && !path.endsWith('.js'), // only watch js files }); chok.watch('./directory'); // other way import { glob } from 'node:fs/promises'; const watcher = watch(await Array.fromAsync(glob('**/*.js'))); // unwatching // v3 chok.unwatch('**/*.js'); // v4 chok.unwatch(await glob('**/*.js')); Also Why was chokidar named this way? What's the meaning behind it? Chowkidar is a transliteration of a Hindi word meaning 'watchman, gatekeeper', चौकीदार. This ultimately comes from Sanskrit _ चतुष्क_ (crossway, quadrangle, consisting-of-four). This word is also used in other languages like Urdu as (چوکیدار) which is widely used in Pakistan and India. License MIT (c) Paul Miller (https://paulmillr.com), see LICENSE file."
  },
  "src/frontend/app-client/node_modules/classnames/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/classnames/HISTORY.html",
    "title": "Changelog",
    "summary": "Changelog v2.5.1 / 2023-12-29 Remove workspaces field from package (#350) v2.5.0 / 2023-12-27 Restore ability to pass a TypeScript interface (#341) Add exports field to package (#342) v2.4.0 / 2023-12-26 Use string concatenation to increase performance thanks Jon Koops (#336) v2.3.3 / 2023-12-21 Fix default export, thanks Remco Haszing (#301) Fix types for read-only arrays, thanks Ben Thompson (#307) Replace README examples with functional-style components, thanks JoeDGit (#303) v2.3.2 / 2022-09-13 Fix TypeScript types when using require, thanks Mark Dalgleish (#276) Fix toString as [Object object] in a vm, thanks Remco Haszing (#281) v2.3.1 / 2021-04-03 Fix bind/dedupe TypeScript types exports Fix mapping Value types, thanks Remco Haszing Removed non-existent named exports from types, thanks Remco Haszing v2.3.0 / 2021-04-01 Added TypeScript types Added consistent support for custom .toString() methods on arguments, thanks Stanislav Titenko v2.2.6 / 2018-06-08 Fixed compatibility issue with usage in an es module environment v2.2.5 / 2016-05-02 Improved performance of dedupe variant even further, thanks Andres Suarez v2.2.4 / 2016-04-25 Improved performance of dedupe variant by about 2x, thanks Bartosz Gościński v2.2.3 / 2016-01-05 Updated bind variant to use [].join(' ') as per the main script in 2.2.2 v2.2.2 / 2016-01-04 Switched from string concatenation to [].join(' ') for a slight performance gain in the main function. v2.2.1 / 2015-11-26 Add deps parameter to the AMD module, fixes an issue using the Dojo loader, thanks Chris Jordan v2.2.0 / 2015-10-18 added a new bind variant for use with css-modules and similar abstractions, thanks to Kirill Yakovenko v2.1.5 / 2015-09-30 reverted a new usage of Object.keys in dedupe.js that slipped through in the last release v2.1.4 / 2015-09-30 new case added to benchmarks safer hasOwnProperty check AMD module is now named, so you can do the following: define([\"classnames\"], function (classNames) { var style = classNames(\"foo\", \"bar\"); // ... }); v2.1.3 / 2015-07-02 updated UMD wrapper to support AMD and CommonJS on the same pacge v2.1.2 / 2015-05-28 added a proper UMD wrapper v2.1.1 / 2015-05-06 minor performance improvement thanks to type caching improved benchmarking and results output v2.1.0 / 2015-05-05 added alternate dedupe version of classNames, which is slower (10x) but ensures that if a class is added then overridden by a falsy value in a subsequent argument, it is excluded from the result. v2.0.0 / 2015-05-03 performance improvement; switched to Array.isArray for type detection, which is much faster in modern browsers. A polyfill is now required for IE8 support, see the Readme for details. v1.2.2 / 2015-04-28 license comment updates to simiplify certain build scenarios v1.2.1 / 2015-04-22 added safe exporting for requireJS usage clarified Bower usage and instructions v1.2.0 / 2015-03-17 added comprehensive support for array arguments, including nested arrays simplified code slightly Previous Please see the git history for the details of previous versions."
  },
  "src/frontend/app-client/node_modules/classnames/README.html": {
    "href": "src/frontend/app-client/node_modules/classnames/README.html",
    "title": "Classnames",
    "summary": "Classnames A simple JavaScript utility for conditionally joining classNames together. Install from the npm registry with your package manager: npm install classnames Use with Node.js, Browserify, or webpack: const classNames = require('classnames'); classNames('foo', 'bar'); // => 'foo bar' Alternatively, you can simply include index.js on your page with a standalone <script> tag and it will export a global classNames method, or define the module if you are using RequireJS. Project philosophy We take the stability and performance of this package seriously, because it is run millions of times a day in browsers all around the world. Updates are thoroughly reviewed for performance implications before being released, and we have a comprehensive test suite. Classnames follows the SemVer standard for versioning. There is also a Changelog. Usage The classNames function takes any number of arguments which can be a string or object. The argument 'foo' is short for { foo: true }. If the value associated with a given key is falsy, that key won't be included in the output. classNames('foo', 'bar'); // => 'foo bar' classNames('foo', { bar: true }); // => 'foo bar' classNames({ 'foo-bar': true }); // => 'foo-bar' classNames({ 'foo-bar': false }); // => '' classNames({ foo: true }, { bar: true }); // => 'foo bar' classNames({ foo: true, bar: true }); // => 'foo bar' // lots of arguments of various types classNames('foo', { bar: true, duck: false }, 'baz', { quux: true }); // => 'foo bar baz quux' // other falsy values are just ignored classNames(null, false, 'bar', undefined, 0, 1, { baz: null }, ''); // => 'bar 1' Arrays will be recursively flattened as per the rules above: const arr = ['b', { c: true, d: false }]; classNames('a', arr); // => 'a b c' Dynamic class names with ES2015 If you're in an environment that supports computed keys (available in ES2015 and Babel) you can use dynamic class names: let buttonType = 'primary'; classNames({ [`btn-${buttonType}`]: true }); Usage with React.js This package is the official replacement for classSet, which was originally shipped in the React.js Addons bundle. One of its primary use cases is to make dynamic and conditional className props simpler to work with (especially more so than conditional string manipulation). So where you may have the following code to generate a className prop for a <button> in React: import React, { useState } from 'react'; export default function Button (props) { const [isPressed, setIsPressed] = useState(false); const [isHovered, setIsHovered] = useState(false); let btnClass = 'btn'; if (isPressed) btnClass += ' btn-pressed'; else if (isHovered) btnClass += ' btn-over'; return ( <button className={btnClass} onMouseDown={() => setIsPressed(true)} onMouseUp={() => setIsPressed(false)} onMouseEnter={() => setIsHovered(true)} onMouseLeave={() => setIsHovered(false)} > {props.label} </button> ); } You can express the conditional classes more simply as an object: import React, { useState } from 'react'; import classNames from 'classnames'; export default function Button (props) { const [isPressed, setIsPressed] = useState(false); const [isHovered, setIsHovered] = useState(false); const btnClass = classNames({ btn: true, 'btn-pressed': isPressed, 'btn-over': !isPressed && isHovered, }); return ( <button className={btnClass} onMouseDown={() => setIsPressed(true)} onMouseUp={() => setIsPressed(false)} onMouseEnter={() => setIsHovered(true)} onMouseLeave={() => setIsHovered(false)} > {props.label} </button> ); } Because you can mix together object, array and string arguments, supporting optional className props is also simpler as only truthy arguments get included in the result: const btnClass = classNames('btn', this.props.className, { 'btn-pressed': isPressed, 'btn-over': !isPressed && isHovered, }); Alternate dedupe version There is an alternate version of classNames available which correctly dedupes classes and ensures that falsy classes specified in later arguments are excluded from the result set. This version is slower (about 5x) so it is offered as an opt-in. To use the dedupe version with Node.js, Browserify, or webpack: const classNames = require('classnames/dedupe'); classNames('foo', 'foo', 'bar'); // => 'foo bar' classNames('foo', { foo: false, bar: true }); // => 'bar' For standalone (global / AMD) use, include dedupe.js in a <script> tag on your page. Alternate bind version (for css-modules) If you are using css-modules, or a similar approach to abstract class 'names' and the real className values that are actually output to the DOM, you may want to use the bind variant. Note that in ES2015 environments, it may be better to use the \"dynamic class names\" approach documented above. const classNames = require('classnames/bind'); const styles = { foo: 'abc', bar: 'def', baz: 'xyz', }; const cx = classNames.bind(styles); const className = cx('foo', ['bar'], { baz: true }); // => 'abc def xyz' Real-world example: /* components/submit-button.js */ import { useState } from 'react'; import classNames from 'classnames/bind'; import styles from './submit-button.css'; const cx = classNames.bind(styles); export default function SubmitButton ({ store, form }) { const [submissionInProgress, setSubmissionInProgress] = useState(store.submissionInProgress); const [errorOccurred, setErrorOccurred] = useState(store.errorOccurred); const [valid, setValid] = useState(form.valid); const text = submissionInProgress ? 'Processing...' : 'Submit'; const className = cx({ base: true, inProgress: submissionInProgress, error: errorOccurred, disabled: valid, }); return <button className={className}>{text}</button>; } Polyfills needed to support older browsers classNames >=2.0.0 Array.isArray: see MDN for details about unsupported older browsers (e.g. <= IE8) and a simple polyfill. LICENSE MIT Copyright (c) 2018 Jed Watson. Copyright of the Typescript bindings are respective of each contributor listed in the definition file."
  },
  "src/frontend/app-client/node_modules/clone/README.html": {
    "href": "src/frontend/app-client/node_modules/clone/README.html",
    "title": "clone",
    "summary": "clone offers foolproof deep cloning of objects, arrays, numbers, strings, maps, sets, promises, etc. in JavaScript. XSS vulnerability detected Installation npm install clone (It also works with browserify, ender or standalone. You may want to use the option noParse in browserify to reduce the resulting file size, since usually Buffers are not needed in browsers.) Example var clone = require('clone'); var a, b; a = { foo: { bar: 'baz' } }; // initial value of a b = clone(a); // clone a -> b a.foo.bar = 'foo'; // change a console.log(a); // show a console.log(b); // show b This will print: { foo: { bar: 'foo' } } { foo: { bar: 'baz' } } clone masters cloning simple objects (even with custom prototype), arrays, Date objects, and RegExp objects. Everything is cloned recursively, so that you can clone dates in arrays in objects, for example. API clone(val, circular, depth) val -- the value that you want to clone, any type allowed circular -- boolean Call clone with circular set to false if you are certain that obj contains no circular references. This will give better performance if needed. There is no error if undefined or null is passed as obj. depth -- depth to which the object is to be cloned (optional, defaults to infinity) prototype -- sets the prototype to be used when cloning an object. (optional, defaults to parent prototype). includeNonEnumerable -- set to true if the non-enumerable properties should be cloned as well. Non-enumerable properties on the prototype chain will be ignored. (optional, defaults to false) clone.clonePrototype(obj) obj -- the object that you want to clone Does a prototype clone as described by Oran Looney. Circular References var a, b; a = { hello: 'world' }; a.myself = a; b = clone(a); console.log(b); This will print: { hello: \"world\", myself: [Circular] } So, b.myself points to b, not a. Neat! Test npm test Changelog v2.1.2 2018-03-21 Use Buffer.allocUnsafe() on Node >= 4.5.0 (contributed by @ChALkeR) v2.1.1 2017-03-09 Fix build badge in README Add support for cloning Maps and Sets on Internet Explorer v2.1.0 2016-11-22 Add support for cloning Errors Exclude non-enumerable symbol-named object properties from cloning Add option to include non-enumerable own properties of objects v2.0.0 2016-09-28 Add support for cloning ES6 Maps, Sets, Promises, and Symbols v1.0.3 2017-11-08 Close XSS vulnerability in the NPM package, which included the file test-apart-ctx.html. This vulnerability was disclosed by Juho Nurminen of 2NS - Second Nature Security. v1.0.2 (deprecated) 2015-03-25 Fix call on getRegExpFlags Refactor utilities Refactor test suite v1.0.1 (deprecated) 2015-03-04 Fix nodeunit version Directly call getRegExpFlags v1.0.0 (deprecated) 2015-02-10 Improve browser support Improve browser testability Move helper methods to private namespace Caveat Some special objects like a socket or process.stdout/stderr are known to not be cloneable. If you find other objects that cannot be cloned, please open an issue. Bugs and Issues If you encounter any bugs or issues, feel free to open an issue at github or send me an email to paul@vorba.ch. I also always like to hear from you, if you’re using my code. License Copyright © 2011-2016 Paul Vorbach and contributors. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/clsx/readme.html": {
    "href": "src/frontend/app-client/node_modules/clsx/readme.html",
    "title": "clsx",
    "summary": "clsx A tiny (239B) utility for constructing className strings conditionally. Also serves as a faster & smaller drop-in replacement for the classnames module. This module is available in three formats: ES Module: dist/clsx.mjs CommonJS: dist/clsx.js UMD: dist/clsx.min.js Install $ npm install --save clsx Usage import clsx from 'clsx'; // or import { clsx } from 'clsx'; // Strings (variadic) clsx('foo', true && 'bar', 'baz'); //=> 'foo bar baz' // Objects clsx({ foo:true, bar:false, baz:isTrue() }); //=> 'foo baz' // Objects (variadic) clsx({ foo:true }, { bar:false }, null, { '--foobar':'hello' }); //=> 'foo --foobar' // Arrays clsx(['foo', 0, false, 'bar']); //=> 'foo bar' // Arrays (variadic) clsx(['foo'], ['', 0, false, 'bar'], [['baz', [['hello'], 'there']]]); //=> 'foo bar baz hello there' // Kitchen sink (with nesting) clsx('foo', [1 && 'bar', { baz:false, bat:null }, ['hello', ['world']]], 'cya'); //=> 'foo bar hello world cya' API clsx(...input) Returns: String input Type: Mixed The clsx function can take any number of arguments, each of which can be an Object, Array, Boolean, or String. Important: Any falsey values are discarded! Standalone Boolean values are discarded as well. clsx(true, false, '', null, undefined, 0, NaN); //=> '' Modes There are multiple \"versions\" of clsx available, which allows you to bring only the functionality you need! clsx Size (gzip): 239 bytes Availability: CommonJS, ES Module, UMD The default clsx module; see API for info. import { clsx } from 'clsx'; // or import clsx from 'clsx'; clsx/lite Size (gzip): 140 bytes Availability: CommonJS, ES Module CAUTION: Accepts ONLY string arguments! Ideal for applications that only use the string-builder pattern. Any non-string arguments are ignored! import { clsx } from 'clsx/lite'; // or import clsx from 'clsx/lite'; // string clsx('hello', true && 'foo', false && 'bar'); // => \"hello foo\" // NOTE: Any non-string input(s) ignored clsx({ foo: true }); //=> \"\" Benchmarks For snapshots of cross-browser results, check out the bench directory~! Support All versions of Node.js are supported. All browsers that support Array.isArray are supported (IE9+). Note: For IE8 support and older, please install clsx@1.0.x and beware of #17. Tailwind Support Here some additional (optional) steps to enable classes autocompletion using clsx with Tailwind CSS. Visual Studio Code Install the \"Tailwind CSS IntelliSense\" Visual Studio Code extension Add the following to your settings.json: { \"tailwindCSS.experimental.classRegex\": [ [\"clsx\\\\(([^)]*)\\\\)\", \"(?:'|\\\"|`)([^']*)(?:'|\\\"|`)\"] ] } You may find the clsx/lite module useful within Tailwind contexts. This is especially true if/when your application only composes classes in this pattern: clsx('text-base', props.active && 'text-primary', props.className); Related obj-str - A smaller (96B) and similiar utility that only works with Objects. License MIT © Luke Edwards"
  },
  "src/frontend/app-client/node_modules/color-convert/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/color-convert/CHANGELOG.html",
    "title": "1.0.0 - 2016-01-07",
    "summary": "1.0.0 - 2016-01-07 Removed: unused speed test Added: Automatic routing between previously unsupported conversions (#27) Removed: xxx2xxx() and xxx2xxxRaw() functions (#27) Removed: convert() class (#27) Changed: all functions to lookup dictionary (#27) Changed: ansi to ansi256 (#27) Fixed: argument grouping for functions requiring only one argument (#27) 0.6.0 - 2015-07-23 Added: methods to handle ANSI 16/256 colors: rgb2ansi16 rgb2ansi hsl2ansi16 hsl2ansi hsv2ansi16 hsv2ansi hwb2ansi16 hwb2ansi cmyk2ansi16 cmyk2ansi keyword2ansi16 keyword2ansi ansi162rgb ansi162hsl ansi162hsv ansi162hwb ansi162cmyk ansi162keyword ansi2rgb ansi2hsl ansi2hsv ansi2hwb ansi2cmyk ansi2keyword (#18) 0.5.3 - 2015-06-02 Fixed: hsl2hsv does not return NaN anymore when using [0,0,0] (#15) Check out commit logs for older releases"
  },
  "src/frontend/app-client/node_modules/color-convert/README.html": {
    "href": "src/frontend/app-client/node_modules/color-convert/README.html",
    "title": "color-convert",
    "summary": "color-convert Color-convert is a color conversion library for JavaScript and node. It converts all ways between rgb, hsl, hsv, hwb, cmyk, ansi, ansi16, hex strings, and CSS keywords (will round to closest): var convert = require('color-convert'); convert.rgb.hsl(140, 200, 100); // [96, 48, 59] convert.keyword.rgb('blue'); // [0, 0, 255] var rgbChannels = convert.rgb.channels; // 3 var cmykChannels = convert.cmyk.channels; // 4 var ansiChannels = convert.ansi16.channels; // 1 Install $ npm install color-convert API Simply get the property of the from and to conversion that you're looking for. All functions have a rounded and unrounded variant. By default, return values are rounded. To get the unrounded (raw) results, simply tack on .raw to the function. All 'from' functions have a hidden property called .channels that indicates the number of channels the function expects (not including alpha). var convert = require('color-convert'); // Hex to LAB convert.hex.lab('DEADBF'); // [ 76, 21, -2 ] convert.hex.lab.raw('DEADBF'); // [ 75.56213190997677, 20.653827952644754, -2.290532499330533 ] // RGB to CMYK convert.rgb.cmyk(167, 255, 4); // [ 35, 0, 98, 0 ] convert.rgb.cmyk.raw(167, 255, 4); // [ 34.509803921568626, 0, 98.43137254901961, 0 ] Arrays All functions that accept multiple arguments also support passing an array. Note that this does not apply to functions that convert from a color that only requires one value (e.g. keyword, ansi256, hex, etc.) var convert = require('color-convert'); convert.rgb.hex(123, 45, 67); // '7B2D43' convert.rgb.hex([123, 45, 67]); // '7B2D43' Routing Conversions that don't have an explicitly defined conversion (in conversions.js), but can be converted by means of sub-conversions (e.g. XYZ -> RGB -> CMYK), are automatically routed together. This allows just about any color model supported by color-convert to be converted to any other model, so long as a sub-conversion path exists. This is also true for conversions requiring more than one step in between (e.g. LCH -> LAB -> XYZ -> RGB -> Hex). Keep in mind that extensive conversions may result in a loss of precision, and exist only to be complete. For a list of \"direct\" (single-step) conversions, see conversions.js. Contribute If there is a new model you would like to support, or want to add a direct conversion between two existing models, please send us a pull request. License Copyright © 2011-2016, Heather Arthur and Josh Junon. Licensed under the MIT License."
  },
  "src/frontend/app-client/node_modules/color-name/README.html": {
    "href": "src/frontend/app-client/node_modules/color-name/README.html",
    "title": "",
    "summary": "A JSON with color names and its values. Based on http://dev.w3.org/csswg/css-color/#named-colors. var colors = require('color-name'); colors.red //[255,0,0]"
  },
  "src/frontend/app-client/node_modules/commander/Readme.html": {
    "href": "src/frontend/app-client/node_modules/commander/Readme.html",
    "title": "Commander.js",
    "summary": "Commander.js The complete solution for node.js command-line interfaces. Read this in other languages: English | 简体中文 Commander.js Installation Quick Start Declaring program variable Options Common option types, boolean and value Default option value Other option types, negatable boolean and boolean|value Required option Variadic option Version option More configuration Custom option processing Commands Command-arguments More configuration Custom argument processing Action handler Stand-alone executable (sub)commands Life cycle hooks Automated help Custom help Display help after errors Display help from code .name .usage .description and .summary .helpOption(flags, description) .addHelpCommand() More configuration Custom event listeners Bits and pieces .parse() and .parseAsync() Parsing Configuration Legacy options as properties TypeScript createCommand() Node options such as --harmony Debugging stand-alone executable subcommands Display error Override exit and output handling Additional documentation Support Commander for enterprise For information about terms used in this document see: terminology Installation npm install commander Quick Start You write code to describe your command line interface. Commander looks after parsing the arguments into options and command-arguments, displays usage errors for problems, and implements a help system. Commander is strict and displays an error for unrecognised options. The two most used option types are a boolean option, and an option which takes its value from the following argument. Example file: split.js const { program } = require('commander'); program .option('--first') .option('-s, --separator <char>'); program.parse(); const options = program.opts(); const limit = options.first ? 1 : undefined; console.log(program.args[0].split(options.separator, limit)); $ node split.js -s / --fits a/b/c error: unknown option '--fits' (Did you mean --first?) $ node split.js -s / --first a/b/c [ 'a' ] Here is a more complete program using a subcommand and with descriptions for the help. In a multi-command program, you have an action handler for each command (or stand-alone executables for the commands). Example file: string-util.js const { Command } = require('commander'); const program = new Command(); program .name('string-util') .description('CLI to some JavaScript string utilities') .version('0.8.0'); program.command('split') .description('Split a string into substrings and display as an array') .argument('<string>', 'string to split') .option('--first', 'display just the first substring') .option('-s, --separator <char>', 'separator character', ',') .action((str, options) => { const limit = options.first ? 1 : undefined; console.log(str.split(options.separator, limit)); }); program.parse(); $ node string-util.js help split Usage: string-util split [options] <string> Split a string into substrings and display as an array. Arguments: string string to split Options: --first display just the first substring -s, --separator <char> separator character (default: \",\") -h, --help display help for command $ node string-util.js split --separator=/ a/b/c [ 'a', 'b', 'c' ] More samples can be found in the examples directory. Declaring program variable Commander exports a global object which is convenient for quick programs. This is used in the examples in this README for brevity. // CommonJS (.cjs) const { program } = require('commander'); For larger programs which may use commander in multiple ways, including unit testing, it is better to create a local Command object to use. // CommonJS (.cjs) const { Command } = require('commander'); const program = new Command(); // ECMAScript (.mjs) import { Command } from 'commander'; const program = new Command(); // TypeScript (.ts) import { Command } from 'commander'; const program = new Command(); Options Options are defined with the .option() method, also serving as documentation for the options. Each option can have a short flag (single character) and a long name, separated by a comma or space or vertical bar ('|'). The parsed options can be accessed by calling .opts() on a Command object, and are passed to the action handler. Multi-word options such as \"--template-engine\" are camel-cased, becoming program.opts().templateEngine etc. An option and its option-argument can be separated by a space, or combined into the same argument. The option-argument can follow the short option directly or follow an = for a long option. serve -p 80 serve -p80 serve --port 80 serve --port=80 You can use -- to indicate the end of the options, and any remaining arguments will be used without being interpreted. By default options on the command line are not positional, and can be specified before or after other arguments. There are additional related routines for when .opts() is not enough: .optsWithGlobals() returns merged local and global option values .getOptionValue() and .setOptionValue() work with a single option value .getOptionValueSource() and .setOptionValueWithSource() include where the option value came from Common option types, boolean and value The two most used option types are a boolean option, and an option which takes its value from the following argument (declared with angle brackets like --expect <value>). Both are undefined unless specified on command line. Example file: options-common.js program .option('-d, --debug', 'output extra debugging') .option('-s, --small', 'small pizza size') .option('-p, --pizza-type <type>', 'flavour of pizza'); program.parse(process.argv); const options = program.opts(); if (options.debug) console.log(options); console.log('pizza details:'); if (options.small) console.log('- small pizza size'); if (options.pizzaType) console.log(`- ${options.pizzaType}`); $ pizza-options -p error: option '-p, --pizza-type <type>' argument missing $ pizza-options -d -s -p vegetarian { debug: true, small: true, pizzaType: 'vegetarian' } pizza details: - small pizza size - vegetarian $ pizza-options --pizza-type=cheese pizza details: - cheese Multiple boolean short options may be combined together following the dash, and may be followed by a single short option taking a value. For example -d -s -p cheese may be written as -ds -p cheese or even -dsp cheese. Options with an expected option-argument are greedy and will consume the following argument whatever the value. So --id -xyz reads -xyz as the option-argument. program.parse(arguments) processes the arguments, leaving any args not consumed by the program options in the program.args array. The parameter is optional and defaults to process.argv. Default option value You can specify a default value for an option. Example file: options-defaults.js program .option('-c, --cheese <type>', 'add the specified type of cheese', 'blue'); program.parse(); console.log(`cheese: ${program.opts().cheese}`); $ pizza-options cheese: blue $ pizza-options --cheese stilton cheese: stilton Other option types, negatable boolean and boolean|value You can define a boolean option long name with a leading no- to set the option value to false when used. Defined alone this also makes the option true by default. If you define --foo first, adding --no-foo does not change the default value from what it would otherwise be. Example file: options-negatable.js program .option('--no-sauce', 'Remove sauce') .option('--cheese <flavour>', 'cheese flavour', 'mozzarella') .option('--no-cheese', 'plain with no cheese') .parse(); const options = program.opts(); const sauceStr = options.sauce ? 'sauce' : 'no sauce'; const cheeseStr = (options.cheese === false) ? 'no cheese' : `${options.cheese} cheese`; console.log(`You ordered a pizza with ${sauceStr} and ${cheeseStr}`); $ pizza-options You ordered a pizza with sauce and mozzarella cheese $ pizza-options --sauce error: unknown option '--sauce' $ pizza-options --cheese=blue You ordered a pizza with sauce and blue cheese $ pizza-options --no-sauce --no-cheese You ordered a pizza with no sauce and no cheese You can specify an option which may be used as a boolean option but may optionally take an option-argument (declared with square brackets like --optional [value]). Example file: options-boolean-or-value.js program .option('-c, --cheese [type]', 'Add cheese with optional type'); program.parse(process.argv); const options = program.opts(); if (options.cheese === undefined) console.log('no cheese'); else if (options.cheese === true) console.log('add cheese'); else console.log(`add cheese type ${options.cheese}`); $ pizza-options no cheese $ pizza-options --cheese add cheese $ pizza-options --cheese mozzarella add cheese type mozzarella Options with an optional option-argument are not greedy and will ignore arguments starting with a dash. So id behaves as a boolean option for --id -5, but you can use a combined form if needed like --id=-5. For information about possible ambiguous cases, see options taking varying arguments. Required option You may specify a required (mandatory) option using .requiredOption(). The option must have a value after parsing, usually specified on the command line, or perhaps from a default value (say from environment). The method is otherwise the same as .option() in format, taking flags and description, and optional default value or custom processing. Example file: options-required.js program .requiredOption('-c, --cheese <type>', 'pizza must have cheese'); program.parse(); $ pizza error: required option '-c, --cheese <type>' not specified Variadic option You may make an option variadic by appending ... to the value placeholder when declaring the option. On the command line you can then specify multiple option-arguments, and the parsed option value will be an array. The extra arguments are read until the first argument starting with a dash. The special argument -- stops option processing entirely. If a value is specified in the same argument as the option then no further values are read. Example file: options-variadic.js program .option('-n, --number <numbers...>', 'specify numbers') .option('-l, --letter [letters...]', 'specify letters'); program.parse(); console.log('Options: ', program.opts()); console.log('Remaining arguments: ', program.args); $ collect -n 1 2 3 --letter a b c Options: { number: [ '1', '2', '3' ], letter: [ 'a', 'b', 'c' ] } Remaining arguments: [] $ collect --letter=A -n80 operand Options: { number: [ '80' ], letter: [ 'A' ] } Remaining arguments: [ 'operand' ] $ collect --letter -n 1 -n 2 3 -- operand Options: { number: [ '1', '2', '3' ], letter: true } Remaining arguments: [ 'operand' ] For information about possible ambiguous cases, see options taking varying arguments. Version option The optional version method adds handling for displaying the command version. The default option flags are -V and --version, and when present the command prints the version number and exits. program.version('0.0.1'); $ ./examples/pizza -V 0.0.1 You may change the flags and description by passing additional parameters to the version method, using the same syntax for flags as the option method. program.version('0.0.1', '-v, --vers', 'output the current version'); More configuration You can add most options using the .option() method, but there are some additional features available by constructing an Option explicitly for less common cases. Example files: options-extra.js, options-env.js, options-conflicts.js, options-implies.js program .addOption(new Option('-s, --secret').hideHelp()) .addOption(new Option('-t, --timeout <delay>', 'timeout in seconds').default(60, 'one minute')) .addOption(new Option('-d, --drink <size>', 'drink size').choices(['small', 'medium', 'large'])) .addOption(new Option('-p, --port <number>', 'port number').env('PORT')) .addOption(new Option('--donate [amount]', 'optional donation in dollars').preset('20').argParser(parseFloat)) .addOption(new Option('--disable-server', 'disables the server').conflicts('port')) .addOption(new Option('--free-drink', 'small drink included free ').implies({ drink: 'small' })); $ extra --help Usage: help [options] Options: -t, --timeout <delay> timeout in seconds (default: one minute) -d, --drink <size> drink cup size (choices: \"small\", \"medium\", \"large\") -p, --port <number> port number (env: PORT) --donate [amount] optional donation in dollars (preset: \"20\") --disable-server disables the server --free-drink small drink included free -h, --help display help for command $ extra --drink huge error: option '-d, --drink <size>' argument 'huge' is invalid. Allowed choices are small, medium, large. $ PORT=80 extra --donate --free-drink Options: { timeout: 60, donate: 20, port: '80', freeDrink: true, drink: 'small' } $ extra --disable-server --port 8000 error: option '--disable-server' cannot be used with option '-p, --port <number>' Specify a required (mandatory) option using the Option method .makeOptionMandatory(). This matches the Command method .requiredOption(). Custom option processing You may specify a function to do custom processing of option-arguments. The callback function receives two parameters, the user specified option-argument and the previous value for the option. It returns the new value for the option. This allows you to coerce the option-argument to the desired type, or accumulate values, or do entirely custom processing. You can optionally specify the default/starting value for the option after the function parameter. Example file: options-custom-processing.js function myParseInt(value, dummyPrevious) { // parseInt takes a string and a radix const parsedValue = parseInt(value, 10); if (isNaN(parsedValue)) { throw new commander.InvalidArgumentError('Not a number.'); } return parsedValue; } function increaseVerbosity(dummyValue, previous) { return previous + 1; } function collect(value, previous) { return previous.concat([value]); } function commaSeparatedList(value, dummyPrevious) { return value.split(','); } program .option('-f, --float <number>', 'float argument', parseFloat) .option('-i, --integer <number>', 'integer argument', myParseInt) .option('-v, --verbose', 'verbosity that can be increased', increaseVerbosity, 0) .option('-c, --collect <value>', 'repeatable value', collect, []) .option('-l, --list <items>', 'comma separated list', commaSeparatedList) ; program.parse(); const options = program.opts(); if (options.float !== undefined) console.log(`float: ${options.float}`); if (options.integer !== undefined) console.log(`integer: ${options.integer}`); if (options.verbose > 0) console.log(`verbosity: ${options.verbose}`); if (options.collect.length > 0) console.log(options.collect); if (options.list !== undefined) console.log(options.list); $ custom -f 1e2 float: 100 $ custom --integer 2 integer: 2 $ custom -v -v -v verbose: 3 $ custom -c a -c b -c c [ 'a', 'b', 'c' ] $ custom --list x,y,z [ 'x', 'y', 'z' ] Commands You can specify (sub)commands using .command() or .addCommand(). There are two ways these can be implemented: using an action handler attached to the command, or as a stand-alone executable file (described in more detail later). The subcommands may be nested (example). In the first parameter to .command() you specify the command name. You may append the command-arguments after the command name, or specify them separately using .argument(). The arguments may be <required> or [optional], and the last argument may also be variadic.... You can use .addCommand() to add an already configured subcommand to the program. For example: // Command implemented using action handler (description is supplied separately to `.command`) // Returns new command for configuring. program .command('clone <source> [destination]') .description('clone a repository into a newly created directory') .action((source, destination) => { console.log('clone command called'); }); // Command implemented using stand-alone executable file, indicated by adding description as second parameter to `.command`. // Returns `this` for adding more commands. program .command('start <service>', 'start named service') .command('stop [service]', 'stop named service, or all if no name supplied'); // Command prepared separately. // Returns `this` for adding more commands. program .addCommand(build.makeBuildCommand()); Configuration options can be passed with the call to .command() and .addCommand(). Specifying hidden: true will remove the command from the generated help output. Specifying isDefault: true will run the subcommand if no other subcommand is specified (example). You can add alternative names for a command with .alias(). (example) For safety, .addCommand() does not automatically copy the inherited settings from the parent command. There is a helper routine .copyInheritedSettings() for copying the settings when they are wanted. Command-arguments For subcommands, you can specify the argument syntax in the call to .command() (as shown above). This is the only method usable for subcommands implemented using a stand-alone executable, but for other subcommands you can instead use the following method. To configure a command, you can use .argument() to specify each expected command-argument. You supply the argument name and an optional description. The argument may be <required> or [optional]. You can specify a default value for an optional command-argument. Example file: argument.js program .version('0.1.0') .argument('<username>', 'user to login') .argument('[password]', 'password for user, if required', 'no password given') .action((username, password) => { console.log('username:', username); console.log('password:', password); }); The last argument of a command can be variadic, and only the last argument. To make an argument variadic you append ... to the argument name. A variadic argument is passed to the action handler as an array. For example: program .version('0.1.0') .command('rmdir') .argument('<dirs...>') .action(function (dirs) { dirs.forEach((dir) => { console.log('rmdir %s', dir); }); }); There is a convenience method to add multiple arguments at once, but without descriptions: program .arguments('<username> <password>'); More configuration There are some additional features available by constructing an Argument explicitly for less common cases. Example file: arguments-extra.js program .addArgument(new commander.Argument('<drink-size>', 'drink cup size').choices(['small', 'medium', 'large'])) .addArgument(new commander.Argument('[timeout]', 'timeout in seconds').default(60, 'one minute')) Custom argument processing You may specify a function to do custom processing of command-arguments (like for option-arguments). The callback function receives two parameters, the user specified command-argument and the previous value for the argument. It returns the new value for the argument. The processed argument values are passed to the action handler, and saved as .processedArgs. You can optionally specify the default/starting value for the argument after the function parameter. Example file: arguments-custom-processing.js program .command('add') .argument('<first>', 'integer argument', myParseInt) .argument('[second]', 'integer argument', myParseInt, 1000) .action((first, second) => { console.log(`${first} + ${second} = ${first + second}`); }) ; Action handler The action handler gets passed a parameter for each command-argument you declared, and two additional parameters which are the parsed options and the command object itself. Example file: thank.js program .argument('<name>') .option('-t, --title <honorific>', 'title to use before name') .option('-d, --debug', 'display some debugging') .action((name, options, command) => { if (options.debug) { console.error('Called %s with options %o', command.name(), options); } const title = options.title ? `${options.title} ` : ''; console.log(`Thank-you ${title}${name}`); }); If you prefer, you can work with the command directly and skip declaring the parameters for the action handler. The this keyword is set to the running command and can be used from a function expression (but not from an arrow function). Example file: action-this.js program .command('serve') .argument('<script>') .option('-p, --port <number>', 'port number', 80) .action(function() { console.error('Run script %s on port %s', this.args[0], this.opts().port); }); You may supply an async action handler, in which case you call .parseAsync rather than .parse. async function run() { /* code goes here */ } async function main() { program .command('run') .action(run); await program.parseAsync(process.argv); } A command's options and arguments on the command line are validated when the command is used. Any unknown options or missing arguments will be reported as an error. You can suppress the unknown option checks with .allowUnknownOption(). By default it is not an error to pass more arguments than declared, but you can make this an error with .allowExcessArguments(false). Stand-alone executable (sub)commands When .command() is invoked with a description argument, this tells Commander that you're going to use stand-alone executables for subcommands. Commander will search the files in the directory of the entry script for a file with the name combination command-subcommand, like pm-install or pm-search in the example below. The search includes trying common file extensions, like .js. You may specify a custom name (and path) with the executableFile configuration option. You may specify a custom search directory for subcommands with .executableDir(). You handle the options for an executable (sub)command in the executable, and don't declare them at the top-level. Example file: pm program .name('pm') .version('0.1.0') .command('install [name]', 'install one or more packages') .command('search [query]', 'search with optional query') .command('update', 'update installed packages', { executableFile: 'myUpdateSubCommand' }) .command('list', 'list packages installed', { isDefault: true }); program.parse(process.argv); If the program is designed to be installed globally, make sure the executables have proper modes, like 755. Life cycle hooks You can add callback hooks to a command for life cycle events. Example file: hook.js program .option('-t, --trace', 'display trace statements for commands') .hook('preAction', (thisCommand, actionCommand) => { if (thisCommand.opts().trace) { console.log(`About to call action handler for subcommand: ${actionCommand.name()}`); console.log('arguments: %O', actionCommand.args); console.log('options: %o', actionCommand.opts()); } }); The callback hook can be async, in which case you call .parseAsync rather than .parse. You can add multiple hooks per event. The supported events are: event name when hook called callback parameters preAction, postAction before/after action handler for this command and its nested subcommands (thisCommand, actionCommand) preSubcommand before parsing direct subcommand (thisCommand, subcommand) For an overview of the life cycle events see parsing life cycle and hooks. Automated help The help information is auto-generated based on the information commander already knows about your program. The default help option is -h,--help. Example file: pizza $ node ./examples/pizza --help Usage: pizza [options] An application for pizza ordering Options: -p, --peppers Add peppers -c, --cheese <type> Add the specified type of cheese (default: \"marble\") -C, --no-cheese You do not want any cheese -h, --help display help for command A help command is added by default if your command has subcommands. It can be used alone, or with a subcommand name to show further help for the subcommand. These are effectively the same if the shell program has implicit help: shell help shell --help shell help spawn shell spawn --help Long descriptions are wrapped to fit the available width. (However, a description that includes a line-break followed by whitespace is assumed to be pre-formatted and not wrapped.) Custom help You can add extra text to be displayed along with the built-in help. Example file: custom-help program .option('-f, --foo', 'enable some foo'); program.addHelpText('after', ` Example call: $ custom-help --help`); Yields the following help output: Usage: custom-help [options] Options: -f, --foo enable some foo -h, --help display help for command Example call: $ custom-help --help The positions in order displayed are: beforeAll: add to the program for a global banner or header before: display extra information before built-in help after: display extra information after built-in help afterAll: add to the program for a global footer (epilog) The positions \"beforeAll\" and \"afterAll\" apply to the command and all its subcommands. The second parameter can be a string, or a function returning a string. The function is passed a context object for your convenience. The properties are: error: a boolean for whether the help is being displayed due to a usage error command: the Command which is displaying the help Display help after errors The default behaviour for usage errors is to just display a short error message. You can change the behaviour to show the full help or a custom help message after an error. program.showHelpAfterError(); // or program.showHelpAfterError('(add --help for additional information)'); $ pizza --unknown error: unknown option '--unknown' (add --help for additional information) The default behaviour is to suggest correct spelling after an error for an unknown command or option. You can disable this. program.showSuggestionAfterError(false); $ pizza --hepl error: unknown option '--hepl' (Did you mean --help?) Display help from code .help(): display help information and exit immediately. You can optionally pass { error: true } to display on stderr and exit with an error status. .outputHelp(): output help information without exiting. You can optionally pass { error: true } to display on stderr. .helpInformation(): get the built-in command help information as a string for processing or displaying yourself. .name The command name appears in the help, and is also used for locating stand-alone executable subcommands. You may specify the program name using .name() or in the Command constructor. For the program, Commander will fallback to using the script name from the full arguments passed into .parse(). However, the script name varies depending on how your program is launched so you may wish to specify it explicitly. program.name('pizza'); const pm = new Command('pm'); Subcommands get a name when specified using .command(). If you create the subcommand yourself to use with .addCommand(), then set the name using .name() or in the Command constructor. .usage This allows you to customise the usage description in the first line of the help. Given: program .name(\"my-command\") .usage(\"[global options] command\") The help will start with: Usage: my-command [global options] command .description and .summary The description appears in the help for the command. You can optionally supply a shorter summary to use when listed as a subcommand of the program. program .command(\"duplicate\") .summary(\"make a copy\") .description(`Make a copy of the current project. This may require additional disk space. `); .helpOption(flags, description) By default every command has a help option. You may change the default help flags and description. Pass false to disable the built-in help option. program .helpOption('-e, --HELP', 'read more information'); .addHelpCommand() A help command is added by default if your command has subcommands. You can explicitly turn on or off the implicit help command with .addHelpCommand() and .addHelpCommand(false). You can both turn on and customise the help command by supplying the name and description: program.addHelpCommand('assist [command]', 'show assistance'); More configuration The built-in help is formatted using the Help class. You can configure the Help behaviour by modifying data properties and methods using .configureHelp(), or by subclassing using .createHelp() if you prefer. The data properties are: helpWidth: specify the wrap width, useful for unit tests sortSubcommands: sort the subcommands alphabetically sortOptions: sort the options alphabetically showGlobalOptions: show a section with the global options from the parent command(s) You can override any method on the Help class. There are methods getting the visible lists of arguments, options, and subcommands. There are methods for formatting the items in the lists, with each item having a term and description. Take a look at .formatHelp() to see how they are used. Example file: configure-help.js program.configureHelp({ sortSubcommands: true, subcommandTerm: (cmd) => cmd.name() // Just show the name, instead of short usage. }); Custom event listeners You can execute custom actions by listening to command and option events. program.on('option:verbose', function () { process.env.VERBOSE = this.opts().verbose; }); Bits and pieces .parse() and .parseAsync() The first argument to .parse is the array of strings to parse. You may omit the parameter to implicitly use process.argv. If the arguments follow different conventions than node you can pass a from option in the second parameter: 'node': default, argv[0] is the application and argv[1] is the script being run, with user parameters after that 'electron': argv[1] varies depending on whether the electron application is packaged 'user': all of the arguments from the user For example: program.parse(process.argv); // Explicit, node conventions program.parse(); // Implicit, and auto-detect electron program.parse(['-f', 'filename'], { from: 'user' }); Parsing Configuration If the default parsing does not suit your needs, there are some behaviours to support other usage patterns. By default program options are recognised before and after subcommands. To only look for program options before subcommands, use .enablePositionalOptions(). This lets you use an option for a different purpose in subcommands. Example file: positional-options.js With positional options, the -b is a program option in the first line and a subcommand option in the second line: program -b subcommand program subcommand -b By default options are recognised before and after command-arguments. To only process options that come before the command-arguments, use .passThroughOptions(). This lets you pass the arguments and following options through to another program without needing to use -- to end the option processing. To use pass through options in a subcommand, the program needs to enable positional options. Example file: pass-through-options.js With pass through options, the --port=80 is a program option in the first line and passed through as a command-argument in the second line: program --port=80 arg program arg --port=80 By default the option processing shows an error for an unknown option. To have an unknown option treated as an ordinary command-argument and continue looking for options, use .allowUnknownOption(). This lets you mix known and unknown options. By default the argument processing does not display an error for more command-arguments than expected. To display an error for excess arguments, use.allowExcessArguments(false). Legacy options as properties Before Commander 7, the option values were stored as properties on the command. This was convenient to code but the downside was possible clashes with existing properties of Command. You can revert to the old behaviour to run unmodified legacy code by using .storeOptionsAsProperties(). program .storeOptionsAsProperties() .option('-d, --debug') .action((commandAndOptions) => { if (commandAndOptions.debug) { console.error(`Called ${commandAndOptions.name()}`); } }); TypeScript extra-typings: There is an optional project to infer extra type information from the option and argument definitions. This adds strong typing to the options returned by .opts() and the parameters to .action(). See commander-js/extra-typings for more. import { Command } from '@commander-js/extra-typings'; ts-node: If you use ts-node and stand-alone executable subcommands written as .ts files, you need to call your program through node to get the subcommands called correctly. e.g. node -r ts-node/register pm.ts createCommand() This factory function creates a new command. It is exported and may be used instead of using new, like: const { createCommand } = require('commander'); const program = createCommand(); createCommand is also a method of the Command object, and creates a new command rather than a subcommand. This gets used internally when creating subcommands using .command(), and you may override it to customise the new subcommand (example file custom-command-class.js). Node options such as --harmony You can enable --harmony option in two ways: Use #! /usr/bin/env node --harmony in the subcommands scripts. (Note Windows does not support this pattern.) Use the --harmony option when call the command, like node --harmony examples/pm publish. The --harmony option will be preserved when spawning subcommand process. Debugging stand-alone executable subcommands An executable subcommand is launched as a separate child process. If you are using the node inspector for debugging executable subcommands using node --inspect et al, the inspector port is incremented by 1 for the spawned subcommand. If you are using VSCode to debug executable subcommands you need to set the \"autoAttachChildProcesses\": true flag in your launch.json configuration. Display error This routine is available to invoke the Commander error handling for your own error conditions. (See also the next section about exit handling.) As well as the error message, you can optionally specify the exitCode (used with process.exit) and code (used with CommanderError). program.error('Password must be longer than four characters'); program.error('Custom processing has failed', { exitCode: 2, code: 'my.custom.error' }); Override exit and output handling By default Commander calls process.exit when it detects errors, or after displaying the help or version. You can override this behaviour and optionally supply a callback. The default override throws a CommanderError. The override callback is passed a CommanderError with properties exitCode number, code string, and message. The default override behaviour is to throw the error, except for async handling of executable subcommand completion which carries on. The normal display of error messages or version or help is not affected by the override which is called after the display. program.exitOverride(); try { program.parse(process.argv); } catch (err) { // custom processing... } By default Commander is configured for a command-line application and writes to stdout and stderr. You can modify this behaviour for custom applications. In addition, you can modify the display of error messages. Example file: configure-output.js function errorColor(str) { // Add ANSI escape codes to display text in red. return `\\x1b[31m${str}\\x1b[0m`; } program .configureOutput({ // Visibly override write routines as example! writeOut: (str) => process.stdout.write(`[OUT] ${str}`), writeErr: (str) => process.stdout.write(`[ERR] ${str}`), // Highlight errors in color. outputError: (str, write) => write(errorColor(str)) }); Additional documentation There is more information available about: deprecated features still supported for backwards compatibility options taking varying arguments parsing life cycle and hooks Support The current version of Commander is fully supported on Long Term Support versions of Node.js, and requires at least v14. (For older versions of Node.js, use an older version of Commander.) The main forum for free and community support is the project Issues on GitHub. Commander for enterprise Available as part of the Tidelift Subscription The maintainers of Commander and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "src/frontend/app-client/node_modules/compressible/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/compressible/HISTORY.html",
    "title": "2.0.18 / 2020-01-05",
    "summary": "2.0.18 / 2020-01-05 deps: mime-db@'>= 1.43.0 < 2' Mark font/ttf as compressible Remove compressible from multipart/mixed 2.0.17 / 2019-04-24 deps: mime-db@'>= 1.40.0 < 2' 2.0.16 / 2019-02-18 deps: mime-db@'>= 1.38.0 < 2' Mark text/less as compressible 2.0.15 / 2018-09-17 deps: mime-db@'>= 1.36.0 < 2' 2.0.14 / 2018-06-05 deps: mime-db@'>= 1.34.0 < 2' Mark all XML-derived types as compressible 2.0.13 / 2018-02-17 deps: mime-db@'>= 1.33.0 < 2' 2.0.12 / 2017-10-20 deps: mime-db@'>= 1.30.0 < 2' 2.0.11 / 2017-07-27 deps: mime-db@'>= 1.29.0 < 2' 2.0.10 / 2017-03-23 deps: mime-db@'>= 1.27.0 < 2' 2.0.9 / 2016-10-31 Fix regex fallback to not override compressible: false in db deps: mime-db@'>= 1.24.0 < 2' 2.0.8 / 2016-05-12 deps: mime-db@'>= 1.23.0 < 2' 2.0.7 / 2016-01-18 deps: mime-db@'>= 1.21.0 < 2' 2.0.6 / 2015-09-29 deps: mime-db@'>= 1.19.0 < 2' 2.0.5 / 2015-07-30 deps: mime-db@'>= 1.16.0 < 2' 2.0.4 / 2015-07-01 deps: mime-db@'>= 1.14.0 < 2' perf: enable strict mode 2.0.3 / 2015-06-08 Fix regex fallback to work if type exists, but is undefined perf: hoist regex declaration perf: use regex to extract mime deps: mime-db@'>= 1.13.0 < 2' 2.0.2 / 2015-01-31 deps: mime-db@'>= 1.1.2 < 2' 2.0.1 / 2014-09-28 deps: mime-db@1.x Add new mime types Add additional compressible Update charsets 2.0.0 / 2014-09-02 use mime-db remove .get() specifications are now private regex is now private stricter regex"
  },
  "src/frontend/app-client/node_modules/compressible/README.html": {
    "href": "src/frontend/app-client/node_modules/compressible/README.html",
    "title": "compressible",
    "summary": "compressible Compressible Content-Type / mime checking. Installation $ npm install compressible API var compressible = require('compressible') compressible(type) Checks if the given Content-Type is compressible. The type argument is expected to be a value MIME type or Content-Type string, though no validation is performed. The MIME is looked up in the mime-db and if there is compressible information in the database entry, that is returned. Otherwise, this module will fallback to true for the following types: text/* */*+json */*+text */*+xml If this module is not sure if a type is specifically compressible or specifically uncompressible, undefined is returned. compressible('text/html') // => true compressible('image/png') // => false License MIT"
  },
  "src/frontend/app-client/node_modules/compression/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/compression/HISTORY.html",
    "title": "1.8.0 / 2025-02-10",
    "summary": "1.8.0 / 2025-02-10 Use res.headersSent when available Replace _implicitHeader with writeHead property add brotli support for versions of node that support it Add the enforceEncoding option for requests without Accept-Encoding header 1.7.5 / 2024-10-31 deps: Replace accepts with negotiator@~0.6.4 Add preference option deps: bytes@3.1.2 Add petabyte (pb) support Fix \"thousandsSeparator\" incorrecting formatting fractional part Fix return value for un-parsable strings deps: compressible@~2.0.18 Mark font/ttf as compressible Remove compressible from multipart/mixed deps: mime-db@'>= 1.43.0 < 2' deps: safe-buffer@5.2.1 1.7.4 / 2019-03-18 deps: compressible@~2.0.16 Mark text/less as compressible deps: mime-db@'>= 1.38.0 < 2' deps: on-headers@~1.0.2 Fix res.writeHead patch missing return value perf: prevent unnecessary buffer copy 1.7.3 / 2018-07-15 deps: accepts@~1.3.5 deps: mime-types@~2.1.18 deps: compressible@~2.0.14 Mark all XML-derived types as compressible deps: mime-db@'>= 1.34.0 < 2' deps: safe-buffer@5.1.2 1.7.2 / 2018-02-18 deps: compressible@~2.0.13 deps: mime-db@'>= 1.33.0 < 2' 1.7.1 / 2017-09-26 deps: accepts@~1.3.4 deps: mime-types@~2.1.16 deps: bytes@3.0.0 deps: compressible@~2.0.11 deps: mime-db@'>= 1.29.0 < 2' deps: debug@2.6.9 deps: vary@~1.1.2 perf: improve header token parsing speed 1.7.0 / 2017-07-10 Use safe-buffer for improved Buffer API deps: bytes@2.5.0 deps: compressible@~2.0.10 Fix regex fallback to not override compressible: false in db deps: mime-db@'>= 1.27.0 < 2' deps: debug@2.6.8 Allow colors in workers Deprecated DEBUG_FD environment variable set to 3 or higher Fix error when running under React Native Fix DEBUG_MAX_ARRAY_LENGTH Use same color for same namespace deps: ms@2.0.0 deps: vary@~1.1.1 perf: hoist regular expression 1.6.2 / 2016-05-12 deps: accepts@~1.3.3 deps: mime-types@~2.1.11 deps: negotiator@0.6.1 deps: bytes@2.3.0 Drop partial bytes on all parsed units Fix parsing byte string that looks like hex perf: hoist regular expressions deps: compressible@~2.0.8 deps: mime-db@'>= 1.23.0 < 2' 1.6.1 / 2016-01-19 deps: bytes@2.2.0 deps: compressible@~2.0.7 deps: mime-db@'>= 1.21.0 < 2' deps: accepts@~1.3.1 deps: mime-types@~2.1.9 1.6.0 / 2015-09-29 Skip compression when response has Cache-Control: no-transform deps: accepts@~1.3.0 deps: mime-types@~2.1.7 deps: negotiator@0.6.0 deps: compressible@~2.0.6 deps: mime-db@'>= 1.19.0 < 2' deps: on-headers@~1.0.1 perf: enable strict mode deps: vary@~1.1.0 Only accept valid field names in the field argument 1.5.2 / 2015-07-30 deps: accepts@~1.2.12 deps: mime-types@~2.1.4 deps: compressible@~2.0.5 deps: mime-db@'>= 1.16.0 < 2' deps: vary@~1.0.1 Fix setting empty header from empty field perf: enable strict mode perf: remove argument reassignments 1.5.1 / 2015-07-05 deps: accepts@~1.2.10 deps: mime-types@~2.1.2 deps: compressible@~2.0.4 deps: mime-db@'>= 1.14.0 < 2' perf: enable strict mode 1.5.0 / 2015-06-09 Fix return value from .end and .write after end Improve detection of zero-length body without Content-Length deps: accepts@~1.2.9 deps: mime-types@~2.1.1 perf: avoid argument reassignment & argument slice perf: avoid negotiator recursive construction perf: enable strict mode perf: remove unnecessary bitwise operator deps: bytes@2.1.0 Slight optimizations Units no longer case sensitive when parsing deps: compressible@~2.0.3 Fix regex fallback to work if type exists, but is undefined deps: mime-db@'>= 1.13.0 < 2' perf: hoist regex declaration perf: use regex to extract mime perf: enable strict mode perf: remove flush reassignment perf: simplify threshold detection 1.4.4 / 2015-05-11 deps: accepts@~1.2.7 deps: mime-types@~2.0.11 deps: negotiator@0.5.3 deps: debug@~2.2.0 deps: ms@0.7.1 1.4.3 / 2015-03-14 deps: accepts@~1.2.5 deps: mime-types@~2.0.10 deps: debug@~2.1.3 Fix high intensity foreground color for bold deps: ms@0.7.0 1.4.2 / 2015-03-11 Fix error when code calls res.end(str, encoding) Specific to Node.js 0.8 deps: debug@~2.1.2 deps: ms@0.7.0 1.4.1 / 2015-02-15 deps: accepts@~1.2.4 deps: mime-types@~2.0.9 deps: negotiator@0.5.1 1.4.0 / 2015-02-01 Prefer gzip over deflate on the server Not all clients agree on what \"deflate\" coding means 1.3.1 / 2015-01-31 deps: accepts@~1.2.3 deps: mime-types@~2.0.8 deps: compressible@~2.0.2 deps: mime-db@'>= 1.1.2 < 2' 1.3.0 / 2014-12-30 Export the default filter function for wrapping deps: accepts@~1.2.2 deps: mime-types@~2.0.7 deps: negotiator@0.5.0 deps: debug@~2.1.1 1.2.2 / 2014-12-10 Fix .end to only proxy to .end Fixes an issue with Node.js 0.11.14 deps: accepts@~1.1.4 deps: mime-types@~2.0.4 1.2.1 / 2014-11-23 deps: accepts@~1.1.3 deps: mime-types@~2.0.3 1.2.0 / 2014-10-16 deps: debug@~2.1.0 Implement DEBUG_FD env variable support 1.1.2 / 2014-10-15 deps: accepts@~1.1.2 Fix error when media type has invalid parameter deps: negotiator@0.4.9 1.1.1 / 2014-10-12 deps: accepts@~1.1.1 deps: mime-types@~2.0.2 deps: negotiator@0.4.8 deps: compressible@~2.0.1 deps: mime-db@1.x 1.1.0 / 2014-09-07 deps: accepts@~1.1.0 deps: compressible@~2.0.0 deps: debug@~2.0.0 1.0.11 / 2014-08-10 deps: on-headers@~1.0.0 deps: vary@~1.0.0 1.0.10 / 2014-08-05 deps: compressible@~1.1.1 Fix upper-case Content-Type characters prevent compression 1.0.9 / 2014-07-20 Add debug messages deps: accepts@~1.0.7 deps: negotiator@0.4.7 1.0.8 / 2014-06-20 deps: accepts@~1.0.5 use mime-types 1.0.7 / 2014-06-11 use vary module for better Vary behavior deps: accepts@1.0.3 deps: compressible@1.1.0 1.0.6 / 2014-06-03 fix regression when negotiation fails 1.0.5 / 2014-06-03 fix listeners for delayed stream creation fixes regression for certain stream.pipe(res) situations 1.0.4 / 2014-06-03 fix adding Vary when value stored as array fix back-pressure behavior fix length check for res.end 1.0.3 / 2014-05-29 use accepts for negotiation use on-headers to handle header checking deps: bytes@1.0.0 1.0.2 / 2014-04-29 only version compatible with node.js 0.8 support headers given to res.writeHead deps: bytes@0.3.0 deps: negotiator@0.4.3 1.0.1 / 2014-03-08 bump negotiator use compressible use .headersSent (drops 0.8 support) handle identity;q=0 case"
  },
  "src/frontend/app-client/node_modules/compression/node_modules/debug/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/compression/node_modules/debug/CHANGELOG.html",
    "title": "2.6.9 / 2017-09-22",
    "summary": "2.6.9 / 2017-09-22 remove ReDoS regexp in %o formatter (#504) 2.6.8 / 2017-05-18 Fix: Check for undefined on browser globals (#462, @marbemac) 2.6.7 / 2017-05-16 Fix: Update ms to 2.0.0 to fix regular expression denial of service vulnerability (#458, @hubdotcom) Fix: Inline extend function in node implementation (#452, @dougwilson) Docs: Fix typo (#455, @msasad) 2.6.5 / 2017-04-27 Fix: null reference check on window.documentElement.style.WebkitAppearance (#447, @thebigredgeek) Misc: clean up browser reference checks (#447, @thebigredgeek) Misc: add npm-debug.log to .gitignore (@thebigredgeek) 2.6.4 / 2017-04-20 Fix: bug that would occure if process.env.DEBUG is a non-string value. (#444, @LucianBuzzo) Chore: ignore bower.json in npm installations. (#437, @joaovieira) Misc: update \"ms\" to v0.7.3 (@tootallnate) 2.6.3 / 2017-03-13 Fix: Electron reference to process.env.DEBUG (#431, @paulcbetts) Docs: Changelog fix (@thebigredgeek) 2.6.2 / 2017-03-10 Fix: DEBUG_MAX_ARRAY_LENGTH (#420, @slavaGanzin) Docs: Add backers and sponsors from Open Collective (#422, @piamancini) Docs: Add Slackin invite badge (@tootallnate) 2.6.1 / 2017-02-10 Fix: Module's export default syntax fix for IE8 Expected identifier error Fix: Whitelist DEBUG_FD for values 1 and 2 only (#415, @pi0) Fix: IE8 \"Expected identifier\" error (#414, @vgoma) Fix: Namespaces would not disable once enabled (#409, @musikov) 2.6.0 / 2016-12-28 Fix: added better null pointer checks for browser useColors (@thebigredgeek) Improvement: removed explicit window.debug export (#404, @tootallnate) Improvement: deprecated DEBUG_FD environment variable (#405, @tootallnate) 2.5.2 / 2016-12-25 Fix: reference error on window within webworkers (#393, @KlausTrainer) Docs: fixed README typo (#391, @lurch) Docs: added notice about v3 api discussion (@thebigredgeek) 2.5.1 / 2016-12-20 Fix: babel-core compatibility 2.5.0 / 2016-12-20 Fix: wrong reference in bower file (@thebigredgeek) Fix: webworker compatibility (@thebigredgeek) Fix: output formatting issue (#388, @kribblo) Fix: babel-loader compatibility (#383, @escwald) Misc: removed built asset from repo and publications (@thebigredgeek) Misc: moved source files to /src (#378, @yamikuronue) Test: added karma integration and replaced babel with browserify for browser tests (#378, @yamikuronue) Test: coveralls integration (#378, @yamikuronue) Docs: simplified language in the opening paragraph (#373, @yamikuronue) 2.4.5 / 2016-12-17 Fix: navigator undefined in Rhino (#376, @jochenberger) Fix: custom log function (#379, @hsiliev) Improvement: bit of cleanup + linting fixes (@thebigredgeek) Improvement: rm non-maintainted dist/ dir (#375, @freewil) Docs: simplified language in the opening paragraph. (#373, @yamikuronue) 2.4.4 / 2016-12-14 Fix: work around debug being loaded in preload scripts for electron (#368, @paulcbetts) 2.4.3 / 2016-12-14 Fix: navigation.userAgent error for react native (#364, @escwald) 2.4.2 / 2016-12-14 Fix: browser colors (#367, @tootallnate) Misc: travis ci integration (@thebigredgeek) Misc: added linting and testing boilerplate with sanity check (@thebigredgeek) 2.4.1 / 2016-12-13 Fix: typo that broke the package (#356) 2.4.0 / 2016-12-13 Fix: bower.json references unbuilt src entry point (#342, @justmatt) Fix: revert \"handle regex special characters\" (@tootallnate) Feature: configurable util.inspect()`options for NodeJS (#327, @tootallnate) Feature: %O`(big O) pretty-prints objects (#322, @tootallnate) Improvement: allow colors in workers (#335, @botverse) Improvement: use same color for same namespace. (#338, @lchenay) 2.3.3 / 2016-11-09 Fix: Catch JSON.stringify() errors (#195, Jovan Alleyne) Fix: Returning localStorage saved values (#331, Levi Thomason) Improvement: Don't create an empty object when no process (Nathan Rajlich) 2.3.2 / 2016-11-09 Fix: be super-safe in index.js as well (@TooTallNate) Fix: should check whether process exists (Tom Newby) 2.3.1 / 2016-11-09 Fix: Added electron compatibility (#324, @paulcbetts) Improvement: Added performance optimizations (@tootallnate) Readme: Corrected PowerShell environment variable example (#252, @gimre) Misc: Removed yarn lock file from source control (#321, @fengmk2) 2.3.0 / 2016-11-07 Fix: Consistent placement of ms diff at end of output (#215, @gorangajic) Fix: Escaping of regex special characters in namespace strings (#250, @zacronos) Fix: Fixed bug causing crash on react-native (#282, @vkarpov15) Feature: Enabled ES6+ compatible import via default export (#212 @bucaran) Feature: Added %O formatter to reflect Chrome's console.log capability (#279, @oncletom) Package: Update \"ms\" to 0.7.2 (#315, @DevSide) Package: removed superfluous version property from bower.json (#207 @kkirsche) Readme: fix USE_COLORS to DEBUG_COLORS Readme: Doc fixes for format string sugar (#269, @mlucool) Readme: Updated docs for DEBUG_FD and DEBUG_COLORS environment variables (#232, @mattlyons0) Readme: doc fixes for PowerShell (#271 #243, @exoticknight @unreadable) Readme: better docs for browser support (#224, @matthewmueller) Tooling: Added yarn integration for development (#317, @thebigredgeek) Misc: Renamed History.md to CHANGELOG.md (@thebigredgeek) Misc: Added license file (#226 #274, @CantemoInternal @sdaitzman) Misc: Updated contributors (@thebigredgeek) 2.2.0 / 2015-05-09 package: update \"ms\" to v0.7.1 (#202, @dougwilson) README: add logging to file example (#193, @DanielOchoa) README: fixed a typo (#191, @amir-s) browser: expose storage (#190, @stephenmathieson) Makefile: add a distclean target (#189, @stephenmathieson) 2.1.3 / 2015-03-13 Updated stdout/stderr example (#186) Updated example/stdout.js to match debug current behaviour Renamed example/stderr.js to stdout.js Update Readme.md (#184) replace high intensity foreground color for bold (#182, #183) 2.1.2 / 2015-03-01 dist: recompile update \"ms\" to v0.7.0 package: update \"browserify\" to v9.0.3 component: fix \"ms.js\" repo location changed bower package name updated documentation about using debug in a browser fix: security error on safari (#167, #168, @yields) 2.1.1 / 2014-12-29 browser: use typeof to check for console existence browser: check for console.log truthiness (fix IE 8/9) browser: add support for Chrome apps Readme: added Windows usage remarks Add bower.json to properly support bower install 2.1.0 / 2014-10-15 node: implement DEBUG_FD env variable support package: update \"browserify\" to v6.1.0 package: add \"license\" field to package.json (#135, @panuhorsmalahti) 2.0.0 / 2014-09-01 package: update \"browserify\" to v5.11.0 node: use stderr rather than stdout for logging (#29, @stephenmathieson) 1.0.4 / 2014-07-15 dist: recompile example: remove console.info() log usage example: add \"Content-Type\" UTF-8 header to browser example browser: place %c marker after the space character browser: reset the \"content\" color via color: inherit browser: add colors support for Firefox >= v31 debug: prefer an instance log() function over the global one (#119) Readme: update documentation about styled console logs for FF v31 (#116, @wryk) 1.0.3 / 2014-07-09 Add support for multiple wildcards in namespaces (#122, @seegno) browser: fix lint 1.0.2 / 2014-06-10 browser: update color palette (#113, @gscottolson) common: make console logging function configurable (#108, @timoxley) node: fix %o colors on old node <= 0.8.x Makefile: find node path using shell/which (#109, @timoxley) 1.0.1 / 2014-06-06 browser: use removeItem() to clear localStorage browser, node: don't set DEBUG if namespaces is undefined (#107, @leedm777) package: add \"contributors\" section node: fix comment typo README: list authors 1.0.0 / 2014-06-04 make ms diff be global, not be scope debug: ignore empty strings in enable() node: make DEBUG_COLORS able to disable coloring *: export the colors array npmignore: don't publish the dist dir Makefile: refactor to use browserify package: add \"browserify\" as a dev dependency Readme: add Web Inspector Colors section node: reset terminal color for the debug content node: map \"%o\" to util.inspect() browser: map \"%j\" to JSON.stringify() debug: add custom \"formatters\" debug: use \"ms\" module for humanizing the diff Readme: add \"bash\" syntax highlighting browser: add Firebug color support browser: add colors for WebKit browsers node: apply log to console rewrite: abstract common logic for Node & browsers add .jshintrc file 0.8.1 / 2014-04-14 package: re-add the \"component\" section 0.8.0 / 2014-03-30 add enable() method for nodejs. Closes #27 change from stderr to stdout remove unnecessary index.js file 0.7.4 / 2013-11-13 remove \"browserify\" key from package.json (fixes something in browserify) 0.7.3 / 2013-10-30 fix: catch localStorage security error when cookies are blocked (Chrome) add debug(err) support. Closes #46 add .browser prop to package.json. Closes #42 0.7.2 / 2013-02-06 fix package.json fix: Mobile Safari (private mode) is broken with debug fix: Use unicode to send escape character to shell instead of octal to work with strict mode javascript 0.7.1 / 2013-02-05 add repository URL to package.json add DEBUG_COLORED to force colored output add browserify support fix component. Closes #24 0.7.0 / 2012-05-04 Added .component to package.json Added debug.component.js build 0.6.0 / 2012-03-16 Added support for \"-\" prefix in DEBUG [Vinay Pulim] Added .enabled flag to the node version [TooTallNate] 0.5.0 / 2012-02-02 Added: humanize diffs. Closes #8 Added debug.disable() to the CS variant Removed padding. Closes #10 Fixed: persist client-side variant again. Closes #9 0.4.0 / 2012-02-01 Added browser variant support for older browsers [TooTallNate] Added debug.enable('project:*') to browser variant [TooTallNate] Added padding to diff (moved it to the right) 0.3.0 / 2012-01-26 Added millisecond diff when isatty, otherwise UTC string 0.2.0 / 2012-01-22 Added wildcard support 0.1.0 / 2011-12-02 Added: remove colors unless stderr isatty [TooTallNate] 0.0.1 / 2010-01-03 Initial release"
  },
  "src/frontend/app-client/node_modules/compression/node_modules/debug/README.html": {
    "href": "src/frontend/app-client/node_modules/compression/node_modules/debug/README.html",
    "title": "debug",
    "summary": "debug A tiny node.js debugging utility modelled after node core's debugging technique. Discussion around the V3 API is under way here Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %s', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var debug = require('debug')('worker'); setInterval(function(){ debug('doing some work'); }, 1000); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows note On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Note that PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Then, run the program to be debugged as usual. Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toUTCString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); Web Inspector Colors Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Colored output looks something like: Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2016 TJ Holowaychuk <tj@vision-media.ca&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/compression/node_modules/ms/license.html": {
    "href": "src/frontend/app-client/node_modules/compression/node_modules/ms/license.html",
    "title": "",
    "summary": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/compression/node_modules/ms/readme.html": {
    "href": "src/frontend/app-client/node_modules/compression/node_modules/ms/readme.html",
    "title": "ms",
    "summary": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 Convert from milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(ms('10 hours')) // \"10h\" Time format written-out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in node and in the browser. If a number is supplied to ms, a string with a unit is returned. If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100'). If you pass a string with a number and a valid unit, the number of equivalent ms is returned. Caught a bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, node will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "src/frontend/app-client/node_modules/compression/README.html": {
    "href": "src/frontend/app-client/node_modules/compression/README.html",
    "title": "compression",
    "summary": "compression Node.js compression middleware. The following compression codings are supported: deflate gzip br (brotli) Note Brotli is supported only since Node.js versions v11.7.0 and v10.16.0. Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install compression API var compression = require('compression') compression([options]) Returns the compression middleware using the given options. The middleware will attempt to compress response bodies for all requests that traverse through the middleware, based on the given options. This middleware will never compress responses that include a Cache-Control header with the no-transform directive, as compressing will transform the body. Options compression() accepts these properties in the options object. In addition to those listed below, zlib options may be passed in to the options object or brotli options. chunkSize Type: Number Default: zlib.constants.Z_DEFAULT_CHUNK, or 16384. See Node.js documentation regarding the usage. filter Type: Function A function to decide if the response should be considered for compression. This function is called as filter(req, res) and is expected to return true to consider the response for compression, or false to not compress the response. The default filter function uses the compressible module to determine if res.getHeader('Content-Type') is compressible. level Type: Number Default: zlib.constants.Z_DEFAULT_COMPRESSION, or -1 The level of zlib compression to apply to responses. A higher level will result in better compression, but will take longer to complete. A lower level will result in less compression, but will be much faster. This is an integer in the range of 0 (no compression) to 9 (maximum compression). The special value -1 can be used to mean the \"default compression level\", which is a default compromise between speed and compression (currently equivalent to level 6). -1 Default compression level (also zlib.constants.Z_DEFAULT_COMPRESSION). 0 No compression (also zlib.constants.Z_NO_COMPRESSION). 1 Fastest compression (also zlib.constants.Z_BEST_SPEED). 2 3 4 5 6 (currently what zlib.constants.Z_DEFAULT_COMPRESSION points to). 7 8 9 Best compression (also zlib.constants.Z_BEST_COMPRESSION). Note in the list above, zlib is from zlib = require('zlib'). memLevel Type: Number Default: zlib.constants.Z_DEFAULT_MEMLEVEL, or 8 This specifies how much memory should be allocated for the internal compression state and is an integer in the range of 1 (minimum level) and 9 (maximum level). See Node.js documentation regarding the usage. brotli Type: Object This specifies the options for configuring Brotli. See Node.js documentation for a complete list of available options. strategy Type: Number Default: zlib.constants.Z_DEFAULT_STRATEGY This is used to tune the compression algorithm. This value only affects the compression ratio, not the correctness of the compressed output, even if it is not set appropriately. zlib.constants.Z_DEFAULT_STRATEGY Use for normal data. zlib.constants.Z_FILTERED Use for data produced by a filter (or predictor). Filtered data consists mostly of small values with a somewhat random distribution. In this case, the compression algorithm is tuned to compress them better. The effect is to force more Huffman coding and less string matching; it is somewhat intermediate between zlib.constants.Z_DEFAULT_STRATEGY and zlib.constants.Z_HUFFMAN_ONLY. zlib.constants.Z_FIXED Use to prevent the use of dynamic Huffman codes, allowing for a simpler decoder for special applications. zlib.constants.Z_HUFFMAN_ONLY Use to force Huffman encoding only (no string match). zlib.constants.Z_RLE Use to limit match distances to one (run-length encoding). This is designed to be almost as fast as zlib.constants.Z_HUFFMAN_ONLY, but give better compression for PNG image data. Note in the list above, zlib is from zlib = require('zlib'). threshold Type: Number or String Default: 1kb The byte threshold for the response body size before compression is considered for the response. This is a number of bytes or any string accepted by the bytes module. Note this is only an advisory setting; if the response size cannot be determined at the time the response headers are written, then it is assumed the response is over the threshold. To guarantee the response size can be determined, be sure set a Content-Length response header. windowBits Type: Number Default: zlib.constants.Z_DEFAULT_WINDOWBITS, or 15 See Node.js documentation regarding the usage. enforceEncoding Type: String Default: identity This is the default encoding to use when the client does not specify an encoding in the request's Accept-Encoding header. .filter The default filter function. This is used to construct a custom filter function that is an extension of the default function. var compression = require('compression') var express = require('express') var app = express() app.use(compression({ filter: shouldCompress })) function shouldCompress (req, res) { if (req.headers['x-no-compression']) { // don't compress responses with this request header return false } // fallback to standard filter function return compression.filter(req, res) } res.flush This module adds a res.flush() method to force the partially-compressed response to be flushed to the client. Examples express When using this module with express, simply app.use the module as high as you like. Requests that pass through the middleware will be compressed. var compression = require('compression') var express = require('express') var app = express() // compress all responses app.use(compression()) // add all routes Node.js HTTP server var compression = require('compression')({ threshold: 0 }) var http = require('http') function createServer (fn) { return http.createServer(function (req, res) { compression(req, res, function (err) { if (err) { res.statusCode = err.status || 500 res.end(err.message) return } fn(req, res) }) }) } var server = createServer(function (req, res) { res.setHeader('Content-Type', 'text/plain') res.end('hello world!') }) server.listen(3000, () => { console.log('> Listening at http://localhost:3000') }) Server-Sent Events Because of the nature of compression this module does not work out of the box with server-sent events. To compress content, a window of the output needs to be buffered up in order to get good compression. Typically when using server-sent events, there are certain block of data that need to reach the client. You can achieve this by calling res.flush() when you need the data written to actually make it to the client. var compression = require('compression') var express = require('express') var app = express() // compress responses app.use(compression()) // server-sent event stream app.get('/events', function (req, res) { res.setHeader('Content-Type', 'text/event-stream') res.setHeader('Cache-Control', 'no-cache') // send a ping approx every 2 seconds var timer = setInterval(function () { res.write('data: ping\\n\\n') // !!! this is the important part res.flush() }, 2000) res.on('close', function () { clearInterval(timer) }) }) Contributing The Express.js project welcomes all constructive contributions. Contributions take many forms, from code for bug fixes and enhancements, to additions and fixes to documentation, additional tests, triaging incoming pull requests and issues, and more! See the Contributing Guide for more technical details on contributing. License MIT"
  },
  "src/frontend/app-client/node_modules/concat-stream/readme.html": {
    "href": "src/frontend/app-client/node_modules/concat-stream/readme.html",
    "title": "concat-stream",
    "summary": "concat-stream Writable stream that concatenates all the data from a stream and calls a callback with the result. Use this when you want to collect all the data from a stream into a single buffer. description Streams emit many buffers. If you want to collect all of the buffers, and when the stream ends concatenate all of the buffers together and receive a single buffer then this is the module for you. Only use this if you know you can fit all of the output of your stream into a single Buffer (e.g. in RAM). There are also objectMode streams that emit things other than Buffers, and you can concatenate these too. See below for details. Related concat-stream is part of the mississippi stream utility collection which includes more useful stream modules similar to this one. examples Buffers var fs = require('fs') var concat = require('concat-stream') var readStream = fs.createReadStream('cat.png') var concatStream = concat(gotPicture) readStream.on('error', handleError) readStream.pipe(concatStream) function gotPicture(imageBuffer) { // imageBuffer is all of `cat.png` as a node.js Buffer } function handleError(err) { // handle your error appropriately here, e.g.: console.error(err) // print the error to STDERR process.exit(1) // exit program with non-zero exit code } Arrays var write = concat(function(data) {}) write.write([1,2,3]) write.write([4,5,6]) write.end() // data will be [1,2,3,4,5,6] in the above callback Uint8Arrays var write = concat(function(data) {}) var a = new Uint8Array(3) a[0] = 97; a[1] = 98; a[2] = 99 write.write(a) write.write('!') write.end(Buffer.from('!!1')) See test/ for more examples methods var concat = require('concat-stream') var writable = concat(opts={}, cb) Return a writable stream that will fire cb(data) with all of the data that was written to the stream. Data can be written to writable as strings, Buffers, arrays of byte integers, and Uint8Arrays. By default concat-stream will give you back the same data type as the type of the first buffer written to the stream. Use opts.encoding to set what format data should be returned as, e.g. if you if you don't want to rely on the built-in type checking or for some other reason. string - get a string buffer - get back a Buffer array - get an array of byte integers uint8array, u8, uint8 - get back a Uint8Array object, get back an array of Objects If you don't specify an encoding, and the types can't be inferred (e.g. you write things that aren't in the list above), it will try to convert concat them into a Buffer. If nothing is written to writable then data will be an empty array []. error handling concat-stream does not handle errors for you, so you must handle errors on whatever streams you pipe into concat-stream. This is a general rule when programming with node.js streams: always handle errors on each and every stream. Since concat-stream is not itself a stream it does not emit errors. We recommend using end-of-stream or pump for writing error tolerant stream code. license MIT LICENSE"
  },
  "src/frontend/app-client/node_modules/content-disposition/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/content-disposition/HISTORY.html",
    "title": "0.5.4 / 2021-12-10",
    "summary": "0.5.4 / 2021-12-10 deps: safe-buffer@5.2.1 0.5.3 / 2018-12-17 Use safe-buffer for improved Buffer API 0.5.2 / 2016-12-08 Fix parse to accept any linear whitespace character 0.5.1 / 2016-01-17 perf: enable strict mode 0.5.0 / 2014-10-11 Add parse function 0.4.0 / 2014-09-21 Expand non-Unicode filename to the full ISO-8859-1 charset 0.3.0 / 2014-09-20 Add fallback option Add type option 0.2.0 / 2014-09-19 Reduce ambiguity of file names with hex escape in buggy browsers 0.1.2 / 2014-09-19 Fix periodic invalid Unicode filename header 0.1.1 / 2014-09-19 Fix invalid characters appearing in filename* parameter 0.1.0 / 2014-09-18 Make the filename argument optional 0.0.0 / 2014-09-18 Initial release"
  },
  "src/frontend/app-client/node_modules/content-disposition/README.html": {
    "href": "src/frontend/app-client/node_modules/content-disposition/README.html",
    "title": "content-disposition",
    "summary": "content-disposition Create and parse HTTP Content-Disposition header Installation $ npm install content-disposition API var contentDisposition = require('content-disposition') contentDisposition(filename, options) Create an attachment Content-Disposition header value using the given file name, if supplied. The filename is optional and if no file name is desired, but you want to specify options, set filename to undefined. res.setHeader('Content-Disposition', contentDisposition('∫ maths.pdf')) note HTTP headers are of the ISO-8859-1 character set. If you are writing this header through a means different from setHeader in Node.js, you'll want to specify the 'binary' encoding in Node.js. Options contentDisposition accepts these properties in the options object. fallback If the filename option is outside ISO-8859-1, then the file name is actually stored in a supplemental field for clients that support Unicode file names and a ISO-8859-1 version of the file name is automatically generated. This specifies the ISO-8859-1 file name to override the automatic generation or disables the generation all together, defaults to true. A string will specify the ISO-8859-1 file name to use in place of automatic generation. false will disable including a ISO-8859-1 file name and only include the Unicode version (unless the file name is already ISO-8859-1). true will enable automatic generation if the file name is outside ISO-8859-1. If the filename option is ISO-8859-1 and this option is specified and has a different value, then the filename option is encoded in the extended field and this set as the fallback field, even though they are both ISO-8859-1. type Specifies the disposition type, defaults to \"attachment\". This can also be \"inline\", or any other value (all values except inline are treated like attachment, but can convey additional information if both parties agree to it). The type is normalized to lower-case. contentDisposition.parse(string) var disposition = contentDisposition.parse('attachment; filename=\"EURO rates.txt\"; filename*=UTF-8\\'\\'%e2%82%ac%20rates.txt') Parse a Content-Disposition header string. This automatically handles extended (\"Unicode\") parameters by decoding them and providing them under the standard parameter name. This will return an object with the following properties (examples are shown for the string 'attachment; filename=\"EURO rates.txt\"; filename*=UTF-8\\'\\'%e2%82%ac%20rates.txt'): type: The disposition type (always lower case). Example: 'attachment' parameters: An object of the parameters in the disposition (name of parameter always lower case and extended versions replace non-extended versions). Example: {filename: \"€ rates.txt\"} Examples Send a file for download var contentDisposition = require('content-disposition') var destroy = require('destroy') var fs = require('fs') var http = require('http') var onFinished = require('on-finished') var filePath = '/path/to/public/plans.pdf' http.createServer(function onRequest (req, res) { // set headers res.setHeader('Content-Type', 'application/pdf') res.setHeader('Content-Disposition', contentDisposition(filePath)) // send file var stream = fs.createReadStream(filePath) stream.pipe(res) onFinished(res, function () { destroy(stream) }) }) Testing $ npm test References RFC 2616: Hypertext Transfer Protocol -- HTTP/1.1 RFC 5987: Character Set and Language Encoding for Hypertext Transfer Protocol (HTTP) Header Field Parameters RFC 6266: Use of the Content-Disposition Header Field in the Hypertext Transfer Protocol (HTTP) Test Cases for HTTP Content-Disposition header field (RFC 6266) and the Encodings defined in RFCs 2047, 2231 and 5987 License MIT"
  },
  "src/frontend/app-client/node_modules/content-type/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/content-type/HISTORY.html",
    "title": "1.0.5 / 2023-01-29",
    "summary": "1.0.5 / 2023-01-29 perf: skip value escaping when unnecessary 1.0.4 / 2017-09-11 perf: skip parameter parsing when no parameters 1.0.3 / 2017-09-10 perf: remove argument reassignment 1.0.2 / 2016-05-09 perf: enable strict mode 1.0.1 / 2015-02-13 Improve missing Content-Type header error message 1.0.0 / 2015-02-01 Initial implementation, derived from media-typer@0.3.0"
  },
  "src/frontend/app-client/node_modules/content-type/README.html": {
    "href": "src/frontend/app-client/node_modules/content-type/README.html",
    "title": "content-type",
    "summary": "content-type Create and parse HTTP Content-Type header according to RFC 7231 Installation $ npm install content-type API var contentType = require('content-type') contentType.parse(string) var obj = contentType.parse('image/svg+xml; charset=utf-8') Parse a Content-Type header. This will return an object with the following properties (examples are shown for the string 'image/svg+xml; charset=utf-8'): type: The media type (the type and subtype, always lower case). Example: 'image/svg+xml' parameters: An object of the parameters in the media type (name of parameter always lower case). Example: {charset: 'utf-8'} Throws a TypeError if the string is missing or invalid. contentType.parse(req) var obj = contentType.parse(req) Parse the Content-Type header from the given req. Short-cut for contentType.parse(req.headers['content-type']). Throws a TypeError if the Content-Type header is missing or invalid. contentType.parse(res) var obj = contentType.parse(res) Parse the Content-Type header set on the given res. Short-cut for contentType.parse(res.getHeader('content-type')). Throws a TypeError if the Content-Type header is missing or invalid. contentType.format(obj) var str = contentType.format({ type: 'image/svg+xml', parameters: { charset: 'utf-8' } }) Format an object into a Content-Type header. This will return a string of the content type for the given object with the following properties (examples are shown that produce the string 'image/svg+xml; charset=utf-8'): type: The media type (will be lower-cased). Example: 'image/svg+xml' parameters: An object of the parameters in the media type (name of the parameter will be lower-cased). Example: {charset: 'utf-8'} Throws a TypeError if the object contains an invalid type or parameter names. License MIT"
  },
  "src/frontend/app-client/node_modules/convert-source-map/README.html": {
    "href": "src/frontend/app-client/node_modules/convert-source-map/README.html",
    "title": "convert-source-map",
    "summary": "convert-source-map Converts a source-map from/to different formats and allows adding/changing properties. var convert = require('convert-source-map'); var json = convert .fromComment('//# sourceMappingURL=data:application/json;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoiYnVpbGQvZm9vLm1pbi5qcyIsInNvdXJjZXMiOlsic3JjL2Zvby5qcyJdLCJuYW1lcyI6W10sIm1hcHBpbmdzIjoiQUFBQSIsInNvdXJjZVJvb3QiOiIvIn0=') .toJSON(); var modified = convert .fromComment('//# sourceMappingURL=data:application/json;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoiYnVpbGQvZm9vLm1pbi5qcyIsInNvdXJjZXMiOlsic3JjL2Zvby5qcyJdLCJuYW1lcyI6W10sIm1hcHBpbmdzIjoiQUFBQSIsInNvdXJjZVJvb3QiOiIvIn0=') .setProperty('sources', [ 'SRC/FOO.JS' ]) .toJSON(); console.log(json); console.log(modified); {\"version\":3,\"file\":\"build/foo.min.js\",\"sources\":[\"src/foo.js\"],\"names\":[],\"mappings\":\"AAAA\",\"sourceRoot\":\"/\"} {\"version\":3,\"file\":\"build/foo.min.js\",\"sources\":[\"SRC/FOO.JS\"],\"names\":[],\"mappings\":\"AAAA\",\"sourceRoot\":\"/\"} Upgrading Prior to v2.0.0, the fromMapFileComment and fromMapFileSource functions took a String directory path and used that to resolve & read the source map file from the filesystem. However, this made the library limited to nodejs environments and broke on sources with querystrings. In v2.0.0, you now need to pass a function that does the file reading. It will receive the source filename as a String that you can resolve to a filesystem path, URL, or anything else. If you are using convert-source-map in nodejs and want the previous behavior, you'll use a function like such: + var fs = require('fs'); // Import the fs module to read a file + var path = require('path'); // Import the path module to resolve a path against your directory - var conv = convert.fromMapFileSource(css, '../my-dir'); + var conv = convert.fromMapFileSource(css, function (filename) { + return fs.readFileSync(path.resolve('../my-dir', filename), 'utf-8'); + }); API fromObject(obj) Returns source map converter from given object. fromJSON(json) Returns source map converter from given json string. fromURI(uri) Returns source map converter from given uri encoded json string. fromBase64(base64) Returns source map converter from given base64 encoded json string. fromComment(comment) Returns source map converter from given base64 or uri encoded json string prefixed with //# sourceMappingURL=.... fromMapFileComment(comment, readMap) Returns source map converter from given filename by parsing //# sourceMappingURL=filename. readMap must be a function which receives the source map filename and returns either a String or Buffer of the source map (if read synchronously), or a Promise containing a String or Buffer of the source map (if read asynchronously). If readMap doesn't return a Promise, fromMapFileComment will return a source map converter synchronously. If readMap returns a Promise, fromMapFileComment will also return Promise. The Promise will be either resolved with the source map converter or rejected with an error. Examples Synchronous read in Node.js: var convert = require('convert-source-map'); var fs = require('fs'); function readMap(filename) { return fs.readFileSync(filename, 'utf8'); } var json = convert .fromMapFileComment('//# sourceMappingURL=map-file-comment.css.map', readMap) .toJSON(); console.log(json); Asynchronous read in Node.js: var convert = require('convert-source-map'); var { promises: fs } = require('fs'); // Notice the `promises` import function readMap(filename) { return fs.readFile(filename, 'utf8'); } var converter = await convert.fromMapFileComment('//# sourceMappingURL=map-file-comment.css.map', readMap) var json = converter.toJSON(); console.log(json); Asynchronous read in the browser: var convert = require('convert-source-map'); async function readMap(url) { const res = await fetch(url); return res.text(); } const converter = await convert.fromMapFileComment('//# sourceMappingURL=map-file-comment.css.map', readMap) var json = converter.toJSON(); console.log(json); fromSource(source) Finds last sourcemap comment in file and returns source map converter or returns null if no source map comment was found. fromMapFileSource(source, readMap) Finds last sourcemap comment in file and returns source map converter or returns null if no source map comment was found. readMap must be a function which receives the source map filename and returns either a String or Buffer of the source map (if read synchronously), or a Promise containing a String or Buffer of the source map (if read asynchronously). If readMap doesn't return a Promise, fromMapFileSource will return a source map converter synchronously. If readMap returns a Promise, fromMapFileSource will also return Promise. The Promise will be either resolved with the source map converter or rejected with an error. toObject() Returns a copy of the underlying source map. toJSON([space]) Converts source map to json string. If space is given (optional), this will be passed to JSON.stringify when the JSON string is generated. toURI() Converts source map to uri encoded json string. toBase64() Converts source map to base64 encoded json string. toComment([options]) Converts source map to an inline comment that can be appended to the source-file. By default, the comment is formatted like: //# sourceMappingURL=..., which you would normally see in a JS source file. When options.encoding == 'uri', the data will be uri encoded, otherwise they will be base64 encoded. When options.multiline == true, the comment is formatted like: /*# sourceMappingURL=... */, which you would find in a CSS source file. addProperty(key, value) Adds given property to the source map. Throws an error if property already exists. setProperty(key, value) Sets given property to the source map. If property doesn't exist it is added, otherwise its value is updated. getProperty(key) Gets given property of the source map. removeComments(src) Returns src with all source map comments removed removeMapFileComments(src) Returns src with all source map comments pointing to map files removed. commentRegex Provides a fresh RegExp each time it is accessed. Can be used to find source map comments. Breaks down a source map comment into groups: Groups: 1: media type, 2: MIME type, 3: charset, 4: encoding, 5: data. mapFileCommentRegex Provides a fresh RegExp each time it is accessed. Can be used to find source map comments pointing to map files. generateMapFileComment(file, [options]) Returns a comment that links to an external source map via file. By default, the comment is formatted like: //# sourceMappingURL=..., which you would normally see in a JS source file. When options.multiline == true, the comment is formatted like: /*# sourceMappingURL=... */, which you would find in a CSS source file."
  },
  "src/frontend/app-client/node_modules/cookie-signature/History.html": {
    "href": "src/frontend/app-client/node_modules/cookie-signature/History.html",
    "title": "1.0.6 / 2015-02-03",
    "summary": "1.0.6 / 2015-02-03 use npm test instead of make test to run tests clearer assertion messages when checking input 1.0.5 / 2014-09-05 add license to package.json 1.0.4 / 2014-06-25 corrected avoidance of timing attacks (thanks @tenbits!) 1.0.3 / 2014-01-28 [incorrect] fix for timing attacks 1.0.2 / 2014-01-28 fix missing repository warning fix typo in test 1.0.1 / 2013-04-15 Revert \"Changed underlying HMAC algo. to sha512.\" Revert \"Fix for timing attacks on MAC verification.\" 0.0.1 / 2010-01-03 Initial release"
  },
  "src/frontend/app-client/node_modules/cookie-signature/Readme.html": {
    "href": "src/frontend/app-client/node_modules/cookie-signature/Readme.html",
    "title": "cookie-signature",
    "summary": "cookie-signature Sign and unsign cookies. Example var cookie = require('cookie-signature'); var val = cookie.sign('hello', 'tobiiscool'); val.should.equal('hello.DGDUkGlIkCzPz+C0B064FNgHdEjox7ch8tOBGslZ5QI'); var val = cookie.sign('hello', 'tobiiscool'); cookie.unsign(val, 'tobiiscool').should.equal('hello'); cookie.unsign(val, 'luna').should.be.false; License (The MIT License) Copyright (c) 2012 LearnBoost <tj@learnboost.com&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/cookie/README.html": {
    "href": "src/frontend/app-client/node_modules/cookie/README.html",
    "title": "cookie",
    "summary": "cookie Basic HTTP cookie parser and serializer for HTTP servers. Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install cookie API var cookie = require('cookie'); cookie.parse(str, options) Parse an HTTP Cookie header string and returning an object of all cookie name-value pairs. The str argument is the string representing a Cookie header value and options is an optional object containing additional parsing options. var cookies = cookie.parse('foo=bar; equation=E%3Dmc%5E2'); // { foo: 'bar', equation: 'E=mc^2' } Options cookie.parse accepts these properties in the options object. decode Specifies a function that will be used to decode a cookie's value. Since the value of a cookie has a limited character set (and must be a simple string), this function can be used to decode a previously-encoded cookie value into a JavaScript string or other object. The default function is the global decodeURIComponent, which will decode any URL-encoded sequences into their byte representations. note if an error is thrown from this function, the original, non-decoded cookie value will be returned as the cookie's value. cookie.serialize(name, value, options) Serialize a cookie name-value pair into a Set-Cookie header string. The name argument is the name for the cookie, the value argument is the value to set the cookie to, and the options argument is an optional object containing additional serialization options. var setCookie = cookie.serialize('foo', 'bar'); // foo=bar Options cookie.serialize accepts these properties in the options object. domain Specifies the value for the Domain Set-Cookie attribute. By default, no domain is set, and most clients will consider the cookie to apply to only the current domain. encode Specifies a function that will be used to encode a cookie's value. Since value of a cookie has a limited character set (and must be a simple string), this function can be used to encode a value into a string suited for a cookie's value. The default function is the global encodeURIComponent, which will encode a JavaScript string into UTF-8 byte sequences and then URL-encode any that fall outside of the cookie range. expires Specifies the Date object to be the value for the Expires Set-Cookie attribute. By default, no expiration is set, and most clients will consider this a \"non-persistent cookie\" and will delete it on a condition like exiting a web browser application. note the cookie storage model specification states that if both expires and maxAge are set, then maxAge takes precedence, but it is possible not all clients by obey this, so if both are set, they should point to the same date and time. httpOnly Specifies the boolean value for the HttpOnly Set-Cookie attribute. When truthy, the HttpOnly attribute is set, otherwise it is not. By default, the HttpOnly attribute is not set. note be careful when setting this to true, as compliant clients will not allow client-side JavaScript to see the cookie in document.cookie. maxAge Specifies the number (in seconds) to be the value for the Max-Age Set-Cookie attribute. The given number will be converted to an integer by rounding down. By default, no maximum age is set. note the cookie storage model specification states that if both expires and maxAge are set, then maxAge takes precedence, but it is possible not all clients by obey this, so if both are set, they should point to the same date and time. partitioned Specifies the boolean value for the Partitioned Set-Cookie attribute. When truthy, the Partitioned attribute is set, otherwise it is not. By default, the Partitioned attribute is not set. note This is an attribute that has not yet been fully standardized, and may change in the future. This also means many clients may ignore this attribute until they understand it. More information about can be found in the proposal. path Specifies the value for the Path Set-Cookie attribute. By default, the path is considered the \"default path\". priority Specifies the string to be the value for the Priority Set-Cookie attribute. 'low' will set the Priority attribute to Low. 'medium' will set the Priority attribute to Medium, the default priority when not set. 'high' will set the Priority attribute to High. More information about the different priority levels can be found in the specification. note This is an attribute that has not yet been fully standardized, and may change in the future. This also means many clients may ignore this attribute until they understand it. sameSite Specifies the boolean or string to be the value for the SameSite Set-Cookie attribute. true will set the SameSite attribute to Strict for strict same site enforcement. false will not set the SameSite attribute. 'lax' will set the SameSite attribute to Lax for lax same site enforcement. 'none' will set the SameSite attribute to None for an explicit cross-site cookie. 'strict' will set the SameSite attribute to Strict for strict same site enforcement. More information about the different enforcement levels can be found in the specification. note This is an attribute that has not yet been fully standardized, and may change in the future. This also means many clients may ignore this attribute until they understand it. secure Specifies the boolean value for the Secure Set-Cookie attribute. When truthy, the Secure attribute is set, otherwise it is not. By default, the Secure attribute is not set. note be careful when setting this to true, as compliant clients will not send the cookie back to the server in the future if the browser does not have an HTTPS connection. Example The following example uses this module in conjunction with the Node.js core HTTP server to prompt a user for their name and display it back on future visits. var cookie = require('cookie'); var escapeHtml = require('escape-html'); var http = require('http'); var url = require('url'); function onRequest(req, res) { // Parse the query string var query = url.parse(req.url, true, true).query; if (query && query.name) { // Set a new cookie with the name res.setHeader('Set-Cookie', cookie.serialize('name', String(query.name), { httpOnly: true, maxAge: 60 * 60 * 24 * 7 // 1 week })); // Redirect back after setting cookie res.statusCode = 302; res.setHeader('Location', req.headers.referer || '/'); res.end(); return; } // Parse the cookies on the request var cookies = cookie.parse(req.headers.cookie || ''); // Get the visitor name set in the cookie var name = cookies.name; res.setHeader('Content-Type', 'text/html; charset=UTF-8'); if (name) { res.write('<p>Welcome back, <b>' + escapeHtml(name) + '</b>!</p>'); } else { res.write('<p>Hello, new visitor!</p>'); } res.write('<form method=\"GET\">'); res.write('<input placeholder=\"enter your name\" name=\"name\"> <input type=\"submit\" value=\"Set Name\">'); res.end('</form>'); } http.createServer(onRequest).listen(3000); Testing $ npm test Benchmark $ npm run bench > cookie@0.5.0 bench > node benchmark/index.js node@18.18.2 acorn@8.10.0 ada@2.6.0 ares@1.19.1 brotli@1.0.9 cldr@43.1 icu@73.2 llhttp@6.0.11 modules@108 napi@9 nghttp2@1.57.0 nghttp3@0.7.0 ngtcp2@0.8.1 openssl@3.0.10+quic simdutf@3.2.14 tz@2023c undici@5.26.3 unicode@15.0 uv@1.44.2 uvwasi@0.0.18 v8@10.2.154.26-node.26 zlib@1.2.13.1-motley > node benchmark/parse-top.js cookie.parse - top sites 14 tests completed. parse accounts.google.com x 2,588,913 ops/sec ±0.74% (186 runs sampled) parse apple.com x 2,370,002 ops/sec ±0.69% (186 runs sampled) parse cloudflare.com x 2,213,102 ops/sec ±0.88% (188 runs sampled) parse docs.google.com x 2,194,157 ops/sec ±1.03% (184 runs sampled) parse drive.google.com x 2,265,084 ops/sec ±0.79% (187 runs sampled) parse en.wikipedia.org x 457,099 ops/sec ±0.81% (186 runs sampled) parse linkedin.com x 504,407 ops/sec ±0.89% (186 runs sampled) parse maps.google.com x 1,230,959 ops/sec ±0.98% (186 runs sampled) parse microsoft.com x 926,294 ops/sec ±0.88% (184 runs sampled) parse play.google.com x 2,311,338 ops/sec ±0.83% (185 runs sampled) parse support.google.com x 1,508,850 ops/sec ±0.86% (186 runs sampled) parse www.google.com x 1,022,582 ops/sec ±1.32% (182 runs sampled) parse youtu.be x 332,136 ops/sec ±1.02% (185 runs sampled) parse youtube.com x 323,833 ops/sec ±0.77% (183 runs sampled) > node benchmark/parse.js cookie.parse - generic 6 tests completed. simple x 3,214,032 ops/sec ±1.61% (183 runs sampled) decode x 587,237 ops/sec ±1.16% (187 runs sampled) unquote x 2,954,618 ops/sec ±1.35% (183 runs sampled) duplicates x 857,008 ops/sec ±0.89% (187 runs sampled) 10 cookies x 292,133 ops/sec ±0.89% (187 runs sampled) 100 cookies x 22,610 ops/sec ±0.68% (187 runs sampled) References RFC 6265: HTTP State Management Mechanism Same-site Cookies License MIT"
  },
  "src/frontend/app-client/node_modules/cookie/SECURITY.html": {
    "href": "src/frontend/app-client/node_modules/cookie/SECURITY.html",
    "title": "Security Policies and Procedures",
    "summary": "Security Policies and Procedures Reporting a Bug The cookie team and community take all security bugs seriously. Thank you for improving the security of the project. We appreciate your efforts and responsible disclosure and will make every effort to acknowledge your contributions. Report security bugs by emailing the current owner(s) of cookie. This information can be found in the npm registry using the command npm owner ls cookie. If unsure or unable to get the information from the above, open an issue in the project issue tracker asking for the current contact information. To ensure the timely response to your report, please ensure that the entirety of the report is contained within the email body and not solely behind a web link or an attachment. At least one owner will acknowledge your email within 48 hours, and will send a more detailed response within 48 hours indicating the next steps in handling your report. After the initial reply to your report, the owners will endeavor to keep you informed of the progress towards a fix and full announcement, and may ask for additional information or guidance."
  },
  "src/frontend/app-client/node_modules/core-util-is/README.html": {
    "href": "src/frontend/app-client/node_modules/core-util-is/README.html",
    "title": "core-util-is",
    "summary": "core-util-is The util.is* functions introduced in Node v0.12."
  },
  "src/frontend/app-client/node_modules/cosmiconfig/node_modules/yaml/README.html": {
    "href": "src/frontend/app-client/node_modules/cosmiconfig/node_modules/yaml/README.html",
    "title": "YAML",
    "summary": "YAML yaml is a JavaScript parser and stringifier for YAML, a human friendly data serialization standard. It supports both parsing and stringifying data using all versions of YAML, along with all common data schemas. As a particularly distinguishing feature, yaml fully supports reading and writing comments and blank lines in YAML documents. The library is released under the ISC open source license, and the code is available on GitHub. It has no external dependencies and runs on Node.js 6 and later, and in browsers from IE 11 upwards. For the purposes of versioning, any changes that break any of the endpoints or APIs documented here will be considered semver-major breaking changes. Undocumented library internals may change between minor versions, and previous APIs may be deprecated (but not removed). For more information, see the project's documentation site: eemeli.org/yaml/v1 To install: npm install yaml Note: This is yaml@1. You may also be interested in the next version, currently available as yaml@next. API Overview The API provided by yaml has three layers, depending on how deep you need to go: Parse & Stringify, Documents, and the CST Parser. The first has the simplest API and \"just works\", the second gets you all the bells and whistles supported by the library along with a decent AST, and the third is the closest to YAML source, making it fast, raw, and crude. import YAML from 'yaml' // or const YAML = require('yaml') Parse & Stringify YAML.parse(str, options): value YAML.stringify(value, options): string YAML Documents YAML.createNode(value, wrapScalars, tag): Node YAML.defaultOptions YAML.Document constructor(options) defaults #anchors #contents #errors YAML.parseAllDocuments(str, options): YAML.Document[] YAML.parseDocument(str, options): YAML.Document import { Pair, YAMLMap, YAMLSeq } from 'yaml/types' new Pair(key, value) new YAMLMap() new YAMLSeq() CST Parser import parseCST from 'yaml/parse-cst' parseCST(str): CSTDocument[] YAML.parseCST(str): CSTDocument[] YAML.parse # file.yml YAML: - A human-readable data serialization language - https://en.wikipedia.org/wiki/YAML yaml: - A complete JavaScript implementation - https://www.npmjs.com/package/yaml import fs from 'fs' import YAML from 'yaml' YAML.parse('3.14159') // 3.14159 YAML.parse('[ true, false, maybe, null ]\\n') // [ true, false, 'maybe', null ] const file = fs.readFileSync('./file.yml', 'utf8') YAML.parse(file) // { YAML: // [ 'A human-readable data serialization language', // 'https://en.wikipedia.org/wiki/YAML' ], // yaml: // [ 'A complete JavaScript implementation', // 'https://www.npmjs.com/package/yaml' ] } YAML.stringify import YAML from 'yaml' YAML.stringify(3.14159) // '3.14159\\n' YAML.stringify([true, false, 'maybe', null]) // `- true // - false // - maybe // - null // ` YAML.stringify({ number: 3, plain: 'string', block: 'two\\nlines\\n' }) // `number: 3 // plain: string // block: > // two // // lines // ` Browser testing provided by:"
  },
  "src/frontend/app-client/node_modules/cosmiconfig/README.html": {
    "href": "src/frontend/app-client/node_modules/cosmiconfig/README.html",
    "title": "cosmiconfig",
    "summary": "cosmiconfig Cosmiconfig searches for and loads configuration for your program. It features smart defaults based on conventional expectations in the JavaScript ecosystem. But it's also flexible enough to search wherever you'd like to search, and load whatever you'd like to load. By default, Cosmiconfig will start where you tell it to start and search up the directory tree for the following: a package.json property a JSON or YAML, extensionless \"rc file\" an \"rc file\" with the extensions .json, .yaml, .yml, .js, or .cjs any of the above two inside a .config subdirectory a .config.js or .config.cjs CommonJS module For example, if your module's name is \"myapp\", cosmiconfig will search up the directory tree for configuration in the following places: a myapp property in package.json a .myapprc file in JSON or YAML format a .myapprc.json, .myapprc.yaml, .myapprc.yml, .myapprc.js, or .myapprc.cjs file a myapprc, myapprc.json, myapprc.yaml, myapprc.yml, myapprc.js or myapprc.cjs file inside a .config subdirectory` a myapp.config.js or myapp.config.cjs CommonJS module exporting an object Cosmiconfig continues to search up the directory tree, checking each of these places in each directory, until it finds some acceptable configuration (or hits the home directory). Table of contents Installation Usage Result Asynchronous API cosmiconfig() explorer.search() explorer.load() explorer.clearLoadCache() explorer.clearSearchCache() explorer.clearCaches() Synchronous API cosmiconfigSync() explorerSync.search() explorerSync.load() explorerSync.clearLoadCache() explorerSync.clearSearchCache() explorerSync.clearCaches() cosmiconfigOptions searchPlaces loaders packageProp stopDir cache transform ignoreEmptySearchPlaces Caching Differences from rc Contributing & Development Installation npm install cosmiconfig Tested in Node 10+. Usage Create a Cosmiconfig explorer, then either search for or directly load a configuration file. const { cosmiconfig, cosmiconfigSync } = require('cosmiconfig'); // ... const explorer = cosmiconfig(moduleName); // Search for a configuration by walking up directories. // See documentation for search, below. explorer.search() .then((result) => { // result.config is the parsed configuration object. // result.filepath is the path to the config file that was found. // result.isEmpty is true if there was nothing to parse in the config file. }) .catch((error) => { // Do something constructive. }); // Load a configuration directly when you know where it should be. // The result object is the same as for search. // See documentation for load, below. explorer.load(pathToConfig).then(..); // You can also search and load synchronously. const explorerSync = cosmiconfigSync(moduleName); const searchedFor = explorerSync.search(); const loaded = explorerSync.load(pathToConfig); Result The result object you get from search or load has the following properties: config: The parsed configuration object. undefined if the file is empty. filepath: The path to the configuration file that was found. isEmpty: true if the configuration file is empty. This property will not be present if the configuration file is not empty. Asynchronous API cosmiconfig() const { cosmiconfig } = require('cosmiconfig'); const explorer = cosmiconfig(moduleName[, cosmiconfigOptions]) Creates a cosmiconfig instance (\"explorer\") configured according to the arguments, and initializes its caches. moduleName Type: string. Required. Your module name. This is used to create the default searchPlaces and packageProp. If your searchPlaces value will include files, as it does by default (e.g. ${moduleName}rc), your moduleName must consist of characters allowed in filenames. That means you should not copy scoped package names, such as @my-org/my-package, directly into moduleName. cosmiconfigOptions are documented below. You may not need them, and should first read about the functions you'll use. explorer.search() explorer.search([searchFrom]).then(result => {..}) Searches for a configuration file. Returns a Promise that resolves with a result or with null, if no configuration file is found. You can do the same thing synchronously with explorerSync.search(). Let's say your module name is goldengrahams so you initialized with const explorer = cosmiconfig('goldengrahams');. Here's how your default search() will work: Starting from process.cwd() (or some other directory defined by the searchFrom argument to search()), look for configuration objects in the following places: A goldengrahams property in a package.json file. A .goldengrahamsrc file with JSON or YAML syntax. A .goldengrahamsrc.json, .goldengrahamsrc.yaml, .goldengrahamsrc.yml, .goldengrahamsrc.js, or .goldengrahamsrc.cjs file. A goldengrahamsrc, goldengrahamsrc.json, goldengrahamsrc.yaml, goldengrahamsrc.yml, goldengrahamsrc.js, or goldengrahamsrc.cjs file in the .config subdirectory. A goldengrahams.config.js or goldengrahams.config.cjs CommonJS module exporting the object. If none of those searches reveal a configuration object, move up one directory level and try again. So the search continues in ./, ../, ../../, ../../../, etc., checking the same places in each directory. Continue searching until arriving at your home directory (or some other directory defined by the cosmiconfig option stopDir). If at any point a parsable configuration is found, the search() Promise resolves with its result (or, with explorerSync.search(), the result is returned). If no configuration object is found, the search() Promise resolves with null (or, with explorerSync.search(), null is returned). If a configuration object is found but is malformed (causing a parsing error), the search() Promise rejects with that error (so you should .catch() it). (Or, with explorerSync.search(), the error is thrown.) If you know exactly where your configuration file should be, you can use load(), instead. The search process is highly customizable. Use the cosmiconfig options searchPlaces and loaders to precisely define where you want to look for configurations and how you want to load them. searchFrom Type: string. Default: process.cwd(). A filename. search() will start its search here. If the value is a directory, that's where the search starts. If it's a file, the search starts in that file's directory. explorer.load() explorer.load(loadPath).then(result => {..}) Loads a configuration file. Returns a Promise that resolves with a result or rejects with an error (if the file does not exist or cannot be loaded). Use load if you already know where the configuration file is and you just need to load it. explorer.load('load/this/file.json'); // Tries to load load/this/file.json. If you load a package.json file, the result will be derived from whatever property is specified as your packageProp. You can do the same thing synchronously with explorerSync.load(). explorer.clearLoadCache() Clears the cache used in load(). explorer.clearSearchCache() Clears the cache used in search(). explorer.clearCaches() Performs both clearLoadCache() and clearSearchCache(). Synchronous API cosmiconfigSync() const { cosmiconfigSync } = require('cosmiconfig'); const explorerSync = cosmiconfigSync(moduleName[, cosmiconfigOptions]) Creates a synchronous cosmiconfig instance (\"explorerSync\") configured according to the arguments, and initializes its caches. See cosmiconfig(). explorerSync.search() const result = explorerSync.search([searchFrom]); Synchronous version of explorer.search(). Returns a result or null. explorerSync.load() const result = explorerSync.load(loadPath); Synchronous version of explorer.load(). Returns a result. explorerSync.clearLoadCache() Clears the cache used in load(). explorerSync.clearSearchCache() Clears the cache used in search(). explorerSync.clearCaches() Performs both clearLoadCache() and clearSearchCache(). cosmiconfigOptions Type: Object. Possible options are documented below. searchPlaces Type: Array<string>. Default: See below. An array of places that search() will check in each directory as it moves up the directory tree. Each place is relative to the directory being searched, and the places are checked in the specified order. Default searchPlaces: [ 'package.json', `.${moduleName}rc`, `.${moduleName}rc.json`, `.${moduleName}rc.yaml`, `.${moduleName}rc.yml`, `.${moduleName}rc.js`, `.${moduleName}rc.cjs`, `.config/${moduleName}rc`, `.config/${moduleName}rc.json`, `.config/${moduleName}rc.yaml`, `.config/${moduleName}rc.yml`, `.config/${moduleName}rc.js`, `.config/${moduleName}rc.cjs`, `${moduleName}.config.js`, `${moduleName}.config.cjs`, ] Create your own array to search more, fewer, or altogether different places. Every item in searchPlaces needs to have a loader in loaders that corresponds to its extension. (Common extensions are covered by default loaders.) Read more about loaders below. package.json is a special value: When it is included in searchPlaces, Cosmiconfig will always parse it as JSON and load a property within it, not the whole file. That property is defined with the packageProp option, and defaults to your module name. Examples, with a module named porgy: // Disallow extensions on rc files: [ 'package.json', '.porgyrc', 'porgy.config.js' ] // ESLint searches for configuration in these places: [ '.eslintrc.js', '.eslintrc.yaml', '.eslintrc.yml', '.eslintrc.json', '.eslintrc', 'package.json' ] // Babel looks in fewer places: [ 'package.json', '.babelrc' ] // Maybe you want to look for a wide variety of JS flavors: [ 'porgy.config.js', 'porgy.config.mjs', 'porgy.config.ts', 'porgy.config.coffee' ] // ^^ You will need to designate custom loaders to tell // Cosmiconfig how to handle these special JS flavors. // Look within a .config/ subdirectory of every searched directory: [ 'package.json', '.porgyrc', '.config/.porgyrc', '.porgyrc.json', '.config/.porgyrc.json' ] loaders Type: Object. Default: See below. An object that maps extensions to the loader functions responsible for loading and parsing files with those extensions. Cosmiconfig exposes its default loaders on a named export defaultLoaders. Default loaders: const { defaultLoaders } = require('cosmiconfig'); console.log(Object.entries(defaultLoaders)) // [ // [ '.cjs', [Function: loadJs] ], // [ '.js', [Function: loadJs] ], // [ '.json', [Function: loadJson] ], // [ '.yaml', [Function: loadYaml] ], // [ '.yml', [Function: loadYaml] ], // [ 'noExt', [Function: loadYaml] ] // ] (YAML is a superset of JSON; which means YAML parsers can parse JSON; which is how extensionless files can be either YAML or JSON with only one parser.) If you provide a loaders object, your object will be merged with the defaults. So you can override one or two without having to override them all. Keys in loaders are extensions (starting with a period), or noExt to specify the loader for files without extensions, like .myapprc. Values in loaders are a loader function (described below) whose values are loader functions. The most common use case for custom loaders value is to load extensionless rc files as strict JSON, instead of JSON or YAML (the default). To accomplish that, provide the following loaders value: { noExt: defaultLoaders['.json'] } If you want to load files that are not handled by the loader functions Cosmiconfig exposes, you can write a custom loader function or use one from NPM if it exists. Third-party loaders: cosmiconfig-typescript-loader Use cases for custom loader function: Allow configuration syntaxes that aren't handled by Cosmiconfig's defaults, like JSON5, INI, or XML. Allow ES2015 modules from .mjs configuration files. Parse JS files with Babel before deriving the configuration. Custom loader functions have the following signature: // Sync (filepath: string, content: string) => Object | null // Async (filepath: string, content: string) => Object | null | Promise<Object | null> Cosmiconfig reads the file when it checks whether the file exists, so it will provide you with both the file's path and its content. Do whatever you need to, and return either a configuration object or null (or, for async-only loaders, a Promise that resolves with one of those). null indicates that no real configuration was found and the search should continue. A few things to note: If you use a custom loader, be aware of whether it's sync or async: you cannot use async customer loaders with the sync API (cosmiconfigSync()). Special JS syntax can also be handled by using a require hook, because defaultLoaders['.js'] just uses require. Whether you use custom loaders or a require hook is up to you. Examples: // Allow JSON5 syntax: { '.json': json5Loader } // Allow a special configuration syntax of your own creation: { '.special': specialLoader } // Allow many flavors of JS, using custom loaders: { '.mjs': esmLoader, '.ts': typeScriptLoader, '.coffee': coffeeScriptLoader } // Allow many flavors of JS but rely on require hooks: { '.mjs': defaultLoaders['.js'], '.ts': defaultLoaders['.js'], '.coffee': defaultLoaders['.js'] } packageProp Type: string | Array<string>. Default: `${moduleName}`. Name of the property in package.json to look for. Use a period-delimited string or an array of strings to describe a path to nested properties. For example, the value 'configs.myPackage' or ['configs', 'myPackage'] will get you the \"myPackage\" value in a package.json like this: { \"configs\": { \"myPackage\": {..} } } If nested property names within the path include periods, you need to use an array of strings. For example, the value ['configs', 'foo.bar', 'baz'] will get you the \"baz\" value in a package.json like this: { \"configs\": { \"foo.bar\": { \"baz\": {..} } } } If a string includes period but corresponds to a top-level property name, it will not be interpreted as a period-delimited path. For example, the value 'one.two' will get you the \"three\" value in a package.json like this: { \"one.two\": \"three\", \"one\": { \"two\": \"four\" } } stopDir Type: string. Default: Absolute path to your home directory. Directory where the search will stop. cache Type: boolean. Default: true. If false, no caches will be used. Read more about \"Caching\" below. transform Type: (Result) => Promise<Result> | Result. A function that transforms the parsed configuration. Receives the result. If using search() or load() (which are async), the transform function can return the transformed result or return a Promise that resolves with the transformed result. If using cosmiconfigSync, search() or load(), the function must be synchronous and return the transformed result. The reason you might use this option — instead of simply applying your transform function some other way — is that the transformed result will be cached. If your transformation involves additional filesystem I/O or other potentially slow processing, you can use this option to avoid repeating those steps every time a given configuration is searched or loaded. ignoreEmptySearchPlaces Type: boolean. Default: true. By default, if search() encounters an empty file (containing nothing but whitespace) in one of the searchPlaces, it will ignore the empty file and move on. If you'd like to load empty configuration files, instead, set this option to false. Why might you want to load empty configuration files? If you want to throw an error, or if an empty configuration file means something to your program. Caching As of v2, cosmiconfig uses caching to reduce the need for repetitious reading of the filesystem or expensive transforms. Every new cosmiconfig instance (created with cosmiconfig()) has its own caches. To avoid or work around caching, you can do the following: Set the cosmiconfig option cache to false. Use the cache-clearing methods clearLoadCache(), clearSearchCache(), and clearCaches(). Create separate instances of cosmiconfig (separate \"explorers\"). Differences from rc rc serves its focused purpose well. cosmiconfig differs in a few key ways — making it more useful for some projects, less useful for others: Looks for configuration in some different places: in a package.json property, an rc file, a .config.js file, and rc files with extensions. Built-in support for JSON, YAML, and CommonJS formats. Stops at the first configuration found, instead of finding all that can be found up the directory tree and merging them automatically. Options. Asynchronous by default (though can be run synchronously). Contributing & Development Please note that this project is released with a Contributor Code of Conduct. By participating in this project you agree to abide by its terms. And please do participate!"
  },
  "src/frontend/app-client/node_modules/cross-spawn/node_modules/which/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/cross-spawn/node_modules/which/CHANGELOG.html",
    "title": "Changes",
    "summary": "Changes 2.0.2 Rename bin to node-which 2.0.1 generate changelog and publish on version bump enforce 100% test coverage Promise interface 2.0.0 Parallel tests, modern JavaScript, and drop support for node < 8 1.3.1 update deps update travis v1.3.0 Add nothrow option to which.sync update tap v1.2.14 appveyor: drop node 5 and 0.x travis-ci: add node 6, drop 0.x v1.2.13 test: Pass missing option to pass on windows update tap update isexe to 2.0.0 neveragain.tech pledge request v1.2.12 Removed unused require v1.2.11 Prevent changelog script from being included in package v1.2.10 Use env.PATH only, not env.Path v1.2.9 fix for paths starting with ../ Remove unused is-absolute module v1.2.8 bullet items in changelog that contain (but don't start with) # v1.2.7 strip 'update changelog' changelog entries out of changelog v1.2.6 make the changelog bulleted v1.2.5 make a changelog, and keep it up to date don't include tests in package Properly handle relative-path executables appveyor Attach error code to Not Found error Make tests pass on Windows v1.2.4 Fix typo v1.2.3 update isexe, fix regression in pathExt handling v1.2.2 update deps, use isexe module, test windows v1.2.1 Sometimes windows PATH entries are quoted Fixed a bug in the check for group and user mode bits. This bug was introduced during refactoring for supporting strict mode. doc cli v1.2.0 Add support for opt.all and -as cli flags test the bin update travis Allow checking for multiple programs in bin/which tap 2 v1.1.2 travis Refactored and fixed undefined error on Windows Support strict mode v1.1.1 test +g exes against secondary groups, if available Use windows exe semantics on cygwin & msys cwd should be first in path on win32, not last Handle lower-case 'env.Path' on Windows Update docs use single-quotes v1.1.0 Add tests, depend on is-absolute v1.0.9 which.js: root is allowed to execute files owned by anyone v1.0.8 don't use graceful-fs v1.0.7 add license to package.json v1.0.6 isc license 1.0.5 Awful typo 1.0.4 Test for path absoluteness properly win: Allow '' as a pathext if cmd has a . in it 1.0.3 Remove references to execPath Make which.sync() work on Windows by honoring the PATHEXT variable. Make isExe() always return true on Windows. MIT 1.0.2 Only files can be exes 1.0.1 Respect the PATHEXT env for win32 support should 0755 the bin binary guts package 1st"
  },
  "src/frontend/app-client/node_modules/cross-spawn/node_modules/which/README.html": {
    "href": "src/frontend/app-client/node_modules/cross-spawn/node_modules/which/README.html",
    "title": "which",
    "summary": "which Like the unix which utility. Finds the first instance of a specified executable in the PATH environment variable. Does not cache the results, so hash -r is not needed when the PATH changes. USAGE var which = require('which') // async usage which('node', function (er, resolvedPath) { // er is returned if no \"node\" is found on the PATH // if it is found, then the absolute path to the exec is returned }) // or promise which('node').then(resolvedPath => { ... }).catch(er => { ... not found ... }) // sync usage // throws if not found var resolved = which.sync('node') // if nothrow option is used, returns null if not found resolved = which.sync('node', {nothrow: true}) // Pass options to override the PATH and PATHEXT environment vars. which('node', { path: someOtherPath }, function (er, resolved) { if (er) throw er console.log('found at %j', resolved) }) CLI USAGE Same as the BSD which(1) binary. usage: which [-as] program ... OPTIONS You may pass an options object as the second argument. path: Use instead of the PATH environment variable. pathExt: Use instead of the PATHEXT environment variable. all: Return all matches, instead of just the first one. Note that this means the function returns an array of strings instead of a single string."
  },
  "src/frontend/app-client/node_modules/cross-spawn/README.html": {
    "href": "src/frontend/app-client/node_modules/cross-spawn/README.html",
    "title": "cross-spawn",
    "summary": "cross-spawn A cross platform solution to node's spawn and spawnSync. Installation Node.js version 8 and up: $ npm install cross-spawn Node.js version 7 and under: $ npm install cross-spawn@6 Why Node has issues when using spawn on Windows: It ignores PATHEXT It does not support shebangs Has problems running commands with spaces Has problems running commands with posix relative paths (e.g.: ./my-folder/my-executable) Has an issue with command shims (files in node_modules/.bin/), where arguments with quotes and parenthesis would result in invalid syntax error No options.shell support on node <v4.8 All these issues are handled correctly by cross-spawn. There are some known modules, such as win-spawn, that try to solve this but they are either broken or provide faulty escaping of shell arguments. Usage Exactly the same way as node's spawn or spawnSync, so it's a drop in replacement. const spawn = require('cross-spawn'); // Spawn NPM asynchronously const child = spawn('npm', ['list', '-g', '-depth', '0'], { stdio: 'inherit' }); // Spawn NPM synchronously const result = spawn.sync('npm', ['list', '-g', '-depth', '0'], { stdio: 'inherit' }); Caveats Using options.shell as an alternative to cross-spawn Starting from node v4.8, spawn has a shell option that allows you run commands from within a shell. This new option solves the PATHEXT issue but: It's not supported in node <v4.8 You must manually escape the command and arguments which is very error prone, specially when passing user input There are a lot of other unresolved issues from the Why section that you must take into account If you are using the shell option to spawn a command in a cross platform way, consider using cross-spawn instead. You have been warned. options.shell support While cross-spawn adds support for options.shell in node <v4.8, all of its enhancements are disabled. This mimics the Node.js behavior. More specifically, the command and its arguments will not be automatically escaped nor shebang support will be offered. This is by design because if you are using options.shell you are probably targeting a specific platform anyway and you don't want things to get into your way. Shebangs support While cross-spawn handles shebangs on Windows, its support is limited. More specifically, it just supports #!/usr/bin/env <program> where <program> must not contain any arguments. If you would like to have the shebang support improved, feel free to contribute via a pull-request. Remember to always test your code on Windows! Tests $ npm test $ npm test -- --watch during development License Released under the MIT License."
  },
  "src/frontend/app-client/node_modules/cssbeautify/CONTRIBUTING.html": {
    "href": "src/frontend/app-client/node_modules/cssbeautify/CONTRIBUTING.html",
    "title": "Contribution Guide",
    "summary": "Contribution Guide This page describes how to contribute changes to CSS Beautify. Please do not create a pull request without reading this guide first. Failure to do so may result in the rejection of the pull request. CLA Before we can accept any contributions, you need to sign Contributor License Agreement. You can do that using Sencha Labs online CLA. Coding Policies Make sure that your code passes JSLint checks. Make sure your patch does break existing tests (open test/index.html in a web browser). If you add a new feature, create a new test associated with that. Feature or enhancement pull request without a corresponding test will not be merged. Pull Request For the actual contribution, please use Github pull request workflow. Please do not create a pull request for multiple unrelated commits. It is strongly recommended to create a topic branch and make the commits as atomic as possible for the merge. This makes it easy to review all the changes."
  },
  "src/frontend/app-client/node_modules/cssbeautify/README.html": {
    "href": "src/frontend/app-client/node_modules/cssbeautify/README.html",
    "title": "CSS Beautify",
    "summary": "CSS Beautify CSS Beautify is a JavaScript implementation of reindenter and reformatter for styles written in CSS. Given the following style: menu{color:red} navigation{background-color:#333} CSS Beautify will produce: menu { color: red } navigation { background-color: #333 } Try it online at cssbeautify.com. For the command-line use, install Node.js cssbeautify package. For more examples, see also its test suite. Using cssbeautify() function Since CSS Beautify is written in pure JavaScript, it can run anywhere that JavaScript can run. The API is very simple: var result = cssbeautify(style, options); options is an optional object to adjust the formatting. Known options so far are: indent is a string used for the indentation of the declaration (default is 4 spaces) openbrace defines the placement of open curly brace, either end-of-line (default) or separate-line. autosemicolon always inserts a semicolon after the last ruleset (default is false) Example call: var beautified = cssbeautify('menu{opacity:.7}', { indent: ' ', openbrace: 'separate-line', autosemicolon: true }); Contributing Contributions are welcomed! Please read the Contribution Guide for more info. License Copyright (C) 2012 Sencha Inc. Copyright (C) 2011 Sencha Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/csstype/README.html": {
    "href": "src/frontend/app-client/node_modules/csstype/README.html",
    "title": "CSSType",
    "summary": "CSSType TypeScript and Flow definitions for CSS, generated by data from MDN. It provides autocompletion and type checking for CSS properties and values. TypeScript import type * as CSS from 'csstype'; const style: CSS.Properties = { colour: 'white', // Type error on property textAlign: 'middle', // Type error on value }; Flow // @flow strict import * as CSS from 'csstype'; const style: CSS.Properties<> = { colour: 'white', // Type error on property textAlign: 'middle', // Type error on value }; Further examples below will be in TypeScript! Getting started $ npm install csstype Table of content Style types At-rule types Pseudo types Generics Usage What should I do when I get type errors? Version 3.0 Contributing Style types Properties are categorized in different uses and in several technical variations to provide typings that suits as many as possible. Default Hyphen Fallback HyphenFallback All Properties PropertiesHyphen PropertiesFallback PropertiesHyphenFallback Standard StandardProperties StandardPropertiesHyphen StandardPropertiesFallback StandardPropertiesHyphenFallback Vendor VendorProperties VendorPropertiesHyphen VendorPropertiesFallback VendorPropertiesHyphenFallback Obsolete ObsoleteProperties ObsoletePropertiesHyphen ObsoletePropertiesFallback ObsoletePropertiesHyphenFallback Svg SvgProperties SvgPropertiesHyphen SvgPropertiesFallback SvgPropertiesHyphenFallback Categories: All - Includes Standard, Vendor, Obsolete and Svg Standard - Current properties and extends subcategories StandardLonghand and StandardShorthand (e.g. StandardShorthandProperties) Vendor - Vendor prefixed properties and extends subcategories VendorLonghand and VendorShorthand (e.g. VendorShorthandProperties) Obsolete - Removed or deprecated properties Svg - SVG-specific properties Variations: Default - JavaScript (camel) cased property names Hyphen - CSS (kebab) cased property names Fallback - Also accepts array of values e.g. string | string[] At-rule types At-rule interfaces with descriptors. TypeScript: These will be found in the AtRule namespace, e.g. AtRule.Viewport. Flow: These will be prefixed with AtRule$, e.g. AtRule$Viewport. Default Hyphen Fallback HyphenFallback @counter-style CounterStyle CounterStyleHyphen CounterStyleFallback CounterStyleHyphenFallback @font-face FontFace FontFaceHyphen FontFaceFallback FontFaceHyphenFallback @viewport Viewport ViewportHyphen ViewportFallback ViewportHyphenFallback Pseudo types String literals of pseudo classes and pseudo elements Pseudos Extends: AdvancedPseudos Function-like pseudos e.g. :not(:first-child). The string literal contains the value excluding the parenthesis: :not. These are separated because they require an argument that results in infinite number of variations. SimplePseudos Plain pseudos e.g. :hover that can only be one variation. Generics All interfaces has two optional generic argument to define length and time: CSS.Properties<TLength = string | 0, TTime = string> Length is the first generic parameter and defaults to string | 0 because 0 is the only length where the unit identifier is optional. You can specify this, e.g. string | number, for platforms and libraries that accepts any numeric value as length with a specific unit. const style: CSS.Properties<string | number> = { width: 100, }; Time is the second generic argument and defaults to string. You can specify this, e.g. string | number, for platforms and libraries that accepts any numeric value as length with a specific unit. const style: CSS.Properties<string | number, number> = { transitionDuration: 1000, }; Usage import type * as CSS from 'csstype'; const style: CSS.Properties = { width: '10px', margin: '1em', }; In some cases, like for CSS-in-JS libraries, an array of values is a way to provide fallback values in CSS. Using CSS.PropertiesFallback instead of CSS.Properties will add the possibility to use any property value as an array of values. import type * as CSS from 'csstype'; const style: CSS.PropertiesFallback = { display: ['-webkit-flex', 'flex'], color: 'white', }; There's even string literals for pseudo selectors and elements. import type * as CSS from 'csstype'; const pseudos: { [P in CSS.SimplePseudos]?: CSS.Properties } = { ':hover': { display: 'flex', }, }; Hyphen cased (kebab cased) properties are provided in CSS.PropertiesHyphen and CSS.PropertiesHyphenFallback. It's not not added by default in CSS.Properties. To allow both of them, you can simply extend with CSS.PropertiesHyphen or/and CSS.PropertiesHyphenFallback. import type * as CSS from 'csstype'; interface Style extends CSS.Properties, CSS.PropertiesHyphen {} const style: Style = { 'flex-grow': 1, 'flex-shrink': 0, 'font-weight': 'normal', backgroundColor: 'white', }; Adding type checked CSS properties to a HTMLElement. import type * as CSS from 'csstype'; const style: CSS.Properties = { color: 'red', margin: '1em', }; let button = document.createElement('button'); Object.assign(button.style, style); What should I do when I get type errors? The goal is to have as perfect types as possible and we're trying to do our best. But with CSS Custom Properties, the CSS specification changing frequently and vendors implementing their own specifications with new releases sometimes causes type errors even if it should work. Here's some steps you could take to get it fixed: If you're using CSS Custom Properties you can step directly to step 3. First of all, make sure you're doing it right. A type error could also indicate that you're not \uD83D\uDE09 Some CSS specs that some vendors has implemented could have been officially rejected or haven't yet received any official acceptance and are therefor not included If you're using TypeScript, type widening could be the reason you get Type 'string' is not assignable to... errors Have a look in issues to see if an issue already has been filed. If not, create a new one. To help us out, please refer to any information you have found. Fix the issue locally with TypeScript (Flow further down): The recommended way is to use module augmentation. Here's a few examples: // My css.d.ts file import type * as CSS from 'csstype'; declare module 'csstype' { interface Properties { // Add a missing property WebkitRocketLauncher?: string; // Add a CSS Custom Property '--theme-color'?: 'black' | 'white'; // Allow namespaced CSS Custom Properties [index: `--theme-${string}`]: any; // Allow any CSS Custom Properties [index: `--${string}`]: any; // ...or allow any other property [index: string]: any; } } The alternative way is to use type assertion. Here's a few examples: const style: CSS.Properties = { // Add a missing property ['WebkitRocketLauncher' as any]: 'launching', // Add a CSS Custom Property ['--theme-color' as any]: 'black', }; Fix the issue locally with Flow: Use type assertion. Here's a few examples: const style: $Exact<CSS.Properties<*>> = { // Add a missing property [('WebkitRocketLauncher': any)]: 'launching', // Add a CSS Custom Property [('--theme-color': any)]: 'black', }; Version 3.0 All property types are exposed with namespace TypeScript: Property.AlignContent (was AlignContentProperty before) Flow: Property$AlignContent All at-rules are exposed with namespace TypeScript: AtRule.FontFace (was FontFace before) Flow: AtRule$FontFace Data types are NOT exposed E.g. Color and Box. Because the generation of data types may suddenly be removed or renamed. TypeScript hack for autocompletion Uses (string & {}) for literal string unions and (number & {}) for literal number unions (related issue). Utilize PropertyValue<T> to unpack types from e.g. (string & {}) to string. New generic for time Read more on the \"Generics\" section. Flow types improvements Flow Strict enabled and exact types are used. Contributing Never modify index.d.ts and index.js.flow directly. They are generated automatically and committed so that we can easily follow any change it results in. Therefor it's important that you run $ git config merge.ours.driver true after you've forked and cloned. That setting prevents merge conflicts when doing rebase. Commands npm run build Generates typings and type checks them npm run watch Runs build on each save npm run test Runs the tests npm run lazy Type checks, lints and formats everything"
  },
  "src/frontend/app-client/node_modules/d3-color/README.html": {
    "href": "src/frontend/app-client/node_modules/d3-color/README.html",
    "title": "d3-color",
    "summary": "d3-color Even though your browser understands a lot about colors, it doesn’t offer much help in manipulating colors through JavaScript. The d3-color module therefore provides representations for various color spaces, allowing specification, conversion and manipulation. (Also see d3-interpolate for color interpolation.) For example, take the color named “steelblue”: const c = d3.color(\"steelblue\"); // {r: 70, g: 130, b: 180, opacity: 1} Let’s try converting it to HSL: const c = d3.hsl(\"steelblue\"); // {h: 207.27…, s: 0.44, l: 0.4902…, opacity: 1} Now rotate the hue by 90°, bump up the saturation, and format as a string for CSS: c.h += 90; c.s += 0.2; c + \"\"; // rgb(198, 45, 205) To fade the color slightly: c.opacity = 0.8; c + \"\"; // rgba(198, 45, 205, 0.8) In addition to the ubiquitous and machine-friendly RGB and HSL color space, d3-color supports color spaces that are designed for humans: CIELAB (a.k.a. “Lab”) CIELChab (a.k.a. “LCh” or “HCL”) Dave Green’s Cubehelix Cubehelix features monotonic lightness, while CIELAB and its polar form CIELChab are perceptually uniform. Extensions For additional color spaces, see: d3-cam16 d3-cam02 d3-hsv d3-hcg d3-hsluv To measure color differences, see: d3-color-difference Installing If you use npm, npm install d3-color. You can also download the latest release on GitHub. For vanilla HTML in modern browsers, import d3-color from Skypack: <script type=\"module\"> import {rgb} from \"https://cdn.skypack.dev/d3-color@3\"; const steelblue = d3.rgb(\"steelblue\"); </script> For legacy environments, you can load d3-color’s UMD bundle from an npm-based CDN such as jsDelivr; a d3 global is exported: <script src=\"https://cdn.jsdelivr.net/npm/d3-color@3\"></script> <script> const steelblue = d3.rgb(\"steelblue\"); </script> Try d3-color in your browser. API Reference # d3.color(specifier) <> Parses the specified CSS Color Module Level 3 specifier string, returning an RGB or HSL color, along with CSS Color Module Level 4 hex specifier strings. If the specifier was not valid, null is returned. Some examples: rgb(255, 255, 255) rgb(10%, 20%, 30%) rgba(255, 255, 255, 0.4) rgba(10%, 20%, 30%, 0.4) hsl(120, 50%, 20%) hsla(120, 50%, 20%, 0.4) #ffeeaa #fea #ffeeaa22 #fea2 steelblue The list of supported named colors is specified by CSS. Note: this function may also be used with instanceof to test if an object is a color instance. The same is true of color subclasses, allowing you to test whether a color is in a particular color space. # color.opacity This color’s opacity, typically in the range [0, 1]. # color.rgb() <> Returns the RGB equivalent of this color. For RGB colors, that’s this. # color.copy([values]) <> Returns a copy of this color. If values is specified, any enumerable own properties of values are assigned to the new returned color. For example, to derive a copy of a color with opacity 0.5, say color.copy({opacity: 0.5}) # color.brighter([k]) <> Returns a brighter copy of this color. If k is specified, it controls how much brighter the returned color should be. If k is not specified, it defaults to 1. The behavior of this method is dependent on the implementing color space. # color.darker([k]) <> Returns a darker copy of this color. If k is specified, it controls how much darker the returned color should be. If k is not specified, it defaults to 1. The behavior of this method is dependent on the implementing color space. # color.displayable() <> Returns true if and only if the color is displayable on standard hardware. For example, this returns false for an RGB color if any channel value is less than zero or greater than 255 when rounded, or if the opacity is not in the range [0, 1]. # color.formatHex() <> Returns a hexadecimal string representing this color in RGB space, such as #f7eaba. If this color is not displayable, a suitable displayable color is returned instead. For example, RGB channel values greater than 255 are clamped to 255. # color.formatHsl() <> Returns a string representing this color according to the CSS Color Module Level 3 specification, such as hsl(257, 50%, 80%) or hsla(257, 50%, 80%, 0.2). If this color is not displayable, a suitable displayable color is returned instead by clamping S and L channel values to the interval [0, 100]. # color.formatRgb() <> Returns a string representing this color according to the CSS Object Model specification, such as rgb(247, 234, 186) or rgba(247, 234, 186, 0.2). If this color is not displayable, a suitable displayable color is returned instead by clamping RGB channel values to the interval [0, 255]. # color.toString() <> An alias for color.formatRgb. # d3.rgb(r, g, b[, opacity]) <> # d3.rgb(specifier) # d3.rgb(color) Constructs a new RGB color. The channel values are exposed as r, g and b properties on the returned instance. Use the RGB color picker to explore this color space. If r, g and b are specified, these represent the channel values of the returned color; an opacity may also be specified. If a CSS Color Module Level 3 specifier string is specified, it is parsed and then converted to the RGB color space. See color for examples. If a color instance is specified, it is converted to the RGB color space using color.rgb. Note that unlike color.rgb this method always returns a new instance, even if color is already an RGB color. # rgb.clamp() <> Returns a new RGB color where the r, g, and b channels are clamped to the range [0, 255] and rounded to the nearest integer value, and the opacity is clamped to the range [0, 1]. # d3.hsl(h, s, l[, opacity]) <> # d3.hsl(specifier) # d3.hsl(color) Constructs a new HSL color. The channel values are exposed as h, s and l properties on the returned instance. Use the HSL color picker to explore this color space. If h, s and l are specified, these represent the channel values of the returned color; an opacity may also be specified. If a CSS Color Module Level 3 specifier string is specified, it is parsed and then converted to the HSL color space. See color for examples. If a color instance is specified, it is converted to the RGB color space using color.rgb and then converted to HSL. (Colors already in the HSL color space skip the conversion to RGB.) # hsl.clamp() <> Returns a new HSL color where the h channel is clamped to the range [0, 360), and the s, l, and opacity channels are clamped to the range [0, 1]. # d3.lab(l, a, b[, opacity]) <> # d3.lab(specifier) # d3.lab(color) Constructs a new CIELAB color. The channel values are exposed as l, a and b properties on the returned instance. Use the CIELAB color picker to explore this color space. The value of l is typically in the range [0, 100], while a and b are typically in [-160, +160]. If l, a and b are specified, these represent the channel values of the returned color; an opacity may also be specified. If a CSS Color Module Level 3 specifier string is specified, it is parsed and then converted to the CIELAB color space. See color for examples. If a color instance is specified, it is converted to the RGB color space using color.rgb and then converted to CIELAB. (Colors already in the CIELAB color space skip the conversion to RGB, and colors in the HCL color space are converted directly to CIELAB.) # d3.gray(l[, opacity]) <> Constructs a new CIELAB color with the specified l value and a = b = 0. # d3.hcl(h, c, l[, opacity]) <> # d3.hcl(specifier) # d3.hcl(color) Equivalent to d3.lch, but with reversed argument order. # d3.lch(l, c, h[, opacity]) <> # d3.lch(specifier) # d3.lch(color) Constructs a new CIELChab color. The channel values are exposed as l, c and h properties on the returned instance. Use the CIELChab color picker to explore this color space. The value of l is typically in the range [0, 100], c is typically in [0, 230], and h is typically in [0, 360). If l, c, and h are specified, these represent the channel values of the returned color; an opacity may also be specified. If a CSS Color Module Level 3 specifier string is specified, it is parsed and then converted to CIELChab color space. See color for examples. If a color instance is specified, it is converted to the RGB color space using color.rgb and then converted to CIELChab. (Colors already in CIELChab color space skip the conversion to RGB, and colors in CIELAB color space are converted directly to CIELChab.) # d3.cubehelix(h, s, l[, opacity]) <> # d3.cubehelix(specifier) # d3.cubehelix(color) Constructs a new Cubehelix color. The channel values are exposed as h, s and l properties on the returned instance. Use the Cubehelix color picker to explore this color space. If h, s and l are specified, these represent the channel values of the returned color; an opacity may also be specified. If a CSS Color Module Level 3 specifier string is specified, it is parsed and then converted to the Cubehelix color space. See color for examples. If a color instance is specified, it is converted to the RGB color space using color.rgb and then converted to Cubehelix. (Colors already in the Cubehelix color space skip the conversion to RGB.)"
  },
  "src/frontend/app-client/node_modules/d3-dispatch/README.html": {
    "href": "src/frontend/app-client/node_modules/d3-dispatch/README.html",
    "title": "d3-dispatch",
    "summary": "d3-dispatch Dispatching is a convenient mechanism for separating concerns with loosely-coupled code: register named callbacks and then call them with arbitrary arguments. A variety of D3 components, such as d3-drag, use this mechanism to emit events to listeners. Think of this like Node’s EventEmitter, except every listener has a well-defined name so it’s easy to remove or replace them. For example, to create a dispatch for start and end events: const dispatch = d3.dispatch(\"start\", \"end\"); You can then register callbacks for these events using dispatch.on: dispatch.on(\"start\", callback1); dispatch.on(\"start.foo\", callback2); dispatch.on(\"end\", callback3); Then, you can invoke all the start callbacks using dispatch.call or dispatch.apply: dispatch.call(\"start\"); Like function.call, you may also specify the this context and any arguments: dispatch.call(\"start\", {about: \"I am a context object\"}, \"I am an argument\"); Want a more involved example? See how to use d3-dispatch for coordinated views. Installing If you use npm, npm install d3-dispatch. You can also download the latest release on GitHub. For vanilla HTML in modern browsers, import d3-dispatch from Skypack: <script type=\"module\"> import {dispatch} from \"https://cdn.skypack.dev/d3-dispatch@3\"; const d = dispatch(\"start\", \"end\"); </script> For legacy environments, you can load d3-dispatch’s UMD bundle from an npm-based CDN such as jsDelivr; a d3 global is exported: <script src=\"https://cdn.jsdelivr.net/npm/d3-dispatch@3\"></script> <script> const d = d3.dispatch(\"start\", \"end\"); </script> Try d3-dispatch in your browser. API Reference # d3.dispatch(types…) · Source Creates a new dispatch for the specified event types. Each type is a string, such as \"start\" or \"end\". # dispatch.on(typenames[, callback]) · Source Adds, removes or gets the callback for the specified typenames. If a callback function is specified, it is registered for the specified (fully-qualified) typenames. If a callback was already registered for the given typenames, the existing callback is removed before the new callback is added. The specified typenames is a string, such as start or end.foo. The type may be optionally followed by a period (.) and a name; the optional name allows multiple callbacks to be registered to receive events of the same type, such as start.foo and start.bar. To specify multiple typenames, separate typenames with spaces, such as start end or start.foo start.bar. To remove all callbacks for a given name foo, say dispatch.on(\".foo\", null). If callback is not specified, returns the current callback for the specified typenames, if any. If multiple typenames are specified, the first matching callback is returned. # dispatch.copy() · Source Returns a copy of this dispatch object. Changes to this dispatch do not affect the returned copy and vice versa. # dispatch.call(type[, that[, arguments…]]) · Source Like function.call, invokes each registered callback for the specified type, passing the callback the specified arguments, with that as the this context. See dispatch.apply for more information. # dispatch.apply(type[, that[, arguments]]) · Source Like function.apply, invokes each registered callback for the specified type, passing the callback the specified arguments, with that as the this context. For example, if you wanted to dispatch your custom callbacks after handling a native click event, while preserving the current this context and arguments, you could say: selection.on(\"click\", function() { dispatch.apply(\"custom\", this, arguments); }); You can pass whatever arguments you want to callbacks; most commonly, you might create an object that represents an event, or pass the current datum (d) and index (i). See function.call and function.apply for further information."
  },
  "src/frontend/app-client/node_modules/d3-drag/README.html": {
    "href": "src/frontend/app-client/node_modules/d3-drag/README.html",
    "title": "d3-drag",
    "summary": "d3-drag Drag-and-drop is a popular and easy-to-learn pointing gesture: move the pointer to an object, press and hold to grab it, “drag” the object to a new location, and release to “drop”. D3’s drag behavior provides a convenient but flexible abstraction for enabling drag-and-drop interaction on selections. For example, you can use d3-drag to facilitate interaction with a force-directed graph, or a simulation of colliding circles: You can also use d3-drag to implement custom user interface elements, such as a slider. But the drag behavior isn’t just for moving elements around; there are a variety of ways to respond to a drag gesture. For example, you can use it to lasso elements in a scatterplot, or to paint lines on a canvas: The drag behavior can be combined with other behaviors, such as d3-zoom for zooming. The drag behavior is agnostic about the DOM, so you can use it with SVG, HTML or even Canvas! And you can extend it with advanced selection techniques, such as a Voronoi overlay or a closest-target search: Best of all, the drag behavior automatically unifies mouse and touch input, and avoids browser idiosyncrasies. When Pointer Events are more widely available, the drag behavior will support those, too. Installing If you use npm, npm install d3-drag. You can also download the latest release on GitHub. For vanilla HTML in modern browsers, import d3-drag from Skypack: <script type=\"module\"> import {drag} from \"https://cdn.skypack.dev/d3-drag@3\"; const handler = drag(); </script> For legacy environments, you can load d3-drag’s UMD bundle from an npm-based CDN such as jsDelivr; a d3 global is exported: <script src=\"https://cdn.jsdelivr.net/npm/d3-dispatch@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-selection@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-drag@3\"></script> <script> const handler = d3.drag(); </script> Try d3-drag in your browser. API Reference This table describes how the drag behavior interprets native events: Event Listening Element Drag Event Default Prevented? mousedown⁵ selection start no¹ mousemove² window¹ drag yes mouseup² window¹ end yes dragstart² window - yes selectstart² window - yes click³ window - yes touchstart selection start no⁴ touchmove selection drag yes touchend selection end no⁴ touchcancel selection end no⁴ The propagation of all consumed events is immediately stopped. If you want to prevent some events from initiating a drag gesture, use drag.filter. ¹ Necessary to capture events outside an iframe; see #9. ² Only applies during an active, mouse-based gesture; see #9. ³ Only applies immediately after some mouse-based gestures; see drag.clickDistance. ⁴ Necessary to allow click emulation on touch input; see #9. ⁵ Ignored if within 500ms of a touch gesture ending; assumes click emulation. # d3.drag() · Source, Examples Creates a new drag behavior. The returned behavior, drag, is both an object and a function, and is typically applied to selected elements via selection.call. # drag(selection) · Source, Examples Applies this drag behavior to the specified selection. This function is typically not invoked directly, and is instead invoked via selection.call. For example, to instantiate a drag behavior and apply it to a selection: d3.selectAll(\".node\").call(d3.drag().on(\"start\", started)); Internally, the drag behavior uses selection.on to bind the necessary event listeners for dragging. The listeners use the name .drag, so you can subsequently unbind the drag behavior as follows: selection.on(\".drag\", null); Applying the drag behavior also sets the -webkit-tap-highlight-color style to transparent, disabling the tap highlight on iOS. If you want a different tap highlight color, remove or re-apply this style after applying the drag behavior. # drag.container([container]) · Source, Examples If container is specified, sets the container accessor to the specified object or function and returns the drag behavior. If container is not specified, returns the current container accessor, which defaults to: function container() { return this.parentNode; } The container of a drag gesture determines the coordinate system of subsequent drag events, affecting event.x and event.y. The element returned by the container accessor is subsequently passed to d3.pointer to determine the local coordinates of the pointer. The default container accessor returns the parent node of the element in the originating selection (see drag) that received the initiating input event. This is often appropriate when dragging SVG or HTML elements, since those elements are typically positioned relative to a parent. For dragging graphical elements with a Canvas, however, you may want to redefine the container as the initiating element itself: function container() { return this; } Alternatively, the container may be specified as the element directly, such as drag.container(canvas). # drag.filter([filter]) · Source, Examples If filter is specified, sets the event filter to the specified function and returns the drag behavior. If filter is not specified, returns the current filter, which defaults to: function filter(event) { return !event.ctrlKey && !event.button; } If the filter returns falsey, the initiating event is ignored and no drag gestures are started. Thus, the filter determines which input events are ignored; the default filter ignores mousedown events on secondary buttons, since those buttons are typically intended for other purposes, such as the context menu. # drag.touchable([touchable]) · Source, Examples If touchable is specified, sets the touch support detector to the specified function and returns the drag behavior. If touchable is not specified, returns the current touch support detector, which defaults to: function touchable() { return navigator.maxTouchPoints || (\"ontouchstart\" in this); } Touch event listeners are only registered if the detector returns truthy for the corresponding element when the drag behavior is applied. The default detector works well for most browsers that are capable of touch input, but not all; Chrome’s mobile device emulator, for example, fails detection. # drag.subject([subject]) · Source, Examples If subject is specified, sets the subject accessor to the specified object or function and returns the drag behavior. If subject is not specified, returns the current subject accessor, which defaults to: function subject(event, d) { return d == null ? {x: event.x, y: event.y} : d; } The subject of a drag gesture represents the thing being dragged. It is computed when an initiating input event is received, such as a mousedown or touchstart, immediately before the drag gesture starts. The subject is then exposed as event.subject on subsequent drag events for this gesture. The default subject is the datum of the element in the originating selection (see drag) that received the initiating input event; if this datum is undefined, an object representing the coordinates of the pointer is created. When dragging circle elements in SVG, the default subject is thus the datum of the circle being dragged. With Canvas, the default subject is the canvas element’s datum (regardless of where on the canvas you click). In this case, a custom subject accessor would be more appropriate, such as one that picks the closest circle to the mouse within a given search radius: function subject(event) { let n = circles.length, i, dx, dy, d2, s2 = radius * radius, circle, subject; for (i = 0; i < n; ++i) { circle = circles[i]; dx = event.x - circle.x; dy = event.y - circle.y; d2 = dx * dx + dy * dy; if (d2 < s2) subject = circle, s2 = d2; } return subject; } (If necessary, the above can be accelerated using quadtree.find, simulation.find or delaunay.find.) The returned subject should be an object that exposes x and y properties, so that the relative position of the subject and the pointer can be preserved during the drag gesture. If the subject is null or undefined, no drag gesture is started for this pointer; however, other starting touches may yet start drag gestures. See also drag.filter. The subject of a drag gesture may not be changed after the gesture starts. The subject accessor is invoked with the same context and arguments as selection.on listeners: the current event (event) and datum d, with the this context as the current DOM element. During the evaluation of the subject accessor, event is a beforestart drag event. Use event.sourceEvent to access the initiating input event and event.identifier to access the touch identifier. The event.x and event.y are relative to the container, and are computed using d3.pointer. # drag.clickDistance([distance]) · Source If distance is specified, sets the maximum distance that the mouse can move between mousedown and mouseup that will trigger a subsequent click event. If at any point between mousedown and mouseup the mouse is greater than or equal to distance from its position on mousedown, the click event following mouseup will be suppressed. If distance is not specified, returns the current distance threshold, which defaults to zero. The distance threshold is measured in client coordinates (event.clientX and event.clientY). # drag.on(typenames, [listener]) · Source If listener is specified, sets the event listener for the specified typenames and returns the drag behavior. If an event listener was already registered for the same type and name, the existing listener is removed before the new listener is added. If listener is null, removes the current event listeners for the specified typenames, if any. If listener is not specified, returns the first currently-assigned listener matching the specified typenames, if any. When a specified event is dispatched, each listener will be invoked with the same context and arguments as selection.on listeners: the current event (event) and datum d, with the this context as the current DOM element. The typenames is a string containing one or more typename separated by whitespace. Each typename is a type, optionally followed by a period (.) and a name, such as drag.foo and drag.bar; the name allows multiple listeners to be registered for the same type. The type must be one of the following: start - after a new pointer becomes active (on mousedown or touchstart). drag - after an active pointer moves (on mousemove or touchmove). end - after an active pointer becomes inactive (on mouseup, touchend or touchcancel). See dispatch.on for more. Changes to registered listeners via drag.on during a drag gesture do not affect the current drag gesture. Instead, you must use event.on, which also allows you to register temporary event listeners for the current drag gesture. Separate events are dispatched for each active pointer during a drag gesture. For example, if simultaneously dragging multiple subjects with multiple fingers, a start event is dispatched for each finger, even if both fingers start touching simultaneously. See Drag Events for more. # d3.dragDisable(window) · Source Prevents native drag-and-drop and text selection on the specified window. As an alternative to preventing the default action of mousedown events (see #9), this method prevents undesirable default actions following mousedown. In supported browsers, this means capturing dragstart and selectstart events, preventing the associated default actions, and immediately stopping their propagation. In browsers that do not support selection events, the user-select CSS property is set to none on the document element. This method is intended to be called on mousedown, followed by d3.dragEnable on mouseup. # d3.dragEnable(window[, noclick]) · Source Allows native drag-and-drop and text selection on the specified window; undoes the effect of d3.dragDisable. This method is intended to be called on mouseup, preceded by d3.dragDisable on mousedown. If noclick is true, this method also temporarily suppresses click events. The suppression of click events expires after a zero-millisecond timeout, such that it only suppress the click event that would immediately follow the current mouseup event, if any. Drag Events When a drag event listener is invoked, it receives the current drag event as its first argument. The event object exposes several fields: target - the associated drag behavior. type - the string “start”, “drag” or “end”; see drag.on. subject - the drag subject, defined by drag.subject. x - the new x-coordinate of the subject; see drag.container. y - the new y-coordinate of the subject; see drag.container. dx - the change in x-coordinate since the previous drag event. dy - the change in y-coordinate since the previous drag event. identifier - the string “mouse”, or a numeric touch identifier. active - the number of currently active drag gestures (on start and end, not including this one). sourceEvent - the underlying input event, such as mousemove or touchmove. The event.active field is useful for detecting the first start event and the last end event in a sequence of concurrent drag gestures: it is zero when the first drag gesture starts, and zero when the last drag gesture ends. The event object also exposes the event.on method. # event.on(typenames, [listener]) · Source Equivalent to drag.on, but only applies to the current drag gesture. Before the drag gesture starts, a copy of the current drag event listeners is made. This copy is bound to the current drag gesture and modified by event.on. This is useful for temporary listeners that only receive events for the current drag gesture. For example, this start event listener registers temporary drag and end event listeners as closures: function started(event) { const circle = d3.select(this).classed(\"dragging\", true); event.on(\"drag\", dragged).on(\"end\", ended); function dragged(event, d) { circle.raise().attr(\"cx\", d.x = event.x).attr(\"cy\", d.y = event.y); } function ended() { circle.classed(\"dragging\", false); } }"
  },
  "src/frontend/app-client/node_modules/d3-ease/README.html": {
    "href": "src/frontend/app-client/node_modules/d3-ease/README.html",
    "title": "d3-ease",
    "summary": "d3-ease Easing is a method of distorting time to control apparent motion in animation. It is most commonly used for slow-in, slow-out. By easing time, animated transitions are smoother and exhibit more plausible motion. The easing types in this module implement the ease method, which takes a normalized time t and returns the corresponding “eased” time tʹ. Both the normalized time and the eased time are typically in the range [0,1], where 0 represents the start of the animation and 1 represents the end; some easing types, such as elastic, may return eased times slightly outside this range. A good easing type should return 0 if t = 0 and 1 if t = 1. See the easing explorer for a visual demonstration. These easing types are largely based on work by Robert Penner. Installing If you use npm, npm install d3-ease. You can also download the latest release on GitHub. For vanilla HTML in modern browsers, import d3-ease from Skypack: <script type=\"module\"> import {easeCubic} from \"https://cdn.skypack.dev/d3-ease@3\"; const e = easeCubic(0.25); </script> For legacy environments, you can load d3-ease’s UMD bundle from an npm-based CDN such as jsDelivr; a d3 global is exported: <script src=\"https://cdn.jsdelivr.net/npm/d3-ease@3\"></script> <script> const e = d3.easeCubic(0.25); </script> Try d3-ease in your browser. API Reference # ease(t) Given the specified normalized time t, typically in the range [0,1], returns the “eased” time tʹ, also typically in [0,1]. 0 represents the start of the animation and 1 represents the end. A good implementation returns 0 if t = 0 and 1 if t = 1. See the easing explorer for a visual demonstration. For example, to apply cubic easing: const te = d3.easeCubic(t); Similarly, to apply custom elastic easing: // Before the animation starts, create your easing function. const customElastic = d3.easeElastic.period(0.4); // During the animation, apply the easing function. const te = customElastic(t); # d3.easeLinear(t) <> Linear easing; the identity function; linear(t) returns t. # d3.easePolyIn(t) <> Polynomial easing; raises t to the specified exponent. If the exponent is not specified, it defaults to 3, equivalent to cubicIn. # d3.easePolyOut(t) <> Reverse polynomial easing; equivalent to 1 - polyIn(1 - t). If the exponent is not specified, it defaults to 3, equivalent to cubicOut. # d3.easePoly(t) <> # d3.easePolyInOut(t) <> Symmetric polynomial easing; scales polyIn for t in [0, 0.5] and polyOut for t in [0.5, 1]. If the exponent is not specified, it defaults to 3, equivalent to cubic. # poly.exponent(e) <> Returns a new polynomial easing with the specified exponent e. For example, to create equivalents of linear, quad, and cubic: const linear = d3.easePoly.exponent(1); const quad = d3.easePoly.exponent(2); const cubic = d3.easePoly.exponent(3); # d3.easeQuadIn(t) <> Quadratic easing; equivalent to polyIn.exponent(2). # d3.easeQuadOut(t) <> Reverse quadratic easing; equivalent to 1 - quadIn(1 - t). Also equivalent to polyOut.exponent(2). # d3.easeQuad(t) <> # d3.easeQuadInOut(t) <> Symmetric quadratic easing; scales quadIn for t in [0, 0.5] and quadOut for t in [0.5, 1]. Also equivalent to poly.exponent(2). # d3.easeCubicIn(t) <> Cubic easing; equivalent to polyIn.exponent(3). # d3.easeCubicOut(t) <> Reverse cubic easing; equivalent to 1 - cubicIn(1 - t). Also equivalent to polyOut.exponent(3). # d3.easeCubic(t) <> # d3.easeCubicInOut(t) <> Symmetric cubic easing; scales cubicIn for t in [0, 0.5] and cubicOut for t in [0.5, 1]. Also equivalent to poly.exponent(3). # d3.easeSinIn(t) <> Sinusoidal easing; returns sin(t). # d3.easeSinOut(t) <> Reverse sinusoidal easing; equivalent to 1 - sinIn(1 - t). # d3.easeSin(t) <> # d3.easeSinInOut(t) <> Symmetric sinusoidal easing; scales sinIn for t in [0, 0.5] and sinOut for t in [0.5, 1]. # d3.easeExpIn(t) <> Exponential easing; raises 2 to the exponent 10 * (t - 1). # d3.easeExpOut(t) <> Reverse exponential easing; equivalent to 1 - expIn(1 - t). # d3.easeExp(t) <> # d3.easeExpInOut(t) <> Symmetric exponential easing; scales expIn for t in [0, 0.5] and expOut for t in [0.5, 1]. # d3.easeCircleIn(t) <> Circular easing. # d3.easeCircleOut(t) <> Reverse circular easing; equivalent to 1 - circleIn(1 - t). # d3.easeCircle(t) <> # d3.easeCircleInOut(t) <> Symmetric circular easing; scales circleIn for t in [0, 0.5] and circleOut for t in [0.5, 1]. # d3.easeElasticIn(t) <> Elastic easing, like a rubber band. The amplitude and period of the oscillation are configurable; if not specified, they default to 1 and 0.3, respectively. # d3.easeElastic(t) <> # d3.easeElasticOut(t) <> Reverse elastic easing; equivalent to 1 - elasticIn(1 - t). # d3.easeElasticInOut(t) <> Symmetric elastic easing; scales elasticIn for t in [0, 0.5] and elasticOut for t in [0.5, 1]. # elastic.amplitude(a) <> Returns a new elastic easing with the specified amplitude a. # elastic.period(p) <> Returns a new elastic easing with the specified period p. # d3.easeBackIn(t) <> Anticipatory easing, like a dancer bending his knees before jumping off the floor. The degree of overshoot is configurable; if not specified, it defaults to 1.70158. # d3.easeBackOut(t) <> Reverse anticipatory easing; equivalent to 1 - backIn(1 - t). # d3.easeBack(t) <> # d3.easeBackInOut(t) <> Symmetric anticipatory easing; scales backIn for t in [0, 0.5] and backOut for t in [0.5, 1]. # back.overshoot(s) <> Returns a new back easing with the specified overshoot s. # d3.easeBounceIn(t) <> Bounce easing, like a rubber ball. # d3.easeBounce(t) <> # d3.easeBounceOut(t) <> Reverse bounce easing; equivalent to 1 - bounceIn(1 - t). # d3.easeBounceInOut(t) <> Symmetric bounce easing; scales bounceIn for t in [0, 0.5] and bounceOut for t in [0.5, 1]."
  },
  "src/frontend/app-client/node_modules/d3-hierarchy/README.html": {
    "href": "src/frontend/app-client/node_modules/d3-hierarchy/README.html",
    "title": "d3-hierarchy",
    "summary": "d3-hierarchy Many datasets are intrinsically hierarchical. Consider geographic entities, such as census blocks, census tracts, counties and states; the command structure of businesses and governments; file systems and software packages. And even non-hierarchical data may be arranged empirically into a hierarchy, as with k-means clustering or phylogenetic trees. This module implements several popular techniques for visualizing hierarchical data: Node-link diagrams show topology using discrete marks for nodes and links, such as a circle for each node and a line connecting each parent and child. The “tidy” tree is delightfully compact, while the dendrogram places leaves at the same level. (These have both polar and Cartesian forms.) Indented trees are useful for interactive browsing. Adjacency diagrams show topology through the relative placement of nodes. They may also encode a quantitative dimension in the area of each node, for example to show revenue or file size. The “icicle” diagram uses rectangles, while the “sunburst” uses annular segments. Enclosure diagrams also use an area encoding, but show topology through containment. A treemap recursively subdivides area into rectangles. Circle-packing tightly nests circles; this is not as space-efficient as a treemap, but perhaps more readily shows topology. A good hierarchical visualization facilitates rapid multiscale inference: micro-observations of individual elements and macro-observations of large groups. Installing If you use NPM, npm install d3-hierarchy. Otherwise, download the latest release. You can also load directly from d3js.org, either as a standalone library or as part of D3. AMD, CommonJS, and vanilla environments are supported. In vanilla, a d3 global is exported: <script src=\"https://d3js.org/d3-hierarchy.v1.min.js\"></script> <script> var treemap = d3.treemap(); </script> API Reference Hierarchy (Stratify) Cluster Tree Treemap (Treemap Tiling) Partition Pack Hierarchy Before you can compute a hierarchical layout, you need a root node. If your data is already in a hierarchical format, such as JSON, you can pass it directly to d3.hierarchy; otherwise, you can rearrange tabular data, such as comma-separated values (CSV), into a hierarchy using d3.stratify. # d3.hierarchy(data[, children]) · Source, Examples Constructs a root node from the specified hierarchical data. The specified data must be an object representing the root node. For example: { \"name\": \"Eve\", \"children\": [ { \"name\": \"Cain\" }, { \"name\": \"Seth\", \"children\": [ { \"name\": \"Enos\" }, { \"name\": \"Noam\" } ] }, { \"name\": \"Abel\" }, { \"name\": \"Awan\", \"children\": [ { \"name\": \"Enoch\" } ] }, { \"name\": \"Azura\" } ] } The specified children accessor function is invoked for each datum, starting with the root data, and must return an array of data representing the children, or null if the current datum has no children. If children is not specified, it defaults to: function children(d) { return d.children; } The returned node and each descendant has the following properties: node.data - the associated data, as specified to the constructor. node.depth - zero for the root node, and increasing by one for each descendant generation. node.height - zero for leaf nodes, and the greatest distance from any descendant leaf for internal nodes. node.parent - the parent node, or null for the root node. node.children - an array of child nodes, if any; undefined for leaf nodes. node.value - the summed value of the node and its descendants; optional, see node.sum and node.count. This method can also be used to test if a node is an instanceof d3.hierarchy and to extend the node prototype. # node.ancestors() · Source, Examples Returns the array of ancestors nodes, starting with this node, then followed by each parent up to the root. # node.descendants() · Source, Examples Returns the array of descendant nodes, starting with this node, then followed by each child in topological order. # node.leaves() · Source, Examples Returns the array of leaf nodes in traversal order; leaves are nodes with no children. # node.path(target) · Source, Examples Returns the shortest path through the hierarchy from this node to the specified target node. The path starts at this node, ascends to the least common ancestor of this node and the target node, and then descends to the target node. This is particularly useful for hierarchical edge bundling. # node.links() · Source, Examples Returns an array of links for this node, where each link is an object that defines source and target properties. The source of each link is the parent node, and the target is a child node. # node.sum(value) · Source, Examples Evaluates the specified value function for this node and each descendant in post-order traversal, and returns this node. The node.value property of each node is set to the numeric value returned by the specified function plus the combined value of all children. The function is passed the node’s data, and must return a non-negative number. The value accessor is evaluated for node and every descendant, including internal nodes; if you only want leaf nodes to have internal value, then return zero for any node with children. For example, as an alternative to node.count: root.sum(function(d) { return d.value ? 1 : 0; }); You must call node.sum or node.count before invoking a hierarchical layout that requires node.value, such as d3.treemap. Since the API supports method chaining, you can invoke node.sum and node.sort before computing the layout, and then subsequently generate an array of all descendant nodes like so: var treemap = d3.treemap() .size([width, height]) .padding(2); var nodes = treemap(root .sum(function(d) { return d.value; }) .sort(function(a, b) { return b.height - a.height || b.value - a.value; })) .descendants(); This example assumes that the node data has a value field. # node.count() · Source, Examples Computes the number of leaves under this node and assigns it to node.value, and similarly for every descendant of node. If this node is a leaf, its count is one. Returns this node. See also node.sum. # node.sort(compare) · Source, Examples Sorts the children of this node, if any, and each of this node’s descendants’ children, in pre-order traversal using the specified compare function, and returns this node. The specified function is passed two nodes a and b to compare. If a should be before b, the function must return a value less than zero; if b should be before a, the function must return a value greater than zero; otherwise, the relative order of a and b are not specified. See array.sort for more. Unlike node.sum, the compare function is passed two nodes rather than two nodes’ data. For example, if the data has a value property, this sorts nodes by the descending aggregate value of the node and all its descendants, as is recommended for circle-packing: root .sum(function(d) { return d.value; }) .sort(function(a, b) { return b.value - a.value; }); Similarly, to sort nodes by descending height (greatest distance from any descendant leaf) and then descending value, as is recommended for treemaps and icicles: root .sum(function(d) { return d.value; }) .sort(function(a, b) { return b.height - a.height || b.value - a.value; }); To sort nodes by descending height and then ascending id, as is recommended for trees and dendrograms: root .sum(function(d) { return d.value; }) .sort(function(a, b) { return b.height - a.height || a.id.localeCompare(b.id); }); You must call node.sort before invoking a hierarchical layout if you want the new sort order to affect the layout; see node.sum for an example. # node.each(function) · Source, Examples Invokes the specified function for node and each descendant in breadth-first order, such that a given node is only visited if all nodes of lesser depth have already been visited, as well as all preceding nodes of the same depth. The specified function is passed the current node. # node.eachAfter(function) · Source, Examples Invokes the specified function for node and each descendant in post-order traversal, such that a given node is only visited after all of its descendants have already been visited. The specified function is passed the current node. # node.eachBefore(function) · Source, Examples Invokes the specified function for node and each descendant in pre-order traversal, such that a given node is only visited after all of its ancestors have already been visited. The specified function is passed the current node. # node.copy() · Source, Examples Return a deep copy of the subtree starting at this node. (The returned deep copy shares the same data, however.) The returned node is the root of a new tree; the returned node’s parent is always null and its depth is always zero. Stratify Consider the following table of relationships: Name Parent Eve Cain Eve Seth Eve Enos Seth Noam Seth Abel Eve Awan Eve Enoch Awan Azura Eve These names are conveniently unique, so we can unambiguously represent the hierarchy as a CSV file: name,parent Eve, Cain,Eve Seth,Eve Enos,Seth Noam,Seth Abel,Eve Awan,Eve Enoch,Awan Azura,Eve To parse the CSV using d3.csvParse: var table = d3.csvParse(text); This returns: [ {\"name\": \"Eve\", \"parent\": \"\"}, {\"name\": \"Cain\", \"parent\": \"Eve\"}, {\"name\": \"Seth\", \"parent\": \"Eve\"}, {\"name\": \"Enos\", \"parent\": \"Seth\"}, {\"name\": \"Noam\", \"parent\": \"Seth\"}, {\"name\": \"Abel\", \"parent\": \"Eve\"}, {\"name\": \"Awan\", \"parent\": \"Eve\"}, {\"name\": \"Enoch\", \"parent\": \"Awan\"}, {\"name\": \"Azura\", \"parent\": \"Eve\"} ] To convert to a hierarchy: var root = d3.stratify() .id(function(d) { return d.name; }) .parentId(function(d) { return d.parent; }) (table); This returns: This hierarchy can now be passed to a hierarchical layout, such as d3.tree, for visualization. # d3.stratify() · Source, Examples Constructs a new stratify operator with the default settings. # stratify(data) · Source, Examples Generates a new hierarchy from the specified tabular data. # stratify.id([id]) · Source, Examples If id is specified, sets the id accessor to the given function and returns this stratify operator. Otherwise, returns the current id accessor, which defaults to: function id(d) { return d.id; } The id accessor is invoked for each element in the input data passed to the stratify operator, being passed the current datum (d) and the current index (i). The returned string is then used to identify the node’s relationships in conjunction with the parent id. For leaf nodes, the id may be undefined; otherwise, the id must be unique. (Null and the empty string are equivalent to undefined.) # stratify.parentId([parentId]) · Source, Examples If parentId is specified, sets the parent id accessor to the given function and returns this stratify operator. Otherwise, returns the current parent id accessor, which defaults to: function parentId(d) { return d.parentId; } The parent id accessor is invoked for each element in the input data passed to the stratify operator, being passed the current datum (d) and the current index (i). The returned string is then used to identify the node’s relationships in conjunction with the id. For the root node, the parent id should be undefined. (Null and the empty string are equivalent to undefined.) There must be exactly one root node in the input data, and no circular relationships. Cluster The cluster layout produces dendrograms: node-link diagrams that place leaf nodes of the tree at the same depth. Dendrograms are typically less compact than tidy trees, but are useful when all the leaves should be at the same level, such as for hierarchical clustering or phylogenetic tree diagrams. # d3.cluster() · Source, Examples Creates a new cluster layout with default settings. # cluster(root) Lays out the specified root hierarchy, assigning the following properties on root and its descendants: node.x - the x-coordinate of the node node.y - the y-coordinate of the node The coordinates x and y represent an arbitrary coordinate system; for example, you can treat x as an angle and y as a radius to produce a radial layout. You may want to call root.sort before passing the hierarchy to the cluster layout. # cluster.size([size]) If size is specified, sets this cluster layout’s size to the specified two-element array of numbers [width, height] and returns this cluster layout. If size is not specified, returns the current layout size, which defaults to [1, 1]. A layout size of null indicates that a node size will be used instead. The coordinates x and y represent an arbitrary coordinate system; for example, to produce a radial layout, a size of [360, radius] corresponds to a breadth of 360° and a depth of radius. # cluster.nodeSize([size]) If size is specified, sets this cluster layout’s node size to the specified two-element array of numbers [width, height] and returns this cluster layout. If size is not specified, returns the current node size, which defaults to null. A node size of null indicates that a layout size will be used instead. When a node size is specified, the root node is always positioned at ⟨0, 0⟩. # cluster.separation([separation]) If separation is specified, sets the separation accessor to the specified function and returns this cluster layout. If separation is not specified, returns the current separation accessor, which defaults to: function separation(a, b) { return a.parent == b.parent ? 1 : 2; } The separation accessor is used to separate neighboring leaves. The separation function is passed two leaves a and b, and must return the desired separation. The nodes are typically siblings, though the nodes may be more distantly related if the layout decides to place such nodes adjacent. Tree The tree layout produces tidy node-link diagrams of trees using the Reingold–Tilford “tidy” algorithm, improved to run in linear time by Buchheim et al. Tidy trees are typically more compact than dendrograms. # d3.tree() · Source, Examples Creates a new tree layout with default settings. # tree(root) Lays out the specified root hierarchy, assigning the following properties on root and its descendants: node.x - the x-coordinate of the node node.y - the y-coordinate of the node The coordinates x and y represent an arbitrary coordinate system; for example, you can treat x as an angle and y as a radius to produce a radial layout. You may want to call root.sort before passing the hierarchy to the tree layout. # tree.size([size]) If size is specified, sets this tree layout’s size to the specified two-element array of numbers [width, height] and returns this tree layout. If size is not specified, returns the current layout size, which defaults to [1, 1]. A layout size of null indicates that a node size will be used instead. The coordinates x and y represent an arbitrary coordinate system; for example, to produce a radial layout, a size of [360, radius] corresponds to a breadth of 360° and a depth of radius. # tree.nodeSize([size]) If size is specified, sets this tree layout’s node size to the specified two-element array of numbers [width, height] and returns this tree layout. If size is not specified, returns the current node size, which defaults to null. A node size of null indicates that a layout size will be used instead. When a node size is specified, the root node is always positioned at ⟨0, 0⟩. # tree.separation([separation]) If separation is specified, sets the separation accessor to the specified function and returns this tree layout. If separation is not specified, returns the current separation accessor, which defaults to: function separation(a, b) { return a.parent == b.parent ? 1 : 2; } A variation that is more appropriate for radial layouts reduces the separation gap proportionally to the radius: function separation(a, b) { return (a.parent == b.parent ? 1 : 2) / a.depth; } The separation accessor is used to separate neighboring nodes. The separation function is passed two nodes a and b, and must return the desired separation. The nodes are typically siblings, though the nodes may be more distantly related if the layout decides to place such nodes adjacent. Treemap Introduced by Ben Shneiderman in 1991, a treemap recursively subdivides area into rectangles according to each node’s associated value. D3’s treemap implementation supports an extensible tiling method: the default squarified method seeks to generate rectangles with a golden aspect ratio; this offers better readability and size estimation than slice-and-dice, which simply alternates between horizontal and vertical subdivision by depth. # d3.treemap() · Source, Examples Creates a new treemap layout with default settings. # treemap(root) Lays out the specified root hierarchy, assigning the following properties on root and its descendants: node.x0 - the left edge of the rectangle node.y0 - the top edge of the rectangle node.x1 - the right edge of the rectangle node.y1 - the bottom edge of the rectangle You must call root.sum before passing the hierarchy to the treemap layout. You probably also want to call root.sort to order the hierarchy before computing the layout. # treemap.tile([tile]) If tile is specified, sets the tiling method to the specified function and returns this treemap layout. If tile is not specified, returns the current tiling method, which defaults to d3.treemapSquarify with the golden ratio. # treemap.size([size]) If size is specified, sets this treemap layout’s size to the specified two-element array of numbers [width, height] and returns this treemap layout. If size is not specified, returns the current size, which defaults to [1, 1]. # treemap.round([round]) If round is specified, enables or disables rounding according to the given boolean and returns this treemap layout. If round is not specified, returns the current rounding state, which defaults to false. # treemap.padding([padding]) If padding is specified, sets the inner and outer padding to the specified number or function and returns this treemap layout. If padding is not specified, returns the current inner padding function. # treemap.paddingInner([padding]) If padding is specified, sets the inner padding to the specified number or function and returns this treemap layout. If padding is not specified, returns the current inner padding function, which defaults to the constant zero. If padding is a function, it is invoked for each node with children, being passed the current node. The inner padding is used to separate a node’s adjacent children. # treemap.paddingOuter([padding]) If padding is specified, sets the top, right, bottom and left padding to the specified number or function and returns this treemap layout. If padding is not specified, returns the current top padding function. # treemap.paddingTop([padding]) If padding is specified, sets the top padding to the specified number or function and returns this treemap layout. If padding is not specified, returns the current top padding function, which defaults to the constant zero. If padding is a function, it is invoked for each node with children, being passed the current node. The top padding is used to separate the top edge of a node from its children. # treemap.paddingRight([padding]) If padding is specified, sets the right padding to the specified number or function and returns this treemap layout. If padding is not specified, returns the current right padding function, which defaults to the constant zero. If padding is a function, it is invoked for each node with children, being passed the current node. The right padding is used to separate the right edge of a node from its children. # treemap.paddingBottom([padding]) If padding is specified, sets the bottom padding to the specified number or function and returns this treemap layout. If padding is not specified, returns the current bottom padding function, which defaults to the constant zero. If padding is a function, it is invoked for each node with children, being passed the current node. The bottom padding is used to separate the bottom edge of a node from its children. # treemap.paddingLeft([padding]) If padding is specified, sets the left padding to the specified number or function and returns this treemap layout. If padding is not specified, returns the current left padding function, which defaults to the constant zero. If padding is a function, it is invoked for each node with children, being passed the current node. The left padding is used to separate the left edge of a node from its children. Treemap Tiling Several built-in tiling methods are provided for use with treemap.tile. # d3.treemapBinary(node, x0, y0, x1, y1) · Source, Examples Recursively partitions the specified nodes into an approximately-balanced binary tree, choosing horizontal partitioning for wide rectangles and vertical partitioning for tall rectangles. # d3.treemapDice(node, x0, y0, x1, y1) · Source, Examples Divides the rectangular area specified by x0, y0, x1, y1 horizontally according the value of each of the specified node’s children. The children are positioned in order, starting with the left edge (x0) of the given rectangle. If the sum of the children’s values is less than the specified node’s value (i.e., if the specified node has a non-zero internal value), the remaining empty space will be positioned on the right edge (x1) of the given rectangle. # d3.treemapSlice(node, x0, y0, x1, y1) · Source, Examples Divides the rectangular area specified by x0, y0, x1, y1 vertically according the value of each of the specified node’s children. The children are positioned in order, starting with the top edge (y0) of the given rectangle. If the sum of the children’s values is less than the specified node’s value (i.e., if the specified node has a non-zero internal value), the remaining empty space will be positioned on the bottom edge (y1) of the given rectangle. # d3.treemapSliceDice(node, x0, y0, x1, y1) · Source, Examples If the specified node has odd depth, delegates to treemapSlice; otherwise delegates to treemapDice. # d3.treemapSquarify(node, x0, y0, x1, y1) · Source, Examples Implements the squarified treemap algorithm by Bruls et al., which seeks to produce rectangles of a given aspect ratio. # d3.treemapResquarify(node, x0, y0, x1, y1) · Source, Examples Like d3.treemapSquarify, except preserves the topology (node adjacencies) of the previous layout computed by d3.treemapResquarify, if there is one and it used the same target aspect ratio. This tiling method is good for animating changes to treemaps because it only changes node sizes and not their relative positions, thus avoiding distracting shuffling and occlusion. The downside of a stable update, however, is a suboptimal layout for subsequent updates: only the first layout uses the Bruls et al. squarified algorithm. # squarify.ratio(ratio) · Source, Examples Specifies the desired aspect ratio of the generated rectangles. The ratio must be specified as a number greater than or equal to one. Note that the orientation of the generated rectangles (tall or wide) is not implied by the ratio; for example, a ratio of two will attempt to produce a mixture of rectangles whose width:height ratio is either 2:1 or 1:2. (However, you can approximately achieve this result by generating a square treemap at different dimensions, and then stretching the treemap to the desired aspect ratio.) Furthermore, the specified ratio is merely a hint to the tiling algorithm; the rectangles are not guaranteed to have the specified aspect ratio. If not specified, the aspect ratio defaults to the golden ratio, φ = (1 + sqrt(5)) / 2, per Kong et al. Partition The partition layout produces adjacency diagrams: a space-filling variant of a node-link tree diagram. Rather than drawing a link between parent and child in the hierarchy, nodes are drawn as solid areas (either arcs or rectangles), and their placement relative to other nodes reveals their position in the hierarchy. The size of the nodes encodes a quantitative dimension that would be difficult to show in a node-link diagram. # d3.partition() · Source, Examples Creates a new partition layout with the default settings. # partition(root) Lays out the specified root hierarchy, assigning the following properties on root and its descendants: node.x0 - the left edge of the rectangle node.y0 - the top edge of the rectangle node.x1 - the right edge of the rectangle node.y1 - the bottom edge of the rectangle You must call root.sum before passing the hierarchy to the partition layout. You probably also want to call root.sort to order the hierarchy before computing the layout. # partition.size([size]) If size is specified, sets this partition layout’s size to the specified two-element array of numbers [width, height] and returns this partition layout. If size is not specified, returns the current size, which defaults to [1, 1]. # partition.round([round]) If round is specified, enables or disables rounding according to the given boolean and returns this partition layout. If round is not specified, returns the current rounding state, which defaults to false. # partition.padding([padding]) If padding is specified, sets the padding to the specified number and returns this partition layout. If padding is not specified, returns the current padding, which defaults to zero. The padding is used to separate a node’s adjacent children. Pack Enclosure diagrams use containment (nesting) to represent a hierarchy. The size of the leaf circles encodes a quantitative dimension of the data. The enclosing circles show the approximate cumulative size of each subtree, but due to wasted space there is some distortion; only the leaf nodes can be compared accurately. Although circle packing does not use space as efficiently as a treemap, the “wasted” space more prominently reveals the hierarchical structure. # d3.pack() · Source, Examples Creates a new pack layout with the default settings. # pack(root) Lays out the specified root hierarchy, assigning the following properties on root and its descendants: node.x - the x-coordinate of the circle’s center node.y - the y-coordinate of the circle’s center node.r - the radius of the circle You must call root.sum before passing the hierarchy to the pack layout. You probably also want to call root.sort to order the hierarchy before computing the layout. # pack.radius([radius]) If radius is specified, sets the pack layout’s radius accessor to the specified function and returns this pack layout. If radius is not specified, returns the current radius accessor, which defaults to null. If the radius accessor is null, the radius of each leaf circle is derived from the leaf node.value (computed by node.sum); the radii are then scaled proportionally to fit the layout size. If the radius accessor is not null, the radius of each leaf circle is specified exactly by the function. # pack.size([size]) If size is specified, sets this pack layout’s size to the specified two-element array of numbers [width, height] and returns this pack layout. If size is not specified, returns the current size, which defaults to [1, 1]. # pack.padding([padding]) If padding is specified, sets this pack layout’s padding accessor to the specified number or function and returns this pack layout. If padding is not specified, returns the current padding accessor, which defaults to the constant zero. When siblings are packed, tangent siblings will be separated by approximately the specified padding; the enclosing parent circle will also be separated from its children by approximately the specified padding. If an explicit radius is not specified, the padding is approximate because a two-pass algorithm is needed to fit within the layout size: the circles are first packed without padding; a scaling factor is computed and applied to the specified padding; and lastly the circles are re-packed with padding. # d3.packSiblings(circles) · Source Packs the specified array of circles, each of which must have a circle.r property specifying the circle’s radius. Assigns the following properties to each circle: circle.x - the x-coordinate of the circle’s center circle.y - the y-coordinate of the circle’s center The circles are positioned according to the front-chain packing algorithm by Wang et al. # d3.packEnclose(circles) · Source, Examples Computes the smallest circle that encloses the specified array of circles, each of which must have a circle.r property specifying the circle’s radius, and circle.x and circle.y properties specifying the circle’s center. The enclosing circle is computed using the Matoušek-Sharir-Welzl algorithm. (See also Apollonius’ Problem.)"
  },
  "src/frontend/app-client/node_modules/d3-interpolate/README.html": {
    "href": "src/frontend/app-client/node_modules/d3-interpolate/README.html",
    "title": "d3-interpolate",
    "summary": "d3-interpolate This module provides a variety of interpolation methods for blending between two values. Values may be numbers, colors, strings, arrays, or even deeply-nested objects. For example: const i = d3.interpolateNumber(10, 20); i(0.0); // 10 i(0.2); // 12 i(0.5); // 15 i(1.0); // 20 The returned function i is called an interpolator. Given a starting value a and an ending value b, it takes a parameter t in the domain [0, 1] and returns the corresponding interpolated value between a and b. An interpolator typically returns a value equivalent to a at t = 0 and a value equivalent to b at t = 1. You can interpolate more than just numbers. To find the perceptual midpoint between steelblue and brown: d3.interpolateLab(\"steelblue\", \"brown\")(0.5); // \"rgb(142, 92, 109)\" Here’s a more elaborate example demonstrating type inference used by interpolate: const i = d3.interpolate({colors: [\"red\", \"blue\"]}, {colors: [\"white\", \"black\"]}); i(0.0); // {colors: [\"rgb(255, 0, 0)\", \"rgb(0, 0, 255)\"]} i(0.5); // {colors: [\"rgb(255, 128, 128)\", \"rgb(0, 0, 128)\"]} i(1.0); // {colors: [\"rgb(255, 255, 255)\", \"rgb(0, 0, 0)\"]} Note that the generic value interpolator detects not only nested objects and arrays, but also color strings and numbers embedded in strings! Installing If you use npm, npm install d3-interpolate. You can also download the latest release on GitHub. For vanilla HTML in modern browsers, import d3-interpolate from Skypack: <script type=\"module\"> import {interpolateRgb} from \"https://cdn.skypack.dev/d3-interpolate@3\"; const interpolate = interpolateRgb(\"steelblue\", \"brown\"); </script> For legacy environments, you can load d3-interpolate’s UMD bundle from an npm-based CDN such as jsDelivr; a d3 global is exported. (If using color interpolation, also load d3-color.) <script src=\"https://cdn.jsdelivr.net/npm/d3-color@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-interpolate@3\"></script> <script> const interpolate = d3.interpolateRgb(\"steelblue\", \"brown\"); </script> API Reference # d3.interpolate(a, b) · Source, Examples Returns an interpolator between the two arbitrary values a and b. The interpolator implementation is based on the type of the end value b, using the following algorithm: If b is null, undefined or a boolean, use the constant b. If b is a number, use interpolateNumber. If b is a color or a string coercible to a color, use interpolateRgb. If b is a date, use interpolateDate. If b is a string, use interpolateString. If b is a typed array of numbers, use interpolateNumberArray. If b is a generic array, use interpolateArray. If b is coercible to a number, use interpolateNumber. Use interpolateObject. Based on the chosen interpolator, a is coerced to the suitable corresponding type. # d3.interpolateNumber(a, b) · Source, Examples Returns an interpolator between the two numbers a and b. The returned interpolator is equivalent to: function interpolator(t) { return a * (1 - t) + b * t; } Caution: avoid interpolating to or from the number zero when the interpolator is used to generate a string. When very small values are stringified, they may be converted to scientific notation, which is an invalid attribute or style property value in older browsers. For example, the number 0.0000001 is converted to the string \"1e-7\". This is particularly noticeable with interpolating opacity. To avoid scientific notation, start or end the transition at 1e-6: the smallest value that is not stringified in scientific notation. # d3.interpolateRound(a, b) · Source, Examples Returns an interpolator between the two numbers a and b; the interpolator is similar to interpolateNumber, except it will round the resulting value to the nearest integer. # d3.interpolateString(a, b) · Source, Examples Returns an interpolator between the two strings a and b. The string interpolator finds numbers embedded in a and b, where each number is of the form understood by JavaScript. A few examples of numbers that will be detected within a string: -1, 42, 3.14159, and 6.0221413e+23. For each number embedded in b, the interpolator will attempt to find a corresponding number in a. If a corresponding number is found, a numeric interpolator is created using interpolateNumber. The remaining parts of the string b are used as a template: the static parts of the string b remain constant for the interpolation, with the interpolated numeric values embedded in the template. For example, if a is \"300 12px sans-serif\", and b is \"500 36px Comic-Sans\", two embedded numbers are found. The remaining static parts (of string b) are a space between the two numbers (\" \"), and the suffix (\"px Comic-Sans\"). The result of the interpolator at t = 0.5 is \"400 24px Comic-Sans\". # d3.interpolateDate(a, b) · Source, Examples Returns an interpolator between the two dates a and b. Note: no defensive copy of the returned date is created; the same Date instance is returned for every evaluation of the interpolator. No copy is made for performance reasons; interpolators are often part of the inner loop of animated transitions. # d3.interpolateArray(a, b) · Source, Examples Returns an interpolator between the two arrays a and b. If b is a typed array (e.g., Float64Array), interpolateNumberArray is called instead. Internally, an array template is created that is the same length as b. For each element in b, if there exists a corresponding element in a, a generic interpolator is created for the two elements using interpolate. If there is no such element, the static value from b is used in the template. Then, for the given parameter t, the template’s embedded interpolators are evaluated. The updated array template is then returned. For example, if a is the array [0, 1] and b is the array [1, 10, 100], then the result of the interpolator for t = 0.5 is the array [0.5, 5.5, 100]. Note: no defensive copy of the template array is created; modifications of the returned array may adversely affect subsequent evaluation of the interpolator. No copy is made for performance reasons; interpolators are often part of the inner loop of animated transitions. # d3.interpolateNumberArray(a, b) · Source, Examples Returns an interpolator between the two arrays of numbers a and b. Internally, an array template is created that is the same type and length as b. For each element in b, if there exists a corresponding element in a, the values are directly interpolated in the array template. If there is no such element, the static value from b is copied. The updated array template is then returned. Note: For performance reasons, no defensive copy is made of the template array and the arguments a and b; modifications of these arrays may affect subsequent evaluation of the interpolator. # d3.interpolateObject(a, b) · Source, Examples Returns an interpolator between the two objects a and b. Internally, an object template is created that has the same properties as b. For each property in b, if there exists a corresponding property in a, a generic interpolator is created for the two elements using interpolate. If there is no such property, the static value from b is used in the template. Then, for the given parameter t, the template's embedded interpolators are evaluated and the updated object template is then returned. For example, if a is the object {x: 0, y: 1} and b is the object {x: 1, y: 10, z: 100}, the result of the interpolator for t = 0.5 is the object {x: 0.5, y: 5.5, z: 100}. Object interpolation is particularly useful for dataspace interpolation, where data is interpolated rather than attribute values. For example, you can interpolate an object which describes an arc in a pie chart, and then use d3.arc to compute the new SVG path data. Note: no defensive copy of the template object is created; modifications of the returned object may adversely affect subsequent evaluation of the interpolator. No copy is made for performance reasons; interpolators are often part of the inner loop of animated transitions. # d3.interpolateTransformCss(a, b) · Source, Examples Returns an interpolator between the two 2D CSS transforms represented by a and b. Each transform is decomposed to a standard representation of translate, rotate, x-skew and scale; these component transformations are then interpolated. This behavior is standardized by CSS: see matrix decomposition for animation. # d3.interpolateTransformSvg(a, b) · Source, Examples Returns an interpolator between the two 2D SVG transforms represented by a and b. Each transform is decomposed to a standard representation of translate, rotate, x-skew and scale; these component transformations are then interpolated. This behavior is standardized by CSS: see matrix decomposition for animation. # d3.interpolateZoom(a, b) · Source, Examples Returns an interpolator between the two views a and b of a two-dimensional plane, based on “Smooth and efficient zooming and panning” by Jarke J. van Wijk and Wim A.A. Nuij. Each view is defined as an array of three numbers: cx, cy and width. The first two coordinates cx, cy represent the center of the viewport; the last coordinate width represents the size of the viewport. The returned interpolator exposes a duration property which encodes the recommended transition duration in milliseconds. This duration is based on the path length of the curved trajectory through x,y space. If you want a slower or faster transition, multiply this by an arbitrary scale factor (V as described in the original paper). # interpolateZoom.rho(rho) · Source Given a zoom interpolator, returns a new zoom interpolator using the specified curvature rho. When rho is close to 0, the interpolator is almost linear. The default curvature is sqrt(2). # d3.interpolateDiscrete(values) · Source, Examples Returns a discrete interpolator for the given array of values. The returned interpolator maps t in [0, 1 / n) to values[0], t in [1 / n, 2 / n) to values[1], and so on, where n = values.length. In effect, this is a lightweight quantize scale with a fixed domain of [0, 1]. Sampling # d3.quantize(interpolator, n) · Source, Examples Returns n uniformly-spaced samples from the specified interpolator, where n is an integer greater than one. The first sample is always at t = 0, and the last sample is always at t = 1. This can be useful in generating a fixed number of samples from a given interpolator, such as to derive the range of a quantize scale from a continuous interpolator. Caution: this method will not work with interpolators that do not return defensive copies of their output, such as d3.interpolateArray, d3.interpolateDate and d3.interpolateObject. For those interpolators, you must wrap the interpolator and create a copy for each returned value. Color Spaces # d3.interpolateRgb(a, b) · Source, Examples Or, with a corrected gamma of 2.2: Returns an RGB color space interpolator between the two colors a and b with a configurable gamma. If the gamma is not specified, it defaults to 1.0. The colors a and b need not be in RGB; they will be converted to RGB using d3.rgb. The return value of the interpolator is an RGB string. # d3.interpolateRgbBasis(colors) · Source, Examples Returns a uniform nonrational B-spline interpolator through the specified array of colors, which are converted to RGB color space. Implicit control points are generated such that the interpolator returns colors[0] at t = 0 and colors[colors.length - 1] at t = 1. Opacity interpolation is not currently supported. See also d3.interpolateBasis, and see d3-scale-chromatic for examples. # d3.interpolateRgbBasisClosed(colors) · Source, Examples Returns a uniform nonrational B-spline interpolator through the specified array of colors, which are converted to RGB color space. The control points are implicitly repeated such that the resulting spline has cyclical C² continuity when repeated around t in [0,1]; this is useful, for example, to create cyclical color scales. Opacity interpolation is not currently supported. See also d3.interpolateBasisClosed, and see d3-scale-chromatic for examples. # d3.interpolateHsl(a, b) · Source, Examples Returns an HSL color space interpolator between the two colors a and b. The colors a and b need not be in HSL; they will be converted to HSL using d3.hsl. If either color’s hue or saturation is NaN, the opposing color’s channel value is used. The shortest path between hues is used. The return value of the interpolator is an RGB string. # d3.interpolateHslLong(a, b) · Source, Examples Like interpolateHsl, but does not use the shortest path between hues. # d3.interpolateLab(a, b) · Source, Examples Returns a CIELAB color space interpolator between the two colors a and b. The colors a and b need not be in CIELAB; they will be converted to CIELAB using d3.lab. The return value of the interpolator is an RGB string. # d3.interpolateHcl(a, b) · Source, Examples Returns a CIELChab color space interpolator between the two colors a and b. The colors a and b need not be in CIELChab; they will be converted to CIELChab using d3.hcl. If either color’s hue or chroma is NaN, the opposing color’s channel value is used. The shortest path between hues is used. The return value of the interpolator is an RGB string. # d3.interpolateHclLong(a, b) · Source, Examples Like interpolateHcl, but does not use the shortest path between hues. # d3.interpolateCubehelix(a, b) · Source, Examples Or, with a gamma of 3.0 to emphasize high-intensity values: Returns a Cubehelix color space interpolator between the two colors a and b using a configurable gamma. If the gamma is not specified, it defaults to 1.0. The colors a and b need not be in Cubehelix; they will be converted to Cubehelix using d3.cubehelix. If either color’s hue or saturation is NaN, the opposing color’s channel value is used. The shortest path between hues is used. The return value of the interpolator is an RGB string. # d3.interpolateCubehelixLong(a, b) · Source, Examples Or, with a gamma of 3.0 to emphasize high-intensity values: Like interpolateCubehelix, but does not use the shortest path between hues. # interpolate.gamma(gamma) Given that interpolate is one of interpolateRgb, interpolateCubehelix or interpolateCubehelixLong, returns a new interpolator factory of the same type using the specified gamma. For example, to interpolate from purple to orange with a gamma of 2.2 in RGB space: const interpolator = d3.interpolateRgb.gamma(2.2)(\"purple\", \"orange\"); See Eric Brasseur’s article, Gamma error in picture scaling, for more on gamma correction. # d3.interpolateHue(a, b) · Source, Examples Returns an interpolator between the two hue angles a and b. If either hue is NaN, the opposing value is used. The shortest path between hues is used. The return value of the interpolator is a number in [0, 360). Splines Whereas standard interpolators blend from a starting value a at t = 0 to an ending value b at t = 1, spline interpolators smoothly blend multiple input values for t in [0,1] using piecewise polynomial functions. Only cubic uniform nonrational B-splines are currently supported, also known as basis splines. # d3.interpolateBasis(values) · Source, Examples Returns a uniform nonrational B-spline interpolator through the specified array of values, which must be numbers. Implicit control points are generated such that the interpolator returns values[0] at t = 0 and values[values.length - 1] at t = 1. See also d3.curveBasis. # d3.interpolateBasisClosed(values) · Source, Examples Returns a uniform nonrational B-spline interpolator through the specified array of values, which must be numbers. The control points are implicitly repeated such that the resulting one-dimensional spline has cyclical C² continuity when repeated around t in [0,1]. See also d3.curveBasisClosed. Piecewise # d3.piecewise([interpolate, ]values) · Source, Examples Returns a piecewise interpolator, composing interpolators for each adjacent pair of values. The returned interpolator maps t in [0, 1 / (n - 1)] to interpolate(values[0], values[1]), t in [1 / (n - 1), 2 / (n - 1)] to interpolate(values[1], values[2]), and so on, where n = values.length. In effect, this is a lightweight linear scale. For example, to blend through red, green and blue: const interpolate = d3.piecewise(d3.interpolateRgb.gamma(2.2), [\"red\", \"green\", \"blue\"]); If interpolate is not specified, defaults to d3.interpolate."
  },
  "src/frontend/app-client/node_modules/d3-path/README.html": {
    "href": "src/frontend/app-client/node_modules/d3-path/README.html",
    "title": "d3-path",
    "summary": "d3-path Say you have some code that draws to a 2D canvas: function drawCircle(context, radius) { context.moveTo(radius, 0); context.arc(0, 0, radius, 0, 2 * Math.PI); } The d3-path module lets you take this exact code and additionally render to SVG. It works by serializing CanvasPathMethods calls to SVG path data. For example: var context = d3.path(); drawCircle(context, 40); pathElement.setAttribute(\"d\", context.toString()); Now code you write once can be used with both Canvas (for performance) and SVG (for convenience). For a practical example, see d3-shape. Installing If you use NPM, npm install d3-path. Otherwise, download the latest release. You can also load directly from d3js.org, either as a standalone library or as part of D3 4.0. AMD, CommonJS, and vanilla environments are supported. In vanilla, a d3 global is exported: <script src=\"https://d3js.org/d3-path.v1.min.js\"></script> <script> var path = d3.path(); path.moveTo(1, 2); path.lineTo(3, 4); path.closePath(); </script> API Reference # d3.path() · Source, Examples Constructs a new path serializer that implements CanvasPathMethods. # path.moveTo(x, y) Move to the specified point ⟨x, y⟩. Equivalent to context.moveTo and SVG’s “moveto” command. # path.closePath() Ends the current subpath and causes an automatic straight line to be drawn from the current point to the initial point of the current subpath. Equivalent to context.closePath and SVG’s “closepath” command. # path.lineTo(x, y) Draws a straight line from the current point to the specified point ⟨x, y⟩. Equivalent to context.lineTo and SVG’s “lineto” command. # path.quadraticCurveTo(cpx, cpy, x, y) Draws a quadratic Bézier segment from the current point to the specified point ⟨x, y⟩, with the specified control point ⟨cpx, cpy⟩. Equivalent to context.quadraticCurveTo and SVG’s quadratic Bézier curve commands. # path.bezierCurveTo(cpx1, cpy1, cpx2, cpy2, x, y) Draws a cubic Bézier segment from the current point to the specified point ⟨x, y⟩, with the specified control points ⟨cpx1, cpy1⟩ and ⟨cpx2, cpy2⟩. Equivalent to context.bezierCurveTo and SVG’s cubic Bézier curve commands. # path.arcTo(x1, y1, x2, y2, radius) Draws a circular arc segment with the specified radius that starts tangent to the line between the current point and the specified point ⟨x1, y1⟩ and ends tangent to the line between the specified points ⟨x1, y1⟩ and ⟨x2, y2⟩. If the first tangent point is not equal to the current point, a straight line is drawn between the current point and the first tangent point. Equivalent to context.arcTo and uses SVG’s elliptical arc curve commands. # path.arc(x, y, radius, startAngle, endAngle[, anticlockwise]) Draws a circular arc segment with the specified center ⟨x, y⟩, radius, startAngle and endAngle. If anticlockwise is true, the arc is drawn in the anticlockwise direction; otherwise, it is drawn in the clockwise direction. If the current point is not equal to the starting point of the arc, a straight line is drawn from the current point to the start of the arc. Equivalent to context.arc and uses SVG’s elliptical arc curve commands. # path.rect(x, y, w, h) Creates a new subpath containing just the four points ⟨x, y⟩, ⟨x + w, y⟩, ⟨x + w, y + h⟩, ⟨x, y + h⟩, with those four points connected by straight lines, and then marks the subpath as closed. Equivalent to context.rect and uses SVG’s “lineto” commands. # path.toString() Returns the string representation of this path according to SVG’s path data specification."
  },
  "src/frontend/app-client/node_modules/d3-selection/README.html": {
    "href": "src/frontend/app-client/node_modules/d3-selection/README.html",
    "title": "d3-selection",
    "summary": "d3-selection Selections allow powerful data-driven transformation of the document object model (DOM): set attributes, styles, properties, HTML or text content, and more. Using the data join’s enter and exit selections, you can also add or remove elements to correspond to data. Selection methods typically return the current selection, or a new selection, allowing the concise application of multiple operations on a given selection via method chaining. For example, to set the class and color style of all paragraph elements in the current document: d3.selectAll(\"p\") .attr(\"class\", \"graf\") .style(\"color\", \"red\"); This is equivalent to: const p = d3.selectAll(\"p\"); p.attr(\"class\", \"graf\"); p.style(\"color\", \"red\"); By convention, selection methods that return the current selection use four spaces of indent, while methods that return a new selection use only two. This helps reveal changes of context by making them stick out of the chain: d3.select(\"body\") .append(\"svg\") .attr(\"width\", 960) .attr(\"height\", 500) .append(\"g\") .attr(\"transform\", \"translate(20,20)\") .append(\"rect\") .attr(\"width\", 920) .attr(\"height\", 460); Selections are immutable. All selection methods that affect which elements are selected (or their order) return a new selection rather than modifying the current selection. However, note that elements are necessarily mutable, as selections drive transformations of the document! For more, see the d3-selection collection on Observable. Installing If you use npm, npm install d3-selection. You can also download the latest release on GitHub. For vanilla HTML in modern browsers, import d3-selection from Skypack: <script type=\"module\"> import {selectAll} from \"https://cdn.skypack.dev/d3-selection@3\"; const div = selectAll(\"div\"); </script> For legacy environments, you can load d3-selection’s UMD bundle from an npm-based CDN such as jsDelivr; a d3 global is exported: <script src=\"https://cdn.jsdelivr.net/npm/d3-selection@3\"></script> <script> const div = d3.selectAll(\"div\"); </script> Try d3-selection in your browser. API Reference Selecting Elements Modifying Elements Joining Data Handling Events Control Flow Local Variables Namespaces Selecting Elements Selection methods accept W3C selector strings such as .fancy to select elements with the class fancy, or div to select DIV elements. Selection methods come in two forms: select and selectAll: the former selects only the first matching element, while the latter selects all matching elements in document order. The top-level selection methods, d3.select and d3.selectAll, query the entire document; the subselection methods, selection.select and selection.selectAll, restrict selection to descendants of the selected elements. # d3.selection() · Source Selects the root element, document.documentElement. This function can also be used to test for selections (instanceof d3.selection) or to extend the selection prototype. For example, to add a method to check checkboxes: d3.selection.prototype.checked = function(value) { return arguments.length < 1 ? this.property(\"checked\") : this.property(\"checked\", !!value); }; And then to use: d3.selectAll(\"input[type=checkbox]\").checked(true); # d3.select(selector) · Source Selects the first element that matches the specified selector string. If no elements match the selector, returns an empty selection. If multiple elements match the selector, only the first matching element (in document order) will be selected. For example, to select the first anchor element: const anchor = d3.select(\"a\"); If the selector is not a string, instead selects the specified node; this is useful if you already have a reference to a node, such as this within an event listener or a global such as document.body. For example, to make a clicked paragraph red: d3.selectAll(\"p\").on(\"click\", function(event) { d3.select(this).style(\"color\", \"red\"); }); # d3.selectAll(selector) · Source Selects all elements that match the specified selector string. The elements will be selected in document order (top-to-bottom). If no elements in the document match the selector, or if the selector is null or undefined, returns an empty selection. For example, to select all paragraphs: const paragraph = d3.selectAll(\"p\"); If the selector is not a string, instead selects the specified array of nodes; this is useful if you already have a reference to nodes, such as this.childNodes within an event listener or a global such as document.links. The nodes may instead be an iterable, or a pseudo-array such as a NodeList. For example, to color all links red: d3.selectAll(document.links).style(\"color\", \"red\"); # selection.select(selector) · Source For each selected element, selects the first descendant element that matches the specified selector string. If no element matches the specified selector for the current element, the element at the current index will be null in the returned selection. (If the selector is null, every element in the returned selection will be null, resulting in an empty selection.) If the current element has associated data, this data is propagated to the corresponding selected element. If multiple elements match the selector, only the first matching element in document order is selected. For example, to select the first bold element in every paragraph: const b = d3.selectAll(\"p\").select(\"b\"); If the selector is a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]). It must return an element, or null if there is no matching element. For example, to select the previous sibling of each paragraph: const previous = d3.selectAll(\"p\").select(function() { return this.previousElementSibling; }); Unlike selection.selectAll, selection.select does not affect grouping: it preserves the existing group structure and indexes, and propagates data (if any) to selected children. Grouping plays an important role in the data join. See Nested Selections and How Selections Work for more on this topic. # selection.selectAll(selector) · Source For each selected element, selects the descendant elements that match the specified selector string. The elements in the returned selection are grouped by their corresponding parent node in this selection. If no element matches the specified selector for the current element, or if the selector is null, the group at the current index will be empty. The selected elements do not inherit data from this selection; use selection.data to propagate data to children. For example, to select the bold elements in every paragraph: const b = d3.selectAll(\"p\").selectAll(\"b\"); If the selector is a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]). It must return an array of elements (or an iterable, or a pseudo-array such as a NodeList), or the empty array if there are no matching elements. For example, to select the previous and next siblings of each paragraph: const sibling = d3.selectAll(\"p\").selectAll(function() { return [ this.previousElementSibling, this.nextElementSibling ]; }); Unlike selection.select, selection.selectAll does affect grouping: each selected descendant is grouped by the parent element in the originating selection. Grouping plays an important role in the data join. See Nested Selections and How Selections Work for more on this topic. # selection.filter(filter) · Source Filters the selection, returning a new selection that contains only the elements for which the specified filter is true. The filter may be specified either as a selector string or a function. If the filter is a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]). For example, to filter a selection of table rows to contain only even rows: const even = d3.selectAll(\"tr\").filter(\":nth-child(even)\"); This is approximately equivalent to using d3.selectAll directly, although the indexes may be different: const even = d3.selectAll(\"tr:nth-child(even)\"); Similarly, using a function: const even = d3.selectAll(\"tr\").filter((d, i) => i & 1); Or using selection.select (and avoiding an arrow function, since this is needed to refer to the current element): const even = d3.selectAll(\"tr\").select(function(d, i) { return i & 1 ? this : null; }); Note that the :nth-child pseudo-class is a one-based index rather than a zero-based index. Also, the above filter functions do not have precisely the same meaning as :nth-child; they rely on the selection index rather than the number of preceding sibling elements in the DOM. The returned filtered selection preserves the parents of this selection, but like array.filter, it does not preserve indexes as some elements may be removed; use selection.select to preserve the index, if needed. # selection.merge(other) · Source Returns a new selection merging this selection with the specified other selection or transition. The returned selection has the same number of groups and the same parents as this selection. Any missing (null) elements in this selection are filled with the corresponding element, if present (not null), from the specified selection. (If the other selection has additional groups or parents, they are ignored.) This method is used internally by selection.join to merge the enter and update selections after binding data. You can also merge explicitly, although note that since merging is based on element index, you should use operations that preserve index, such as selection.select instead of selection.filter. For example: const odd = selection.select(function(d, i) { return i & 1 ? this : null; )); const even = selection.select(function(d, i) { return i & 1 ? null : this; )); const merged = odd.merge(even); See selection.data for more. This method is not intended for concatenating arbitrary selections, however: if both this selection and the specified other selection have (non-null) elements at the same index, this selection’s element is returned in the merge and the other selection’s element is ignored. # selection.selectChild([selector]) · Source Returns a new selection with the (first) child of each element of the current selection matching the selector. If no selector is specified, selects the first child (if any). If the selector is specified as a string, selects the first child that matches (if any). If the selector is a function, it is evaluated for each of the children nodes, in order, being passed the child (child), the child’s index (i), and the list of children (children); the method selects the first child for which the selector return truthy, if any. # selection.selectChildren([selector]) · Source Returns a new selection with the children of each element of the current selection matching the selector. If no selector is specified, selects all the children. If the selector is specified as a string, selects the children that match (if any). If the selector is a function, it is evaluated for each of the children nodes, in order, being passed the child (child), the child’s index (i), and the list of children (children); the method selects all children for which the selector return truthy. # selection.selection() · Source Returns the selection (for symmetry with transition.selection). # d3.matcher(selector) · Source Given the specified selector, returns a function which returns true if this element matches the specified selector. This method is used internally by selection.filter. For example, this: const div = selection.filter(\"div\"); Is equivalent to: const div = selection.filter(d3.matcher(\"div\")); (Although D3 is not a compatibility layer, this implementation does support vendor-prefixed implementations due to the recent standardization of element.matches.) # d3.selector(selector) · Source Given the specified selector, returns a function which returns the first descendant of this element that matches the specified selector. This method is used internally by selection.select. For example, this: const div = selection.select(\"div\"); Is equivalent to: const div = selection.select(d3.selector(\"div\")); # d3.selectorAll(selector) · Source Given the specified selector, returns a function which returns all descendants of this element that match the specified selector. This method is used internally by selection.selectAll. For example, this: const div = selection.selectAll(\"div\"); Is equivalent to: const div = selection.selectAll(d3.selectorAll(\"div\")); # d3.window(node) · Source Returns the owner window for the specified node. If node is a node, returns the owner document’s default view; if node is a document, returns its default view; otherwise returns the node. # d3.style(node, name) · Source Returns the value of the style property with the specified name for the specified node. If the node has an inline style with the specified name, its value is returned; otherwise, the computed property value is returned. See also selection.style. Modifying Elements After selecting elements, use the selection’s transformation methods to affect document content. For example, to set the name attribute and color style of an anchor element: d3.select(\"a\") .attr(\"name\", \"fred\") .style(\"color\", \"red\"); To experiment with selections, visit d3js.org and open your browser’s developer console! (In Chrome, open the console with ⌥⌘J.) Select elements and then inspect the returned selection to see which elements are selected and how they are grouped. Call selection methods and see how the page content changes. # selection.attr(name[, value]) · Source If a value is specified, sets the attribute with the specified name to the specified value on the selected elements and returns this selection. If the value is a constant, all elements are given the same attribute value; otherwise, if the value is a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]). The function’s return value is then used to set each element’s attribute. A null value will remove the specified attribute. If a value is not specified, returns the current value of the specified attribute for the first (non-null) element in the selection. This is generally useful only if you know that the selection contains exactly one element. The specified name may have a namespace prefix, such as xlink:href to specify the href attribute in the XLink namespace. See namespaces for the map of supported namespaces; additional namespaces can be registered by adding to the map. # selection.classed(names[, value]) · Source If a value is specified, assigns or unassigns the specified CSS class names on the selected elements by setting the class attribute or modifying the classList property and returns this selection. The specified names is a string of space-separated class names. For example, to assign the classes foo and bar to the selected elements: selection.classed(\"foo bar\", true); If the value is truthy, then all elements are assigned the specified classes; otherwise, the classes are unassigned. If the value is a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]). The function’s return value is then used to assign or unassign classes on each element. For example, to randomly associate the class foo with on average half the selected elements: selection.classed(\"foo\", () => Math.random() > 0.5); If a value is not specified, returns true if and only if the first (non-null) selected element has the specified classes. This is generally useful only if you know the selection contains exactly one element. # selection.style(name[, value[, priority]]) · Source If a value is specified, sets the style property with the specified name to the specified value on the selected elements and returns this selection. If the value is a constant, then all elements are given the same style property value; otherwise, if the value is a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]). The function’s return value is then used to set each element’s style property. A null value will remove the style property. An optional priority may also be specified, either as null or the string important (without the exclamation point). If a value is not specified, returns the current value of the specified style property for the first (non-null) element in the selection. The current value is defined as the element’s inline value, if present, and otherwise its computed value. Accessing the current style value is generally useful only if you know the selection contains exactly one element. Caution: unlike many SVG attributes, CSS styles typically have associated units. For example, 3px is a valid stroke-width property value, while 3 is not. Some browsers implicitly assign the px (pixel) unit to numeric values, but not all browsers do: IE, for example, throws an “invalid arguments” error! # selection.property(name[, value]) · Source Some HTML elements have special properties that are not addressable using attributes or styles, such as a form field’s text value and a checkbox’s checked boolean. Use this method to get or set these properties. If a value is specified, sets the property with the specified name to the specified value on selected elements. If the value is a constant, then all elements are given the same property value; otherwise, if the value is a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]). The function’s return value is then used to set each element’s property. A null value will delete the specified property. If a value is not specified, returns the value of the specified property for the first (non-null) element in the selection. This is generally useful only if you know the selection contains exactly one element. # selection.text([value]) · Source If a value is specified, sets the text content to the specified value on all selected elements, replacing any existing child elements. If the value is a constant, then all elements are given the same text content; otherwise, if the value is a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]). The function’s return value is then used to set each element’s text content. A null value will clear the content. If a value is not specified, returns the text content for the first (non-null) element in the selection. This is generally useful only if you know the selection contains exactly one element. # selection.html([value]) · Source If a value is specified, sets the inner HTML to the specified value on all selected elements, replacing any existing child elements. If the value is a constant, then all elements are given the same inner HTML; otherwise, if the value is a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]). The function’s return value is then used to set each element’s inner HTML. A null value will clear the content. If a value is not specified, returns the inner HTML for the first (non-null) element in the selection. This is generally useful only if you know the selection contains exactly one element. Use selection.append or selection.insert instead to create data-driven content; this method is intended for when you want a little bit of HTML, say for rich formatting. Also, selection.html is only supported on HTML elements. SVG elements and other non-HTML elements do not support the innerHTML property, and thus are incompatible with selection.html. Consider using XMLSerializer to convert a DOM subtree to text. See also the innersvg polyfill, which provides a shim to support the innerHTML property on SVG elements. # selection.append(type) · Source If the specified type is a string, appends a new element of this type (tag name) as the last child of each selected element, or before the next following sibling in the update selection if this is an enter selection. The latter behavior for enter selections allows you to insert elements into the DOM in an order consistent with the new bound data; however, note that selection.order may still be required if updating elements change order (i.e., if the order of new data is inconsistent with old data). If the specified type is a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]). This function should return an element to be appended. (The function typically creates a new element, but it may instead return an existing element.) For example, to append a paragraph to each DIV element: d3.selectAll(\"div\").append(\"p\"); This is equivalent to: d3.selectAll(\"div\").append(() => document.createElement(\"p\")); Which is equivalent to: d3.selectAll(\"div\").select(function() { return this.appendChild(document.createElement(\"p\")); }); In both cases, this method returns a new selection containing the appended elements. Each new element inherits the data of the current elements, if any, in the same manner as selection.select. The specified name may have a namespace prefix, such as svg:text to specify a text attribute in the SVG namespace. See namespaces for the map of supported namespaces; additional namespaces can be registered by adding to the map. If no namespace is specified, the namespace will be inherited from the parent element; or, if the name is one of the known prefixes, the corresponding namespace will be used (for example, svg implies svg:svg). # selection.insert(type[, before]) · Source If the specified type is a string, inserts a new element of this type (tag name) before the first element matching the specified before selector for each selected element. For example, a before selector :first-child will prepend nodes before the first child. If before is not specified, it defaults to null. (To append elements in an order consistent with bound data, use selection.append.) Both type and before may instead be specified as functions which are evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]). The type function should return an element to be inserted; the before function should return the child element before which the element should be inserted. For example, to append a paragraph to each DIV element: d3.selectAll(\"div\").insert(\"p\"); This is equivalent to: d3.selectAll(\"div\").insert(() => document.createElement(\"p\")); Which is equivalent to: d3.selectAll(\"div\").select(function() { return this.insertBefore(document.createElement(\"p\"), null); }); In both cases, this method returns a new selection containing the appended elements. Each new element inherits the data of the current elements, if any, in the same manner as selection.select. The specified name may have a namespace prefix, such as svg:text to specify a text attribute in the SVG namespace. See namespaces for the map of supported namespaces; additional namespaces can be registered by adding to the map. If no namespace is specified, the namespace will be inherited from the parent element; or, if the name is one of the known prefixes, the corresponding namespace will be used (for example, svg implies svg:svg). # selection.remove() · Source Removes the selected elements from the document. Returns this selection (the removed elements) which are now detached from the DOM. There is not currently a dedicated API to add removed elements back to the document; however, you can pass a function to selection.append or selection.insert to re-add elements. # selection.clone([deep]) · Source Inserts clones of the selected elements immediately following the selected elements and returns a selection of the newly added clones. If deep is truthy, the descendant nodes of the selected elements will be cloned as well. Otherwise, only the elements themselves will be cloned. Equivalent to: selection.select(function() { return this.parentNode.insertBefore(this.cloneNode(deep), this.nextSibling); }); # selection.sort(compare) · Source Returns a new selection that contains a copy of each group in this selection sorted according to the compare function. After sorting, re-inserts elements to match the resulting order (per selection.order). The compare function, which defaults to ascending, is passed two elements’ data a and b to compare. It should return either a negative, positive, or zero value. If negative, then a should be before b; if positive, then a should be after b; otherwise, a and b are considered equal and the order is arbitrary. Note that sorting is not guaranteed to be stable; however, it is guaranteed to have the same behavior as your browser’s built-in sort method on arrays. # selection.order() · Source Re-inserts elements into the document such that the document order of each group matches the selection order. This is equivalent to calling selection.sort if the data is already sorted, but much faster. # selection.raise() · Source Re-inserts each selected element, in order, as the last child of its parent. Equivalent to: selection.each(function() { this.parentNode.appendChild(this); }); # selection.lower() · Source Re-inserts each selected element, in order, as the first child of its parent. Equivalent to: selection.each(function() { this.parentNode.insertBefore(this, this.parentNode.firstChild); }); # d3.create(name) · Source Given the specified element name, returns a single-element selection containing a detached element of the given name in the current document. This method assumes the HTML namespace, so you must specify a namespace explicitly when creating SVG or other non-HTML elements; see namespace for details on supported namespace prefixes. d3.create(\"svg\") // equivalent to svg:svg d3.create(\"svg:svg\") // more explicitly d3.create(\"svg:g\") // an SVG G element d3.create(\"g\") // an HTML G (unknown) element # d3.creator(name) · Source Given the specified element name, returns a function which creates an element of the given name, assuming that this is the parent element. This method is used internally by selection.append and selection.insert to create new elements. For example, this: selection.append(\"div\"); Is equivalent to: selection.append(d3.creator(\"div\")); See namespace for details on supported namespace prefixes, such as for SVG elements. Joining Data For an introduction to D3’s data joins, see the selection.join notebook. Also see Thinking With Joins. # selection.data([data[, key]]) · Source, Examples Binds the specified array of data with the selected elements, returning a new selection that represents the update selection: the elements successfully bound to data. Also defines the enter and exit selections on the returned selection, which can be used to add or remove elements to correspond to the new data. The specified data is an array of arbitrary values (e.g., numbers or objects), or a function that returns an array of values for each group. When data is assigned to an element, it is stored in the property __data__, thus making the data “sticky” and available on re-selection. The data is specified for each group in the selection. If the selection has multiple groups (such as d3.selectAll followed by selection.selectAll), then data should typically be specified as a function. This function will be evaluated for each group in order, being passed the group’s parent datum (d, which may be undefined), the group index (i), and the selection’s parent nodes (nodes), with this as the group’s parent element. In conjunction with selection.join (or more explicitly with selection.enter, selection.exit, selection.append and selection.remove), selection.data can be used to enter, update and exit elements to match data. For example, to create an HTML table from a matrix of numbers: const matrix = [ [11975, 5871, 8916, 2868], [ 1951, 10048, 2060, 6171], [ 8010, 16145, 8090, 8045], [ 1013, 990, 940, 6907] ]; d3.select(\"body\") .append(\"table\") .selectAll(\"tr\") .data(matrix) .join(\"tr\") .selectAll(\"td\") .data(d => d) .join(\"td\") .text(d => d); In this example the data function is the identity function: for each table row, it returns the corresponding row from the data matrix. If a key function is not specified, then the first datum in data is assigned to the first selected element, the second datum to the second selected element, and so on. A key function may be specified to control which datum is assigned to which element, replacing the default join-by-index, by computing a string identifier for each datum and element. This key function is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]); the returned string is the element’s key. The key function is then also evaluated for each new datum in data, being passed the current datum (d), the current index (i), and the group’s new data, with this as the group’s parent DOM element; the returned string is the datum’s key. The datum for a given key is assigned to the element with the matching key. If multiple elements have the same key, the duplicate elements are put into the exit selection; if multiple data have the same key, the duplicate data are put into the enter selection. For example, given this document: <div id=\"Ford\"></div> <div id=\"Jarrah\"></div> <div id=\"Kwon\"></div> <div id=\"Locke\"></div> <div id=\"Reyes\"></div> <div id=\"Shephard\"></div> You could join data by key as follows: const data = [ {name: \"Locke\", number: 4}, {name: \"Reyes\", number: 8}, {name: \"Ford\", number: 15}, {name: \"Jarrah\", number: 16}, {name: \"Shephard\", number: 23}, {name: \"Kwon\", number: 42} ]; d3.selectAll(\"div\") .data(data, function(d) { return d ? d.name : this.id; }) .text(d => d.number); This example key function uses the datum d if present, and otherwise falls back to the element’s id property. Since these elements were not previously bound to data, the datum d is null when the key function is evaluated on selected elements, and non-null when the key function is evaluated on the new data. The update and enter selections are returned in data order, while the exit selection preserves the selection order prior to the join. If a key function is specified, the order of elements in the selection may not match their order in the document; use selection.order or selection.sort as needed. For more on how the key function affects the join, see A Bar Chart, Part 2 and Object Constancy. If data is not specified, this method returns the array of data for the selected elements. This method cannot be used to clear bound data; use selection.datum instead. # selection.join(enter[, update][, exit]) · Source Appends, removes and reorders elements as necessary to match the data that was previously bound by selection.data, returning the merged enter and update selection. This method is a convenient alternative to the explicit general update pattern, replacing selection.enter, selection.exit, selection.append, selection.remove, and selection.order. For example: svg.selectAll(\"circle\") .data(data) .join(\"circle\") .attr(\"fill\", \"none\") .attr(\"stroke\", \"black\"); The enter function may be specified as a string shorthand, as above, which is equivalent to selection.append with the given element name. Likewise, optional update and exit functions may be specified, which default to the identity function and calling selection.remove, respectively. The shorthand above is thus equivalent to: svg.selectAll(\"circle\") .data(data) .join( enter => enter.append(\"circle\"), update => update, exit => exit.remove() ) .attr(\"fill\", \"none\") .attr(\"stroke\", \"black\"); By passing separate functions on enter, update and exit, you have greater control over what happens. And by specifying a key function to selection.data, you can minimize changes to the DOM to optimize performance. For example, to set different fill colors for enter and update: svg.selectAll(\"circle\") .data(data) .join( enter => enter.append(\"circle\").attr(\"fill\", \"green\"), update => update.attr(\"fill\", \"blue\") ) .attr(\"stroke\", \"black\"); The selections returned by the enter and update functions are merged and then returned by selection.join. You can animate enter, update and exit by creating transitions inside the enter, update and exit functions. If the enter and update functions return transitions, their underlying selections are merged and then returned by selection.join. The return value of the exit function is not used. For more, see the selection.join notebook. # selection.enter() · Source Returns the enter selection: placeholder nodes for each datum that had no corresponding DOM element in the selection. (The enter selection is empty for selections not returned by selection.data.) The enter selection is typically used to create “missing” elements corresponding to new data. For example, to create DIV elements from an array of numbers: const div = d3.select(\"body\") .selectAll(\"div\") .data([4, 8, 15, 16, 23, 42]) .enter().append(\"div\") .text(d => d); If the body is initially empty, the above code will create six new DIV elements, append them to the body in-order, and assign their text content as the associated (string-coerced) number: <div>4</div> <div>8</div> <div>15</div> <div>16</div> <div>23</div> <div>42</div> Conceptually, the enter selection’s placeholders are pointers to the parent element (in this example, the document body). The enter selection is typically only used transiently to append elements, and is often merged with the update selection after appending, such that modifications can be applied to both entering and updating elements. # selection.exit() · Source Returns the exit selection: existing DOM elements in the selection for which no new datum was found. (The exit selection is empty for selections not returned by selection.data.) The exit selection is typically used to remove “superfluous” elements corresponding to old data. For example, to update the DIV elements created previously with a new array of numbers: div = div.data([1, 2, 4, 8, 16, 32], d => d); Since a key function was specified (as the identity function), and the new data contains the numbers [4, 8, 16] which match existing elements in the document, the update selection contains three DIV elements. Leaving those elements as-is, we can append new elements for [1, 2, 32] using the enter selection: div.enter().append(\"div\").text(d => d); Likewise, to remove the exiting elements [15, 23, 42]: div.exit().remove(); Now the document body looks like this: <div>1</div> <div>2</div> <div>4</div> <div>8</div> <div>16</div> <div>32</div> The order of the DOM elements matches the order of the data because the old data’s order and the new data’s order were consistent. If the new data’s order is different, use selection.order to reorder the elements in the DOM. See the General Update Pattern example thread for more on data joins. # selection.datum([value]) · Source Gets or sets the bound data for each selected element. Unlike selection.data, this method does not compute a join and does not affect indexes or the enter and exit selections. If a value is specified, sets the element’s bound data to the specified value on all selected elements. If the value is a constant, all elements are given the same datum; otherwise, if the value is a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]). The function is then used to set each element’s new data. A null value will delete the bound data. If a value is not specified, returns the bound datum for the first (non-null) element in the selection. This is generally useful only if you know the selection contains exactly one element. This method is useful for accessing HTML5 custom data attributes. For example, given the following elements: <ul id=\"list\"> <li data-username=\"shawnbot\">Shawn Allen</li> <li data-username=\"mbostock\">Mike Bostock</li> </ul> You can expose the custom data attributes by setting each element’s data as the built-in dataset property: selection.datum(function() { return this.dataset; }) Handling Events For interaction, selections allow listening for and dispatching of events. # selection.on(typenames[, listener[, options]]) · Source Adds or removes a listener to each selected element for the specified event typenames. The typenames is a string event type, such as click, mouseover, or submit; any DOM event type supported by your browser may be used. The type may be optionally followed by a period (.) and a name; the optional name allows multiple callbacks to be registered to receive events of the same type, such as click.foo and click.bar. To specify multiple typenames, separate typenames with spaces, such as input change or click.foo click.bar. When a specified event is dispatched on a selected element, the specified listener will be evaluated for the element, being passed the current event (event) and the current datum (d), with this as the current DOM element (event.currentTarget). Listeners always see the latest datum for their element. Note: while you can use event.pageX and event.pageY directly, it is often convenient to transform the event position to the local coordinate system of the element that received the event using d3.pointer. If an event listener was previously registered for the same typename on a selected element, the old listener is removed before the new listener is added. To remove a listener, pass null as the listener. To remove all listeners for a given name, pass null as the listener and .foo as the typename, where foo is the name; to remove all listeners with no name, specify . as the typename. An optional options object may specify characteristics about the event listener, such as whether it is capturing or passive; see element.addEventListener. If a listener is not specified, returns the currently-assigned listener for the specified event typename on the first (non-null) selected element, if any. If multiple typenames are specified, the first matching listener is returned. # selection.dispatch(type[, parameters]) · Source Dispatches a custom event of the specified type to each selected element, in order. An optional parameters map may be specified to set additional properties of the event. It may contain the following fields: bubbles - if true, the event is dispatched to ancestors in reverse tree order. cancelable - if true, event.preventDefault is allowed. detail - any custom data associated with the event. If parameters is a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]). It must return the parameters map for the current element. # d3.pointer(event[, target]) · Source Returns a two-element array of numbers [x, y] representing the coordinates of the specified event relative to the specified target. event can be a MouseEvent, a PointerEvent, a Touch, or a custom event holding a UIEvent as event.sourceEvent. If target is not specified, it defaults to the source event’s currentTarget property, if available. If the target is an SVG element, the event’s coordinates are transformed using the inverse of the screen coordinate transformation matrix. If the target is an HTML element, the event’s coordinates are translated relative to the top-left corner of the target’s bounding client rectangle. (As such, the coordinate system can only be translated relative to the client coordinates. See also GeometryUtils.) Otherwise, [event.pageX, event.pageY] is returned. # d3.pointers(event[, target]) · Source Returns an array [[x0, y0], [x1, y1]…] of coordinates of the specified event’s pointer locations relative to the specified target. For touch events, the returned array of positions corresponds to the event.touches array; for other events, returns a single-element array. If target is not specified, it defaults to the source event’s currentTarget property, if any. Control Flow For advanced usage, selections provide methods for custom control flow. # selection.each(function) · Source Invokes the specified function for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element (nodes[i]). This method can be used to invoke arbitrary code for each selected element, and is useful for creating a context to access parent and child data simultaneously, such as: parent.each(function(p, j) { d3.select(this) .selectAll(\".child\") .text(d => `child ${d.name} of ${p.name}`); }); See Sized Donut Multiples for an example. # selection.call(function[, arguments…]) · Source Invokes the specified function exactly once, passing in this selection along with any optional arguments. Returns this selection. This is equivalent to invoking the function by hand but facilitates method chaining. For example, to set several styles in a reusable function: function name(selection, first, last) { selection .attr(\"first-name\", first) .attr(\"last-name\", last); } Now say: d3.selectAll(\"div\").call(name, \"John\", \"Snow\"); This is roughly equivalent to: name(d3.selectAll(\"div\"), \"John\", \"Snow\"); The only difference is that selection.call always returns the selection and not the return value of the called function, name. # selection.empty() · Source Returns true if this selection contains no (non-null) elements. # selection.nodes() · Source Returns an array of all (non-null) elements in this selection. Equivalent to: const elements = Array.from(selection); See also selection[Symbol.iterator]. # selection.node() · Source Returns the first (non-null) element in this selection. If the selection is empty, returns null. # selection.size() · Source Returns the total number of (non-null) elements in this selection. # selection[Symbol.iterator]() · Source Returns an iterator over the selected (non-null) elements. For example, to iterate over the selected elements: for (const element of selection) { console.log(element); } To flatten the selection to an array: const elements = [...selection]; Local Variables D3 locals allow you to define local state independent of data. For instance, when rendering small multiples of time-series data, you might want the same x-scale for all charts but distinct y-scales to compare the relative performance of each metric. D3 locals are scoped by DOM elements: on set, the value is stored on the given element; on get, the value is retrieved from given element or the nearest ancestor that defines it. # d3.local() · Source Declares a new local variable. For example: const foo = d3.local(); Like var, each local is a distinct symbolic reference; unlike var, the value of each local is also scoped by the DOM. # local.set(node, value) · Source Sets the value of this local on the specified node to the value, and returns the specified value. This is often performed using selection.each: selection.each(function(d) { foo.set(this, d.value); }); If you are just setting a single variable, consider using selection.property: selection.property(foo, d => d.value); # local.get(node) · Source Returns the value of this local on the specified node. If the node does not define this local, returns the value from the nearest ancestor that defines it. Returns undefined if no ancestor defines this local. # local.remove(node) · Source Deletes this local’s value from the specified node. Returns true if the node defined this local prior to removal, and false otherwise. If ancestors also define this local, those definitions are unaffected, and thus local.get will still return the inherited value. # local.toString() · Source Returns the automatically-generated identifier for this local. This is the name of the property that is used to store the local’s value on elements, and thus you can also set or get the local’s value using element[local] or by using selection.property. Namespaces XML namespaces are fun! Right? Fortunately you can mostly ignore them. # d3.namespace(name) · Source Qualifies the specified name, which may or may not have a namespace prefix. If the name contains a colon (:), the substring before the colon is interpreted as the namespace prefix, which must be registered in d3.namespaces. Returns an object space and local attributes describing the full namespace URL and the local name. For example: d3.namespace(\"svg:text\"); // {space: \"http://www.w3.org/2000/svg\", local: \"text\"} If the name does not contain a colon, this function merely returns the input name. # d3.namespaces · Source The map of registered namespace prefixes. The initial value is: { svg: \"http://www.w3.org/2000/svg\", xhtml: \"http://www.w3.org/1999/xhtml\", xlink: \"http://www.w3.org/1999/xlink\", xml: \"http://www.w3.org/XML/1998/namespace\", xmlns: \"http://www.w3.org/2000/xmlns/\" } Additional prefixes may be assigned as needed to create elements or attributes in other namespaces."
  },
  "src/frontend/app-client/node_modules/d3-shape/README.html": {
    "href": "src/frontend/app-client/node_modules/d3-shape/README.html",
    "title": "d3-shape",
    "summary": "d3-shape Visualizations typically consist of discrete graphical marks, such as symbols, arcs, lines and areas. While the rectangles of a bar chart may be easy enough to generate directly using SVG or Canvas, other shapes are complex, such as rounded annular sectors and centripetal Catmull–Rom splines. This module provides a variety of shape generators for your convenience. As with other aspects of D3, these shapes are driven by data: each shape generator exposes accessors that control how the input data are mapped to a visual representation. For example, you might define a line generator for a time series by scaling fields of your data to fit the chart: var line = d3.line() .x(function(d) { return x(d.date); }) .y(function(d) { return y(d.value); }); This line generator can then be used to compute the d attribute of an SVG path element: path.datum(data).attr(\"d\", line); Or you can use it to render to a Canvas 2D context: line.context(context)(data); For more, read Introducing d3-shape. Installing If you use NPM, npm install d3-shape. Otherwise, download the latest release. You can also load directly from d3js.org, either as a standalone library or as part of D3. AMD, CommonJS, and vanilla environments are supported. In vanilla, a d3 global is exported: <script src=\"https://d3js.org/d3-path.v1.min.js\"></script> <script src=\"https://d3js.org/d3-shape.v1.min.js\"></script> <script> var line = d3.line(); </script> API Reference Arcs Pies Lines Areas Curves Custom Curves Links Symbols Custom Symbol Types Stacks Arcs The arc generator produces a circular or annular sector, as in a pie or donut chart. If the difference between the start and end angles (the angular span) is greater than τ, the arc generator will produce a complete circle or annulus. If it is less than τ, arcs may have rounded corners and angular padding. Arcs are always centered at ⟨0,0⟩; use a transform (see: SVG, Canvas) to move the arc to a different position. See also the pie generator, which computes the necessary angles to represent an array of data as a pie or donut chart; these angles can then be passed to an arc generator. # d3.arc() · Source Constructs a new arc generator with the default settings. # arc(arguments…) · Source Generates an arc for the given arguments. The arguments are arbitrary; they are simply propagated to the arc generator’s accessor functions along with the this object. For example, with the default settings, an object with radii and angles is expected: var arc = d3.arc(); arc({ innerRadius: 0, outerRadius: 100, startAngle: 0, endAngle: Math.PI / 2 }); // \"M0,-100A100,100,0,0,1,100,0L0,0Z\" If the radii and angles are instead defined as constants, you can generate an arc without any arguments: var arc = d3.arc() .innerRadius(0) .outerRadius(100) .startAngle(0) .endAngle(Math.PI / 2); arc(); // \"M0,-100A100,100,0,0,1,100,0L0,0Z\" If the arc generator has a context, then the arc is rendered to this context as a sequence of path method calls and this function returns void. Otherwise, a path data string is returned. # arc.centroid(arguments…) · Source Computes the midpoint [x, y] of the center line of the arc that would be generated by the given arguments. The arguments are arbitrary; they are simply propagated to the arc generator’s accessor functions along with the this object. To be consistent with the generated arc, the accessors must be deterministic, i.e., return the same value given the same arguments. The midpoint is defined as (startAngle + endAngle) / 2 and (innerRadius + outerRadius) / 2. For example: Note that this is not the geometric center of the arc, which may be outside the arc; this method is merely a convenience for positioning labels. # arc.innerRadius([radius]) · Source If radius is specified, sets the inner radius to the specified function or number and returns this arc generator. If radius is not specified, returns the current inner radius accessor, which defaults to: function innerRadius(d) { return d.innerRadius; } Specifying the inner radius as a function is useful for constructing a stacked polar bar chart, often in conjunction with a sqrt scale. More commonly, a constant inner radius is used for a donut or pie chart. If the outer radius is smaller than the inner radius, the inner and outer radii are swapped. A negative value is treated as zero. # arc.outerRadius([radius]) · Source If radius is specified, sets the outer radius to the specified function or number and returns this arc generator. If radius is not specified, returns the current outer radius accessor, which defaults to: function outerRadius(d) { return d.outerRadius; } Specifying the outer radius as a function is useful for constructing a coxcomb or polar bar chart, often in conjunction with a sqrt scale. More commonly, a constant outer radius is used for a pie or donut chart. If the outer radius is smaller than the inner radius, the inner and outer radii are swapped. A negative value is treated as zero. # arc.cornerRadius([radius]) · Source If radius is specified, sets the corner radius to the specified function or number and returns this arc generator. If radius is not specified, returns the current corner radius accessor, which defaults to: function cornerRadius() { return 0; } If the corner radius is greater than zero, the corners of the arc are rounded using circles of the given radius. For a circular sector, the two outer corners are rounded; for an annular sector, all four corners are rounded. The corner circles are shown in this diagram: The corner radius may not be larger than (outerRadius - innerRadius) / 2. In addition, for arcs whose angular span is less than π, the corner radius may be reduced as two adjacent rounded corners intersect. This is occurs more often with the inner corners. See the arc corners animation for illustration. # arc.startAngle([angle]) · Source If angle is specified, sets the start angle to the specified function or number and returns this arc generator. If angle is not specified, returns the current start angle accessor, which defaults to: function startAngle(d) { return d.startAngle; } The angle is specified in radians, with 0 at -y (12 o’clock) and positive angles proceeding clockwise. If |endAngle - startAngle| ≥ τ, a complete circle or annulus is generated rather than a sector. # arc.endAngle([angle]) · Source If angle is specified, sets the end angle to the specified function or number and returns this arc generator. If angle is not specified, returns the current end angle accessor, which defaults to: function endAngle(d) { return d.endAngle; } The angle is specified in radians, with 0 at -y (12 o’clock) and positive angles proceeding clockwise. If |endAngle - startAngle| ≥ τ, a complete circle or annulus is generated rather than a sector. # arc.padAngle([angle]) · Source If angle is specified, sets the pad angle to the specified function or number and returns this arc generator. If angle is not specified, returns the current pad angle accessor, which defaults to: function padAngle() { return d && d.padAngle; } The pad angle is converted to a fixed linear distance separating adjacent arcs, defined as padRadius * padAngle. This distance is subtracted equally from the start and end of the arc. If the arc forms a complete circle or annulus, as when |endAngle - startAngle| ≥ τ, the pad angle is ignored. If the inner radius or angular span is small relative to the pad angle, it may not be possible to maintain parallel edges between adjacent arcs. In this case, the inner edge of the arc may collapse to a point, similar to a circular sector. For this reason, padding is typically only applied to annular sectors (i.e., when innerRadius is positive), as shown in this diagram: The recommended minimum inner radius when using padding is outerRadius * padAngle / sin(θ), where θ is the angular span of the smallest arc before padding. For example, if the outer radius is 200 pixels and the pad angle is 0.02 radians, a reasonable θ is 0.04 radians, and a reasonable inner radius is 100 pixels. See the arc padding animation for illustration. Often, the pad angle is not set directly on the arc generator, but is instead computed by the pie generator so as to ensure that the area of padded arcs is proportional to their value; see pie.padAngle. See the pie padding animation for illustration. If you apply a constant pad angle to the arc generator directly, it tends to subtract disproportionately from smaller arcs, introducing distortion. # arc.padRadius([radius]) · Source If radius is specified, sets the pad radius to the specified function or number and returns this arc generator. If radius is not specified, returns the current pad radius accessor, which defaults to null, indicating that the pad radius should be automatically computed as sqrt(innerRadius * innerRadius + outerRadius * outerRadius). The pad radius determines the fixed linear distance separating adjacent arcs, defined as padRadius * padAngle. # arc.context([context]) · Source If context is specified, sets the context and returns this arc generator. If context is not specified, returns the current context, which defaults to null. If the context is not null, then the generated arc is rendered to this context as a sequence of path method calls. Otherwise, a path data string representing the generated arc is returned. Pies The pie generator does not produce a shape directly, but instead computes the necessary angles to represent a tabular dataset as a pie or donut chart; these angles can then be passed to an arc generator. # d3.pie() · Source Constructs a new pie generator with the default settings. # pie(data[, arguments…]) · Source Generates a pie for the given array of data, returning an array of objects representing each datum’s arc angles. Any additional arguments are arbitrary; they are simply propagated to the pie generator’s accessor functions along with the this object. The length of the returned array is the same as data, and each element i in the returned array corresponds to the element i in the input data. Each object in the returned array has the following properties: data - the input datum; the corresponding element in the input data array. value - the numeric value of the arc. index - the zero-based sorted index of the arc. startAngle - the start angle of the arc. endAngle - the end angle of the arc. padAngle - the pad angle of the arc. This representation is designed to work with the arc generator’s default startAngle, endAngle and padAngle accessors. The angular units are arbitrary, but if you plan to use the pie generator in conjunction with an arc generator, you should specify angles in radians, with 0 at -y (12 o’clock) and positive angles proceeding clockwise. Given a small dataset of numbers, here is how to compute the arc angles to render this data as a pie chart: var data = [1, 1, 2, 3, 5, 8, 13, 21]; var arcs = d3.pie()(data); The first pair of parens, pie(), constructs a default pie generator. The second, pie()(data), invokes this generator on the dataset, returning an array of objects: [ {\"data\": 1, \"value\": 1, \"index\": 6, \"startAngle\": 6.050474740247008, \"endAngle\": 6.166830023713296, \"padAngle\": 0}, {\"data\": 1, \"value\": 1, \"index\": 7, \"startAngle\": 6.166830023713296, \"endAngle\": 6.283185307179584, \"padAngle\": 0}, {\"data\": 2, \"value\": 2, \"index\": 5, \"startAngle\": 5.817764173314431, \"endAngle\": 6.050474740247008, \"padAngle\": 0}, {\"data\": 3, \"value\": 3, \"index\": 4, \"startAngle\": 5.468698322915565, \"endAngle\": 5.817764173314431, \"padAngle\": 0}, {\"data\": 5, \"value\": 5, \"index\": 3, \"startAngle\": 4.886921905584122, \"endAngle\": 5.468698322915565, \"padAngle\": 0}, {\"data\": 8, \"value\": 8, \"index\": 2, \"startAngle\": 3.956079637853813, \"endAngle\": 4.886921905584122, \"padAngle\": 0}, {\"data\": 13, \"value\": 13, \"index\": 1, \"startAngle\": 2.443460952792061, \"endAngle\": 3.956079637853813, \"padAngle\": 0}, {\"data\": 21, \"value\": 21, \"index\": 0, \"startAngle\": 0.000000000000000, \"endAngle\": 2.443460952792061, \"padAngle\": 0} ] Note that the returned array is in the same order as the data, even though this pie chart is sorted by descending value, starting with the arc for the last datum (value 21) at 12 o’clock. # pie.value([value]) · Source If value is specified, sets the value accessor to the specified function or number and returns this pie generator. If value is not specified, returns the current value accessor, which defaults to: function value(d) { return d; } When a pie is generated, the value accessor will be invoked for each element in the input data array, being passed the element d, the index i, and the array data as three arguments. The default value accessor assumes that the input data are numbers, or that they are coercible to numbers using valueOf. If your data are not simply numbers, then you should specify an accessor that returns the corresponding numeric value for a given datum. For example: var data = [ {\"number\": 4, \"name\": \"Locke\"}, {\"number\": 8, \"name\": \"Reyes\"}, {\"number\": 15, \"name\": \"Ford\"}, {\"number\": 16, \"name\": \"Jarrah\"}, {\"number\": 23, \"name\": \"Shephard\"}, {\"number\": 42, \"name\": \"Kwon\"} ]; var arcs = d3.pie() .value(function(d) { return d.number; }) (data); This is similar to mapping your data to values before invoking the pie generator: var arcs = d3.pie()(data.map(function(d) { return d.number; })); The benefit of an accessor is that the input data remains associated with the returned objects, thereby making it easier to access other fields of the data, for example to set the color or to add text labels. # pie.sort([compare]) · Source If compare is specified, sets the data comparator to the specified function and returns this pie generator. If compare is not specified, returns the current data comparator, which defaults to null. If both the data comparator and the value comparator are null, then arcs are positioned in the original input order. Otherwise, the data is sorted according to the data comparator, and the resulting order is used. Setting the data comparator implicitly sets the value comparator to null. The compare function takes two arguments a and b, each elements from the input data array. If the arc for a should be before the arc for b, then the comparator must return a number less than zero; if the arc for a should be after the arc for b, then the comparator must return a number greater than zero; returning zero means that the relative order of a and b is unspecified. For example, to sort arcs by their associated name: pie.sort(function(a, b) { return a.name.localeCompare(b.name); }); Sorting does not affect the order of the generated arc array which is always in the same order as the input data array; it merely affects the computed angles of each arc. The first arc starts at the start angle and the last arc ends at the end angle. # pie.sortValues([compare]) · Source If compare is specified, sets the value comparator to the specified function and returns this pie generator. If compare is not specified, returns the current value comparator, which defaults to descending value. The default value comparator is implemented as: function compare(a, b) { return b - a; } If both the data comparator and the value comparator are null, then arcs are positioned in the original input order. Otherwise, the data is sorted according to the data comparator, and the resulting order is used. Setting the value comparator implicitly sets the data comparator to null. The value comparator is similar to the data comparator, except the two arguments a and b are values derived from the input data array using the value accessor, not the data elements. If the arc for a should be before the arc for b, then the comparator must return a number less than zero; if the arc for a should be after the arc for b, then the comparator must return a number greater than zero; returning zero means that the relative order of a and b is unspecified. For example, to sort arcs by ascending value: pie.sortValues(function(a, b) { return a - b; }); Sorting does not affect the order of the generated arc array which is always in the same order as the input data array; it merely affects the computed angles of each arc. The first arc starts at the start angle and the last arc ends at the end angle. # pie.startAngle([angle]) · Source If angle is specified, sets the overall start angle of the pie to the specified function or number and returns this pie generator. If angle is not specified, returns the current start angle accessor, which defaults to: function startAngle() { return 0; } The start angle here means the overall start angle of the pie, i.e., the start angle of the first arc. The start angle accessor is invoked once, being passed the same arguments and this context as the pie generator. The units of angle are arbitrary, but if you plan to use the pie generator in conjunction with an arc generator, you should specify an angle in radians, with 0 at -y (12 o’clock) and positive angles proceeding clockwise. # pie.endAngle([angle]) · Source If angle is specified, sets the overall end angle of the pie to the specified function or number and returns this pie generator. If angle is not specified, returns the current end angle accessor, which defaults to: function endAngle() { return 2 * Math.PI; } The end angle here means the overall end angle of the pie, i.e., the end angle of the last arc. The end angle accessor is invoked once, being passed the same arguments and this context as the pie generator. The units of angle are arbitrary, but if you plan to use the pie generator in conjunction with an arc generator, you should specify an angle in radians, with 0 at -y (12 o’clock) and positive angles proceeding clockwise. The value of the end angle is constrained to startAngle ± τ, such that |endAngle - startAngle| ≤ τ. # pie.padAngle([angle]) · Source If angle is specified, sets the pad angle to the specified function or number and returns this pie generator. If angle is not specified, returns the current pad angle accessor, which defaults to: function padAngle() { return 0; } The pad angle here means the angular separation between each adjacent arc. The total amount of padding reserved is the specified angle times the number of elements in the input data array, and at most |endAngle - startAngle|; the remaining space is then divided proportionally by value such that the relative area of each arc is preserved. See the pie padding animation for illustration. The pad angle accessor is invoked once, being passed the same arguments and this context as the pie generator. The units of angle are arbitrary, but if you plan to use the pie generator in conjunction with an arc generator, you should specify an angle in radians. Lines The line generator produces a spline or polyline, as in a line chart. Lines also appear in many other visualization types, such as the links in hierarchical edge bundling. # d3.line() · Source, Examples Constructs a new line generator with the default settings. # line(data) · Source, Examples Generates a line for the given array of data. Depending on this line generator’s associated curve, the given input data may need to be sorted by x-value before being passed to the line generator. If the line generator has a context, then the line is rendered to this context as a sequence of path method calls and this function returns void. Otherwise, a path data string is returned. # line.x([x]) · Source, Examples If x is specified, sets the x accessor to the specified function or number and returns this line generator. If x is not specified, returns the current x accessor, which defaults to: function x(d) { return d[0]; } When a line is generated, the x accessor will be invoked for each defined element in the input data array, being passed the element d, the index i, and the array data as three arguments. The default x accessor assumes that the input data are two-element arrays of numbers. If your data are in a different format, or if you wish to transform the data before rendering, then you should specify a custom accessor. For example, if x is a time scale and y is a linear scale: var data = [ {date: new Date(2007, 3, 24), value: 93.24}, {date: new Date(2007, 3, 25), value: 95.35}, {date: new Date(2007, 3, 26), value: 98.84}, {date: new Date(2007, 3, 27), value: 99.92}, {date: new Date(2007, 3, 30), value: 99.80}, {date: new Date(2007, 4, 1), value: 99.47}, … ]; var line = d3.line() .x(function(d) { return x(d.date); }) .y(function(d) { return y(d.value); }); # line.y([y]) · Source, Examples If y is specified, sets the y accessor to the specified function or number and returns this line generator. If y is not specified, returns the current y accessor, which defaults to: function y(d) { return d[1]; } When a line is generated, the y accessor will be invoked for each defined element in the input data array, being passed the element d, the index i, and the array data as three arguments. The default y accessor assumes that the input data are two-element arrays of numbers. See line.x for more information. # line.defined([defined]) · Source, Examples If defined is specified, sets the defined accessor to the specified function or boolean and returns this line generator. If defined is not specified, returns the current defined accessor, which defaults to: function defined() { return true; } The default accessor thus assumes that the input data is always defined. When a line is generated, the defined accessor will be invoked for each element in the input data array, being passed the element d, the index i, and the array data as three arguments. If the given element is defined (i.e., if the defined accessor returns a truthy value for this element), the x and y accessors will subsequently be evaluated and the point will be added to the current line segment. Otherwise, the element will be skipped, the current line segment will be ended, and a new line segment will be generated for the next defined point. As a result, the generated line may have several discrete segments. For example: Note that if a line segment consists of only a single point, it may appear invisible unless rendered with rounded or square line caps. In addition, some curves such as curveCardinalOpen only render a visible segment if it contains multiple points. # line.curve([curve]) · Source, Examples If curve is specified, sets the curve factory and returns this line generator. If curve is not specified, returns the current curve factory, which defaults to curveLinear. # line.context([context]) · Source, Examples If context is specified, sets the context and returns this line generator. If context is not specified, returns the current context, which defaults to null. If the context is not null, then the generated line is rendered to this context as a sequence of path method calls. Otherwise, a path data string representing the generated line is returned. # d3.lineRadial() · Source, Examples Constructs a new radial line generator with the default settings. A radial line generator is equivalent to the standard Cartesian line generator, except the x and y accessors are replaced with angle and radius accessors. Radial lines are always positioned relative to ⟨0,0⟩; use a transform (see: SVG, Canvas) to change the origin. # lineRadial(data) · Source, Examples Equivalent to line. # lineRadial.angle([angle]) · Source, Examples Equivalent to line.x, except the accessor returns the angle in radians, with 0 at -y (12 o’clock). # lineRadial.radius([radius]) · Source, Examples Equivalent to line.y, except the accessor returns the radius: the distance from the origin ⟨0,0⟩. # lineRadial.defined([defined]) Equivalent to line.defined. # lineRadial.curve([curve]) · Source, Examples Equivalent to line.curve. Note that curveMonotoneX or curveMonotoneY are not recommended for radial lines because they assume that the data is monotonic in x or y, which is typically untrue of radial lines. # lineRadial.context([context]) Equivalent to line.context. Areas The area generator produces an area, as in an area chart. An area is defined by two bounding lines, either splines or polylines. Typically, the two lines share the same x-values (x0 = x1), differing only in y-value (y0 and y1); most commonly, y0 is defined as a constant representing zero. The first line (the topline) is defined by x1 and y1 and is rendered first; the second line (the baseline) is defined by x0 and y0 and is rendered second, with the points in reverse order. With a curveLinear curve, this produces a clockwise polygon. # d3.area() · Source Constructs a new area generator with the default settings. # area(data) · Source Generates an area for the given array of data. Depending on this area generator’s associated curve, the given input data may need to be sorted by x-value before being passed to the area generator. If the area generator has a context, then the area is rendered to this context as a sequence of path method calls and this function returns void. Otherwise, a path data string is returned. # area.x([x]) · Source If x is specified, sets x0 to x and x1 to null and returns this area generator. If x is not specified, returns the current x0 accessor. # area.x0([x]) · Source If x is specified, sets the x0 accessor to the specified function or number and returns this area generator. If x is not specified, returns the current x0 accessor, which defaults to: function x(d) { return d[0]; } When an area is generated, the x0 accessor will be invoked for each defined element in the input data array, being passed the element d, the index i, and the array data as three arguments. The default x0 accessor assumes that the input data are two-element arrays of numbers. If your data are in a different format, or if you wish to transform the data before rendering, then you should specify a custom accessor. For example, if x is a time scale and y is a linear scale: var data = [ {date: new Date(2007, 3, 24), value: 93.24}, {date: new Date(2007, 3, 25), value: 95.35}, {date: new Date(2007, 3, 26), value: 98.84}, {date: new Date(2007, 3, 27), value: 99.92}, {date: new Date(2007, 3, 30), value: 99.80}, {date: new Date(2007, 4, 1), value: 99.47}, … ]; var area = d3.area() .x(function(d) { return x(d.date); }) .y1(function(d) { return y(d.value); }) .y0(y(0)); # area.x1([x]) · Source If x is specified, sets the x1 accessor to the specified function or number and returns this area generator. If x is not specified, returns the current x1 accessor, which defaults to null, indicating that the previously-computed x0 value should be reused for the x1 value. When an area is generated, the x1 accessor will be invoked for each defined element in the input data array, being passed the element d, the index i, and the array data as three arguments. See area.x0 for more information. # area.y([y]) · Source If y is specified, sets y0 to y and y1 to null and returns this area generator. If y is not specified, returns the current y0 accessor. # area.y0([y]) · Source If y is specified, sets the y0 accessor to the specified function or number and returns this area generator. If y is not specified, returns the current y0 accessor, which defaults to: function y() { return 0; } When an area is generated, the y0 accessor will be invoked for each defined element in the input data array, being passed the element d, the index i, and the array data as three arguments. See area.x0 for more information. # area.y1([y]) · Source If y is specified, sets the y1 accessor to the specified function or number and returns this area generator. If y is not specified, returns the current y1 accessor, which defaults to: function y(d) { return d[1]; } A null accessor is also allowed, indicating that the previously-computed y0 value should be reused for the y1 value. When an area is generated, the y1 accessor will be invoked for each defined element in the input data array, being passed the element d, the index i, and the array data as three arguments. See area.x0 for more information. # area.defined([defined]) · Source If defined is specified, sets the defined accessor to the specified function or boolean and returns this area generator. If defined is not specified, returns the current defined accessor, which defaults to: function defined() { return true; } The default accessor thus assumes that the input data is always defined. When an area is generated, the defined accessor will be invoked for each element in the input data array, being passed the element d, the index i, and the array data as three arguments. If the given element is defined (i.e., if the defined accessor returns a truthy value for this element), the x0, x1, y0 and y1 accessors will subsequently be evaluated and the point will be added to the current area segment. Otherwise, the element will be skipped, the current area segment will be ended, and a new area segment will be generated for the next defined point. As a result, the generated area may have several discrete segments. For example: Note that if an area segment consists of only a single point, it may appear invisible unless rendered with rounded or square line caps. In addition, some curves such as curveCardinalOpen only render a visible segment if it contains multiple points. # area.curve([curve]) · Source If curve is specified, sets the curve factory and returns this area generator. If curve is not specified, returns the current curve factory, which defaults to curveLinear. # area.context([context]) · Source If context is specified, sets the context and returns this area generator. If context is not specified, returns the current context, which defaults to null. If the context is not null, then the generated area is rendered to this context as a sequence of path method calls. Otherwise, a path data string representing the generated area is returned. # area.lineX0() · Source # area.lineY0() · Source Returns a new line generator that has this area generator’s current defined accessor, curve and context. The line’s x-accessor is this area’s x0-accessor, and the line’s y-accessor is this area’s y0-accessor. # area.lineX1() · Source Returns a new line generator that has this area generator’s current defined accessor, curve and context. The line’s x-accessor is this area’s x1-accessor, and the line’s y-accessor is this area’s y0-accessor. # area.lineY1() · Source Returns a new line generator that has this area generator’s current defined accessor, curve and context. The line’s x-accessor is this area’s x0-accessor, and the line’s y-accessor is this area’s y1-accessor. # d3.areaRadial() · Source Constructs a new radial area generator with the default settings. A radial area generator is equivalent to the standard Cartesian area generator, except the x and y accessors are replaced with angle and radius accessors. Radial areas are always positioned relative to ⟨0,0⟩; use a transform (see: SVG, Canvas) to change the origin. # areaRadial(data) Equivalent to area. # areaRadial.angle([angle]) · Source Equivalent to area.x, except the accessor returns the angle in radians, with 0 at -y (12 o’clock). # areaRadial.startAngle([angle]) · Source Equivalent to area.x0, except the accessor returns the angle in radians, with 0 at -y (12 o’clock). Note: typically angle is used instead of setting separate start and end angles. # areaRadial.endAngle([angle]) · Source Equivalent to area.x1, except the accessor returns the angle in radians, with 0 at -y (12 o’clock). Note: typically angle is used instead of setting separate start and end angles. # areaRadial.radius([radius]) · Source Equivalent to area.y, except the accessor returns the radius: the distance from the origin ⟨0,0⟩. # areaRadial.innerRadius([radius]) · Source Equivalent to area.y0, except the accessor returns the radius: the distance from the origin ⟨0,0⟩. # areaRadial.outerRadius([radius]) · Source Equivalent to area.y1, except the accessor returns the radius: the distance from the origin ⟨0,0⟩. # areaRadial.defined([defined]) Equivalent to area.defined. # areaRadial.curve([curve]) · Source Equivalent to area.curve. Note that curveMonotoneX or curveMonotoneY are not recommended for radial areas because they assume that the data is monotonic in x or y, which is typically untrue of radial areas. # areaRadial.context([context]) Equivalent to line.context. # areaRadial.lineStartAngle() · Source # areaRadial.lineInnerRadius() · Source Returns a new radial line generator that has this radial area generator’s current defined accessor, curve and context. The line’s angle accessor is this area’s start angle accessor, and the line’s radius accessor is this area’s inner radius accessor. # areaRadial.lineEndAngle() · Source Returns a new radial line generator that has this radial area generator’s current defined accessor, curve and context. The line’s angle accessor is this area’s end angle accessor, and the line’s radius accessor is this area’s inner radius accessor. # areaRadial.lineOuterRadius() · Source Returns a new radial line generator that has this radial area generator’s current defined accessor, curve and context. The line’s angle accessor is this area’s start angle accessor, and the line’s radius accessor is this area’s outer radius accessor. Curves While lines are defined as a sequence of two-dimensional [x, y] points, and areas are similarly defined by a topline and a baseline, there remains the task of transforming this discrete representation into a continuous shape: i.e., how to interpolate between the points. A variety of curves are provided for this purpose. Curves are typically not constructed or used directly, instead being passed to line.curve and area.curve. For example: var line = d3.line() .x(function(d) { return x(d.date); }) .y(function(d) { return y(d.value); }) .curve(d3.curveCatmullRom.alpha(0.5)); # d3.curveBasis(context) · Source Produces a cubic basis spline using the specified control points. The first and last points are triplicated such that the spline starts at the first point and ends at the last point, and is tangent to the line between the first and second points, and to the line between the penultimate and last points. # d3.curveBasisClosed(context) · Source Produces a closed cubic basis spline using the specified control points. When a line segment ends, the first three control points are repeated, producing a closed loop with C2 continuity. # d3.curveBasisOpen(context) · Source Produces a cubic basis spline using the specified control points. Unlike basis, the first and last points are not repeated, and thus the curve typically does not intersect these points. # d3.curveBundle(context) · Source Produces a straightened cubic basis spline using the specified control points, with the spline straightened according to the curve’s beta, which defaults to 0.85. This curve is typically used in hierarchical edge bundling to disambiguate connections, as proposed by Danny Holten in Hierarchical Edge Bundles: Visualization of Adjacency Relations in Hierarchical Data. This curve does not implement curve.areaStart and curve.areaEnd; it is intended to work with d3.line, not d3.area. # bundle.beta(beta) · Source Returns a bundle curve with the specified beta in the range [0, 1], representing the bundle strength. If beta equals zero, a straight line between the first and last point is produced; if beta equals one, a standard basis spline is produced. For example: var line = d3.line().curve(d3.curveBundle.beta(0.5)); # d3.curveCardinal(context) · Source Produces a cubic cardinal spline using the specified control points, with one-sided differences used for the first and last piece. The default tension is 0. # d3.curveCardinalClosed(context) · Source Produces a closed cubic cardinal spline using the specified control points. When a line segment ends, the first three control points are repeated, producing a closed loop. The default tension is 0. # d3.curveCardinalOpen(context) · Source Produces a cubic cardinal spline using the specified control points. Unlike curveCardinal, one-sided differences are not used for the first and last piece, and thus the curve starts at the second point and ends at the penultimate point. The default tension is 0. # cardinal.tension(tension) · Source Returns a cardinal curve with the specified tension in the range [0, 1]. The tension determines the length of the tangents: a tension of one yields all zero tangents, equivalent to curveLinear; a tension of zero produces a uniform Catmull–Rom spline. For example: var line = d3.line().curve(d3.curveCardinal.tension(0.5)); # d3.curveCatmullRom(context) · Source Produces a cubic Catmull–Rom spline using the specified control points and the parameter alpha, which defaults to 0.5, as proposed by Yuksel et al. in On the Parameterization of Catmull–Rom Curves, with one-sided differences used for the first and last piece. # d3.curveCatmullRomClosed(context) · Source Produces a closed cubic Catmull–Rom spline using the specified control points and the parameter alpha, which defaults to 0.5, as proposed by Yuksel et al. When a line segment ends, the first three control points are repeated, producing a closed loop. # d3.curveCatmullRomOpen(context) · Source Produces a cubic Catmull–Rom spline using the specified control points and the parameter alpha, which defaults to 0.5, as proposed by Yuksel et al. Unlike curveCatmullRom, one-sided differences are not used for the first and last piece, and thus the curve starts at the second point and ends at the penultimate point. # catmullRom.alpha(alpha) · Source Returns a cubic Catmull–Rom curve with the specified alpha in the range [0, 1]. If alpha is zero, produces a uniform spline, equivalent to curveCardinal with a tension of zero; if alpha is one, produces a chordal spline; if alpha is 0.5, produces a centripetal spline. Centripetal splines are recommended to avoid self-intersections and overshoot. For example: var line = d3.line().curve(d3.curveCatmullRom.alpha(0.5)); # d3.curveLinear(context) · Source Produces a polyline through the specified points. # d3.curveLinearClosed(context) · Source Produces a closed polyline through the specified points by repeating the first point when the line segment ends. # d3.curveMonotoneX(context) · Source Produces a cubic spline that preserves monotonicity in y, assuming monotonicity in x, as proposed by Steffen in A simple method for monotonic interpolation in one dimension: “a smooth curve with continuous first-order derivatives that passes through any given set of data points without spurious oscillations. Local extrema can occur only at grid points where they are given by the data, but not in between two adjacent grid points.” # d3.curveMonotoneY(context) · Source Produces a cubic spline that preserves monotonicity in x, assuming monotonicity in y, as proposed by Steffen in A simple method for monotonic interpolation in one dimension: “a smooth curve with continuous first-order derivatives that passes through any given set of data points without spurious oscillations. Local extrema can occur only at grid points where they are given by the data, but not in between two adjacent grid points.” # d3.curveNatural(context) · Source Produces a natural cubic spline with the second derivative of the spline set to zero at the endpoints. # d3.curveStep(context) · Source Produces a piecewise constant function (a step function) consisting of alternating horizontal and vertical lines. The y-value changes at the midpoint of each pair of adjacent x-values. # d3.curveStepAfter(context) · Source Produces a piecewise constant function (a step function) consisting of alternating horizontal and vertical lines. The y-value changes after the x-value. # d3.curveStepBefore(context) · Source Produces a piecewise constant function (a step function) consisting of alternating horizontal and vertical lines. The y-value changes before the x-value. Custom Curves Curves are typically not used directly, instead being passed to line.curve and area.curve. However, you can define your own curve implementation should none of the built-in curves satisfy your needs using the following interface. You can also use this low-level interface with a built-in curve type as an alternative to the line and area generators. # curve.areaStart() · Source Indicates the start of a new area segment. Each area segment consists of exactly two line segments: the topline, followed by the baseline, with the baseline points in reverse order. # curve.areaEnd() · Source Indicates the end of the current area segment. # curve.lineStart() · Source Indicates the start of a new line segment. Zero or more points will follow. # curve.lineEnd() · Source Indicates the end of the current line segment. # curve.point(x, y) · Source Indicates a new point in the current line segment with the given x- and y-values. Links The link shape generates a smooth cubic Bézier curve from a source point to a target point. The tangents of the curve at the start and end are either vertical, horizontal or radial. # d3.linkVertical() · Source Returns a new link generator with vertical tangents. For example, to visualize links in a tree diagram rooted on the top edge of the display, you might say: var link = d3.linkVertical() .x(function(d) { return d.x; }) .y(function(d) { return d.y; }); # d3.linkHorizontal() · Source Returns a new link generator with horizontal tangents. For example, to visualize links in a tree diagram rooted on the left edge of the display, you might say: var link = d3.linkHorizontal() .x(function(d) { return d.y; }) .y(function(d) { return d.x; }); # link(arguments…) · Source Generates a link for the given arguments. The arguments are arbitrary; they are simply propagated to the link generator’s accessor functions along with the this object. For example, with the default settings, an object expected: link({ source: [100, 100], target: [300, 300] }); # link.source([source]) · Source If source is specified, sets the source accessor to the specified function and returns this link generator. If source is not specified, returns the current source accessor, which defaults to: function source(d) { return d.source; } # link.target([target]) · Source If target is specified, sets the target accessor to the specified function and returns this link generator. If target is not specified, returns the current target accessor, which defaults to: function target(d) { return d.target; } # link.x([x]) · Source If x is specified, sets the x-accessor to the specified function or number and returns this link generator. If x is not specified, returns the current x-accessor, which defaults to: function x(d) { return d[0]; } # link.y([y]) · Source If y is specified, sets the y-accessor to the specified function or number and returns this link generator. If y is not specified, returns the current y-accessor, which defaults to: function y(d) { return d[1]; } # link.context([context]) · Source If context is specified, sets the context and returns this link generator. If context is not specified, returns the current context, which defaults to null. If the context is not null, then the generated link is rendered to this context as a sequence of path method calls. Otherwise, a path data string representing the generated link is returned. See also d3-path. # d3.linkRadial() · Source Returns a new link generator with radial tangents. For example, to visualize links in a tree diagram rooted in the center of the display, you might say: var link = d3.linkRadial() .angle(function(d) { return d.x; }) .radius(function(d) { return d.y; }); # linkRadial.angle([angle]) · Source Equivalent to link.x, except the accessor returns the angle in radians, with 0 at -y (12 o’clock). # linkRadial.radius([radius]) · Source Equivalent to link.y, except the accessor returns the radius: the distance from the origin ⟨0,0⟩. Symbols Symbols provide a categorical shape encoding as is commonly used in scatterplots. Symbols are always centered at ⟨0,0⟩; use a transform (see: SVG, Canvas) to move the symbol to a different position. # d3.symbol() · Source Constructs a new symbol generator with the default settings. # symbol(arguments…) · Source Generates a symbol for the given arguments. The arguments are arbitrary; they are simply propagated to the symbol generator’s accessor functions along with the this object. For example, with the default settings, no arguments are needed to produce a circle with area 64 square pixels. If the symbol generator has a context, then the symbol is rendered to this context as a sequence of path method calls and this function returns void. Otherwise, a path data string is returned. # symbol.type([type]) · Source If type is specified, sets the symbol type to the specified function or symbol type and returns this symbol generator. If type is a function, the symbol generator’s arguments and this are passed through. (See selection.attr if you are using d3-selection.) If type is not specified, returns the current symbol type accessor, which defaults to: function type() { return circle; } See symbols for the set of built-in symbol types. To implement a custom symbol type, pass an object that implements symbolType.draw. # symbol.size([size]) · Source If size is specified, sets the size to the specified function or number and returns this symbol generator. If size is a function, the symbol generator’s arguments and this are passed through. (See selection.attr if you are using d3-selection.) If size is not specified, returns the current size accessor, which defaults to: function size() { return 64; } Specifying the size as a function is useful for constructing a scatterplot with a size encoding. If you wish to scale the symbol to fit a given bounding box, rather than by area, try SVG’s getBBox. # symbol.context([context]) · Source If context is specified, sets the context and returns this symbol generator. If context is not specified, returns the current context, which defaults to null. If the context is not null, then the generated symbol is rendered to this context as a sequence of path method calls. Otherwise, a path data string representing the generated symbol is returned. # d3.symbols An array containing the set of all built-in symbol types: circle, cross, diamond, square, star, triangle, and wye. Useful for constructing the range of an ordinal scale should you wish to use a shape encoding for categorical data. # d3.symbolCircle · Source The circle symbol type. # d3.symbolCross · Source The Greek cross symbol type, with arms of equal length. # d3.symbolDiamond · Source The rhombus symbol type. # d3.symbolSquare · Source The square symbol type. # d3.symbolStar · Source The pentagonal star (pentagram) symbol type. # d3.symbolTriangle · Source The up-pointing triangle symbol type. # d3.symbolWye · Source The Y-shape symbol type. # d3.pointRadial(angle, radius) · Source Returns the point [x, y] for the given angle in radians, with 0 at -y (12 o’clock) and positive angles proceeding clockwise, and the given radius. Custom Symbol Types Symbol types are typically not used directly, instead being passed to symbol.type. However, you can define your own symbol type implementation should none of the built-in types satisfy your needs using the following interface. You can also use this low-level interface with a built-in symbol type as an alternative to the symbol generator. # symbolType.draw(context, size) Renders this symbol type to the specified context with the specified size in square pixels. The context implements the CanvasPathMethods interface. (Note that this is a subset of the CanvasRenderingContext2D interface!) Stacks Some shape types can be stacked, placing one shape adjacent to another. For example, a bar chart of monthly sales might be broken down into a multi-series bar chart by product category, stacking bars vertically. This is equivalent to subdividing a bar chart by an ordinal dimension (such as product category) and applying a color encoding. Stacked charts can show overall value and per-category value simultaneously; however, it is typically harder to compare across categories, as only the bottom layer of the stack is aligned. So, chose the stack order carefully, and consider a streamgraph. (See also grouped charts.) Like the pie generator, the stack generator does not produce a shape directly. Instead it computes positions which you can then pass to an area generator or use directly, say to position bars. # d3.stack() · Source Constructs a new stack generator with the default settings. # stack(data[, arguments…]) · Source Generates a stack for the given array of data, returning an array representing each series. Any additional arguments are arbitrary; they are simply propagated to accessors along with the this object. The series are determined by the keys accessor; each series i in the returned array corresponds to the ith key. Each series is an array of points, where each point j corresponds to the jth element in the input data. Lastly, each point is represented as an array [y0, y1] where y0 is the lower value (baseline) and y1 is the upper value (topline); the difference between y0 and y1 corresponds to the computed value for this point. The key for each series is available as series.key, and the index as series.index. The input data element for each point is available as point.data. For example, consider the following table representing monthly sales of fruits: Month Apples Bananas Cherries Dates 1/2015 3840 1920 960 400 2/2015 1600 1440 960 400 3/2015 640 960 640 400 4/2015 320 480 640 400 This might be represented in JavaScript as an array of objects: var data = [ {month: new Date(2015, 0, 1), apples: 3840, bananas: 1920, cherries: 960, dates: 400}, {month: new Date(2015, 1, 1), apples: 1600, bananas: 1440, cherries: 960, dates: 400}, {month: new Date(2015, 2, 1), apples: 640, bananas: 960, cherries: 640, dates: 400}, {month: new Date(2015, 3, 1), apples: 320, bananas: 480, cherries: 640, dates: 400} ]; To produce a stack for this data: var stack = d3.stack() .keys([\"apples\", \"bananas\", \"cherries\", \"dates\"]) .order(d3.stackOrderNone) .offset(d3.stackOffsetNone); var series = stack(data); The resulting array has one element per series. Each series has one point per month, and each point has a lower and upper value defining the baseline and topline: [ [[ 0, 3840], [ 0, 1600], [ 0, 640], [ 0, 320]], // apples [[3840, 5760], [1600, 3040], [ 640, 1600], [ 320, 800]], // bananas [[5760, 6720], [3040, 4000], [1600, 2240], [ 800, 1440]], // cherries [[6720, 7120], [4000, 4400], [2240, 2640], [1440, 1840]], // dates ] Each series in then typically passed to an area generator to render an area chart, or used to construct rectangles for a bar chart. # stack.keys([keys]) · Source If keys is specified, sets the keys accessor to the specified function or array and returns this stack generator. If keys is not specified, returns the current keys accessor, which defaults to the empty array. A series (layer) is generated for each key. Keys are typically strings, but they may be arbitrary values. The series’ key is passed to the value accessor, along with each data point, to compute the point’s value. # stack.value([value]) · Source If value is specified, sets the value accessor to the specified function or number and returns this stack generator. If value is not specified, returns the current value accessor, which defaults to: function value(d, key) { return d[key]; } Thus, by default the stack generator assumes that the input data is an array of objects, with each object exposing named properties with numeric values; see stack for an example. # stack.order([order]) · Source If order is specified, sets the order accessor to the specified function or array and returns this stack generator. If order is not specified, returns the current order acccesor, which defaults to stackOrderNone; this uses the order given by the key accessor. See stack orders for the built-in orders. If order is a function, it is passed the generated series array and must return an array of numeric indexes representing the stack order. For example, the default order is defined as: function orderNone(series) { var n = series.length, o = new Array(n); while (--n >= 0) o[n] = n; return o; } The stack order is computed prior to the offset; thus, the lower value for all points is zero at the time the order is computed. The index attribute for each series is also not set until after the order is computed. # stack.offset([offset]) · Source If offset is specified, sets the offset accessor to the specified function or array and returns this stack generator. If offset is not specified, returns the current offset acccesor, which defaults to stackOffsetNone; this uses a zero baseline. See stack offsets for the built-in offsets. If offset is a function, it is passed the generated series array and the order index array. The offset function is then responsible for updating the lower and upper values in the series array to layout the stack. For example, the default offset is defined as: function offsetNone(series, order) { if (!((n = series.length) > 1)) return; for (var i = 1, s0, s1 = series[order[0]], n, m = s1.length; i < n; ++i) { s0 = s1, s1 = series[order[i]]; for (var j = 0; j < m; ++j) { s1[j][1] += s1[j][0] = s0[j][1]; } } } Stack Orders Stack orders are typically not used directly, but are instead passed to stack.order. # d3.stackOrderAppearance(series) · Source Returns a series order such that the earliest series (according to the maximum value) is at the bottom. # d3.stackOrderAscending(series) · Source Returns a series order such that the smallest series (according to the sum of values) is at the bottom. # d3.stackOrderDescending(series) · Source Returns a series order such that the largest series (according to the sum of values) is at the bottom. # d3.stackOrderInsideOut(series) · Source Returns a series order such that the earliest series (according to the maximum value) are on the inside and the later series are on the outside. This order is recommended for streamgraphs in conjunction with the wiggle offset. See Stacked Graphs—Geometry & Aesthetics by Byron & Wattenberg for more information. # d3.stackOrderNone(series) · Source Returns the given series order [0, 1, … n - 1] where n is the number of elements in series. Thus, the stack order is given by the key accessor. # d3.stackOrderReverse(series) · Source Returns the reverse of the given series order [n - 1, n - 2, … 0] where n is the number of elements in series. Thus, the stack order is given by the reverse of the key accessor. Stack Offsets Stack offsets are typically not used directly, but are instead passed to stack.offset. # d3.stackOffsetExpand(series, order) · Source Applies a zero baseline and normalizes the values for each point such that the topline is always one. # d3.stackOffsetDiverging(series, order) · Source Positive values are stacked above zero, negative values are stacked below zero, and zero values are stacked at zero. # d3.stackOffsetNone(series, order) · Source Applies a zero baseline. # d3.stackOffsetSilhouette(series, order) · Source Shifts the baseline down such that the center of the streamgraph is always at zero. # d3.stackOffsetWiggle(series, order) · Source Shifts the baseline so as to minimize the weighted wiggle of layers. This offset is recommended for streamgraphs in conjunction with the inside-out order. See Stacked Graphs—Geometry & Aesthetics by Bryon & Wattenberg for more information."
  },
  "src/frontend/app-client/node_modules/d3-timer/README.html": {
    "href": "src/frontend/app-client/node_modules/d3-timer/README.html",
    "title": "d3-timer",
    "summary": "d3-timer This module provides an efficient queue capable of managing thousands of concurrent animations, while guaranteeing consistent, synchronized timing with concurrent or staged animations. Internally, it uses requestAnimationFrame for fluid animation (if available), switching to setTimeout for delays longer than 24ms. Installing If you use npm, npm install d3-timer. You can also download the latest release on GitHub. For vanilla HTML in modern browsers, import d3-timer from Skypack: <script type=\"module\"> import {timer} from \"https://cdn.skypack.dev/d3-timer@3\"; const t = timer(callback); </script> For legacy environments, you can load d3-timer’s UMD bundle from an npm-based CDN such as jsDelivr; a d3 global is exported: <script src=\"https://cdn.jsdelivr.net/npm/d3-timer@3\"></script> <script> const timer = d3.timer(callback); </script> API Reference # d3.now() <> Returns the current time as defined by performance.now if available, and Date.now if not. The current time is updated at the start of a frame; it is thus consistent during the frame, and any timers scheduled during the same frame will be synchronized. If this method is called outside of a frame, such as in response to a user event, the current time is calculated and then fixed until the next frame, again ensuring consistent timing during event handling. # d3.timer(callback[, delay[, time]]) <> Schedules a new timer, invoking the specified callback repeatedly until the timer is stopped. An optional numeric delay in milliseconds may be specified to invoke the given callback after a delay; if delay is not specified, it defaults to zero. The delay is relative to the specified time in milliseconds; if time is not specified, it defaults to now. The callback is passed the (apparent) elapsed time since the timer became active. For example: const t = d3.timer((elapsed) => { console.log(elapsed); if (elapsed > 200) t.stop(); }, 150); This produces roughly the following console output: 3 25 48 65 85 106 125 146 167 189 209 (The exact values may vary depending on your JavaScript runtime and what else your computer is doing.) Note that the first elapsed time is 3ms: this is the elapsed time since the timer started, not since the timer was scheduled. Here the timer started 150ms after it was scheduled due to the specified delay. The apparent elapsed time may be less than the true elapsed time if the page is backgrounded and requestAnimationFrame is paused; in the background, apparent time is frozen. If timer is called within the callback of another timer, the new timer callback (if eligible as determined by the specified delay and time) will be invoked immediately at the end of the current frame, rather than waiting until the next frame. Within a frame, timer callbacks are guaranteed to be invoked in the order they were scheduled, regardless of their start time. # timer.restart(callback[, delay[, time]]) <> Restart a timer with the specified callback and optional delay and time. This is equivalent to stopping this timer and creating a new timer with the specified arguments, although this timer retains the original invocation priority. # timer.stop() <> Stops this timer, preventing subsequent callbacks. This method has no effect if the timer has already stopped. # d3.timerFlush() <> Immediately invoke any eligible timer callbacks. Note that zero-delay timers are normally first executed after one frame (~17ms). This can cause a brief flicker because the browser renders the page twice: once at the end of the first event loop, then again immediately on the first timer callback. By flushing the timer queue at the end of the first event loop, you can run any zero-delay timers immediately and avoid the flicker. # d3.timeout(callback[, delay[, time]]) <> Like timer, except the timer automatically stops on its first callback. A suitable replacement for setTimeout that is guaranteed to not run in the background. The callback is passed the elapsed time. # d3.interval(callback[, delay[, time]]) <> Like timer, except the callback is invoked only every delay milliseconds; if delay is not specified, this is equivalent to timer. A suitable replacement for setInterval that is guaranteed to not run in the background. The callback is passed the elapsed time."
  },
  "src/frontend/app-client/node_modules/d3-transition/README.html": {
    "href": "src/frontend/app-client/node_modules/d3-transition/README.html",
    "title": "d3-transition",
    "summary": "d3-transition A transition is a selection-like interface for animating changes to the DOM. Instead of applying changes instantaneously, transitions smoothly interpolate the DOM from its current state to the desired target state over a given duration. To apply a transition, select elements, call selection.transition, and then make the desired changes. For example: d3.select(\"body\") .transition() .style(\"background-color\", \"red\"); Transitions support most selection methods (such as transition.attr and transition.style in place of selection.attr and selection.style), but not all methods are supported; for example, you must append elements or bind data before a transition starts. A transition.remove operator is provided for convenient removal of elements when the transition ends. To compute intermediate state, transitions leverage a variety of built-in interpolators. Colors, numbers, and transforms are automatically detected. Strings with embedded numbers are also detected, as is common with many styles (such as padding or font sizes) and paths. To specify a custom interpolator, use transition.attrTween, transition.styleTween or transition.tween. Installing If you use npm, npm install d3-transition. You can also download the latest release on GitHub. For vanilla HTML in modern browsers, import d3-transition from Skypack: <script type=\"module\"> import {transition} from \"https://cdn.skypack.dev/d3-transition@3\"; const t = transition(); </script> For legacy environments, you can load d3-transition’s UMD bundle from an npm-based CDN such as jsDelivr; a d3 global is exported: <script src=\"https://cdn.jsdelivr.net/npm/d3-color@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-dispatch@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-ease@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-interpolate@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-selection@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-timer@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-transition@3\"></script> <script> const t = d3.transition(); </script> Try d3-transition in your browser. API Reference Selecting Elements Modifying Elements Timing Control Flow The Life of a Transition Selecting Elements Transitions are derived from selections via selection.transition. You can also create a transition on the document root element using d3.transition. # selection.transition([name]) · Source Returns a new transition on the given selection with the specified name. If a name is not specified, null is used. The new transition is only exclusive with other transitions of the same name. If the name is a transition instance, the returned transition has the same id and name as the specified transition. If a transition with the same id already exists on a selected element, the existing transition is returned for that element. Otherwise, the timing of the returned transition is inherited from the existing transition of the same id on the nearest ancestor of each selected element. Thus, this method can be used to synchronize a transition across multiple selections, or to re-select a transition for specific elements and modify its configuration. For example: var t = d3.transition() .duration(750) .ease(d3.easeLinear); d3.selectAll(\".apple\").transition(t) .style(\"fill\", \"red\"); d3.selectAll(\".orange\").transition(t) .style(\"fill\", \"orange\"); If the specified transition is not found on a selected node or its ancestors (such as if the transition already ended), the default timing parameters are used; however, in a future release, this will likely be changed to throw an error. See #59. # selection.interrupt([name]) · Source Interrupts the active transition of the specified name on the selected elements, and cancels any pending transitions with the specified name, if any. If a name is not specified, null is used. Interrupting a transition on an element has no effect on any transitions on any descendant elements. For example, an axis transition consists of multiple independent, synchronized transitions on the descendants of the axis G element (the tick lines, the tick labels, the domain path, etc.). To interrupt the axis transition, you must therefore interrupt the descendants: selection.selectAll(\"*\").interrupt(); The universal selector, *, selects all descendant elements. If you also want to interrupt the G element itself: selection.interrupt().selectAll(\"*\").interrupt(); # d3.interrupt(node[, name]) · Source Interrupts the active transition of the specified name on the specified node, and cancels any pending transitions with the specified name, if any. If a name is not specified, null is used. See also selection.interrupt. # d3.transition([name]) · Source Returns a new transition on the root element, document.documentElement, with the specified name. If a name is not specified, null is used. The new transition is only exclusive with other transitions of the same name. The name may also be a transition instance; see selection.transition. This method is equivalent to: d3.selection() .transition(name) This function can also be used to test for transitions (instanceof d3.transition) or to extend the transition prototype. # transition.select(selector) · Source For each selected element, selects the first descendant element that matches the specified selector string, if any, and returns a transition on the resulting selection. The selector may be specified either as a selector string or a function. If a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. The new transition has the same id, name and timing as this transition; however, if a transition with the same id already exists on a selected element, the existing transition is returned for that element. This method is equivalent to deriving the selection for this transition via transition.selection, creating a subselection via selection.select, and then creating a new transition via selection.transition: transition .selection() .select(selector) .transition(transition) # transition.selectAll(selector) · Source For each selected element, selects all descendant elements that match the specified selector string, if any, and returns a transition on the resulting selection. The selector may be specified either as a selector string or a function. If a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. The new transition has the same id, name and timing as this transition; however, if a transition with the same id already exists on a selected element, the existing transition is returned for that element. This method is equivalent to deriving the selection for this transition via transition.selection, creating a subselection via selection.selectAll, and then creating a new transition via selection.transition: transition .selection() .selectAll(selector) .transition(transition) # transition.selectChild([selector]) · Source For each selected element, selects the first child element that matches the specified selector string, if any, and returns a transition on the resulting selection. The selector may be specified either as a selector string or a function. If a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. The new transition has the same id, name and timing as this transition; however, if a transition with the same id already exists on a selected element, the existing transition is returned for that element. This method is equivalent to deriving the selection for this transition via transition.selection, creating a subselection via selection.selectChild, and then creating a new transition via selection.transition: transition .selection() .selectChild(selector) .transition(transition) # transition.selectChildren([selector]) · Source For each selected element, selects all children that match the specified selector string, if any, and returns a transition on the resulting selection. The selector may be specified either as a selector string or a function. If a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. The new transition has the same id, name and timing as this transition; however, if a transition with the same id already exists on a selected element, the existing transition is returned for that element. This method is equivalent to deriving the selection for this transition via transition.selection, creating a subselection via selection.selectChildren, and then creating a new transition via selection.transition: transition .selection() .selectChildren(selector) .transition(transition) # transition.filter(filter) · Source For each selected element, selects only the elements that match the specified filter, and returns a transition on the resulting selection. The filter may be specified either as a selector string or a function. If a function, it is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. The new transition has the same id, name and timing as this transition; however, if a transition with the same id already exists on a selected element, the existing transition is returned for that element. This method is equivalent to deriving the selection for this transition via transition.selection, creating a subselection via selection.filter, and then creating a new transition via selection.transition: transition .selection() .filter(filter) .transition(transition) # transition.merge(other) · Source Returns a new transition merging this transition with the specified other transition, which must have the same id as this transition. The returned transition has the same number of groups, the same parents, the same name and the same id as this transition. Any missing (null) elements in this transition are filled with the corresponding element, if present (not null), from the other transition. This method is equivalent to deriving the selection for this transition via transition.selection, merging with the selection likewise derived from the other transition via selection.merge, and then creating a new transition via selection.transition: transition .selection() .merge(other.selection()) .transition(transition) # transition.transition() · Source Returns a new transition on the same selected elements as this transition, scheduled to start when this transition ends. The new transition inherits a reference time equal to this transition’s time plus its delay and duration. The new transition also inherits this transition’s name, duration, and easing. This method can be used to schedule a sequence of chained transitions. For example: d3.selectAll(\".apple\") .transition() // First fade to green. .style(\"fill\", \"green\") .transition() // Then red. .style(\"fill\", \"red\") .transition() // Wait one second. Then brown, and remove. .delay(1000) .style(\"fill\", \"brown\") .remove(); The delay for each transition is relative to its previous transition. Thus, in the above example, apples will stay red for one second before the last transition to brown starts. # transition.selection() · Source Returns the selection corresponding to this transition. # d3.active(node[, name]) · Source Returns the active transition on the specified node with the specified name, if any. If no name is specified, null is used. Returns null if there is no such active transition on the specified node. This method is useful for creating chained transitions. For example, to initiate disco mode: d3.selectAll(\"circle\").transition() .delay(function(d, i) { return i * 50; }) .on(\"start\", function repeat() { d3.active(this) .style(\"fill\", \"red\") .transition() .style(\"fill\", \"green\") .transition() .style(\"fill\", \"blue\") .transition() .on(\"start\", repeat); }); See chained transitions for an example. Modifying Elements After selecting elements and creating a transition with selection.transition, use the transition’s transformation methods to affect document content. # transition.attr(name, value) · Source For each selected element, assigns the attribute tween for the attribute with the specified name to the specified target value. The starting value of the tween is the attribute’s value when the transition starts. The target value may be specified either as a constant or a function. If a function, it is immediately evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. If the target value is null, the attribute is removed when the transition starts. Otherwise, an interpolator is chosen based on the type of the target value, using the following algorithm: If value is a number, use interpolateNumber. If value is a color or a string coercible to a color, use interpolateRgb. Use interpolateString. To apply a different interpolator, use transition.attrTween. # transition.attrTween(name[, factory]) · Source If factory is specified and not null, assigns the attribute tween for the attribute with the specified name to the specified interpolator factory. An interpolator factory is a function that returns an interpolator; when the transition starts, the factory is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. The returned interpolator will then be invoked for each frame of the transition, in order, being passed the eased time t, typically in the range [0, 1]. Lastly, the return value of the interpolator will be used to set the attribute value. The interpolator must return a string. (To remove an attribute at the start of a transition, use transition.attr; to remove an attribute at the end of a transition, use transition.on to listen for the end event.) If the specified factory is null, removes the previously-assigned attribute tween of the specified name, if any. If factory is not specified, returns the current interpolator factory for attribute with the specified name, or undefined if no such tween exists. For example, to interpolate the fill attribute from red to blue: transition.attrTween(\"fill\", function() { return d3.interpolateRgb(\"red\", \"blue\"); }); Or to interpolate from the current fill to blue, like transition.attr: transition.attrTween(\"fill\", function() { return d3.interpolateRgb(this.getAttribute(\"fill\"), \"blue\"); }); Or to apply a custom rainbow interpolator: transition.attrTween(\"fill\", function() { return function(t) { return \"hsl(\" + t * 360 + \",100%,50%)\"; }; }); This method is useful to specify a custom interpolator, such as one that understands SVG paths. A useful technique is data interpolation, where d3.interpolateObject is used to interpolate two data values, and the resulting value is then used (say, with a shape) to compute the new attribute value. # transition.style(name, value[, priority]) · Source For each selected element, assigns the style tween for the style with the specified name to the specified target value with the specified priority. The starting value of the tween is the style’s inline value if present, and otherwise its computed value, when the transition starts. The target value may be specified either as a constant or a function. If a function, it is immediately evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. If the target value is null, the style is removed when the transition starts. Otherwise, an interpolator is chosen based on the type of the target value, using the following algorithm: If value is a number, use interpolateNumber. If value is a color or a string coercible to a color, use interpolateRgb. Use interpolateString. To apply a different interpolator, use transition.styleTween. # transition.styleTween(name[, factory[, priority]]) · Source If factory is specified and not null, assigns the style tween for the style with the specified name to the specified interpolator factory. An interpolator factory is a function that returns an interpolator; when the transition starts, the factory is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. The returned interpolator will then be invoked for each frame of the transition, in order, being passed the eased time t, typically in the range [0, 1]. Lastly, the return value of the interpolator will be used to set the style value with the specified priority. The interpolator must return a string. (To remove an style at the start of a transition, use transition.style; to remove an style at the end of a transition, use transition.on to listen for the end event.) If the specified factory is null, removes the previously-assigned style tween of the specified name, if any. If factory is not specified, returns the current interpolator factory for style with the specified name, or undefined if no such tween exists. For example, to interpolate the fill style from red to blue: transition.styleTween(\"fill\", function() { return d3.interpolateRgb(\"red\", \"blue\"); }); Or to interpolate from the current fill to blue, like transition.style: transition.styleTween(\"fill\", function() { return d3.interpolateRgb(this.style.fill, \"blue\"); }); Or to apply a custom rainbow interpolator: transition.styleTween(\"fill\", function() { return function(t) { return \"hsl(\" + t * 360 + \",100%,50%)\"; }; }); This method is useful to specify a custom interpolator, such as with data interpolation, where d3.interpolateObject is used to interpolate two data values, and the resulting value is then used to compute the new style value. # transition.text(value) · Source For each selected element, sets the text content to the specified target value when the transition starts. The value may be specified either as a constant or a function. If a function, it is immediately evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. The function’s return value is then used to set each element’s text content. A null value will clear the content. To interpolate text rather than to set it on start, use transition.textTween or append a replacement element and cross-fade opacity. Text is not interpolated by default because it is usually undesirable. # transition.textTween(factory) · Source, Examples If factory is specified and not null, assigns the text tween to the specified interpolator factory. An interpolator factory is a function that returns an interpolator; when the transition starts, the factory is evaluated for each selected element, in order, being passed the current datum d and index i, with the this context as the current DOM element. The returned interpolator will then be invoked for each frame of the transition, in order, being passed the eased time t, typically in the range [0, 1]. Lastly, the return value of the interpolator will be used to set the text. The interpolator must return a string. For example, to interpolate the text with integers from 0 to 100: transition.textTween(function() { return d3.interpolateRound(0, 100); }); If the specified factory is null, removes the previously-assigned text tween, if any. If factory is not specified, returns the current interpolator factory for text, or undefined if no such tween exists. # transition.remove() · Source For each selected element, removes the element when the transition ends, as long as the element has no other active or pending transitions. If the element has other active or pending transitions, does nothing. # transition.tween(name[, value]) · Source For each selected element, assigns the tween with the specified name with the specified value function. The value must be specified as a function that returns a function. When the transition starts, the value function is evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. The returned function is then invoked for each frame of the transition, in order, being passed the eased time t, typically in the range [0, 1]. If the specified value is null, removes the previously-assigned tween of the specified name, if any. For example, to interpolate the fill attribute to blue, like transition.attr: transition.tween(\"attr.fill\", function() { var i = d3.interpolateRgb(this.getAttribute(\"fill\"), \"blue\"); return function(t) { this.setAttribute(\"fill\", i(t)); }; }); This method is useful to specify a custom interpolator, or to perform side-effects, say to animate the scroll offset. Timing The easing, delay and duration of a transition is configurable. For example, a per-element delay can be used to stagger the reordering of elements, improving perception. See Animated Transitions in Statistical Data Graphics for recommendations. # transition.delay([value]) · Source For each selected element, sets the transition delay to the specified value in milliseconds. The value may be specified either as a constant or a function. If a function, it is immediately evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. The function’s return value is then used to set each element’s transition delay. If a delay is not specified, it defaults to zero. If a value is not specified, returns the current value of the delay for the first (non-null) element in the transition. This is generally useful only if you know that the transition contains exactly one element. Setting the delay to a multiple of the index i is a convenient way to stagger transitions across a set of elements. For example: transition.delay(function(d, i) { return i * 10; }); Of course, you can also compute the delay as a function of the data, or sort the selection before computed an index-based delay. # transition.duration([value]) · Source For each selected element, sets the transition duration to the specified value in milliseconds. The value may be specified either as a constant or a function. If a function, it is immediately evaluated for each selected element, in order, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. The function’s return value is then used to set each element’s transition duration. If a duration is not specified, it defaults to 250ms. If a value is not specified, returns the current value of the duration for the first (non-null) element in the transition. This is generally useful only if you know that the transition contains exactly one element. # transition.ease([value]) · Source Specifies the transition easing function for all selected elements. The value must be specified as a function. The easing function is invoked for each frame of the animation, being passed the normalized time t in the range [0, 1]; it must then return the eased time tʹ which is typically also in the range [0, 1]. A good easing function should return 0 if t = 0 and 1 if t = 1. If an easing function is not specified, it defaults to d3.easeCubic. If a value is not specified, returns the current easing function for the first (non-null) element in the transition. This is generally useful only if you know that the transition contains exactly one element. # transition.easeVarying(factory) <> Specifies a factory for the transition easing function. The factory must be a function. It is invoked for each node of the selection, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. It must return an easing function. Control Flow For advanced usage, transitions provide methods for custom control flow. # transition.end() · Source Returns a promise that resolves when every selected element finishes transitioning. If any element’s transition is cancelled or interrupted, the promise rejects. # transition.on(typenames[, listener]) · Source Adds or removes a listener to each selected element for the specified event typenames. The typenames is one of the following string event types: start - when the transition starts. end - when the transition ends. interrupt - when the transition is interrupted. cancel - when the transition is cancelled. See The Life of a Transition for more. Note that these are not native DOM events as implemented by selection.on and selection.dispatch, but transition events! The type may be optionally followed by a period (.) and a name; the optional name allows multiple callbacks to be registered to receive events of the same type, such as start.foo and start.bar. To specify multiple typenames, separate typenames with spaces, such as interrupt end or start.foo start.bar. When a specified transition event is dispatched on a selected node, the specified listener will be invoked for the transitioning element, being passed the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. Listeners always see the latest datum for their element, but the index is a property of the selection and is fixed when the listener is assigned; to update the index, re-assign the listener. If an event listener was previously registered for the same typename on a selected element, the old listener is removed before the new listener is added. To remove a listener, pass null as the listener. To remove all listeners for a given name, pass null as the listener and .foo as the typename, where foo is the name; to remove all listeners with no name, specify . as the typename. If a listener is not specified, returns the currently-assigned listener for the specified event typename on the first (non-null) selected element, if any. If multiple typenames are specified, the first matching listener is returned. # transition.each(function) · Source Invokes the specified function for each selected element, passing in the current datum (d), the current index (i), and the current group (nodes), with this as the current DOM element. This method can be used to invoke arbitrary code for each selected element, and is useful for creating a context to access parent and child data simultaneously. Equivalent to selection.each. # transition.call(function[, arguments…]) · Source Invokes the specified function exactly once, passing in this transition along with any optional arguments. Returns this transition. This is equivalent to invoking the function by hand but facilitates method chaining. For example, to set several attributes in a reusable function: function color(transition, fill, stroke) { transition .style(\"fill\", fill) .style(\"stroke\", stroke); } Now say: d3.selectAll(\"div\").transition().call(color, \"red\", \"blue\"); This is equivalent to: color(d3.selectAll(\"div\").transition(), \"red\", \"blue\"); Equivalent to selection.call. # transition.empty() · Source Returns true if this transition contains no (non-null) elements. Equivalent to selection.empty. # transition.nodes() · Source Returns an array of all (non-null) elements in this transition. Equivalent to selection.nodes. # transition.node() · Source Returns the first (non-null) element in this transition. If the transition is empty, returns null. Equivalent to selection.node. # transition.size() · Source Returns the total number of elements in this transition. Equivalent to selection.size. The Life of a Transition Immediately after creating a transition, such as by selection.transition or transition.transition, you may configure the transition using methods such as transition.delay, transition.duration, transition.attr and transition.style. Methods that specify target values (such as transition.attr) are evaluated synchronously; however, methods that require the starting value for interpolation, such as transition.attrTween and transition.styleTween, must be deferred until the transition starts. Shortly after creation, either at the end of the current frame or during the next frame, the transition is scheduled. At this point, the delay and start event listeners may no longer be changed; attempting to do so throws an error with the message “too late: already scheduled” (or if the transition has ended, “transition not found”). When the transition subsequently starts, it interrupts the active transition of the same name on the same element, if any, dispatching an interrupt event to registered listeners. (Note that interrupts happen on start, not creation, and thus even a zero-delay transition will not immediately interrupt the active transition: the old transition is given a final frame. Use selection.interrupt to interrupt immediately.) The starting transition also cancels any pending transitions of the same name on the same element that were created before the starting transition. The transition then dispatches a start event to registered listeners. This is the last moment at which the transition may be modified: the transition’s timing, tweens, and listeners may not be changed when it is running; attempting to do so throws an error with the message “too late: already running” (or if the transition has ended, “transition not found”). The transition initializes its tweens immediately after starting. During the frame the transition starts, but after all transitions starting this frame have been started, the transition invokes its tweens for the first time. Batching tween initialization, which typically involves reading from the DOM, improves performance by avoiding interleaved DOM reads and writes. For each frame that a transition is active, it invokes its tweens with an eased t-value ranging from 0 to 1. Within each frame, the transition invokes its tweens in the order they were registered. When a transition ends, it invokes its tweens a final time with a (non-eased) t-value of 1. It then dispatches an end event to registered listeners. This is the last moment at which the transition may be inspected: after ending, the transition is deleted from the element, and its configuration is destroyed. (A transition’s configuration is also destroyed on interrupt or cancel.) Attempting to inspect a transition after it is destroyed throws an error with the message “transition not found”."
  },
  "src/frontend/app-client/node_modules/d3-zoom/README.html": {
    "href": "src/frontend/app-client/node_modules/d3-zoom/README.html",
    "title": "d3-zoom",
    "summary": "d3-zoom Panning and zooming are popular interaction techniques which let the user focus on a region of interest by restricting the view. It is easy to learn due to direct manipulation: click-and-drag to pan (translate), spin the wheel to zoom (scale), or use touch. Panning and zooming are widely used in web-based mapping, but can also be used with visualizations such as time-series and scatterplots. The zoom behavior implemented by d3-zoom is a convenient but flexible abstraction for enabling pan-and-zoom on selections. It handles a surprising variety of input events and browser quirks. The zoom behavior is agnostic about the DOM, so you can use it with SVG, HTML or Canvas. The zoom behavior is also designed to work with d3-scale and d3-axis; see transform.rescaleX and transform.rescaleY. You can also restrict zooming using zoom.scaleExtent and panning using zoom.translateExtent. The zoom behavior can be combined with other behaviors, such as d3-drag for dragging, and d3-brush for focus + context. The zoom behavior can be controlled programmatically using zoom.transform, allowing you to implement user interface controls which drive the display or to stage animated tours through your data. Smooth zoom transitions are based on “Smooth and efficient zooming and panning” by Jarke J. van Wijk and Wim A.A. Nuij. See also d3-tile for examples panning and zooming maps. Installing If you use npm, npm install d3-zoom. You can also download the latest release on GitHub. For vanilla HTML in modern browsers, import d3-zoom from Skypack: <script type=\"module\"> import {zoom} from \"https://cdn.skypack.dev/d3-zoom@3\"; const handler = zoom(); </script> For legacy environments, you can load d3-zoom’s UMD bundle from an npm-based CDN such as jsDelivr; a d3 global is exported: <script src=\"https://cdn.jsdelivr.net/npm/d3-color@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-dispatch@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-ease@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-interpolate@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-selection@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-timer@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-transition@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-drag@3\"></script> <script src=\"https://cdn.jsdelivr.net/npm/d3-zoom@3\"></script> <script> const zoom = d3.zoom(); </script> Try d3-zoom in your browser. API Reference This table describes how the zoom behavior interprets native events: Event Listening Element Zoom Event Default Prevented? mousedown⁵ selection start no¹ mousemove² window¹ zoom yes mouseup² window¹ end yes dragstart² window - yes selectstart² window - yes click³ window - yes dblclick selection multiple⁶ yes wheel⁸ selection zoom⁷ yes touchstart selection multiple⁶ no⁴ touchmove selection zoom yes touchend selection end no⁴ touchcancel selection end no⁴ The propagation of all consumed events is immediately stopped. ¹ Necessary to capture events outside an iframe; see d3-drag#9. ² Only applies during an active, mouse-based gesture; see d3-drag#9. ³ Only applies immediately after some mouse-based gestures; see zoom.clickDistance. ⁴ Necessary to allow click emulation on touch input; see d3-drag#9. ⁵ Ignored if within 500ms of a touch gesture ending; assumes click emulation. ⁶ Double-click and double-tap initiate a transition that emits start, zoom and end events; see zoom.tapDistance.. ⁷ The first wheel event emits a start event; an end event is emitted when no wheel events are received for 150ms. ⁸ Ignored if already at the corresponding limit of the scale extent. # d3.zoom() · Source, Examples Creates a new zoom behavior. The returned behavior, zoom, is both an object and a function, and is typically applied to selected elements via selection.call. # zoom(selection) · Source, Examples Applies this zoom behavior to the specified selection, binding the necessary event listeners to allow panning and zooming, and initializing the zoom transform on each selected element to the identity transform if not already defined. This function is typically not invoked directly, and is instead invoked via selection.call. For example, to instantiate a zoom behavior and apply it to a selection: selection.call(d3.zoom().on(\"zoom\", zoomed)); Internally, the zoom behavior uses selection.on to bind the necessary event listeners for zooming. The listeners use the name .zoom, so you can subsequently unbind the zoom behavior as follows: selection.on(\".zoom\", null); To disable just wheel-driven zooming (say to not interfere with native scrolling), you can remove the zoom behavior’s wheel event listener after applying the zoom behavior to the selection: selection .call(zoom) .on(\"wheel.zoom\", null); Alternatively, use zoom.filter for greater control over which events can initiate zoom gestures. Applying the zoom behavior also sets the -webkit-tap-highlight-color style to transparent, disabling the tap highlight on iOS. If you want a different tap highlight color, remove or re-apply this style after applying the drag behavior. # zoom.transform(selection, transform[, point]) · Source, Examples If selection is a selection, sets the current zoom transform of the selected elements to the specified transform, instantaneously emitting start, zoom and end events. If selection is a transition, defines a “zoom” tween to the specified transform using d3.interpolateZoom, emitting a start event when the transition starts, zoom events for each tick of the transition, and then an end event when the transition ends (or is interrupted). The transition will attempt to minimize the visual movement around the specified point; if the point is not specified, it defaults to the center of the viewport extent. The transform may be specified either as a zoom transform or as a function that returns a zoom transform; similarly, the point may be specified either as a two-element array [x, y] or a function that returns such an array. If a function, it is invoked for each selected element, being passed the current event (event) and datum d, with the this context as the current DOM element. This function is typically not invoked directly, and is instead invoked via selection.call or transition.call. For example, to reset the zoom transform to the identity transform instantaneously: selection.call(zoom.transform, d3.zoomIdentity); To smoothly reset the zoom transform to the identity transform over 750 milliseconds: selection.transition().duration(750).call(zoom.transform, d3.zoomIdentity); This method requires that you specify the new zoom transform completely, and does not enforce the defined scale extent and translate extent, if any. To derive a new transform from the existing transform, and to enforce the scale and translate extents, see the convenience methods zoom.translateBy, zoom.scaleBy and zoom.scaleTo. # zoom.translateBy(selection, x, y) · Source If selection is a selection, translates the current zoom transform of the selected elements by x and y, such that the new tx1 = tx0 + kx and ty1 = ty0 + ky. If selection is a transition, defines a “zoom” tween translating the current transform. This method is a convenience method for zoom.transform. The x and y translation amounts may be specified either as numbers or as functions that return numbers. If a function, it is invoked for each selected element, being passed the current datum d and index i, with the this context as the current DOM element. # zoom.translateTo(selection, x, y[, p]) · Source If selection is a selection, translates the current zoom transform of the selected elements such that the given position ⟨x,y⟩ appears at given point p. The new tx = px - kx and ty = py - ky. If p is not specified, it defaults to the center of the viewport extent. If selection is a transition, defines a “zoom” tween translating the current transform. This method is a convenience method for zoom.transform. The x and y coordinates may be specified either as numbers or as functions that returns numbers; similarly the p point may be specified either as a two-element array [px,py] or a function. If a function, it is invoked for each selected element, being passed the current datum d and index i, with the this context as the current DOM element. # zoom.scaleBy(selection, k[, p]) · Source If selection is a selection, scales the current zoom transform of the selected elements by k, such that the new k₁ = k₀k. The reference point p does move. If p is not specified, it defaults to the center of the viewport extent. If selection is a transition, defines a “zoom” tween translating the current transform. This method is a convenience method for zoom.transform. The k scale factor may be specified either as a number or a function that returns a number; similarly the p point may be specified either as a two-element array [px,py] or a function. If a function, it is invoked for each selected element, being passed the current datum d and index i, with the this context as the current DOM element. # zoom.scaleTo(selection, k[, p]) · Source If selection is a selection, scales the current zoom transform of the selected elements to k, such that the new k₁ = k. The reference point p does move. If p is not specified, it defaults to the center of the viewport extent. If selection is a transition, defines a “zoom” tween translating the current transform. This method is a convenience method for zoom.transform. The k scale factor may be specified either as a number or a function that returns a number; similarly the p point may be specified either as a two-element array [px,py] or a function. If a function, it is invoked for each selected element, being passed the current datum d and index i, with the this context as the current DOM element. # zoom.constrain([constrain]) · Source If constrain is specified, sets the transform constraint function to the specified function and returns the zoom behavior. If constrain is not specified, returns the current constraint function, which defaults to: function constrain(transform, extent, translateExtent) { var dx0 = transform.invertX(extent[0][0]) - translateExtent[0][0], dx1 = transform.invertX(extent[1][0]) - translateExtent[1][0], dy0 = transform.invertY(extent[0][1]) - translateExtent[0][1], dy1 = transform.invertY(extent[1][1]) - translateExtent[1][1]; return transform.translate( dx1 > dx0 ? (dx0 + dx1) / 2 : Math.min(0, dx0) || Math.max(0, dx1), dy1 > dy0 ? (dy0 + dy1) / 2 : Math.min(0, dy0) || Math.max(0, dy1) ); } The constraint function must return a transform given the current transform, viewport extent and translate extent. The default implementation attempts to ensure that the viewport extent does not go outside the translate extent. # zoom.filter([filter]) · Source If filter is specified, sets the filter to the specified function and returns the zoom behavior. If filter is not specified, returns the current filter, which defaults to: function filter(event) { return (!event.ctrlKey || event.type === 'wheel') && !event.button; } The filter is passed the current event (event) and datum d, with the this context as the current DOM element. If the filter returns falsey, the initiating event is ignored and no zoom gestures are started. Thus, the filter determines which input events are ignored. The default filter ignores mousedown events on secondary buttons, since those buttons are typically intended for other purposes, such as the context menu. # zoom.touchable([touchable]) · Source If touchable is specified, sets the touch support detector to the specified function and returns the zoom behavior. If touchable is not specified, returns the current touch support detector, which defaults to: function touchable() { return navigator.maxTouchPoints || (\"ontouchstart\" in this); } Touch event listeners are only registered if the detector returns truthy for the corresponding element when the zoom behavior is applied. The default detector works well for most browsers that are capable of touch input, but not all; Chrome’s mobile device emulator, for example, fails detection. # zoom.wheelDelta([delta]) · Source If delta is specified, sets the wheel delta function to the specified function and returns the zoom behavior. If delta is not specified, returns the current wheel delta function, which defaults to: function wheelDelta(event) { return -event.deltaY * (event.deltaMode === 1 ? 0.05 : event.deltaMode ? 1 : 0.002); } The value Δ returned by the wheel delta function determines the amount of scaling applied in response to a WheelEvent. The scale factor transform.k is multiplied by 2Δ; for example, a Δ of +1 doubles the scale factor, Δ of -1 halves the scale factor. # zoom.extent([extent]) · Source If extent is specified, sets the viewport extent to the specified array of points [[x0, y0], [x1, y1]], where [x0, y0] is the top-left corner of the viewport and [x1, y1] is the bottom-right corner of the viewport, and returns this zoom behavior. The extent may also be specified as a function which returns such an array; if a function, it is invoked for each selected element, being passed the current datum d, with the this context as the current DOM element. If extent is not specified, returns the current extent accessor, which defaults to [[0, 0], [width, height]] where width is the client width of the element and height is its client height; for SVG elements, the nearest ancestor SVG element’s viewBox, or width and height attributes, are used. Alternatively, consider using element.getBoundingClientRect. The viewport extent affects several functions: the center of the viewport remains fixed during changes by zoom.scaleBy and zoom.scaleTo; the viewport center and dimensions affect the path chosen by d3.interpolateZoom; and the viewport extent is needed to enforce the optional translate extent. # zoom.scaleExtent([extent]) · Source If extent is specified, sets the scale extent to the specified array of numbers [k0, k1] where k0 is the minimum allowed scale factor and k1 is the maximum allowed scale factor, and returns this zoom behavior. If extent is not specified, returns the current scale extent, which defaults to [0, ∞]. The scale extent restricts zooming in and out. It is enforced on interaction and when using zoom.scaleBy, zoom.scaleTo and zoom.translateBy; however, it is not enforced when using zoom.transform to set the transform explicitly. If the user tries to zoom by wheeling when already at the corresponding limit of the scale extent, the wheel events will be ignored and not initiate a zoom gesture. This allows the user to scroll down past a zoomable area after zooming in, or to scroll up after zooming out. If you would prefer to always prevent scrolling on wheel input regardless of the scale extent, register a wheel event listener to prevent the browser default behavior: selection .call(zoom) .on(\"wheel\", event => event.preventDefault()); # zoom.translateExtent([extent]) · Source If extent is specified, sets the translate extent to the specified array of points [[x0, y0], [x1, y1]], where [x0, y0] is the top-left corner of the world and [x1, y1] is the bottom-right corner of the world, and returns this zoom behavior. If extent is not specified, returns the current translate extent, which defaults to [[-∞, -∞], [+∞, +∞]]. The translate extent restricts panning, and may cause translation on zoom out. It is enforced on interaction and when using zoom.scaleBy, zoom.scaleTo and zoom.translateBy; however, it is not enforced when using zoom.transform to set the transform explicitly. # zoom.clickDistance([distance]) · Source If distance is specified, sets the maximum distance that the mouse can move between mousedown and mouseup that will trigger a subsequent click event. If at any point between mousedown and mouseup the mouse is greater than or equal to distance from its position on mousedown, the click event following mouseup will be suppressed. If distance is not specified, returns the current distance threshold, which defaults to zero. The distance threshold is measured in client coordinates (event.clientX and event.clientY). # zoom.tapDistance([distance]) · Source If distance is specified, sets the maximum distance that a double-tap gesture can move between first touchstart and second touchend that will trigger a subsequent double-click event. If distance is not specified, returns the current distance threshold, which defaults to 10. The distance threshold is measured in client coordinates (event.clientX and event.clientY). # zoom.duration([duration]) · Source If duration is specified, sets the duration for zoom transitions on double-click and double-tap to the specified number of milliseconds and returns the zoom behavior. If duration is not specified, returns the current duration, which defaults to 250 milliseconds. If the duration is not greater than zero, double-click and -tap trigger instantaneous changes to the zoom transform rather than initiating smooth transitions. To disable double-click and double-tap transitions, you can remove the zoom behavior’s dblclick event listener after applying the zoom behavior to the selection: selection .call(zoom) .on(\"dblclick.zoom\", null); # zoom.interpolate([interpolate]) · Source If interpolate is specified, sets the interpolation factory for zoom transitions to the specified function. If interpolate is not specified, returns the current interpolation factory, which defaults to d3.interpolateZoom to implement smooth zooming. To apply direct interpolation between two views, try d3.interpolate instead. # zoom.on(typenames[, listener]) · Source If listener is specified, sets the event listener for the specified typenames and returns the zoom behavior. If an event listener was already registered for the same type and name, the existing listener is removed before the new listener is added. If listener is null, removes the current event listeners for the specified typenames, if any. If listener is not specified, returns the first currently-assigned listener matching the specified typenames, if any. When a specified event is dispatched, each listener will be invoked with the same context and arguments as selection.on listeners: the current event (event) and datum d, with the this context as the current DOM element. The typenames is a string containing one or more typename separated by whitespace. Each typename is a type, optionally followed by a period (.) and a name, such as zoom.foo and zoom.bar; the name allows multiple listeners to be registered for the same type. The type must be one of the following: start - after zooming begins (such as on mousedown). zoom - after a change to the zoom transform (such as on mousemove). end - after zooming ends (such as on mouseup ). See dispatch.on for more. Zoom Events When a zoom event listener is invoked, it receives the current zoom event as a first argument. The event object exposes several fields: event.target - the associated zoom behavior. event.type - the string “start”, “zoom” or “end”; see zoom.on. event.transform - the current zoom transform. event.sourceEvent - the underlying input event, such as mousemove or touchmove. Zoom Transforms The zoom behavior stores the zoom state on the element to which the zoom behavior was applied, not on the zoom behavior itself. This is because the zoom behavior can be applied to many elements simultaneously, and each element can be zoomed independently. The zoom state can change either on user interaction or programmatically via zoom.transform. To retrieve the zoom state, use event.transform on the current zoom event within a zoom event listener (see zoom.on), or use d3.zoomTransform for a given node. The latter is particularly useful for modifying the zoom state programmatically, say to implement buttons for zooming in and out. # d3.zoomTransform(node) · Source Returns the current transform for the specified node. Note that node should typically be a DOM element, not a selection. (A selection may consist of multiple nodes, in different states, and this function only returns a single transform.) If you have a selection, call selection.node first: var transform = d3.zoomTransform(selection.node()); In the context of an event listener, the node is typically the element that received the input event (which should be equal to event.transform), this: var transform = d3.zoomTransform(this); Internally, an element’s transform is stored as element.__zoom; however, you should use this method rather than accessing it directly. If the given node has no defined transform, returns the transform of the closest ancestor, or if none exists, the identity transformation. The returned transform represents a two-dimensional transformation matrix of the form: k 0 tx 0 k ty 0 0 1 (This matrix is capable of representing only scale and translation; a future release may also allow rotation, though this would probably not be a backwards-compatible change.) The position ⟨x,y⟩ is transformed to ⟨xk + tx,yk + ty⟩. The transform object exposes the following properties: transform.x - the translation amount tx along the x-axis. transform.y - the translation amount ty along the y-axis. transform.k - the scale factor k. These properties should be considered read-only; instead of mutating a transform, use transform.scale and transform.translate to derive a new transform. Also see zoom.scaleBy, zoom.scaleTo and zoom.translateBy for convenience methods on the zoom behavior. To create a transform with a given k, tx, and ty: var t = d3.zoomIdentity.translate(x, y).scale(k); To apply the transformation to a Canvas 2D context, use context.translate followed by context.scale: context.translate(transform.x, transform.y); context.scale(transform.k, transform.k); Similarly, to apply the transformation to HTML elements via CSS: div.style(\"transform\", \"translate(\" + transform.x + \"px,\" + transform.y + \"px) scale(\" + transform.k + \")\"); div.style(\"transform-origin\", \"0 0\"); To apply the transformation to SVG: g.attr(\"transform\", \"translate(\" + transform.x + \",\" + transform.y + \") scale(\" + transform.k + \")\"); Or more simply, taking advantage of transform.toString: g.attr(\"transform\", transform); Note that the order of transformations matters! The translate must be applied before the scale. # transform.scale(k) · Source Returns a transform whose scale k₁ is equal to k₀k, where k₀ is this transform’s scale. # transform.translate(x, y) · Source Returns a transform whose translation tx1 and ty1 is equal to tx0 + tk x and ty0 + tk y, where tx0 and ty0 is this transform’s translation and tk is this transform’s scale. # transform.apply(point) · Source Returns the transformation of the specified point which is a two-element array of numbers [x, y]. The returned point is equal to [xk + tx, yk + ty]. # transform.applyX(x) · Source Returns the transformation of the specified x-coordinate, xk + tx. # transform.applyY(y) · Source Returns the transformation of the specified y-coordinate, yk + ty. # transform.invert(point) · Source Returns the inverse transformation of the specified point which is a two-element array of numbers [x, y]. The returned point is equal to [(x - tx) / k, (y - ty) / k]. # transform.invertX(x) · Source Returns the inverse transformation of the specified x-coordinate, (x - tx) / k. # transform.invertY(y) · Source Returns the inverse transformation of the specified y-coordinate, (y - ty) / k. # transform.rescaleX(x) · Source Returns a copy of the continuous scale x whose domain is transformed. This is implemented by first applying the inverse x-transform on the scale’s range, and then applying the inverse scale to compute the corresponding domain: function rescaleX(x) { var range = x.range().map(transform.invertX, transform), domain = range.map(x.invert, x); return x.copy().domain(domain); } The scale x must use d3.interpolateNumber; do not use continuous.rangeRound as this reduces the accuracy of continuous.invert and can lead to an inaccurate rescaled domain. This method does not modify the input scale x; x thus represents the untransformed scale, while the returned scale represents its transformed view. # transform.rescaleY(y) · Source Returns a copy of the continuous scale y whose domain is transformed. This is implemented by first applying the inverse y-transform on the scale’s range, and then applying the inverse scale to compute the corresponding domain: function rescaleY(y) { var range = y.range().map(transform.invertY, transform), domain = range.map(y.invert, y); return y.copy().domain(domain); } The scale y must use d3.interpolateNumber; do not use continuous.rangeRound as this reduces the accuracy of continuous.invert and can lead to an inaccurate rescaled domain. This method does not modify the input scale y; y thus represents the untransformed scale, while the returned scale represents its transformed view. # transform.toString() · Source Returns a string representing the SVG transform corresponding to this transform. Implemented as: function toString() { return \"translate(\" + this.x + \",\" + this.y + \") scale(\" + this.k + \")\"; } # d3.zoomIdentity · Source The identity transform, where k = 1, tx = ty = 0."
  },
  "src/frontend/app-client/node_modules/daisyui/README.html": {
    "href": "src/frontend/app-client/node_modules/daisyui/README.html",
    "title": "daisyUI 5",
    "summary": "The most popular, free and open-source component library for Tailwind CSS daisyUI 5 \uD83C\uDF3C Official website → \uD83C\uDF3C See all components → \uD83C\uDF3C How to use →"
  },
  "src/frontend/app-client/node_modules/date-fns/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/date-fns/CHANGELOG.html",
    "title": "Change Log",
    "summary": "Change Log All notable changes to this project will be documented in this file. This project adheres to Semantic Versioning. This change log follows the format documented in Keep a CHANGELOG. v4.1.0 - 2024-09-17 This release adds time zone support to format functions (that I somehow missed when working on the feature) and fixes a few bugs. Make sure also upgrade TZDate to v1.0.2 as it includes a bunch of critical bug fixes. Fixed Fixed internal constructFrom throwing an exception on null arguments. While null isn't allowed, the functions should rather return Invalid Date or NaN in such cases. See #3885. Added Added missing time zone support to format, formatISO, formatISO9075, formatRelative and formatRFC3339. See #3886. v4.0.0 - 2024-09-16 I have great news! First, ten years after its release, date-fns finally gets first-class time zone support. Another great news is that there aren't many breaking changes in this release. All of them are type-related and will affect only those explicitly using internal date-fns types. Finally, it has been less than a year since the last major release, which is an improvement over the previous four years between v2 and v3. I plan on keeping the pace and minimizing breaking changes moving forward. Read more about the release in the announcement blog post. - Sasha @kossnocorp Added Added time zones support via @date-fns/tz's TZDate class and tz helper function. See its README for the details about the API. All relevant functions now accept the context in option, which allows to specify the time zone to make the calculations in. If the function also returns a date, it will be in the specified time zone: import { addDays, startOfDay } from \"date-fns\"; import { tz } from \"@date-fns/tz\"; startOfDay(addDays(Date.now(), 5, { in: tz(\"Asia/Singapore\") })); //=> \"2024-09-16T00:00:00.000+08:00\" In the example, addDays will get the current date and time in Singapore and add 5 days to it. startOfDay will inherit the date type and return the start of the day in Singapore. Changed The function arguments, as well as Interval's start and end, now can be of different types, allowing you to mix UTCDate, TZDate, Date, and other extensions, as well as primitives (strings and numbers). The functions will normalize these values, make calculations, and return the result in the same type, preventing any bugs caused by the discrepancy. If passed, the type will be inferred from the context in option or the first encountered argument object type. The Interval's start and end will be considered separately, starting from start. In the given example, the result will be in the TZDate as the first argument is a number, and the start takes precedence over the end. clamp(Date.now(), { start: new TZDate(start, \"Asia/Singapore\"), end: new UTCDate(), }); //=> TZDate BREAKING: This release contains a bunch of types changes that should not affect the library's expected usage. The changes are primarily internal and nuanced, so rather than listing them here, I recommend you running the type checker after the upgrade. If there are unfixable problems, please open an issue. BREAKING: The package now is ESM-first. The CommonJS is still support and It should not affect most users, but it might break in certains environments. If you encounter any issues, please report them. Fixed Fixed CDN build compatibility with jQuery and other tools that expose $ by properly wrapping the code in an IIFE. v3.6.0 - 2024-03-18 On this release worked @kossnocorp and @world1dan. Also, thanks to @seated for sponsoring me. Fixed Fixed weeks in the Belarisuan locale's formatDistance. Added Added CDN versions of modules compatible with older browsers. See the CDN guide. v3.5.0 - 2024-03-15 Kudos to @fturmel, @kossnocorp, @makstyle119, @tan75, @marcreichel, @tareknatsheh and @audunru for working on the release. Also, thanks to @seated for sponsoring me. Fixed Fixed functions that use current date internally and made them work with date extensions like UTCDate. Fixed daysToWeeks returning negative 0. Fixed German grammar for the \"half a minute\" string. Added Added the Northern Sámi (se) locale. Added the constructNow function that creates the current date using the passed reference date's constructor. v3.4.0 - 2024-03-11 Kudos to @kossnocorp, @sakamossan and @Revan99 for working on the release. Also, thanks to @seated for sponsoring me. Added Added roundToNearestHours function. Added Central Kurdish (ckb) locale. v3.3.1 - 2024-01-22 Kudos to @kossnocorp and @fturmel for working on the release. Fixed Fixed DST issue in getOverlappingDaysInIntervals, resulting in an inconsistent number of days returned for intervals starting and ending in different DST periods. Fixed functions incorrectly using trunc instead of round. The bug was introduced in v3.3.0. The affected functions: differenceInCalendarDays, differenceInCalendarISOWeeks, differenceInCalendarWeeks, getISOWeek, getWeek, and getISOWeeksInYear. v3.3.0 - 2024-01-20 On this release worked @kossnocorp, @TheKvikk, @fturmel and @ckcherry23. Fixed Fixed the bug in getOverlappingDaysInIntervals caused by incorrect sorting of interval components that led to 0 for timestamps of different lengths. Fixed bugs when working with negative numbers caused by using Math.floor (-1.1 → -2) instead of Math.trunc (-1.1 → -1). Most of the conversion functions (i.e., hoursToMinutes) were affected when passing some negative fractional input. Also, some other functions that could be possibly affected by unfortunate timezone/date combinations were fixed. The functions that were affected: format, parse, getUnixTime, daysToWeeks, hoursToMilliseconds, hoursToMinutes, hoursToSeconds, milliseconds, minutesToMilliseconds, millisecondsToMinutes, monthsToYears, millisecondsToHours, millisecondsToSeconds, minutesToHours, minutesToSeconds, yearsToQuarters, yearsToMonths, yearsToDays, weeksToDays, secondsToMinutes, secondsToHours, quartersToYears, quartersToMonths and monthsToQuarters. Fixed the Czech locale's formatDistance to include 1 in formatDistance. Fixed differenceInSeconds and other functions relying on rounding options that can produce a negative 0. Added a preprocessor to the locales API, enabling fixing a long-standing bug in the French locale. (#1391) Added missing yearsToDays to the FP submodule. Made functions using rounding methods always return 0 instead of -0. Added Added format alias formatDate with corresponding FormatDateOptions interface. v3.2.0 - 2024-01-09 This release is brought to you by @kossnocorp, @fturmel, @grossbart, @MelvinVermeer, and @jcarstairs-scottlogic. Fixed Fixed types compatibility with Lodash's flow and fp-ts's pipe. (#3641) Fixed inconsistent behavior of roundToNearestMinutes. Added Added exports of format, lightFormat, and parse internals that enable 3rd-parties to consume those. v3.1.0 - 2024-01-05 This release is brought to you by @kossnocorp, @makstyle119 and @dmgawel. Fixed Fixed the plural form of weeks in Swedish. Added Added yearsToDays function. Added warning about using protected tokens like Y or D without passing a corresponding option. See #2950. v3.0.6 - 2023-12-22 On this release worked @imwh0im, @jamcry and @tyrw. Fixed Fixed bug in areIntervalsOverlapping caused by incorrect sorting (#3614) v3.0.5 - 2023-12-21 This release is brought to you by @goku4199. Fixed Fixed internal toDate not processing string arguments properly v3.0.4 - 2023-12-21 This release is brought to you by @kossnocorp. Fixed Fixed isWithinInterval bug caused by incorrectly sorting dates (#3623). v3.0.3 - 2023-12-21 Fixed Rolled back pointing ESM types to the same d.ts files. Instead now it copies the content to avoid the Masquerading as CJS problem reported by \"Are the types wrong?\". v3.0.2 - 2023-12-21 Fixed Fixed yet another issue caused by ESM types by pointing to the same d.ts files. Added package.json to exports to provide access to tooling. Fixed TypeScript 5.4 build break by using the latest type names. v3.0.1 - 2023-12-20 Fixed Fixed an error in certain environments caused by d.mts files exporting only types. v3.0.0 - 2023-12-18 Changed BREAKING: date-fns is now a dual-package with the support of both ESM and CommonJS. The files exports are now explicitly in the package.json. The ESM files now have .mjs extension. BREAKING: The package now has a flat structure, meaning functions are now named node_modules/date-fns/add.mjs, locales are node_modules/date-fns/locale/enUS.mjs, etc. BREAKING: Now all file content’s exported via named exports instead of export default, which will require change direct imports i.e. const addDays = require(‘date-fns/addDays’) to const { addDays } = require(‘date-fns/addDays’). BREAKING: TypeScript types are now completely rewritten, check out the d.ts files for more information. BREAKING: constants now is not exported via the index, so to import one use import { daysInYear } from \"date-fns/constants\";. It improves compatibility with setups that modularize imports like Next.js. BREAKING: Functions now don’t check the number of passed arguments, delegating this task to type checkers. The functions are now slimmer because of this. BREAKING The arguments are not explicitly converted to the target types. Instead, they are passed as is, delegating this task to type checkers. BREAKING: Functions that accept Interval arguments now do not throw an error if the start is before the end and handle it as a negative interval. If one of the properties in an Invalid Date, these functions also do not throw and handle them as invalid intervals. areIntervalsOverlapping normalize intervals before comparison, so { start: a, end: b } is practically equivalent to { start: b, end: a }. When comparing intervals with one of the properties being Invalid Date, the function will return false unless the others are valid and equal, given the inclusive option is passed. Otherwise, and when even one of the intervals has both properties invalid, the function will always return false. getOverlappingDaysInIntervals now normalizes intervals before comparison, so { start: a, end: b } is practically equivalent to { start: b, end: a }. If any of the intervals’ properties is an Invalid Date, the function will always return 0. isWithinInterval now normalizes intervals before comparison, so { start: a, end: b } is practically equivalent to { start: b, end: a }. If any of the intervals’ properties is an Invalid Date, the function will always return false. intervalToDuration now returns negative durations for negative intervals. If one or both of the interval properties are invalid, the function will return an empty object. The eachXOfInterval functions (eachDayOfInterval, eachHourOfInterval, eachMinuteOfInterval, eachMonthOfInterval, eachWeekendOfInterval, eachWeekendOfMonth, eachWeekendOfYear, eachWeekOfInterval, eachYearOfInterval) now return a reversed array if the passed interval’s start is after the end. Invalid properties will result in an empty array. Functions that accept the step option now also allow negative, 0, and NaN values and return reversed results if the step is negative and an empty array otherwise. BREAKING: intervalToDuration now skips 0 values in the resulting duration, resulting in more compact objects with only relevant properties. BREAKING: roundToNearestMinutes now returns Invalid Date instead of throwing an error when nearestTo option is less than 1 or more than 30. BREAKING: IE is no longer supported. BREAKING: Now all functions use Math.trunc rounding method where rounding is required. The behavior is configurable on a per-function basis. BREAKING: Undocumented onlyNumeric option was removed from nn and sv locales. If you relied on it, please contact me. BREAKING: Flow is not supported anymore. If you relied on it, please contact me. BREAKING: The locales now use regular functions instead of the UTC version, which should not break any code unless you used locales directly. Added All functions that accept date arguments now also accept strings. All functions now export options interfaces. Now functions allow passing custom Date extensions like UTCDate. They will detect and use the arguments constructor to generate the result of the same class. eachMonthOfInterval, eachQuarterOfInterval, eachWeekOfInterval, and eachYearOfInterval now accept the step option like most of the eachXOfInterval functions. A new interval function that validates interval, emulating the v2 interval functions behavior. differenceInX functions now accept options and allow setting up roundingMethod that configures how the result is rounded. Math.trunc is the default method. v2.30.0 Kudos to @kossnocorp and @Andarist for working on the release. Changes Fixed increased build size after enabling compatibility with older browsers in the previous release. This was done by adding @babel/runtime as a dependency. See more details. v2.29.3 - 2022-09-13 This release is prepared by our own @leshakoss. Fixed Fixed Ukrainian (uk) locale grammar for formatDistance. Improved browser compatibility by transforming the code with @babel/preset-env. v2.29.2 - 2022-08-18 This release is brought to you by @nopears, @vadimpopa and @leshakoss. Fixed Fixed sv locale abbreviated months matcher. Fixed uk locale abbreviated months matcher. Fixed a breaking change in intervalToDuration by removing a recently introduced RangeError. v2.29.1 - 2022-08-18 Thanks to @fturmel for working on the release. Fixed Fixed TypeScript and flow types for daysInYear constant. v2.29.0 - 2022-07-22 On this release worked @tan75, @kossnocorp, @nopears, @Balastrong, @cpapazoglou, @dovca, @aliasgar55, @tomchentw, @JuanM04, @alexandresaura, @fturmel, @aezell, @andersravn, @TiagoPortfolio, @SukkaW, @Zebreus, @aviskarkc10, @maic66, @a-korzun, @Mejans, @davidspiess, @alexgul1, @matroskin062, @undecaf, @mprovenc, @jooola and @leshakoss. Added Added intlFormatDistance function`. Added setDefaultOptions and getDefaultOptions functions that allow you to set default default locale, weekStartsOn and firstWeekContainsDate. Added roundingMethod option to roundToNearestMinutes. Added Swiss Italian locale (it-CH). Added Occitan (oc) locale. (#2061) Added Belarusian Classic (be-tarask) locale. Fixed Fixed Azerbaijani (az) locale for formatDistance. Fixed Czech (cs) locale for parse. Fixed TypeScript types for constants. Fixed long formatters in the South African English locale (en-ZA). Fixed a typo in the Icelandic locale (is) for format. Fixed weekday format for formatRelative in the Portuguese locale (pt). Fixed intervalToDuration being off by 1 day sometimes. Fixed ordinal number formatting in Italian locale (it). Fixed issue parsing months in Croatian (hr), Georgian (ka) and Serbian (sr and sr-Latn) locales. Changed Replaced git.io links with full URLs in error messages. Internal: removed \"v2.0.0 breaking changes\" section from individual function docs v2.28.0 - 2021-12-28 Kudos to @tan75, @fturmel, @arcanar7, @jeffjose, @helmut-lang, @zrev2220, @jooola, @minitesh, @cowboy-bebug, @mesqueeb, @JuanM04, @zhirzh, @damon02 and @leshakoss for working on the release. Added Added West Frisian (fy) locale. Added Uzbek Cyrillic locale (uz-Cyrl). Fixed add the missing accent mark for Saturday in Spanish locale (es) for format. allowed K token to be used with a or b in parse. v2.27.0 - 2021-11-30 Kudos to @tan75, @hg-pyun, @07akioni, @razvanmitre, @Haqverdi, @pgcalixto, @janziemba, @fturmel, @JuanM04, @zhirzh, @seanghay, @bulutfatih, @nodeadtree, @cHaLkdusT, @a-korzun, @fishmandev, @wingclover, @Zacharias3690, @kossnocorp and @leshakoss for working on the release. Fixed Fixed translation for quarters in format in Chinese Simplified locale (zh-CN). Fixed P token in format for Romanian locale (ro). Fixed era and month formatters in Azerbaijani locale (az). Fixed formatRelative patterns in Georgian locale (ka). Fixed regular expressions for parse in Estonian locale (er). Fixed the format of zeros in formatDuration in Czech locale (cs). Fixed ordinal formatting for years, weeks, hours, minutes and seconds in fr, fr-CA and fr-CH locales. Fixed constants not having proper TypeScript and Flow types. Fixed translation for Monday in Turkish locale (tr). Fixed eachMinuteOfInterval not handling intervals less than a minute correctly. Fixed flow types for closestTo and closestIndexTo. Added Added Khmer locale (km). v2.26.0 - 2021-11-19 Thanks to @kossnocorp, @leshakoss, @tan75, @gaplo, @AbdAllahAbdElFattah13, @fturmel, @kentaro84207, @V-Gutierrez, @atefBB, @jhonatanmacazana, @zhirzh, @Haqverdi, @mandaputtra, @micnic and @rikkalo for working on the release. Fixed Fixed formatRelative format for lastWeek in Spanish locale. Fixed translation for October in Hindi locale. Fixed Azerbaijani locale to use correct era matchers for parse. Added the functions that use weekStartsOn and firstWeekContainsDate that were missing from the Locale documentation page. Changed Changed abbreviation for August from \"Ags\" to \"Agt\" in Indonesian locale. Added Added Irish English locale (en-IE). Added Arabic locale (ar). (#1670) Added Hong Kong Traditional Chinese locale (zh-HK). (#2684) Added Egyptian Arabic locale (ar-EG). v2.25.0 - 2021-10-05 This release is brought to you by @kossnocorp, @gierschv, @fturmel, @redbmk, @mprovenc, @artyom-ivanov and @tan75. Added Added Japanese Hiragana locale (ja-Hira). Added standalone months support to de and de-AT locales. v2.24.0 - 2021-09-17 Kudos to Sasha Koss, Lucas Silva, Jan Ziemba, Anastasia Kobzar, Deepak Gupta, Jonas L, Kentaro Suzuki, Koussay Haj Kacem, fturmel, Tan75 and Adriaan Callaerts for working on the release. Fixed Fixed an edge case in the Slovak locale caused by unescaped character. (#2083) Changed Used 1 instead of ein for German formatDuration to make it consistent with other locales and formats. (#2505) Made Norwegian formatDuration consistent with other locales by using numeric representation instead of written. (#2469) Use the word \"sekunda\" instead of \"vteřina\" for second in the Czech locale. Made Flemish short date format corresponds to the Flemish government. Added Added roundingMethod option to differenceInHours, differenceInMinutes, differenceInQuarters, differenceInSeconds and differenceInWeeks with trunc as the default method. (#2555) Added new functions: previousDay, previousMonday, previousTuesday, previousWednesday, previousThursday, previousFriday, previousSaturday and previousSunday. v2.23.0 - 2021-07-23 Thanks to Liam Tait, fturmel, Takuya Uehara, Branislav Lazic, Seyyed Morteza Moosavi, Felipe Armoni, Sasha Koss, Michael Mok, Tan75 and Maxim Topciu for working on the release. Changed Improved nextDay performance by roughly 50%. Added more ordinal formatting to the Japanese locale. Added Added a new clamp function that allows to bound a date to an interval. Added Bosnian locale (bs). Allowed passing undefined in the duration to add and sub functions. v2.22.1 - 2021-05-28 Thanks to Sasha Koss for working on the release. Fixed Fixed constant typings. (#2491) v2.22.0 - 2021-05-28 Sasha Koss, Lucas Silva, Lay, jwbth, fturmel, Tan75 and Anastasia Kobzar worked on this release. Fixed Fixed Taiwanese locale to use traditional Chinese and removed unnecessary spaces. Fixed Russian locale to use correct long formats. Added Added 18 new conversion functions: daysToWeeks hoursToMilliseconds hoursToMinutes hoursToSeconds millisecondsToHours millisecondsToMinutes millisecondsToSeconds minutesToHours minutesToMilliseconds minutesToSeconds monthsToQuarters monthsToYears quartersToMonths quartersToYears secondsToHours secondsToMilliseconds secondsToMinutes weeksToDays yearsToMonths yearsToQuarters v2.21.3 - 2021-05-08 This release is brought to you by Maxim Topciu. Fixed Fixed IE11 support by babelifing the shorthand properties. v2.21.2 - 2021-05-05 Kudos to Aleksei Korzun, Maxim Topciu, Jonas L, Mohammad ali Ali panah and Tan75 for working on the release. Fixed differenceInBusinessDays now returns NaN instead of Invalid Date when an invalid argument is passed to the function. Fixed weekStartsOn in Persian locale. v2.21.1 - 2021-04-15 Thanks to Sasha Koss for working on the release. Fixed Fixed a breaking change introduced by using modern default argument value syntax (see https://github.com/Hacker0x01/react-datepicker/issues/2870). v2.21.0 - 2021-04-14 This release is brought to you by Aleksei Korzun, Tan75, Rubens Mariuzzo, Christoph Stenglein and Clément Tamisier. Fixed Made formatDistanceStrict return 12 months instead of 1 year when unit: 'month'. Added Added Haitian Creole (ht) locale. Added Austrian German (de-AT) locale. v2.20.3 - 2021-04-13 Kudos to fturmel for working on the release. Fixed Fixed broken tree-shaking caused by missing links to corresponding ESM. (#2207) v2.20.2 - 2021-04-12 Kudos to Maxim Topciu for working on the release. Fixed Fixed IE11 incompatibility caused by the usage of spread syntax. (#2408) v2.20.1 - 2021-04-09 This release is brought to you by Sasha Koss and Tan75. Fixed Fixed isDate Flow typings that we broke in v2.20.0. v2.20.0 - 2021-04-08 This release is brought to you by Sasha Koss, Maxim Topciu, tu4mo, Tan75, Ardit Dine, Carl Rosell, Roman Mahotskyi, Mateusz Krzak, fgottschalk, Anastasia Kobzar, Bilguun Ochirbat, Lesha Koss, YuLe and guyroberts21. Fixed Made formatDistanceStrict and formatDistanceToNowStrict always return 1 year instead of 12 months. (#2388) Fixed nextDay, nextMonday and nextTuesday missing in exports and type definitions. (#2325) Fixed a DST bug in formatDistanceStrict. (#2307) Added Added new eachMinuteOfInterval function. Added Albanian (sq) locale Added Mongolian (mn) locale Added nextWednesday, nextThursday, nextFriday, nextSaturday and nextSunday. v2.19.0 - 2021-03-05 Tan75 worked on this release. Fixed Assigned the correct firstWeekContainsDate value (4) for the French locale. (#2148) Fixed torsdag abbreviation in the Swedish locale. Fixed a bug in differenceInMonths and intervalToDuration that occurs when dealing with the 28th of February. (#2255) Added Added new functions: nextDay, nextMonday and nextTuesday that allows getting the next day of the week, Monday or Tuesday respectively. v2.18.0 - 2021-03-01 Thanks to Tan75 and Lesha Koss. Fixed Fixed documentation missing for intlFormat. (#2258) Fixed date formats in the Latvian locale. (#2202) Added Added support of positive and negative offsets in parseJSON. (#2149) [2.17.0] - 2021-02-05 Kudos to @shaykav, @davidgape89, @rikkalo, @tan75, @talgautb, @owenl131, @kylesezhi, @inigoiparragirre, @gius, @Endeauvirr and @frankyston. Fixed Fixed Russian locale parsing issue. Fixed differenceInMonths for edge cases, such as the end of February dates. Fixed suffixes for the Kazakh locale. Fixed formatDuration week translation in pt and pt-BR locales. Made Japanese locale to use the correct value for the start of the week. Adjusted date formats in the Basque locale. Fixed the short and medium date formats in the Czech locale. Adjusted the Polish translations of formatDistance. Fixed the week's abbreviations in the Brazilian Portuguese. Added Added intlFormat a lightweight formatting function that uses Intl API. Eventually, it will become the default formatting function, so it's highly recommended for new code. Added en-ZA locale. Added an ability to format lowercase am/pm with aaa and bbb tokens. Added ordinal formatting for Japanese year values. 2.16.1 - 2020-07-31 Kudos to @aleksaps, @leedriscoll and @BanForFun for pull-requests! Fixed Fixed a typo in Scottish Gaelic (gd) locale. Fixed typos in Serbian Latin locale. Fixed greek grammar for Saturday on formatRelative. Removed locale snapshots from the npm package making it lighter. 2.16.0 - 2020-08-27 Kudos to @jvpelt, @piotrl, @yotamofek, @dwaxweiler, @leedriscoll and @bradevans for working on the release. Also thanks to @PascalHonegger, @pickfire, @TheJaredWilcurt, @SidKH and @nfantone for improving the documentation. Fixed Added correct translations for Welsh 1 minute and 2 days. Fixed formatRFC3339 formatting timezone offset with minutes. Added missing locale type definition for formatDuration Fixed Scottish Gaelic locale issues. Changed Used shorter Hebrew alternative for \"about\". Improved string arguments warning after upgrading to v2. Added Added Luxembourgish (lb) locale. 2.15.0 - 2020-07-17 Thanks to @belgamo, @Matsuuu, @Imballinst, @arsnyder16, @pankajupadhyay29, @DCBN, @leedriscoll, @gottsohn, @mukuljainx and @dtriana for working on the release. Also kudos to @KidkArolis, @imgx64, @fjc0k, @wmonk, @djD-REK, @dandv, @psimk and @brimworks for improving the documentation. Fixed Fixed behavior of addBusinessDays when input date is a weekend day. Fixed parseISO not returning Invalid Date on incorrect string when there are spaces in it. Fixed es round-tripping dates with Wednesday. Fixed round-trip bug with d/EEEE ordering in tokens like PPPPP. Fixed issues with parsing values in Japanese. Fixed Hungarian breaking IE11. Fixed Spanish accents in Saturday and Wednesday. Changed Improved the message of protected tokens error. Added Added Swiss-French fr-CH locale. Added Flemish nl-BE locale. Added Scottish Gaelic gd locale. Added New Zealand English en-NZ locale. Added isMatch function. 2.14.0 - 2020-05-18 Kudos to @julamb, @JacobSoderblom, @justingrant, @dragunoff, @jmate0321, @gbhasha, @rasck, @AlbertoPdRF, @sebastianhaberey and @giogonzo for working on the release! Fixed Fixed DST issues with add, addDays and addMonths. Fixed \"quarter\" translation in the Bulgarian locale. Fixed formatDistance strings in the Hungarian locale. Fixed Danish month abbreviations. Fixed parsing of mei in the Dutch locale. Fixed missing preposition in formatLong in the Spanish locale. Fixed formatRelative in the Italian locale. Added Added eachQuarterOfInterval. Added Basque (eu) locale. Added Indian English (en-IN) locale. Added eachHourOfInterval. 2.13.0 - 2020-05-06 Thanks to @JorenVos, @developergouli, @rhlowe and @justingrant for working on the release! Fixed Fixed mei abbreviation in the Dutch locale. Fixed differenceInDays DST behavior broken in 2.12.0. Added Added Kannada locale support. Added formatISODuration function. Added intervalToDuration function. 2.12.0 - 2020-04-09 Kudos to @leshakoss, @skyuplam, @so99ynoodles, @dkozickis, @belgamo, @akgondber, @dcousens and @BoomDev for working on the release! Fixed Fixed minulý štvrtok in Slovak locale. Fixed date ordinalNumber for ja/zh-CN/zh-TW and ko. Fixed quarters parsing. Fixed setDay with weekStartsOn != 0. Fixed differenceInDays across DST. Fixed required arguments exception message. Added Added new function formatDistanceToNowStrict. 2.11.1 - 2020-03-26 Fixed Rebuilt TypeScript and flow types. 2.11.0 - 2020-03-13 Kudos to @oakhan3, @Mukhammadali, @altrim, @leepowellcouk, @amatzon, @bryanMt, @kalekseev, @eugene-platov and @tjrobinson for working on the release. Fixed Fixed a bug in differenceInYears causing incorrect results when the left date is a leap day. Fixed parseISO to work correctly around time shift dates. Fixed format to work correctly with GMT-0752/GMT-0456 and similar timezones. Changed Changed getDay typings to return 0|1|2|3|4|5|6 instead of number. Improved Chinese locale: Change date format to meet the national standard (GB/T 7408-2005). Improve ordinalNumber function behavior. Add prefix in formatRelative depending on if it's a current week or not. Added Added Uzbek uz locale. Updated Macedonian locale for v2. Added Maltese mt locale. 2.10.0 - 2020-02-25 Fixed Fixed formatISO when formatting time with timezones with minute offsets > 0. Kudos to @dcRUSTy. Fixed Fixed a bug in setDay when using weekStartsOn that is not 0 Added Added weeks to Duration. Added weeks support to add and sub. Added details message in throwProtectedError. 2.9.0 - 2020-01-08 Thanks to @mborgbrant, @saintplay, @mrenty, @kibertoad, @levibuzolic, @Anshuman71, @talgautb, @filipjuza, @tobyzerner, @emil9453, @fintara, @pascaliske, @rramiachraf, @marnusw and @Imballinst for working on the release. Fixed Fixed a bug with addBusinessDays returning the Tuesday when adding 1 day on weekends. Now it returns the Monday. Added missing timezone to formatISO. Removed dots from short day period names in the Kazakh locale. Fixed typo in formatDistance in the Czech locale. Fixed shortenings in the Bulgarian locale. Fixed regex for the May in the Portuguese locale. Added Added eachMonthOfInterval and eachYearOfInterval. Added inclusive option to `areIntervalsOverlapping. Added isExists function that checks if the given date is exists. Added add function to add seconds, minutes, hours, weeks, years in single call. Added sub function, the opposite of add. Added Duration type used in add and sub. Added Azerbaijani (az) locale. Added Moroccan Arabic (ar-MA) locale. Changed Reduced the total minified build size by 1Kb/4%. Made all properties in Locale type optional. Added missing properties to Locale type. Add the locale code to Locale type. Added support of space time separator to parseJSON. Allowed up to 7 digits in milliseconds in parseJSON. 2.8.1 - 2019-11-22 Thanks to @Imballinst for the bug fix! Fixed Add colon between the hour and minutes for formatRFC3339. See #1548. 2.8.0 - 2019-11-19 Kudos to @NaridaL, @Zyten, @Imballinst, @leshakoss and @Neorth for working on the release. Fixed Remove the next week preposition in the Swedish locale. Added Added Malay (ms) locale. Added formatISO, formatISO9075, formatRFC3339, and formatRFC7231 functions. 2.7.0 - 2019-11-07 Thanks to @mzgajner, @NaridaL, @Zyten, @leshakoss, @fintara, @kpr-hellofresh for contributing to the release. Fixed Fixed a mistake in the Slovenian locale. Fixed incorrect behavior of parseISO in Firefox caused by differences in getTimezoneOffset. Changed Make object arguments types more elaborate in Flow type definitions. Get rid of deprecated Function in Flow type definitions. Allow parseJSON to accept strings without trailing 'Z' symbol and with up to 6 digits in the milliseconds' field. Added Added Bulgarian (bg) locale. 2.6.0 - 2019-10-22 Kudos to @marnusw, @cdrikd and @rogyvoje for working on the release! Added Added parseJSON - lightweight function (just 411 B) that parses dates formatted with toJSON. Added the language code to each locale. Added subBusinessDays function. Added both Serbian - cyrillic (sr) and latin (sr-Latn) locales. 2.5.1 - 2019-10-18 Thanks to @mitchellbutler for the bug fix! Fixed Fixed infinite loop in addBusinessDays. 2.5.0 - 2019-10-16 Kudos to @dkozickis, @drugoi, @kranthilakum, @102, @gpetrioli and @JulienMalige for making the release happen. Fixed Fixed compatibility with IE11 by removing findIndex from the code. Fixed Greek locale patterns. Added Added Kazakh (kk) locale. Added Telugu (te) locale. Added Canadian French (fr-CA) locale. Added Australian English (en-AU) locale. Exported Interval and Locale types from Flow typings. 2.4.1 - 2019-09-28 Thanks to @mrclayman for reporting the issue and @leshakoss for fixing it. Fixed Fixed am/pm mixup in the Czech locale. 2.4.0 - 2019-09-27 This release is brought to you by these amazing people: @lovelovedokidoki, @alexigityan, @kalekseev and @andybangs. You rock! Fixed Fixed Vietnamese parsing patterns. Fixed Czech parsing regexes. Fixed offset for Eastern Hemisphere in parseISO. Added Added Armenian locale support. 2.3.0 - 2019-09-24 Huge thanks to @lovelovedokidoki who improved 8 (!) locales in an unstoppable open-source rampage and @VesterDe for fixing Slovenian locale \uD83D\uDC4F Fixed Fixed the translation of \"yesterday\" in the Slovenian locale. Fixed French parsing issues with June and August. Improved Turkish parsing. Fixed \"March\" in Dutch parsing patterns. Fixed Hindi parsing patterns. Added Added Finnish matching patterns. Accept abbreviated March, June, July in Norwegian locales. Added parsing for Greek months with long formatting. 2.2.1 - 2019-09-12 Kudos to date-fns contributors: @mzgajner, @sibiraj-s, @mukeshmandiwal, @SneakyFish5 and @CarterLi. Added Added new set function. Updated Slovenian (sl) locale for v2. Added Tamil (ta) locale. Added Hindi (hi) locale. Added support of \\n in format, lightFormat and parse. 2.1.0 - 2019-09-06 Thanks to date-fns contributors: @ManadayM, @illuminist, @visualfanatic, @vsaarinen and at last but not the least @leshakoss! Fixed Set start of the week to Sunday for Thai locale. Fixed month matching in Polish locale. Fixed eachWeekendOfInterval skipping the first date in the supplied interval. Added Added Gujarati locale. 2.0.1 - 2019-08-23 Fixed Fix getWeekOfMonth with options.weekStartsOn set to 1 not working for Sundays. Kudos to @waseemahmad31! 2.0.0 - 2019-08-20 If you're upgrading from v2 alpha or beta, see the pre-release changelog. Fixed Fixed the toDate bug occurring when parsing ISO-8601 style dates (but not valid ISO format) with a trailing Z (e.g 2012-01Z), it returned Invalid Date for FireFox/IE11 #510 Fixed differenceIn... functions returning negative zero in some cases: #692 isDate now works properly with dates passed across iframes #754. Fixed a few bugs that appeared in timezones with offsets that include seconds (e.g. GMT+00:57:44). See PR #789. Fixed DST issue. See #972 and #992 for more details. Fixed DST issue in eachDayOfInterval that caused time in the days after DST change to have the shift as well. Fixed bug in Galician locale caused by incorrect usage of getHours instead of getUTCHours. Changed BREAKING: now functions don't accept string arguments, but only numbers or dates. When a string is passed, it will result in an unexpected result (Invalid Date, NaN, etc). From now on a string should be parsed using parseISO (ISO 8601) or parse. In v1 we've used new Date() to parse strings, but it resulted in many hard-to-track bugs caused by inconsistencies in different browsers. To address that we've implemented our ISO 8601 parser but that made library to significantly grow in size. To prevent inevitable bugs and keep the library tiny, we made this trade-off. See this post for more details. // Before v2.0.0 addDays(\"2016-01-01\", 1); // v2.0.0 onward addDays(parseISO(\"2016-01-01\"), 1); BREAKING: new format string API for format function which is based on Unicode Technical Standard #35. See this post for more details. Unit v2 Pattern v1 Pattern Result examples Era G..GGG AD, BC GGGG Anno Domini, Before Christ GGGGG A, B Calendar year y 44, 1, 1900, 2017 yo 44th, 1st, 0th, 17th yy YY 44, 01, 00, 17 yyy 044, 001, 1900, 2017 yyyy YYYY 0044, 0001, 1900, 2017 yyyyy ... Local week-numbering year Y 44, 1, 1900, 2017 Yo 44th, 1st, 1900th, 2017th YY 44, 01, 00, 17 YYY 044, 001, 1900, 2017 YYYY 0044, 0001, 1900, 2017 YYYYY ... ISO week-numbering year R -43, 0, 1, 1900, 2017 RR GG -43, 00, 01, 1900, 2017 RRR -043, 000, 001, 1900, 2017 RRRR GGGG -0043, 0000, 0001, 1900, 2017 RRRRR ... Extended year u -43, 0, 1, 1900, 2017 uu -43, 01, 1900, 2017 uuu -043, 001, 1900, 2017 uuuu -0043, 0001, 1900, 2017 uuuuu ... Quarter (formatting) Q 1, 2, 3, 4 Qo 1st, 2nd, 3rd, 4th QQ 01, 02, 03, 04 QQQ Q1, Q2, Q3, Q4 QQQQ 1st quarter, 2nd quarter, ... QQQQQ 1, 2, 3, 4 Quarter (stand-alone) q Q 1, 2, 3, 4 qo Qo 1st, 2nd, 3rd, 4th qq 01, 02, 03, 04 qqq Q1, Q2, Q3, Q4 qqqq 1st quarter, 2nd quarter, ... qqqqq 1, 2, 3, 4 Month (formatting) M 1, 2, ..., 12 Mo 1st, 2nd, ..., 12th MM 01, 02, ..., 12 MMM Jan, Feb, ..., Dec MMMM January, February, ..., December MMMMM J, F, ..., D Month (stand-alone) L M 1, 2, ..., 12 Lo 1st, 2nd, ..., 12th LL MM 01, 02, ..., 12 LLL MMM Jan, Feb, ..., Dec LLLL MMMM January, February, ..., December LLLLL J, F, ..., D Local week of year w 1, 2, ..., 53 wo 1st, 2nd, ..., 53th ww 01, 02, ..., 53 ISO week of year I W 1, 2, ..., 53 Io Wo 1st, 2nd, ..., 53th II WW 01, 02, ..., 53 Day of month d D 1, 2, ..., 31 do Do 1st, 2nd, ..., 31st dd DD 01, 02, ..., 31 Day of year D DDD 1, 2, ..., 365, 366 Do DDDo 1st, 2nd, ..., 365th, 366th DD 01, 02, ..., 365, 366 DDD DDDD 001, 002, ..., 365, 366 DDDD ... Day of week (formatting) E..EEE Mon, Tue, Wed, ..., Su EEEE Monday, Tuesday, ..., Sunday EEEEE M, T, W, T, F, S, S EEEEEE Mo, Tu, We, Th, Fr, Sa, Su ISO day of week (formatting) i E 1, 2, 3, ..., 7 io do 1st, 2nd, ..., 7th ii 01, 02, ..., 07 iii ddd Mon, Tue, Wed, ..., Su iiii dddd Monday, Tuesday, ..., Sunday iiiii M, T, W, T, F, S, S iiiiii dd Mo, Tu, We, Th, Fr, Sa, Su Local day of week (formatting) e 2, 3, 4, ..., 1 eo 2nd, 3rd, ..., 1st ee 02, 03, ..., 01 eee Mon, Tue, Wed, ..., Su eeee Monday, Tuesday, ..., Sunday eeeee M, T, W, T, F, S, S eeeeee Mo, Tu, We, Th, Fr, Sa, Su Local day of week (stand-alone) c 2, 3, 4, ..., 1 co 2nd, 3rd, ..., 1st cc 02, 03, ..., 01 ccc Mon, Tue, Wed, ..., Su cccc Monday, Tuesday, ..., Sunday ccccc M, T, W, T, F, S, S cccccc Mo, Tu, We, Th, Fr, Sa, Su AM, PM a..aaa A AM, PM aaaa aa a.m., p.m. aaaaa a, p AM, PM, noon, midnight b..bbb AM, PM, noon, midnight bbbb a.m., p.m., noon, midnight bbbbb a, p, n, mi Flexible day period B..BBB at night, in the morning, ... BBBB at night, in the morning, ... BBBBB at night, in the morning, ... Hour [1-12] h 1, 2, ..., 11, 12 ho 1st, 2nd, ..., 11th, 12th hh 01, 02, ..., 11, 12 Hour [0-23] H 0, 1, 2, ..., 23 Ho 0th, 1st, 2nd, ..., 23rd HH 00, 01, 02, ..., 23 Hour [0-11] K 1, 2, ..., 11, 0 Ko 1st, 2nd, ..., 11th, 0th KK 1, 2, ..., 11, 0 Hour [1-24] k 24, 1, 2, ..., 23 ko 24th, 1st, 2nd, ..., 23rd kk 24, 01, 02, ..., 23 Minute m 0, 1, ..., 59 mo 0th, 1st, ..., 59th mm 00, 01, ..., 59 Second s 0, 1, ..., 59 so 0th, 1st, ..., 59th ss 00, 01, ..., 59 Fraction of second S 0, 1, ..., 9 SS 00, 01, ..., 99 SSS 000, 0001, ..., 999 SSSS ... Timezone (ISO-8601 w/ Z) X -08, +0530, Z XX -0800, +0530, Z XXX -08:00, +05:30, Z XXXX -0800, +0530, Z, +123456 XXXXX -08:00, +05:30, Z, +12:34:56 Timezone (ISO-8601 w/o Z) x -08, +0530, +00 xx ZZ -0800, +0530, +0000 xxx Z -08:00, +05:30, +00:00 xxxx -0800, +0530, +0000, +123456 xxxxx -08:00, +05:30, +00:00, +12:34:56 Timezone (GMT) O...OOO GMT-8, GMT+5:30, GMT+0 OOOO GMT-08:00, GMT+05:30, GMT+00:00 Timezone (specific non-locat.) z...zzz GMT-8, GMT+5:30, GMT+0 zzzz GMT-08:00, GMT+05:30, GMT+00:00 Seconds timestamp t X 512969520 tt ... Milliseconds timestamp T x 512969520900 TT ... Long localized date P 5/29/53 PP May 29, 1453 PPP May 29th, 1453 PPPP Sunday, May 29th, 1453 Long localized time p 12:00 AM pp 12:00:00 AM ppp 12:00:00 AM GMT+2 pppp 12:00:00 AM GMT+02:00 Combination of date and time Pp 5/29/53, 12:00 AM PPpp May 29, 1453, 12:00 AM PPPppp May 29th, 1453 at ... PPPPpppp Sunday, May 29th, 1453 at ... Characters are now escaped using single quote symbols (') instead of square brackets. format now throws RangeError if it encounters an unescaped latin character that isn't a valid formatting token. To use YY and YYYY tokens that represent week-numbering years, you should set useAdditionalWeekYearTokens option: format(Date.now(), \"YY\", { useAdditionalWeekYearTokens: true }); //=> '86' To use D and DD tokens which represent days of the year, set useAdditionalDayOfYearTokens option: format(Date.now(), \"D\", { useAdditionalDayOfYearTokens: true }); //=> '364' BREAKING: function submodules now use camelCase naming schema: // Before v2.0.0 import differenceInCalendarISOYears from \"date-fns/difference_in_calendar_iso_years\"; // v2.0.0 onward import differenceInCalendarISOYears from \"date-fns/differenceInCalendarISOYears\"; BREAKING: min and max functions now accept an array of dates rather than spread arguments. // Before v2.0.0 var date1 = new Date(1989, 6 /* Jul */, 10); var date2 = new Date(1987, 1 /* Feb */, 11); var minDate = min(date1, date2); var maxDate = max(date1, date2); // v2.0.0 onward: var dates = [ new Date(1989, 6 /* Jul */, 10), new Date(1987, 1 /* Feb */, 11), ]; var minDate = min(dates); var maxDate = max(dates); BREAKING: make the second argument of format required for the sake of explicitness. // Before v2.0.0 format(new Date(2016, 0, 1)); // v2.0.0 onward format(new Date(2016, 0, 1), \"yyyy-MM-dd'T'HH:mm:ss.SSSxxx\"); BREAKING renamed ISO week-numbering year helpers: addISOYears → addISOWeekYears differenceInCalendarISOYears → differenceInCalendarISOWeekYears differenceInISOYears → differenceInISOWeekYears endOfISOYear → endOfISOWeekYear getISOYear → getISOWeekYear isSameISOYear → isSameISOWeekYear lastDayOfISOYear → lastDayOfISOWeekYear setISOYear → setISOWeekYear subISOYears → subISOWeekYears i.e. \"ISO year\" renamed to \"ISO week year\", which is short for ISO week-numbering year. It makes them consistent with locale-dependent week-numbering year helpers, e.g., startOfWeekYear. BREAKING: functions renamed: areRangesOverlapping → areIntervalsOverlapping eachDay → eachDayOfInterval getOverlappingDaysInRanges → getOverlappingDaysInIntervals isWithinRange → isWithinInterval This change was made to mirror the use of the word \"interval\" in standard ISO 8601:2004 terminology: 2.1.3 time interval part of the time axis limited by two instants Also these functions now accept an object with start and end properties instead of two arguments as an interval. All these functions throw RangeError if the start of the interval is after its end or if any date in the interval is Invalid Date. // Before v2.0.0 areRangesOverlapping( new Date(2014, 0, 10), new Date(2014, 0, 20), new Date(2014, 0, 17), new Date(2014, 0, 21), ); eachDay(new Date(2014, 0, 10), new Date(2014, 0, 20)); getOverlappingDaysInRanges( new Date(2014, 0, 10), new Date(2014, 0, 20), new Date(2014, 0, 17), new Date(2014, 0, 21), ); isWithinRange( new Date(2014, 0, 3), new Date(2014, 0, 1), new Date(2014, 0, 7), ); // v2.0.0 onward areIntervalsOverlapping( { start: new Date(2014, 0, 10), end: new Date(2014, 0, 20) }, { start: new Date(2014, 0, 17), end: new Date(2014, 0, 21) }, ); eachDayOfInterval({ start: new Date(2014, 0, 10), end: new Date(2014, 0, 20), }); getOverlappingDaysInIntervals( { start: new Date(2014, 0, 10), end: new Date(2014, 0, 20) }, { start: new Date(2014, 0, 17), end: new Date(2014, 0, 21) }, ); isWithinInterval(new Date(2014, 0, 3), { start: new Date(2014, 0, 1), end: new Date(2014, 0, 7), }); BREAKING: functions renamed: distanceInWords → formatDistance distanceInWordsStrict → formatDistanceStrict distanceInWordsToNow → formatDistanceToNow to make them consistent with format and formatRelative. BREAKING: The order of arguments of distanceInWords and distanceInWordsStrict is swapped to make them consistent with differenceIn... functions. // Before v2.0.0 distanceInWords( new Date(1986, 3, 4, 10, 32, 0), new Date(1986, 3, 4, 11, 32, 0), { addSuffix: true }, ); //=> 'in about 1 hour' // v2.0.0 onward formatDistance( new Date(1986, 3, 4, 11, 32, 0), new Date(1986, 3, 4, 10, 32, 0), { addSuffix: true }, ); //=> 'in about 1 hour' BREAKING: partialMethod option in formatDistanceStrict is renamed to roundingMethod. // Before v2.0.0 distanceInWordsStrict( new Date(1986, 3, 4, 10, 32, 0), new Date(1986, 3, 4, 10, 33, 1), { partialMethod: \"ceil\" }, ); //=> '2 minutes' // v2.0.0 onward formatDistanceStrict( new Date(1986, 3, 4, 10, 33, 1), new Date(1986, 3, 4, 10, 32, 0), { roundingMethod: \"ceil\" }, ); //=> '2 minutes' BREAKING: in formatDistanceStrict, if roundingMethod is not specified, it now defaults to round instead of floor. BREAKING: unit option in formatDistanceStrict now accepts one of the strings: 'second', 'minute', 'hour', 'day', 'month' or 'year' instead of 's', 'm', 'h', 'd', 'M' or 'Y' // Before v2.0.0 distanceInWordsStrict( new Date(1986, 3, 4, 10, 32, 0), new Date(1986, 3, 4, 10, 33, 1), { unit: \"m\" }, ); // v2.0.0 onward formatDistanceStrict( new Date(1986, 3, 4, 10, 33, 1), new Date(1986, 3, 4, 10, 32, 0), { unit: \"minute\" }, ); BREAKING: parse that previously used to convert strings and numbers to dates now parses only strings in an arbitrary format specified as an argument. Use toDate to coerce numbers and parseISO to parse ISO 8601 strings. // Before v2.0.0 parse(\"2016-01-01\"); parse(1547005581366); parse(new Date()); // Clone the date // v2.0.0 onward parse(\"2016-01-01\", \"yyyy-MM-dd\", new Date()); parseISO(\"2016-01-01\"); toDate(1547005581366); toDate(new Date()); // Clone the date BREAKING: toDate (previously parse) now doesn't accept string arguments but only numbers and dates. toDate called with an invalid argument will return Invalid Date. BREAKING: new locale format. See docs/Locale. Locales renamed: en → en-US zh_cn → zh-CN zh_tw → zh-TW // Before v2.0.0 import locale from \"date-fns/locale/zh_cn\"; // v2.0.0 onward import locale from \"date-fns/locale/zh-CN\"; BREAKING: now closestTo and closestIndexTo don't throw an exception when the second argument is not an array, and return Invalid Date instead. BREAKING: now isValid doesn't throw an exception if the first argument is not an instance of Date. Instead, argument is converted beforehand using toDate. Examples: isValid argument Before v2.0.0 v2.0.0 onward new Date() true true new Date('2016-01-01') true true new Date('') false false new Date(1488370835081) true true new Date(NaN) false false '2016-01-01' TypeError false '' TypeError false 1488370835081 TypeError true NaN TypeError false We introduce this change to make date-fns consistent with ECMAScript behavior that try to coerce arguments to the expected type (which is also the case with other date-fns functions). BREAKING: functions now throw RangeError if optional values passed to options are not undefined or have expected values. This change is introduced for consistency with ECMAScript standard library which does the same. BREAKING: format, formatDistance (previously distanceInWords) and formatDistanceStrict (previously distanceInWordsStrict) now throw RangeError if one of the passed arguments is invalid. It reflects behavior of toISOString and Intl API. See #1032. BREAKING: all functions now implicitly convert arguments by following rules: date number string boolean 0 new Date(0) 0 '0' false '0' Invalid Date 0 '0' false 1 new Date(1) 1 '1' true '1' Invalid Date 1 '1' true true Invalid Date NaN 'true' true false Invalid Date NaN 'false' false null Invalid Date NaN 'null' false undefined Invalid Date NaN 'undefined' false NaN Invalid Date NaN 'NaN' false Notes: as before, arguments expected to be Date are converted to Date using date-fns' toDate function; arguments expected to be numbers are converted to integer numbers using our custom toInteger implementation (see #765); arguments expected to be strings are converted to strings using JavaScript's String function; arguments expected to be booleans are converted to boolean using JavaScript's Boolean function. null and undefined passed to optional arguments (i.e. properties of options argument) are ignored as if no argument was passed. If any resulting argument is invalid (i.e. NaN for numbers and Invalid Date for dates), an invalid value will be returned: false for functions that return booleans (expect isValid); Invalid Date for functions that return dates; and NaN for functions that return numbers. See tests and PRs #460 and #765 for exact behavior. BREAKING: all functions now check if the passed number of arguments is less than the number of required arguments and will throw TypeError exception if so. BREAKING: all functions that accept numbers as arguments, now coerce values using Number() and also round off decimals. Positive decimals are rounded using Math.floor, decimals less than zero are rounded using Math.ceil. BREAKING: The Bower & UMD/CDN package versions are no longer supported. BREAKING: null now is not a valid date. isValid(null) returns false; toDate(null) returns an invalid date. Since toDate is used internally by all the functions, operations over null will also return an invalid date. See #537 for the reasoning. toDate (previously parse) and isValid functions now accept any type as the first argument. Exclude docs.json from the npm package. Kudos to @hawkrives. Added FP functions like those in lodash, that support currying, and, as a consequence, functional-style function composing. Functions with options (format, parse, etc.) have two FP counterparts: one that has the options object as its first argument and one that hasn't. The name of the former has WithOptions added to the end of its name. In FP functions, the order of arguments is reversed. See FP Guide for more information. import addYears from \"date-fns/fp/addYears\"; import formatWithOptions from \"date-fns/fp/formatWithOptions\"; import eo from \"date-fns/locale/eo\"; // If FP function has not received enough arguments, it returns another function const addFiveYears = addYears(5); // Several arguments can be curried at once const dateToString = formatWithOptions({ locale: eo }, \"d MMMM yyyy\"); const dates = [ new Date(2017, 0 /* Jan */, 1), new Date(2017, 1 /* Feb */, 11), new Date(2017, 6 /* Jul */, 2), ]; const formattedDates = dates.map((date) => dateToString(addFiveYears(date))); //=> ['1 januaro 2022', '11 februaro 2022', '2 julio 2022'] Added support for ECMAScript Modules. It allows usage with bundlers that support tree-shaking, like rollup.js and webpack: // Without tree-shaking: import format from \"date-fns/format\"; import parse from \"date-fns/parse\"; // With tree-shaking: import { format, parse } from \"date-fns\"; Also, ESM functions provide default export, they can be used with TypeScript to import functions in more idiomatic way: // Before import * as format from \"date-fns/format\"; // Now import format from \"date-fns/format\"; formatRelative function. See formatRelative Flow typings for index.js, fp/index.js, locale/index.js, and their ESM equivalents. See PR #558 New locale-dependent week-numbering year helpers: getWeek getWeekYear setWeek setWeekYear startOfWeekYear Added eachWeekOfInterval, the weekly equivalent of eachDayOfInterval Added getUnixTime function. Kudos to @Kingwl. New decade helpers. Thanks to @y-nk! getDecade startOfDecade endOfDecade lastDayOfDecade New roundToNearestMinutes function. Kudos to @xkizer. Added new function fromUnixTime. Thanks to @xkizer. New interval, month, and year helpers to fetch a list of all Saturdays and Sundays (weekends) for a given date interval. eachWeekendOfInterval is the handler function while the other two are wrapper functions. Kudos to @laekettavong! eachWeekendOfInterval eachWeekendOfMonth eachWeekendOfYear Build-efficient lightFormat that only supports the popular subset of tokens. See #1050. parseISO function that parses ISO 8601 strings. See #1023. Add constants that can be imported directly from date-fns or the submodule date-fns/constants: maxTime minTime New locales: Norwegian Nynorsk locale (nn) by @draperunner. Ukrainian locale (ua) by @korzhyk. Vietnamese locale (vi) by @trongthanh. Persian locale (fa-IR) by @mort3za. Latvian locale (lv) by @prudolfs. Bengali locale (bb) by @nutboltu and @touhidrahman. Hungarian (hu) and Lithuanian (lt) locales by @izifortune and pardoeryanair. Canadian English locale (en-CA) by @markowsiak. Great Britain English locale (en-GB) by @glintik. Uighur locale (ug) by @abduwaly. Added new function differenceInBusinessDays which calculates the difference in business days. Kudos to @ThorrStevens! Added new function addBusinessDays, similar to addDays but ignoring weekends. Thanks to @ThorrStevens! [1.30.1] - 2018-12-10 Fixed Fixed DST issue. See #972 and #992 for more details. This fix was backported from v2. Fix a few bugs that appear in timezones with offsets that include seconds (e.g. GMT+00:57:44). See PR #789. This fix was backported from v2. Fixed misspelled January in the Thai locale. Thanks to @ratchapol-an! Added Added Serbian locale. Kudos to @mawi12345! Added Belarusian locale. Kudos to @mawi12345 again! Changed Improved ja translation of distanceInWords. Thanks to @kudohamu! [1.30.0] - 2018-12-10 ⚠️ The release got failed. [1.29.0] - 2017-10-11 Fixed Fixed Italian translations for formatDistance. (see the issue: #550; see the PR: #552) Thanks to @giofilo! Added Hungarian locale (hu) (thanks to László Horváth @horvathlg) Slovenian locale (sl) (thanks to Adam Stradovnik @Neoglyph) Added step to eachDay function. Thanks to @BDav24. See PR #487. 1.28.5 - 2017-05-19 Fixed Fixed a.m./p.m. formatters in Chinese Simplified locale. Thanks to @fnlctrl. See PR #486 1.28.4 - 2017-04-26 Fixed Fixed accents on weekdays in the Italian locale. See PR #481. Thanks to @albertorestifo Fixed typo in ddd format token in Spanish language locale. Kudos to @fjaguero. See PR #482 1.28.3 - 2017-04-14 Fixed Fixed ordinal numbers for Danish language locale. Thanks to @kgram. See PR #474 1.28.2 - 2017-03-27 Fixed Fixed dd and ddd formatters in Polish language locale. Kudos to @justrag. See PR: #467 1.28.1 - 2017-03-19 Fixed Fixed DST border bug in addMilliseconds, addSeconds, addMinutes, addHours, subMilliseconds, subSeconds, subMinutes and subHours. See issue #465 Minor fix for Indonesian locale. Thanks to @bentinata. See PR: #458 1.28.0 - 2017-02-27 Added Romanian locale (ro) (thanks to Sergiu Munteanu @jsergiu) Fixed All functions now convert all their arguments to the respective types. See PR: #443 Fixes for ordinals (1er, 2, 3, …) in French locale. Thanks to @fbonzon. See PR: #449 1.27.2 - 2017-02-01 Fixed Various fixes for Dutch locale. See PR: #416. Thanks to Ruben Stolk @rubenstolk 1.27.1 - 2017-01-20 Fixed Added generation of TypeScript locale sub-modules, allowing import of locales in TypeScript. 1.27.0 - 2017-01-19 Added Macedonian locale (mk) (thanks to Petar Vlahu @vlahupetar) 1.26.0 - 2017-01-15 Added getTime Fixed Various fixes for Japanese locale. See PR: 395. Thanks to Yamagishi Kazutoshi @ykzts 1.25.0 - 2017-01-11 Added Bulgarian locale (bg) (thanks to Nikolay Stoynov @arvigeus) Czech locale (cs) (thanks to David Rus @davidrus) 1.24.0 - 2017-01-06 Added Modern Standard Arabic locale (ar) (thanks to Abdallah Hassan @AbdallahAHO) 1.23.0 - 2017-01-05 Added Auto generate TypeScript and flow typings from documentation on release. Thanks to @mattlewis92. See related PRs: #355, #370 Croatian locale (hr) (thanks to Matija Marohnić @silvenon) Thai locale (th) (thanks to Athiwat Hirunworawongkun @athivvat) Finnish locale (fi) (thanks to Pyry-Samuli Lahti @Pyppe) 1.22.0 - 2016-12-28 Added Icelandic locale (is) (thanks to Derek Blank @derekblank) 1.21.1 - 2016-12-18 Fixed Fixed isBefore and isAfter documentation mistakes. 1.21.0 - 2016-12-16 Added Filipino locale (fil) (thanks to Ian De La Cruz @RIanDeLaCruz) Danish locale (da) (kudos to Anders B. Hansen @Andersbiha) 1.20.1 - 2016-12-14 Fixed Fixed documentation for getOverlappingDaysInRanges. 1.20.0 - 2016-12-13 Added areRangesOverlapping and getOverlappingDaysInRanges Thanks to Joanna T @asia-t. See PR: #331 1.19.0 - 2016-12-13 Added Greek locale (el) (kudos to Theodoros Orfanidis @teoulas) Slovak locale (sk) (kudos to Marek Suscak @mareksuscak) Added yarn support. Thanks to Uladzimir Havenchyk @havenchyk. See PR: #288 1.18.0 - 2016-12-12 Added Turkish locale (tr) (kudos to Alpcan Aydın @alpcanaydin) Korean locale (ko) (thanks to Hong Chulju @angdev) Fixed SS and SSS formats in format are now correctly displayed with leading zeros. Thanks to Paul Dijou @pauldijou. See PR: #330 1.17.0 - 2016-12-10 Added Polish locale (pl) (thanks to Mateusz Derks @ertrzyiks) Portuguese locale (pt) (thanks to Dário Freire @dfreire) Swedish locale (sv) (thanks to Johannes Ulén @ejulen) French locale (fr) (thanks to Jean Dupouy @izeau) Performance tests. See PR: #289 Fixed Fixed TypeScript and flow typings for isValid. See PR: #310 Fixed incorrect locale tests that could potentially lead to format bugs. Kudos to Mateusz Derks @ertrzyiks. See related PRs: #312, #320 Minor language fixes in the documentation. Thanks to Vedad Šoše @vedadsose (#314) and Asia @asia-t (#318) Changed format now returns String('Invalid Date') if the passed date is invalid. See PR: #323 distanceInWords, distanceInWordsToNow, distanceInWordsStrict and format functions now check if the passed locale is valid, and fallback to English locale otherwise. See PR: #321 Internal: use a loop instead of Object.keys in buildFormattingTokensRegExp to improve compatibility with older browsers. See PR: #322 1.16.0 - 2016-12-08 Added Italian locale (it) (thanks to Alberto Restifo @albertorestifo) For German buildDistanceInWordsLocale, add nominative case translations (for distances without a suffix). Kudos to Asia @asia-t. See related PR: #295 1.15.1 - 2016-12-07 Fixed Fixed TypeScript imports from individual modules. Thanks to @mattlewis92. See related PR: #287 1.15.0 - 2016-12-07 Added Indonesian locale (id) (thanks to Rahmat Budiharso @rbudiharso) Catalan locale (ca) (thanks to Guillermo Grau @guigrpa) Fixed Fixed some inaccuracies in Spanish locale. Kudos to @guigrpa. See related PR: #302 1.14.1 - 2016-12-06 Fixed Fixed broken test for Norwegian Bokmål locale. 1.14.0 - 2016-12-06 Added Norwegian Bokmål locale (nb) (thanks to Hans-Kristian Koren @Hanse) 1.13.0 - 2016-12-06 Added Chinese Traditional locale (zh_tw) (thanks to tonypai @tpai). Dutch language locale (nl) (kudos to Jorik Tangelder @jtangelder) 1.12.1 - 2016-12-05 Fixed Added distanceInWordsStrict to the list of supported functions in I18n doc. 1.12.0 - 2016-12-05 Added Spanish language locale (es) (thanks to Juan Angosto @juanangosto). Fixed Fixed flow typings for some of the functions. See PR: #273 1.11.2 - 2016-11-28 Fixed Bug in parse when it sometimes parses ISO week-numbering dates incorrectly. See PR: #262 Bug in some functions which caused them to handle dates earlier than 100 AD incorrectly. See PR: #263 1.11.1 - 2016-11-24 Fixed Include TypeScript typings with npm package. 1.11.0 - 2016-11-23 Added distanceInWordsStrict. Kudos to @STRML. See related PR: #254 TypeScript typings for all functions. Kudos to @mattlewis92. See related PR: #255 1.10.0 - 2016-11-01 Added parse now can parse dates that are ISO 8601 centuries (e.g., 19 and +0019). var result = parse(\"19\"); //=> Mon Jan 01 1900 00:00:00 In parse, added ability to specify the number of additional digits for extended year or century format (possible values are 0, 1 or 2; default is 2). parse(\"+002016-11-01\"); parse(\"+02016-11-01\", { additionalDigits: 1 }); parse(\"+2016-11-01\", { additionalDigits: 0 }); 1.9.0 - 2016-10-25 Added Got index.js imports to work with SystemJS. 1.8.1 - 2016-10-24 Fixed Added Japanese and German language locales to the list in I18n doc. 1.8.0 - 2016-10-23 Added Japanese language locale (ja) (thanks to Thomas Eilmsteiner @DeMuu again!) getISODay setISODay 1.7.0 - 2016-10-20 Added German language locale (de) (thanks to Thomas Eilmsteiner @DeMuu). 1.6.0 - 2016-10-16 Added Chinese Simplified locale (zh_cn) (kudos to Changyu @KingMario Geng). 1.5.2 - 2016-10-13 Fixed Incorrectly generated docs for format. Fixed typo in I18n doc. 1.5.1 - 2016-10-12 Fixed A change log entry for 1.5.0 is added. 1.5.0 - 2016-10-12 Added The initial I18n support 1.4.0 - 2016-10-09 Added Basic SystemJS support. Fixed Fixed incorrect behaviour of YYYY and YY for years prior to 1000: now format(new Date('0001-01-01'), 'YYYY-MM-DD') returns 0001-01-01 instead of 1-01-01. 1.3.0 - 2016-05-26 Added closestIndexTo 1.2.0 - 2016-05-23 Added Added an ability to pass negative numbers to setDay. 1.1.1 - 2016-05-19 Fixed Fixed Flow declarations for some of the functions. 1.1.0 - 2016-05-19 Added Flow declarations for each function in the \".js.flow\" style. Kudos to @JohnyDays. See related PRs: #205 #207 1.0.0 - 2016-05-18 Fixed format now returns the correct result for key E. Prevent startOf..., endOf... and lastDayOf... functions to return dates with an incorrect time when the date is modifying into another time zone. parse now parses years from 1 AD to 99 AD correctly. Fix a bug in getISOWeek appearing because of a changing time zone (e.g., when the given date is in DST and the start of the ISO year is not). Changed BREAKING: all functions are moved to the root of the library, so they are now accessible with require('date-fns/name_of_function') or import nameOfFunction from 'date-fns/name_of_function'. // Before v1.0.0 var addMonths = require(\"date-fns/src/add_months\"); // v1.0.0 onward var addMonths = require(\"date-fns/add_months\"); BREAKING: functions that had the last optional argument weekStartsAt (i.e. endOfWeek, isSameWeek, lastDayOfWeek, setDay, startOfWeek) now instead receive the object options with the property options.weekStartsOn as the last argument. // Before v1.0.0 var result = endOfWeek(new Date(2014, 8, 2), 1); // v1.0.0 onward var result = endOfWeek(new Date(2014, 8, 2), { weekStartsOn: 1 }); BREAKING: remove the function getTimeSinceMidnight that was used inside the other functions. BREAKING: differenceInDays now returns the number of full days instead of calendar days. BREAKING: eachDay and isWithinRange now throw an exception when the given range boundaries are invalid. Faster isLeapYear. Internal: make the documentation more verbose. Internal: convert the tests from Chai to power-assert allowing them to run against IE8. Added addISOYears closestTo differenceInCalendarDays differenceInCalendarISOWeeks differenceInCalendarISOYears differenceInCalendarMonths differenceInCalendarQuarters differenceInCalendarWeeks differenceInCalendarYears differenceInHours differenceInISOYears differenceInMilliseconds differenceInMinutes differenceInMonths differenceInQuarters differenceInSeconds differenceInWeeks differenceInYears distanceInWords distanceInWordsToNow endOfISOWeek endOfISOYear endOfToday endOfTomorrow endOfYesterday getDaysInYear isDate isFriday isMonday isSameISOWeek isSameISOYear isSaturday isSunday isThisHour isThisISOWeek isThisISOYear isThisMinute isThisMonth isThisQuarter isThisSecond isThisWeek isThisYear isThursday isTomorrow isTuesday isValid isWednesday isYesterday lastDayOfISOWeek lastDayOfISOYear startOfISOWeek startOfToday startOfTomorrow startOfYesterday subISOYears Add Qo, W, Wo, WW, GG, GGGG, Z, ZZ, X, x keys to format. 0.17.0 - 2015-09-29 Fixed Fixed a lot of bugs appearing when date is modifying into other time zone (e.g., when adding months and original date is in DST but new date is not). Prevent instances of Date to lose milliseconds value when passed to. parse in IE10. Changed setISOWeek now keeps time from original date. Internal: reuse getDaysInMonth inside of addMonths. Added differenceInDays getTimeSinceMidnight format now has new format key aa, which returns a.m./p.m. as opposed to a that returns am/pm. Complete UMD package (for Bower and CDN). 0.16.0 - 2015-09-01 Changed Use parse to clean date arguments in all functions. parse now fallbacks to new Date when the argument is not an ISO formatted date. Internal: reuse getDaysInMonth inside of setMonth. Added addQuarters addWeeks endOfQuarter getDate getDay getDaysInMonth getHours getISOWeeksInYear getMilliseconds getMinutes getMonth getSeconds getYear isLeapYear isSameHour isSameMinute isSameQuarter isSameSecond lastDayOfQuarter lastDayOfWeek max min setDate setDay setHours setMilliseconds setMinutes setSeconds startOfQuarter subQuarters subWeeks 0.15.0 - 2015-08-26 Changed format now returns a.m./p.m. instead of am/pm. setMonth now sets last day of month if original date was last day of longer month. Internal: Fix code style according to ESLint. Internal: Make tests run through all time zones. Added getQuarter setQuarter getDayOfYear setDayOfYear isPast addSeconds subSeconds startOfSecond endOfSecond startOfMinute endOfMinute addMilliseconds subMilliseconds endOfYear addYears subYears lastDayOfYear lastDayOfMonth 0.14.11 - 2015-08-21 Fixed format now uses parse to avoid time zone bugs. Changed setIsoWeek now sets time to the start of the day. 0.14.10 - 2015-07-29 Fixed format now behaves correctly with 12:00 am. format now behaves correctly with ordinal numbers. Added compareAsc compareDesc addHours subHours isSameDay parse getISOYear setISOYear startOfISOYear getISOWeek setISOWeek 0.14.9 - 2015-01-14 Fixed addMonths now correctly behaves with February (see #18). 0.14.8 - 2014-12-25 Fixed format function now behaves correctly with pm/am. 0.14.6 - 2014-12-04 Fixed Fix broken Bower support. 0.14.0 - 2014-11-05 Added Bower package. 0.13.0 - 2014-10-22 Added addMinutes subMinutes isEqual isBefore isAfter 0.12.1 - 2014-10-19 Fixed Incorrect rounding in DDD formatter. 0.12.0 - 2014-10-15 Added isSameYear 0.11.0 - 2014-10-15 Added isWithinRange 0.10.0 - 2014-10-13 Added format startOfYear 0.9.0 - 2014-10-10 Changed Internal: simplify isWeekend Added isFuture 0.8.0 - 2014-10-09 Changed Internal: reuse addDays inside of subDays. Added addMonths subMonths setMonth setYear 0.7.0 - 2014-10-08 Added isSameWeek 0.6.0 - 2014-10-07 Fixed Inconsistent behavior of endOfMonth. Added isFirstDayOfMonth isLastDayOfMonth isSameMonth 0.5.0 - 2014-10-07 Added addDays subDays 0.4.0 - 2014-10-07 Added startOfWeek endOfWeek eachDay 0.3.0 - 2014-10-06 Changed startOfDay now sets milliseconds as well. Added endOfDay startOfMonth endOfMonth 0.2.0 - 2014-10-06 Added isToday isWeekend 0.1.0 - 2014-10-06 Added startOfDay"
  },
  "src/frontend/app-client/node_modules/date-fns/docs/cdn.html": {
    "href": "src/frontend/app-client/node_modules/date-fns/docs/cdn.html",
    "title": "CDN",
    "summary": "CDN Starting with v3.6.0, the CDN versions of date-fns are available on jsDelivr and other CDNs. They expose the date-fns functionality via the window.dateFns global variable. Unlike the npm package, the CDN is transpiled to be compatible with IE11, so it supports a wide variety of legacy browsers and environments. <script src=\"https://cdn.jsdelivr.net/npm/date-fns@3.6.0/cdn.min.js\"></script> <script src=\"https://cdn.jsdelivr.net/npm/date-fns@3.6.0/locale/es/cdn.min.js\"></script> <script src=\"https://cdn.jsdelivr.net/npm/date-fns@3.6.0/locale/ru/cdn.min.js\"></script> <script> dateFns.formatRelative(dateFns.subDays(new Date(), 3), new Date()); //=> \"last Friday at 7:26 p.m.\" dateFns.formatRelative(dateFns.subDays(new Date(), 3), new Date(), { locale: dateFns.locale.es, }); //=> \"el viernes pasado a las 19:26\" dateFns.formatRelative(dateFns.subDays(new Date(), 3), new Date(), { locale: dateFns.locale.ru, }); //=> \"в прошлую пятницу в 19:26\" </script> The CDN versions are available for the main module, all & individual locales, and the FP submodule. They come in two flavors: cdn.js and cdn.min.js. The latter is minified and should be used in production. The former is useful for debugging and development. Keep in mind that using the CDN versions in production is suboptimal because they bundle all the date-fns functionality you will never use. It's much better to use the npm package and a tree-shaking-enabled bundler like webpack or Rollup. However, the CDN versions are helpful for quick prototyping, small projects, educational purposes, or working in a legacy environment. Main module The main module with all functions bundled: https://cdn.jsdelivr.net/npm/date-fns@VERSION/cdn.js https://cdn.jsdelivr.net/npm/date-fns@VERSION/cdn.min.js You can access it via the dateFns global variable: <script src=\"https://cdn.jsdelivr.net/npm/date-fns@3.6.0/cdn.min.js\"></script> <script> dateFns.addDays(new Date(2014, 1, 11), 10); //=> Tue Feb 21 2014 00:00:00 </script> The FP submodule The FP submodule with all functions bundled: https://cdn.jsdelivr.net/npm/date-fns@VERSION/fp/cdn.js https://cdn.jsdelivr.net/npm/date-fns@VERSION/fp/cdn.min.js You can access it via the dateFns.fp global variable: <script src=\"https://cdn.jsdelivr.net/npm/date-fns@3.6.0/fp/cdn.min.js\"></script> <script> dateFns.fp.addDays(10, new Date(2014, 1, 11)); //=> Tue Feb 21 2014 00:00:00 </script> Locales All locales bundled: https://cdn.jsdelivr.net/npm/date-fns@VERSION/locale/cdn.js https://cdn.jsdelivr.net/npm/date-fns@VERSION/locale/cdn.min.js You can access them via the dateFns.locale global variable: <script src=\"https://cdn.jsdelivr.net/npm/date-fns@3.6.0/cdn.min.js\"></script> <script src=\"https://cdn.jsdelivr.net/npm/date-fns@3.6.0/locale/cdn.min.js\"></script> <script> dateFns.formatRelative(dateFns.subDays(new Date(), 3), new Date(), { locale: dateFns.locale.es, }); //=> \"el viernes pasado a las 19:26\" </script> The locales are also available as individual files. https://cdn.jsdelivr.net/npm/date-fns@VERSION/locale/LOCALE/cdn.js https://cdn.jsdelivr.net/npm/date-fns@VERSION/locale/LOCALE/cdn.min.js You can access them via the dateFns.locale.LOCALE global variable: <script src=\"https://cdn.jsdelivr.net/npm/date-fns@3.6.0/cdn.min.js\"></script> <script src=\"https://cdn.jsdelivr.net/npm/date-fns@3.6.0/locale/es/cdn.min.js\"></script> <script> dateFns.formatRelative(dateFns.subDays(new Date(), 3), new Date(), { locale: dateFns.locale.es, }); //=> \"el viernes pasado a las 19:26\" </script>"
  },
  "src/frontend/app-client/node_modules/date-fns/docs/fp.html": {
    "href": "src/frontend/app-client/node_modules/date-fns/docs/fp.html",
    "title": "FP Guide",
    "summary": "FP Guide date-fns v2.x provides functional programming (FP) friendly functions, like those in lodash, that support currying. Table of Contents Usage Using Function Composition Usage FP functions are provided via 'date-fns/fp' submodule. Functions with options (format, parse, etc.) have two FP counterparts: one that has the options object as its first argument and one that hasn't. The name of the former has WithOptions added to the end of its name. In date-fns' FP functions, the order of arguments is reversed. import { addYears, formatWithOptions } from \"date-fns/fp\"; import { eo } from \"date-fns/locale\"; import toUpper from \"lodash/fp/toUpper\"; // 'date-fns/fp' is compatible with 'lodash/fp'! // If FP function has not received enough arguments, it returns another function const addFiveYears = addYears(5); // Several arguments can be curried at once const dateToString = formatWithOptions({ locale: eo }, \"d MMMM yyyy\"); const dates = [ new Date(2017, 0 /* Jan */, 1), new Date(2017, 1 /* Feb */, 11), new Date(2017, 6 /* Jul */, 2), ]; const formattedDates = dates.map(addFiveYears).map(dateToString).map(toUpper); //=> ['1 JANUARO 2022', '11 FEBRUARO 2022', '2 JULIO 2022'] Using Function Composition The main advantage of FP functions is support of functional-style function composing. In the example above, you can compose addFiveYears, dateToString and toUpper into a single function: const formattedDates = dates.map((date) => toUpper(dateToString(addFiveYears(date))), ); Or you can use compose function provided by lodash to do the same in more idiomatic way: import { compose } from \"lodash/fp/compose\"; const formattedDates = dates.map(compose(toUpper, dateToString, addFiveYears)); Or if you prefer natural direction of composing (as opposed to the computationally correct order), you can use lodash' flow instead: import flow from \"lodash/fp/flow\"; const formattedDates = dates.map(flow(addFiveYears, dateToString, toUpper));"
  },
  "src/frontend/app-client/node_modules/date-fns/docs/gettingStarted.html": {
    "href": "src/frontend/app-client/node_modules/date-fns/docs/gettingStarted.html",
    "title": "Getting Started",
    "summary": "Getting Started Table of Contents Introduction Submodules Installation Introduction date-fns provides the most comprehensive, yet simple and consistent toolset for manipulating JavaScript dates in a browser & Node.js. date-fns is like lodash for dates. It has 200+ functions for all occasions. import { format, compareAsc } from \"date-fns\"; format(new Date(2014, 1, 11), \"MM/dd/yyyy\"); //=> '02/11/2014' const dates = [ new Date(1995, 6, 2), new Date(1987, 1, 11), new Date(1989, 6, 10), ]; dates.sort(compareAsc); //=> [ // Wed Feb 11 1987 00:00:00, // Mon Jul 10 1989 00:00:00, // Sun Jul 02 1995 00:00:00 // ] Submodules date-fns includes some optional features as submodules in the npm package. Here is the list of them, in order of nesting: FP — functional programming-friendly variations of the functions. See FP Guide; The later submodules are also included inside the former if you want to use multiple features from the list. To use submodule features, install the npm package and then import a function from a submodule: // The main submodule: import { addDays } from \"date-fns\"; // FP variation: import { addDays, format } from \"date-fns/fp\"; Installation The library is available as an npm package. To install the package, run: npm install date-fns --save # or yarn add date-fns Start using: import { formatDistance, subDays } from \"date-fns\"; formatDistance(subDays(new Date(), 3), new Date(), { addSuffix: true }); //=> \"3 days ago\""
  },
  "src/frontend/app-client/node_modules/date-fns/docs/i18n.html": {
    "href": "src/frontend/app-client/node_modules/date-fns/docs/i18n.html",
    "title": "Internationalization",
    "summary": "Internationalization Table of Contents Usage Adding New Language Usage There are just a few functions that support I18n: format formatDistance formatDistanceStrict formatRelative To use a locale, you need to require it and then pass as an option to a function: import { formatDistance } from \"date-fns\"; // Require Esperanto locale import { eo } from \"date-fns/locale\"; const result = formatDistance( new Date(2016, 7, 1), new Date(2015, 0, 1), { locale: eo }, // Pass the locale as an option ); //=> 'pli ol 1 jaro' It might seem complicated to require and pass locales as options, but unlike Moment.js which bloats your build with all the locales by default date-fns forces developer to manually require locales when needed. To make API simple, we encourage you to write tiny wrappers and use those instead of original functions: // app/_lib/format.js import { format } from \"date-fns\"; import { enGB, eo, ru } from \"date-fns/locale\"; const locales = { enGB, eo, ru }; // by providing a default string of 'PP' or any of its variants for `formatStr` // it will format dates in whichever way is appropriate to the locale export default function (date, formatStr = \"PP\") { return format(date, formatStr, { locale: locales[window.__localeId__], // or global.__localeId__ }); } // Later: import format from \"app/_lib/format\"; window.__localeId__ = \"enGB\"; format(friday13, \"EEEE d\"); //=> 'Friday 13' window.__localeId__ = \"eo\"; format(friday13, \"EEEE d\"); //=> 'vendredo 13' // If the format string is omitted, it will take the default for the locale. window.__localeId__ = \"enGB\"; format(friday13); //=> Jul 13, 2019 window.__localeId__ = \"eo\"; format(friday13); //=> 2019-jul-13 Adding New Language At the moment there is no definitive guide, so if you feel brave enough, use this quick guide: First of all, create an issue so you won't overlap with others. A detailed explanation of how to add a new locale. Use English locale as the basis and then incrementally adjust the tests and the code. Directions on adding a locale with the same language as another locale. If you have questions or need guidance, leave a comment in the issue. Thank you for your support!"
  },
  "src/frontend/app-client/node_modules/date-fns/docs/i18nContributionGuide.html": {
    "href": "src/frontend/app-client/node_modules/date-fns/docs/i18nContributionGuide.html",
    "title": "I18n Contribution Guide",
    "summary": "I18n Contribution Guide Table of Contents Adding a new locale Choosing a directory name for a locale index.js localize localize.ordinalNumber localize.era and using buildLocalizeFn function Formatting localizers localize.quarter localize.month localize.day localize.dayPeriod formatLong formatLong.dateFormats formatLong.timeFormats formatLong.dateTimeFormats formatRelative match formatDistance Tests Creating a locale with the same language as another locale Adding a new locale To add a new locale: Choose a directory name for it. Copy the content of an existing locale (e.g. en-US) into the newly created directory. Replace the values in the content with yours file-by-file. Use CLDR data as a point of reference which values to choose. All locales contain a number of properties: formatDistance — distance localizer function used by formatDistance and formatDistanceStrict. formatLong — contains long date localizer functions used by format and formatRelative. formatRelative — relative date localizer function used by formatRelative. localize — contains functions, which localize the various date values. Required by format and formatRelative. match — contains functions to parse date values. Required by parse. options — contains the index of the first day of the week for functions such as startOfWeek, and the value which determines the first week of the year for functions like setWeek. Choosing a directory name for a locale Use the four letter code for the directory name (e.g. en-GB), Use the two/three letter code: if the language code and the country code are the same (e.g. pt instead of pt-PT). if the language is used in only one country (e.g. fil instead of fil-PH). if all countries who use the language also use the same regional standards: the first day of the week, the week numbering (see: https://en.wikipedia.org/wiki/Week#The_ISO_week_date_system), calendar date format (see: https://en.wikipedia.org/wiki/Calendar_date) and date representation (see: https://en.wikipedia.org/wiki/Date_and_time_representation_by_country and: https://en.wikipedia.org/wiki/Date_format_by_country) (e.g. ca instead of ca-ES and ca-AD). index.js Locale's index.js is where all the properties of the locale are combined in a single file, documented in JSDoc format. import formatDistance from \"./_lib/formatDistance/index.js\"; import formatLong from \"./_lib/formatLong/index.js\"; import formatRelative from \"./_lib/formatRelative/index.js\"; import localize from \"./_lib/localize/index.js\"; import match from \"./_lib/match/index.js\"; /** * @type {Locale} * @category Locales * * // Name of the locale. * // Inside the parentheses - name of the country - if the locale uses the four letter code, e.g. en-US, fr-CA or pt-BR. * @summary English locale (United States). * * // Name of the language (used by https://date-fns.org/ website) * @language English * * // ISO 639-2 code. See the list here: * // https://www.loc.gov/standards/iso639-2/php/code_list.php * // Used by https://date-fns.org/ to detect the list of the countries that uses the language. * @iso-639-2 eng * * // Authors of the locale (including anyone who corrected or fixed the locale) * @author Sasha Koss [@kossnocorp]{@link https://github.com/kossnocorp} * @author Lesha Koss [@leshakoss]{@link https://github.com/leshakoss} */ var locale = { code: \"en\", formatDistance: formatDistance, formatLong: formatLong, formatRelative: formatRelative, localize: localize, match: match, options: { // Index of the first day of the week. // Sunday is 0, Monday is 1, Saturday is 6. weekStartsOn: 0, // Nth of January which is always in the first week of the year. See: // https://en.wikipedia.org/wiki/Week#The_ISO_week_date_system // http://www.pjh2.de/datetime/weeknumber/wnd.php?l=en firstWeekContainsDate: 1, }, }; export default locale; localize Put this object in _lib/localize/index.js inside your locale directory. Contains a number of functions for used by format: var localize = { ordinalNumber, era, quarter, month, day, dayPeriod, }; export default localize; localize.ordinalNumber Function that takes a numeric argument and returns a string with ordinal number: // In `en-US` locale: function ordinalNumber(dirtyNumber, dirtyOptions) { var number = Number(dirtyNumber); var rem100 = number % 100; if (rem100 > 20 || rem100 < 10) { switch (rem100 % 10) { case 1: return number + \"st\"; case 2: return number + \"nd\"; case 3: return number + \"rd\"; } } return number + \"th\"; } var localize = { ordinalNumber: ordinalNumber, // ... }; If the form of the ordinal number depends on the grammatical case (or other grammatical structures), use options.unit argument which could be one of the values 'year', 'quarter', 'month', 'week', 'date', 'dayOfYear', 'day', 'hour', 'minute' or 'second': // In `ru` locale: function ordinalNumber(dirtyNumber, dirtyOptions) { var options = dirtyOptions || {}; var unit = String(options.unit); var suffix; if (unit === \"date\") { suffix = \"-е\"; } else if (unit === \"week\" || unit === \"minute\" || unit === \"second\") { suffix = \"-я\"; } else { suffix = \"-й\"; } return dirtyNumber + suffix; } localize.era and using buildLocalizeFn function Localizes a numeric era. Takes either 0 or 1 as the first argument. As with many of the localize functions, they can be generated by built-in buildLocalizeFn function. From the CLDR chart, use 'Date & Time'/'Gregorian'/'Eras' values. // In `en-US` locale: import buildLocalizeFn from \"../../../_lib/buildLocalizeFn/index.js\"; var eraValues = { narrow: [\"B\", \"A\"], abbreviated: [\"BC\", \"AD\"], wide: [\"Before Christ\", \"Anno Domini\"], }; var localize = { // ... era: buildLocalizeFn({ values: eraValues, defaultWidth: \"wide\", }), // ... }; export default localize; General usage of the function: var result = locale.localize.era(1, { width: \"abbreviated\" }); //=> 'AD' If width is not provided or the values object does not contain values for the provided width, defaultWidth will be used. defaultWidth should indicate the longest form of the localized value. The same is true for all other localize functions. width for localize.era function could be either 'narrow', 'abbreviated' or 'wide'. var result = locale.localize.era(1, { width: \"foobar\" }); //=> 'Anno Domini' Formatting localizers For some languages, there is a difference between \"stand-alone\" localizers and \"formatting\" localizers. \"Stand-alone\" means that the resulting value should make grammatical sense without context. \"Formatting\" means that the resulting value should be decided using the grammar rules of the language as if the value was a part of a date. For example, for languages with grammatical cases, the stand-alone month could be in the nominative case (\"January\"), and the formatting month could decline as a part of the phrase \"1st of January\". In this case, use parameters formattingValues and defaultFormattingWidth of buildLocalizeFn function. Any localizer could be stand-alone and formatting. Check the CLDR chart for the unit to see if stand-alone and formatting values are different for a certain unit. If there's no difference (usually it happens in languages without grammatical cases), parameters formattingValues and defaultFormattingWidth are not needed. In this example, in Russian language a stand-alone month is in the nominative case (\"январь\"), and formatting month is in the genitive case (\"января\" as in \"1-е января\"). Notice the different endings: // In `ru` locale: var monthValues = { narrow: [\"Я\", \"Ф\", \"М\", \"А\", \"М\", \"И\", \"И\", \"А\", \"С\", \"О\", \"Н\", \"Д\"], abbreviated: [ \"янв.\", \"фев.\", \"март\", \"апр.\", \"май\", \"июнь\", \"июль\", \"авг.\", \"сент.\", \"окт.\", \"нояб.\", \"дек.\", ], wide: [ \"январь\", \"февраль\", \"март\", \"апрель\", \"май\", \"июнь\", \"июль\", \"август\", \"сентябрь\", \"октябрь\", \"ноябрь\", \"декабрь\", ], }; var formattingMonthValues = { narrow: [\"Я\", \"Ф\", \"М\", \"А\", \"М\", \"И\", \"И\", \"А\", \"С\", \"О\", \"Н\", \"Д\"], abbreviated: [ \"янв.\", \"фев.\", \"мар.\", \"апр.\", \"мая\", \"июн.\", \"июл.\", \"авг.\", \"сент.\", \"окт.\", \"нояб.\", \"дек.\", ], wide: [ \"января\", \"февраля\", \"марта\", \"апреля\", \"мая\", \"июня\", \"июля\", \"августа\", \"сентября\", \"октября\", \"ноября\", \"декабря\", ], }; var localize = { // ... month: buildLocalizeFn({ values: monthValues, defaultWidth: \"wide\", formattingValues: formattingMonthValues, defaultFormattingWidth: \"wide\", }), // ... }; export default localize; localize.quarter Localizes a quarter. Takes 1, 2, 3 or 4 as the first argument. width could be either 'narrow', 'abbreviated' or 'wide'. From the CLDR chart, use 'Date & Time'/'Gregorian'/'Quarters' values. // In `en-US` locale: import buildLocalizeFn from \"../../../_lib/buildLocalizeFn/index.js\"; var quarterValues = { narrow: [\"1\", \"2\", \"3\", \"4\"], abbreviated: [\"Q1\", \"Q2\", \"Q3\", \"Q4\"], wide: [\"1st quarter\", \"2nd quarter\", \"3rd quarter\", \"4th quarter\"], }; var localize = { // ... quarter: buildLocalizeFn({ values: quarterValues, defaultWidth: \"wide\", argumentCallback: function (quarter) { return Number(quarter) - 1; }, }), // ... }; export default localize; Note the usage of argumentCallback here. It converts the value passed into localize.quarter function (one of 1, 2, 3 or 4) into the index of the values array inside quarterValues (one of 0, 1, 2 or 3). localize.month Localizes a month. Takes numbers between 0 (for January) and 11 (for December). width could be either 'narrow', 'abbreviated' or 'wide'. From the CLDR chart, use 'Date & Time'/'Gregorian'/'Months' values. // In `en-US` locale: import buildLocalizeFn from \"../../../_lib/buildLocalizeFn/index.js\"; var monthValues = { narrow: [\"J\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\", \"O\", \"N\", \"D\"], abbreviated: [ \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\", ], wide: [ \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\", ], }; var localize = { // ... month: buildLocalizeFn({ values: monthValues, defaultWidth: \"wide\", }), // ... }; export default localize; NOTE: in English, the names of days of the week and months are capitalized. Check if the same is true for the language you're working on. Generally, formatted dates should look like they are in the middle of a sentence, e.g. in Spanish language the weekdays and months should be in the lowercase: // In `es` locale: var monthValues = { narrow: [\"E\", \"F\", \"M\", \"A\", \"M\", \"J\", \"J\", \"A\", \"S\", \"O\", \"N\", \"D\"], abbreviated: [ \"ene.\", \"feb.\", \"mar.\", \"abr.\", \"may.\", \"jun.\", \"jul.\", \"ago.\", \"sep.\", \"oct.\", \"nov.\", \"dic.\", ], wide: [ \"enero\", \"febrero\", \"marzo\", \"abril\", \"mayo\", \"junio\", \"julio\", \"agosto\", \"septiembre\", \"octubre\", \"noviembre\", \"diciembre\", ], }; monthValues.narrow are usually capitalized in every language. Check the CLDR chart for your language. localize.day Localizes a week day. Takes numbers between 0 (for Sunday) and 6 (for Saturday). width could be either 'narrow', 'short', 'abbreviated' or 'wide'. From the CLDR chart, use 'Date & Time'/'Gregorian'/'Days' values. // In `en-US` locale: import buildLocalizeFn from \"../../../_lib/buildLocalizeFn/index.js\"; var dayValues = { narrow: [\"S\", \"M\", \"T\", \"W\", \"T\", \"F\", \"S\"], short: [\"Su\", \"Mo\", \"Tu\", \"We\", \"Th\", \"Fr\", \"Sa\"], abbreviated: [\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"], wide: [ \"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", ], }; var localize = { // ... day: buildLocalizeFn({ values: dayValues, defaultWidth: \"wide\", }), // ... }; export default localize; NOTE: the rules of capitalization from localize.month are also true for localize.day. localize.dayPeriod Localizes a certain day period. Could take one of these strings as the argument: 'am', 'pm', 'midnight', 'noon', 'morning', 'afternoon', 'evening', 'night'. width could be either 'narrow', 'abbreviated' or 'wide'. From the CLDR chart, use 'Date & Time'/'Gregorian'/'Day periods' values. // In `en-US` locale: import buildLocalizeFn from \"../../../_lib/buildLocalizeFn/index.js\"; var dayPeriodValues = { narrow: { am: \"a\", pm: \"p\", midnight: \"mi\", noon: \"n\", morning: \"in the morning\", afternoon: \"in the afternoon\", evening: \"in the evening\", night: \"at night\", }, abbreviated: { am: \"AM\", pm: \"PM\", midnight: \"midnight\", noon: \"noon\", morning: \"in the morning\", afternoon: \"in the afternoon\", evening: \"in the evening\", night: \"at night\", }, wide: { am: \"a.m.\", pm: \"p.m.\", midnight: \"midnight\", noon: \"noon\", morning: \"in the morning\", afternoon: \"in the afternoon\", evening: \"in the evening\", night: \"at night\", }, }; var localize = { // ... dayPeriod: buildLocalizeFn({ values: dayPeriodValues, defaultWidth: \"wide\", }), }; export default localize; formatLong Put this object in _lib/formatLong/index.js inside your locale directory. Locale date formats written in format token string format. See the list of tokens: https://date-fns.org/docs/format Use https://en.wikipedia.org/wiki/Date_format_by_country and CLDR chart as the reference. formatLong.dateFormats Use 'Date & Time'/'Gregorian'/'Formats - Standard - Date Formats' values from the CLDR chart as a reference. // In `en-US` locale import buildFormatLongFn from \"../../../_lib/buildFormatLongFn/index.js\"; var dateFormats = { full: \"EEEE, MMMM do, y\", long: \"MMMM do, y\", medium: \"MMM d, y\", short: \"MM/dd/yyyy\", }; var formatLong = { date: buildFormatLongFn({ formats: dateFormats, defaultWidth: \"full\", }), // ... }; export default formatLong; dateFormats.long usually contains the longest form of writing the year, the month, and the day of the month. Use ordinal day of the month ('do' token) where applicable (date-fns, unlike CLDR supports ordinal numbers). dateFormats.full contains the same but with the day of the week. dateFormats.medium contains the same values as dateFormats.long, but with short form of month and non-ordinal day. dateFormats.short usually contains a strictly numerical form of the date. Pay attention to the order of units (big-, little- or middle-endian) formatLong.timeFormats Use 'Date & Time'/'Gregorian'/'Formats - Standard - Time Formats' values from the CLDR chart as a reference. Use some variation of 'h:mm aa' for 12-hour clock locales or 'H:mm' for 24-hour clock locales. Use the local time separator. // In `en-US` locale import buildFormatLongFn from \"../../../_lib/buildFormatLongFn/index.js\"; var timeFormats = { full: \"h:mm:ss a zzzz\", long: \"h:mm:ss a z\", medium: \"h:mm:ss a\", short: \"h:mm a\", }; var formatLong = { // ... time: buildFormatLongFn({ formats: timeFormats, defaultWidth: \"full\", }), // ... }; export default formatLong; formatLong.dateTimeFormats Use 'Date & Time'/'Gregorian'/'Formats - Standard - Date & Time Combination Formats' values from the CLDR chart. // In `en-US` locale import buildFormatLongFn from \"../../../_lib/buildFormatLongFn/index.js\"; var dateTimeFormats = { full: \"{{date}} 'at' {{time}}\", long: \"{{date}} 'at' {{time}}\", medium: \"{{date}}, {{time}}\", short: \"{{date}}, {{time}}\", }; var formatLong = { // ... dateTime: buildFormatLongFn({ formats: dateTimeFormats, defaultWidth: \"full\", }), }; export default formatLong; '{{date}}' and '{{time}}' from the strings will be replaced with the date and time respectively. formatRelative Put this function in _lib/formatRelative/index.js inside your locale directory. Relative date formats written in format token string format. See the list of tokens: https://date-fns.org/docs/format. Has to process lastWeek, yesterday, today, tomorrow, nextWeek and other tokens. // In `en-US` locale var formatRelativeLocale = { lastWeek: \"'last' eeee 'at' p\", yesterday: \"'yesterday at' p\", today: \"'today at' p\", tomorrow: \"'tomorrow at' p\", nextWeek: \"eeee 'at' p\", other: \"P\", }; export default function formatRelative(token, date, baseDate, options) { return formatRelativeLocale[token]; } You can use date and baseDate supplied to the function for the difficult situations (e.g. grammatical genders and cases of the days of the week). Example is below. Note the different grammatical case for weekdays (accusative instead of nominative) and declension of word \"прошлый\" which depends on the grammatical gender of the weekday: // In `ru` locale var accusativeWeekdays = [ \"воскресенье\", \"понедельник\", \"вторник\", \"среду\", \"четверг\", \"пятницу\", \"субботу\", ]; function lastWeek(day) { var weekday = accusativeWeekdays[day]; switch (day) { case 0: return \"'в прошлое \" + weekday + \" в' p\"; case 1: case 2: case 4: return \"'в прошлый \" + weekday + \" в' p\"; case 3: case 5: case 6: return \"'в прошлую \" + weekday + \" в' p\"; } } function thisWeek(day) { // ... } function nextWeek(day) { // ... } var formatRelativeLocale = { lastWeek: function (date, baseDate, options) { var day = date.getDay(); if (isSameUTCWeek(date, baseDate, options)) { return thisWeek(day); } else { return lastWeek(day); } }, yesterday: \"'вчера в' p\", today: \"'сегодня в' p\", tomorrow: \"'завтра в' p\", nextWeek: function (date, baseDate, options) { var day = date.getDay(); if (isSameUTCWeek(date, baseDate, options)) { return thisWeek(day); } else { return nextWeek(day); } }, other: \"P\", }; export default function formatRelative(token, date, baseDate, options) { var format = formatRelativeLocale[token]; if (typeof format === \"function\") { return format(date, baseDate, options); } return format; } match Put this object in _lib/match/index.js inside your locale directory. Contains the functions used by parse to parse a localized value: // In `en-US` locale: import buildMatchPatternFn from \"../../../_lib/buildMatchPatternFn/index.js\"; import buildMatchFn from \"../../../_lib/buildMatchFn/index.js\"; var matchOrdinalNumberPattern = /^(\\d+)(th|st|nd|rd)?/i; var parseOrdinalNumberPattern = /\\d+/i; var matchEraPatterns = { narrow: /^(b|a)/i, abbreviated: /^(b\\.?\\s?c\\.?|b\\.?\\s?c\\.?\\s?e\\.?|a\\.?\\s?d\\.?|c\\.?\\s?e\\.?)/i, wide: /^(before christ|before common era|anno domini|common era)/i, }; var parseEraPatterns = { any: [/^b/i, /^(a|c)/i], }; var matchQuarterPatterns = { narrow: /^[1234]/i, abbreviated: /^q[1234]/i, wide: /^[1234](th|st|nd|rd)? quarter/i, }; var parseQuarterPatterns = { any: [/1/i, /2/i, /3/i, /4/i], }; var matchMonthPatterns = { narrow: /^[jfmasond]/i, abbreviated: /^(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)/i, wide: /^(january|february|march|april|may|june|july|august|september|october|november|december)/i, }; var parseMonthPatterns = { narrow: [ /^j/i, /^f/i, /^m/i, /^a/i, /^m/i, /^j/i, /^j/i, /^a/i, /^s/i, /^o/i, /^n/i, /^d/i, ], any: [ /^ja/i, /^f/i, /^mar/i, /^ap/i, /^may/i, /^jun/i, /^jul/i, /^au/i, /^s/i, /^o/i, /^n/i, /^d/i, ], }; var matchDayPatterns = { narrow: /^[smtwf]/i, short: /^(su|mo|tu|we|th|fr|sa)/i, abbreviated: /^(sun|mon|tue|wed|thu|fri|sat)/i, wide: /^(sunday|monday|tuesday|wednesday|thursday|friday|saturday)/i, }; var parseDayPatterns = { narrow: [/^s/i, /^m/i, /^t/i, /^w/i, /^t/i, /^f/i, /^s/i], any: [/^su/i, /^m/i, /^tu/i, /^w/i, /^th/i, /^f/i, /^sa/i], }; var matchDayPeriodPatterns = { narrow: /^(a|p|mi|n|(in the|at) (morning|afternoon|evening|night))/i, any: /^([ap]\\.?\\s?m\\.?|midnight|noon|(in the|at) (morning|afternoon|evening|night))/i, }; var parseDayPeriodPatterns = { any: { am: /^a/i, pm: /^p/i, midnight: /^mi/i, noon: /^no/i, morning: /morning/i, afternoon: /afternoon/i, evening: /evening/i, night: /night/i, }, }; var match = { ordinalNumber: buildMatchPatternFn({ matchPattern: matchOrdinalNumberPattern, parsePattern: parseOrdinalNumberPattern, valueCallback: function (value) { return parseInt(value, 10); }, }), era: buildMatchFn({ matchPatterns: matchEraPatterns, defaultMatchWidth: \"wide\", parsePatterns: parseEraPatterns, defaultParseWidth: \"any\", }), quarter: buildMatchFn({ matchPatterns: matchQuarterPatterns, defaultMatchWidth: \"wide\", parsePatterns: parseQuarterPatterns, defaultParseWidth: \"any\", valueCallback: function (index) { return index + 1; }, }), month: buildMatchFn({ matchPatterns: matchMonthPatterns, defaultMatchWidth: \"wide\", parsePatterns: parseMonthPatterns, defaultParseWidth: \"any\", }), day: buildMatchFn({ matchPatterns: matchDayPatterns, defaultMatchWidth: \"wide\", parsePatterns: parseDayPatterns, defaultParseWidth: \"any\", }), dayPeriod: buildMatchFn({ matchPatterns: matchDayPeriodPatterns, defaultMatchWidth: \"any\", parsePatterns: parseDayPeriodPatterns, defaultParseWidth: \"any\", }), }; export default match; These functions mirror those in localize. For matchPatterns the patterns should match the whole meaningful word for the parsed value (which will be cut from the string in the process of parsing). parsePatterns contains patterns to detect one of the values from the result of matchPatterns Note that the patterns for parsePatterns don't necessary contain the whole word: // In `en-US` locale: var parseDayPatterns = { narrow: [/^s/i, /^m/i, /^t/i, /^w/i, /^t/i, /^f/i, /^s/i], any: [/^su/i, /^m/i, /^tu/i, /^w/i, /^th/i, /^f/i, /^sa/i], }; but only the bare minimum to parse the value. Also note that all patterns have \"case-insensitive\" flags to match as much arbitrary user input as possible. For the same reason, try to match any variation of diacritical marks: // In `eo` locale: var matchDayPatterns = { narrow: /^[dlmĵjvs]/i, short: /^(di|lu|ma|me|(ĵ|jx|jh|j)a|ve|sa)/i, abbreviated: /^(dim|lun|mar|mer|(ĵ|jx|jh|j)a(ŭ|ux|uh|u)|ven|sab)/i, wide: /^(diman(ĉ|cx|ch|c)o|lundo|mardo|merkredo|(ĵ|jx|jh|j)a(ŭ|ux|uh|u)do|vendredo|sabato)/i, }; var parseDayPatterns = { narrow: [/^d/i, /^l/i, /^m/i, /^m/i, /^(j|ĵ)/i, /^v/i, /^s/i], any: [/^d/i, /^l/i, /^ma/i, /^me/i, /^(j|ĵ)/i, /^v/i, /^s/i], }; Here, for the word \"dimanĉo\" the functions will match also \"dimancxo\", \"dimancho\" and even grammatically incorrect \"dimanco\". Try to match any possible way of writing the word. Don't forget the grammatical cases: // In `ru` locale: var matchMonthPatterns = { narrow: /^[яфмаисонд]/i, abbreviated: /^(янв|фев|март?|апр|ма[йя]|июн[ья]?|июл[ья]?|авг|сент?|окт|нояб?|дек)/i, wide: /^(январ[ья]|феврал[ья]|марта?|апрел[ья]|ма[йя]|июн[ья]|июл[ья]|августа?|сентябр[ья]|октябр[ья]|октябр[ья]|ноябр[ья]|декабр[ья])/i, }; and variations of short weekdays and months: // In `ru` locale: var matchDayPatterns = { narrow: /^[впсч]/i, short: /^(вс|во|пн|по|вт|ср|чт|че|пт|пя|сб|су)\\.?/i, abbreviated: /^(вск|вос|пнд|пон|втр|вто|срд|сре|чтв|чет|птн|пят|суб).?/i, wide: /^(воскресень[ея]|понедельника?|вторника?|сред[аы]|четверга?|пятниц[аы]|суббот[аы])/i, }; (here, the abbreviated pattern will match both вск and вос as the short of воскресенье {Sunday}) In match.ordinalNumber match ordinal numbers as well as non-ordinal numbers: // In `en-US` locale: var matchOrdinalNumberPattern = /^(\\d+)(th|st|nd|rd)?/i; Don't forget the grammatical genders: // In `ru` locale: var matchOrdinalNumberPattern = /^(\\d+)(-?(е|я|й|ое|ье|ая|ья|ый|ой|ий|ый))?/i; formatDistance formatDistance property of locale is a function which takes three arguments: token passed by date-fns' formatDistance function (e.g. 'lessThanXMinutes'), a number of units to be displayed by the function (e.g. locale.formatDistance('lessThanXMinutes', 5) would display localized 'less than 5 minutes') and object with options. Your best guess is to copy formatDistance property from another locale and change the values. Tests To test locales we use snapshots. See en-US snapshot for an example. To generate snapshots, run npm run locale-snapshots. The snapshot for the locale you're working on will appear in the root locale directory (e.g. src/locales/ru/snapshot.md). Once you are done with the locale, generate the snapshot and review the output values. Creating a locale with the same language as another locale Import the locale properties already implemented for the language, but replace unique properties. // Same as en-US import formatDistance from \"../en-US/_lib/formatDistance/index.js\"; import formatRelative from \"../en-US/_lib/formatRelative/index.js\"; import localize from \"../en-US/_lib/localize/index.js\"; import match from \"../en-US/_lib/match/index.js\"; // Unique for en-GB import formatLong from \"./_lib/formatLong/index.js\"; /** * @type {Locale} * @category Locales * @summary English locale (United Kingdom). * @language English * @iso-639-2 eng * @author John Doe [@example]{@link https://github.com/example} */ var locale = { formatDistance: formatDistance, formatLong: formatLong, formatRelative: formatRelative, localize: localize, match: match, // Unique for en-GB options: { weekStartsOn: 1, firstWeekContainsDate: 4, }, }; export default locale;"
  },
  "src/frontend/app-client/node_modules/date-fns/docs/release.html": {
    "href": "src/frontend/app-client/node_modules/date-fns/docs/release.html",
    "title": "Releasing date-fns",
    "summary": "Releasing date-fns First, make sure that the library is built by running ./scripts/build/build.sh and committing and pushing any change you would have. Then add the changelog entry generated by npx tsx scripts/release/buildChangelog.ts to (CHANGELOG.md)[../CHANGELOG.md]. Make sure that the output is valid Markdown and fix if there're any errors. Commit and push the file. Using the version that the changelog script generated, run the command: env VERSION=\"vX.XX.X\" APP_ENV=\"production\" GOOGLE_APPLICATION_CREDENTIALS=\"secrets/production/key.json\" ./scripts/release/release.sh The script will change package.json. Do not commit the change, and reset it instead. Now when the package is published, go to GitHub Releases and draft a new version using the changelog entry you generated earlier. Finally, write an announce tweet using the created GitHub release as the tweet link. You're done, great job!"
  },
  "src/frontend/app-client/node_modules/date-fns/docs/timeZones.html": {
    "href": "src/frontend/app-client/node_modules/date-fns/docs/timeZones.html",
    "title": "Time zones",
    "summary": "Time zones Starting from v4, date-fns has first-class support for time zones. It is provided via @date-fns/tz and @date-fns/utc packages. Visit the links to learn more about corresponding packages. Just like with everything else in date-fns, the time zones support has a minimal bundle size footprint with UTCDateMini and TZDateMini being 239 B and 761 B, respectively. If you're looking for time zone support prior to date-fns v4, see the third-party date-fns-tz package. See the announcement blog post for details about the motivation and implementation and the change log entry for the list of changes in v4.0. Working with time zones There are two ways to start working with time zones: Using the Date extensions TZDate and UTCDate Using the date-fns functions' in option Using TZDate & UTCDate One way is to use TZDate or UTCDate Date extensions,with regular date-fns functions: import { TZDate } from \"@date-fns/tz\"; import { addHours } from \"date-fns\"; // Given that the system time zone is America/Los_Angeles // where DST happens on Sunday, 13 March 2022, 02:00:00 // Using the system time zone will produce 03:00 instead of 02:00 because of DST: const date = new Date(2022, 2, 13); addHours(date, 2).toString(); //=> 'Sun Mar 13 2022 03:00:00 GMT-0700 (Pacific Daylight Time)' // Using Asia/Singapore will provide the expected 02:00: const tzDate = new TZDate(2022, 2, 13, \"Asia/Singapore\"); addHours(tzDate, 2).toString(); //=> 'Sun Mar 13 2022 02:00:00 GMT+0800 (Singapore Standard Time)' You can safely mix and match regular Date instances, as well as UTCDate or TZDate in different time zones and primitive values (timestamps and strings). date-fns will normalize the arguments, taking the first object argument (Date or a Date extension instance) as the reference and return the result in the reference type: import { TZDate } from \"@date-fns/tz\"; import { differenceInBusinessDays } from \"date-fns\"; const laterDate = new TZDate(2025, 0, 1, \"Asia/Singapore\"); const earlierDate = new TZDate(2024, 0, 1, \"America/New_York\"); // Will calculate in Asia/Singapore differenceInBusinessDays(laterDate, earlierDate); //=> 262 // Will calculate in America/New_York differenceInBusinessDays(earlierDate, laterDate); //=> -261 In the given example, the one-day difference comes from the fact that in New York (UTC-5), the earlierDate will be Dec 31 rather than Jan 1: laterDate.withTimeZone(\"Asia/Singapore\").toString(); //=> 'Wed Jan 01 2025 00:00:00 GMT+0800 (Singapore Standard Time)' earlierDate.withTimeZone(\"Asia/Singapore\").toString(); //=> 'Mon Jan 01 2024 13:00:00 GMT+0800 (Singapore Standard Time)' laterDate.withTimeZone(\"America/New_York\").toString(); //=> 'Tue Dec 31 2024 11:00:00 GMT-0500 (Eastern Standard Time)' earlierDate.withTimeZone(\"America/New_York\").toString(); //=> 'Mon Jan 01 2024 00:00:00 GMT-0500 (Eastern Standard Time)' This is essential to understand and consider when making calculations. Using in option When it is important to get the value in a specific time zone or when you are unsure about the type of arguments, use the function context in option. Each function, where the calculation might be affected by the time zone, like with differenceInBusinessDays, accepts the in option that provides the context for the arguments and the result, so you can explicitly say what time zone to use: import { tz } from \"@date-fns/tz\"; // Will calculate in Asia/Singapore differenceInBusinessDays(laterDate, earlierDate); //=> 262 // Will normalize to America/Los_Angeles differenceInBusinessDays(laterDate, earlierDate, { in: tz(\"America/Los_Angeles\"), }); //=> 261 In the example, we forced differenceInBusinessDays to use the Los Angeles time zone. Further reading Read more about the time zone packages visiting their READMEs: @date-fns/tz @date-fns/utc"
  },
  "src/frontend/app-client/node_modules/date-fns/docs/unicodeTokens.html": {
    "href": "src/frontend/app-client/node_modules/date-fns/docs/unicodeTokens.html",
    "title": "Unicode Tokens",
    "summary": "Unicode Tokens Starting with v2, format and parse use Unicode tokens. The tokens are different from Moment.js and other libraries that opted to use custom formatting rules. While usage of a standard ensures compatibility and the future of the library, it causes confusion that this document intends to resolve. Popular mistakes There are 4 tokens that cause most of the confusion: D and DD that represent the day of a year (1, 2, ..., 365, 366) are often confused with d and dd that represent the day of a month (1, 2, ..., 31). YY and YYYY that represent the local week-numbering year (44, 01, 00, 17) are often confused with yy and yyyy that represent the calendar year. // ❌ Wrong! format(new Date(), \"YYYY-MM-DD\"); //=> 2018-10-283 // ✅ Correct format(new Date(), \"yyyy-MM-dd\"); //=> 2018-10-10 // ❌ Wrong! parse(\"11.02.87\", \"D.MM.YY\", new Date()).toString(); //=> 'Sat Jan 11 1986 00:00:00 GMT+0200 (EET)' // ✅ Correct parse(\"11.02.87\", \"d.MM.yy\", new Date()).toString(); //=> 'Wed Feb 11 1987 00:00:00 GMT+0200 (EET)' To help with the issue, format and parse functions won't accept these tokens without useAdditionalDayOfYearTokens option for D and DD and useAdditionalWeekYearTokens options for YY and YYYY: format(new Date(), \"D\", { useAdditionalDayOfYearTokens: true }); //=> '283' parse(\"365+1987\", \"DD+YYYY\", new Date(), { useAdditionalDayOfYearTokens: true, useAdditionalWeekYearTokens: true, }).toString(); //=> 'Wed Dec 31 1986 00:00:00 GMT+0200 (EET)'"
  },
  "src/frontend/app-client/node_modules/date-fns/docs/webpack.html": {
    "href": "src/frontend/app-client/node_modules/date-fns/docs/webpack.html",
    "title": "webpack",
    "summary": "webpack Removing unused languages from dynamic import If a locale is imported dynamically, then all locales from date-fns are loaded by webpack into a bundle (~160kb) or split across the chunks. This prolongs the build process and increases the amount of space taken. However, it is possible to use webpack to trim down languages using ContextReplacementPlugin. Let's assume that we have a single point in which supported locales are present: config.js: // `see date-fns/src/locale` for available locales export const supportedLocales = [\"en-US\", \"de\", \"pl\", \"it\"]; We could also have a function that formats the date: const getLocale = (locale) => import(`date-fns-locale/locale/${locale}.js`); // or require() if using CommonJS const formatDate = (date, formatStyle, locale) => { return format(date, formatStyle, { locale: getLocale(locale).default, }); }; In order to exclude unused languages we can use webpacks ContextReplacementPlugin. webpack.config.js: import webpack from \"webpack\"; import { supportedLocales } from \"./config.js\"; export default config = { resolve: { alias: { \"date-fns-locale\": path.dirname(require.resolve(\"date-fns/package.json\")), }, }, plugins: [ new webpack.ContextReplacementPlugin( /date-fns[/\\\\]locale/, new RegExp(`(${locales.join(\"|\")})\\.js$`), ), ], }; This results in a language bundle of ~23kb ."
  },
  "src/frontend/app-client/node_modules/date-fns/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/date-fns/LICENSE.html",
    "title": "",
    "summary": "MIT License Copyright (c) 2021 Sasha Koss and Lesha Koss https://kossnocorp.mit-license.org Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/date-fns/README.html": {
    "href": "src/frontend/app-client/node_modules/date-fns/README.html",
    "title": "",
    "summary": "\uD83D\uDD25️ NEW: date-fns v4.0 with first-class time zone support is out! date-fns provides the most comprehensive, yet simple and consistent toolset for manipulating JavaScript dates in a browser & Node.js \uD83D\uDC49 Documentation \uD83D\uDC49 Blog It's like Lodash for dates It has 200+ functions for all occasions. Modular: Pick what you need. Works with webpack, Browserify, or Rollup and also supports tree-shaking. Native dates: Uses existing native type. It doesn't extend core objects for safety's sake. Immutable & Pure: Built using pure functions and always returns a new date instance. TypeScript: The library is 100% TypeScript with brand-new handcrafted types. I18n: Dozens of locales. Include only what you need. and many more benefits import { compareAsc, format } from \"date-fns\"; format(new Date(2014, 1, 11), \"yyyy-MM-dd\"); //=> '2014-02-11' const dates = [ new Date(1995, 6, 2), new Date(1987, 1, 11), new Date(1989, 6, 10), ]; dates.sort(compareAsc); //=> [ // Wed Feb 11 1987 00:00:00, // Mon Jul 10 1989 00:00:00, // Sun Jul 02 1995 00:00:00 // ] The library is available as an npm package. To install the package run: npm install date-fns --save Docs See date-fns.org for more details, API, and other docs. License MIT © Sasha Koss"
  },
  "src/frontend/app-client/node_modules/date-fns/SECURITY.html": {
    "href": "src/frontend/app-client/node_modules/date-fns/SECURITY.html",
    "title": "Security Policy",
    "summary": "Security Policy Supported Versions Security updates are applied only to the latest release. Reporting a Vulnerability If you have discovered a security vulnerability in this project, please report it privately. Do not disclose it as a public issue. This gives us time to work with you to fix the issue before public exposure, reducing the chance that the exploit will be used before a patch is released. Please disclose it to Sasha Koss. This project is maintained by a team of volunteers on a reasonable-effort basis. As such, please give us at least 90 days to work on a fix before public exposure."
  },
  "src/frontend/app-client/node_modules/debug/README.html": {
    "href": "src/frontend/app-client/node_modules/debug/README.html",
    "title": "debug",
    "summary": "debug A tiny JavaScript debugging utility modelled after Node.js core's debugging technique. Works in Node.js and web browsers. Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %o', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var a = require('debug')('worker:a') , b = require('debug')('worker:b'); function work() { a('doing lots of uninteresting work'); setTimeout(work, Math.random() * 1000); } work(); function workb() { b('doing some work'); setTimeout(workb, Math.random() * 2000); } workb(); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows command prompt notes CMD On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Example: set DEBUG=* & node app.js PowerShell (VS Code default) PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Example: $env:DEBUG='app';node app.js Then, run the program to be debugged as usual. npm script example: \"windowsDebug\": \"@powershell -Command $env:DEBUG='*';node app.js\", Namespace Colors Every debug instance has a color generated for it based on its namespace name. This helps when visually parsing the debug output to identify which debug instance a debug line belongs to. Node.js In Node.js, colors are enabled when stderr is a TTY. You also should install the supports-color module alongside debug, otherwise debug will only use a small handful of basic colors. Web Browser Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toISOString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". If you append a \"*\" to the end of your name, it will always be enabled regardless of the setting of the DEBUG environment variable. You can then use it for normal output as well as debug output. Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_HIDE_DATE Hide date from debug output (non-TTY). DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser Support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); In Chromium-based web browsers (e.g. Brave, Chrome, and Electron), the JavaScript console will—by default—only show messages logged by debug if the \"Verbose\" log level is enabled. Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Extend You can simply extend debugger const log = require('debug')('auth'); //creates new debug instance with extended namespace const logSign = log.extend('sign'); const logLogin = log.extend('login'); log('hello'); // auth hello logSign('hello'); //auth:sign hello logLogin('hello'); //auth:login hello Set dynamically You can also enable debug dynamically by calling the enable() method : let debug = require('debug'); console.log(1, debug.enabled('test')); debug.enable('test'); console.log(2, debug.enabled('test')); debug.disable(); console.log(3, debug.enabled('test')); print : 1 false 2 true 3 false Usage : enable(namespaces) namespaces can include modes separated by a colon and wildcards. Note that calling enable() completely overrides previously set DEBUG variable : $ DEBUG=foo node -e 'var dbg = require(\"debug\"); dbg.enable(\"bar\"); console.log(dbg.enabled(\"foo\"))' => false disable() Will disable all namespaces. The functions returns the namespaces currently enabled (and skipped). This can be useful if you want to disable debugging temporarily without knowing what was enabled to begin with. For example: let debug = require('debug'); debug.enable('foo:*,-foo:bar'); let namespaces = debug.disable(); debug.enable(namespaces); Note: There is no guarantee that the string will be identical to the initial enable string, but semantically they will be identical. Checking whether a debug target is enabled After you've created a debug instance, you can determine whether or not it is enabled by checking the enabled property: const debug = require('debug')('http'); if (debug.enabled) { // do stuff... } You can also manually toggle this property to force the debug instance to be enabled or disabled. Usage in child processes Due to the way debug detects if the output is a TTY or not, colors are not shown in child processes when stderr is piped. A solution is to pass the DEBUG_COLORS=1 environment variable to the child process. For example: worker = fork(WORKER_WRAP_PATH, [workerPath], { stdio: [ /* stdin: */ 0, /* stdout: */ 'pipe', /* stderr: */ 'pipe', 'ipc', ], env: Object.assign({}, process.env, { DEBUG_COLORS: 1 // without this settings, colors won't be shown }), }); worker.stderr.pipe(process.stderr, { end: false }); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Josh Junon Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2017 TJ Holowaychuk <tj@vision-media.ca&gt; Copyright (c) 2018-2021 Josh Junon Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/dedent/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/dedent/LICENSE.html",
    "title": "MIT License",
    "summary": "MIT License Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/dedent/README.html": {
    "href": "src/frontend/app-client/node_modules/dedent/README.html",
    "title": "dedent",
    "summary": "dedent A string tag that strips indentation from multi-line strings. ⬅️ Usage npm i dedent import dedent from \"dedent\"; function usageExample() { const first = dedent`A string that gets so long you need to break it over multiple lines. Luckily dedent is here to keep it readable without lots of spaces ending up in the string itself.`; const second = dedent` Leading and trailing lines will be trimmed, so you can write something like this and have it work as you expect: * how convenient it is * that I can use an indented list - and still have it do the right thing That's all. `; const third = dedent(` Wait! I lied. Dedent can also be used as a function. `); return first + \"\\n\\n\" + second + \"\\n\\n\" + third; } console.log(usageExample()); A string that gets so long you need to break it over multiple lines. Luckily dedent is here to keep it readable without lots of spaces ending up in the string itself. Leading and trailing lines will be trimmed, so you can write something like this and have it work as you expect: * how convenient it is * that I can use an indented list - and still have it do the right thing That's all. Wait! I lied. Dedent can also be used as a function. Options You can customize the options dedent runs with by calling its withOptions method with an object: import dedent from 'dedent'; dedent.withOptions({ /* ... */ })`input`; dedent.withOptions({ /* ... */ })(`input`); options returns a new dedent function, so if you'd like to reuse the same options, you can create a dedicated dedent function: import dedent from 'dedent'; const dedenter = dedent.withOptions({ /* ... */ }); dedenter`input`; dedenter(`input`); escapeSpecialCharacters JavaScript string tags by default add an extra \\ escape in front of some special characters such as $ dollar signs. dedent will escape those special characters when called as a string tag. If you'd like to change the behavior, an escapeSpecialCharacters option is available. It defaults to: false: when dedent is called as a function true: when dedent is called as a string tag import dedent from \"dedent\"; // \"$hello!\" dedent` $hello! `; // \"\\$hello!\" dedent.withOptions({ escapeSpecialCharacters: false })` $hello! `; // \"$hello!\" dedent.withOptions({ escapeSpecialCharacters: true })` $hello! `; For more context, see \uD83D\uDE80 Feature: Add an option to disable special character escaping. License MIT Contributors Adrian Jost \uD83D\uDCBB Andri Möll \uD83D\uDC1B Benny Powers - עם ישראל חי! \uD83D\uDD27 Craig Spence \uD83D\uDCBB Desmond Brand \uD83D\uDC1B \uD83D\uDCBB \uD83D\uDCD6 \uD83E\uDD14 \uD83D\uDE87 \uD83D\uDEA7 \uD83D\uDCC6 \uD83D\uDD27 Gareth Jones \uD83D\uDCBB \uD83D\uDC1B Gray Zhang \uD83D\uDC1B Haroen Viaene \uD83D\uDCBB \uD83D\uDEA7 Hyeseong Kim \uD83D\uDD27 \uD83D\uDE87 John L. Armstrong IV \uD83D\uDC1B Josh Goldberg ✨ \uD83D\uDC1B \uD83D\uDCBB \uD83D\uDCD6 \uD83E\uDD14 \uD83D\uDE87 \uD83D\uDEA7 \uD83D\uDCC6 \uD83D\uDD27 Pratap Vardhan \uD83D\uDCBB Simon Lydell \uD83D\uDC1B Yusuke Iinuma \uD83D\uDCBB Yves M. \uD83D\uDD27 d07riv \uD83D\uDC1B mizdra \uD83D\uDCBB sirian \uD83D\uDC1B \uD83D\uDC99 This package was templated with create-typescript-app."
  },
  "src/frontend/app-client/node_modules/depd/History.html": {
    "href": "src/frontend/app-client/node_modules/depd/History.html",
    "title": "2.0.0 / 2018-10-26",
    "summary": "2.0.0 / 2018-10-26 Drop support for Node.js 0.6 Replace internal eval usage with Function constructor Use instance methods on process to check for listeners 1.1.2 / 2018-01-11 perf: remove argument reassignment Support Node.js 0.6 to 9.x 1.1.1 / 2017-07-27 Remove unnecessary Buffer loading Support Node.js 0.6 to 8.x 1.1.0 / 2015-09-14 Enable strict mode in more places Support io.js 3.x Support io.js 2.x Support web browser loading Requires bundler like Browserify or webpack 1.0.1 / 2015-04-07 Fix TypeErrors when under 'use strict' code Fix useless type name on auto-generated messages Support io.js 1.x Support Node.js 0.12 1.0.0 / 2014-09-17 No changes 0.4.5 / 2014-09-09 Improve call speed to functions using the function wrapper Support Node.js 0.6 0.4.4 / 2014-07-27 Work-around v8 generating empty stack traces 0.4.3 / 2014-07-26 Fix exception when global Error.stackTraceLimit is too low 0.4.2 / 2014-07-19 Correct call site for wrapped functions and properties 0.4.1 / 2014-07-19 Improve automatic message generation for function properties 0.4.0 / 2014-07-19 Add TRACE_DEPRECATION environment variable Remove non-standard grey color from color output Support --no-deprecation argument Support --trace-deprecation argument Support deprecate.property(fn, prop, message) 0.3.0 / 2014-06-16 Add NO_DEPRECATION environment variable 0.2.0 / 2014-06-15 Add deprecate.property(obj, prop, message) Remove supports-color dependency for node.js 0.8 0.1.0 / 2014-06-15 Add deprecate.function(fn, message) Add process.on('deprecation', fn) emitter Automatically generate message when omitted from deprecate() 0.0.1 / 2014-06-15 Fix warning for dynamic calls at singe call site 0.0.0 / 2014-06-15 Initial implementation"
  },
  "src/frontend/app-client/node_modules/depd/Readme.html": {
    "href": "src/frontend/app-client/node_modules/depd/Readme.html",
    "title": "depd",
    "summary": "depd Deprecate all the things With great modules comes great responsibility; mark things deprecated! Install This module is installed directly using npm: $ npm install depd This module can also be bundled with systems like Browserify or webpack, though by default this module will alter it's API to no longer display or track deprecations. API var deprecate = require('depd')('my-module') This library allows you to display deprecation messages to your users. This library goes above and beyond with deprecation warnings by introspection of the call stack (but only the bits that it is interested in). Instead of just warning on the first invocation of a deprecated function and never again, this module will warn on the first invocation of a deprecated function per unique call site, making it ideal to alert users of all deprecated uses across the code base, rather than just whatever happens to execute first. The deprecation warnings from this module also include the file and line information for the call into the module that the deprecated function was in. NOTE this library has a similar interface to the debug module, and this module uses the calling file to get the boundary for the call stacks, so you should always create a new deprecate object in each file and not within some central file. depd(namespace) Create a new deprecate function that uses the given namespace name in the messages and will display the call site prior to the stack entering the file this function was called from. It is highly suggested you use the name of your module as the namespace. deprecate(message) Call this function from deprecated code to display a deprecation message. This message will appear once per unique caller site. Caller site is the first call site in the stack in a different file from the caller of this function. If the message is omitted, a message is generated for you based on the site of the deprecate() call and will display the name of the function called, similar to the name displayed in a stack trace. deprecate.function(fn, message) Call this function to wrap a given function in a deprecation message on any call to the function. An optional message can be supplied to provide a custom message. deprecate.property(obj, prop, message) Call this function to wrap a given property on object in a deprecation message on any accessing or setting of the property. An optional message can be supplied to provide a custom message. The method must be called on the object where the property belongs (not inherited from the prototype). If the property is a data descriptor, it will be converted to an accessor descriptor in order to display the deprecation message. process.on('deprecation', fn) This module will allow easy capturing of deprecation errors by emitting the errors as the type \"deprecation\" on the global process. If there are no listeners for this type, the errors are written to STDERR as normal, but if there are any listeners, nothing will be written to STDERR and instead only emitted. From there, you can write the errors in a different format or to a logging source. The error represents the deprecation and is emitted only once with the same rules as writing to STDERR. The error has the following properties: message - This is the message given by the library name - This is always 'DeprecationError' namespace - This is the namespace the deprecation came from stack - This is the stack of the call to the deprecated thing Example error.stack output: DeprecationError: my-cool-module deprecated oldfunction at Object.<anonymous> ([eval]-wrapper:6:22) at Module._compile (module.js:456:26) at evalScript (node.js:532:25) at startup (node.js:80:7) at node.js:902:3 process.env.NO_DEPRECATION As a user of modules that are deprecated, the environment variable NO_DEPRECATION is provided as a quick solution to silencing deprecation warnings from being output. The format of this is similar to that of DEBUG: $ NO_DEPRECATION=my-module,othermod node app.js This will suppress deprecations from being output for \"my-module\" and \"othermod\". The value is a list of comma-separated namespaces. To suppress every warning across all namespaces, use the value * for a namespace. Providing the argument --no-deprecation to the node executable will suppress all deprecations (only available in Node.js 0.8 or higher). NOTE This will not suppress the deperecations given to any \"deprecation\" event listeners, just the output to STDERR. process.env.TRACE_DEPRECATION As a user of modules that are deprecated, the environment variable TRACE_DEPRECATION is provided as a solution to getting more detailed location information in deprecation warnings by including the entire stack trace. The format of this is the same as NO_DEPRECATION: $ TRACE_DEPRECATION=my-module,othermod node app.js This will include stack traces for deprecations being output for \"my-module\" and \"othermod\". The value is a list of comma-separated namespaces. To trace every warning across all namespaces, use the value * for a namespace. Providing the argument --trace-deprecation to the node executable will trace all deprecations (only available in Node.js 0.8 or higher). NOTE This will not trace the deperecations silenced by NO_DEPRECATION. Display When a user calls a function in your library that you mark deprecated, they will see the following written to STDERR (in the given colors, similar colors and layout to the debug module): bright cyan bright yellow | | reset cyan | | | | ▼ ▼ ▼ ▼ my-cool-module deprecated oldfunction [eval]-wrapper:6:22 ▲ ▲ ▲ ▲ | | | | namespace | | location of mycoolmod.oldfunction() call | deprecation message the word \"deprecated\" If the user redirects their STDERR to a file or somewhere that does not support colors, they see (similar layout to the debug module): Sun, 15 Jun 2014 05:21:37 GMT my-cool-module deprecated oldfunction at [eval]-wrapper:6:22 ▲ ▲ ▲ ▲ ▲ | | | | | timestamp of message namespace | | location of mycoolmod.oldfunction() call | deprecation message the word \"deprecated\" Examples Deprecating all calls to a function This will display a deprecated message about \"oldfunction\" being deprecated from \"my-module\" on STDERR. var deprecate = require('depd')('my-cool-module') // message automatically derived from function name // Object.oldfunction exports.oldfunction = deprecate.function(function oldfunction () { // all calls to function are deprecated }) // specific message exports.oldfunction = deprecate.function(function () { // all calls to function are deprecated }, 'oldfunction') Conditionally deprecating a function call This will display a deprecated message about \"weirdfunction\" being deprecated from \"my-module\" on STDERR when called with less than 2 arguments. var deprecate = require('depd')('my-cool-module') exports.weirdfunction = function () { if (arguments.length < 2) { // calls with 0 or 1 args are deprecated deprecate('weirdfunction args < 2') } } When calling deprecate as a function, the warning is counted per call site within your own module, so you can display different deprecations depending on different situations and the users will still get all the warnings: var deprecate = require('depd')('my-cool-module') exports.weirdfunction = function () { if (arguments.length < 2) { // calls with 0 or 1 args are deprecated deprecate('weirdfunction args < 2') } else if (typeof arguments[0] !== 'string') { // calls with non-string first argument are deprecated deprecate('weirdfunction non-string first arg') } } Deprecating property access This will display a deprecated message about \"oldprop\" being deprecated from \"my-module\" on STDERR when accessed. A deprecation will be displayed when setting the value and when getting the value. var deprecate = require('depd')('my-cool-module') exports.oldprop = 'something' // message automatically derives from property name deprecate.property(exports, 'oldprop') // explicit message deprecate.property(exports, 'oldprop', 'oldprop >= 0.10') License MIT"
  },
  "src/frontend/app-client/node_modules/dequal/readme.html": {
    "href": "src/frontend/app-client/node_modules/dequal/readme.html",
    "title": "dequal",
    "summary": "dequal A tiny (304B to 489B) utility to check for deep equality This module supports comparison of all types, including Function, RegExp, Date, Set, Map, TypedArrays, DataView, null, undefined, and NaN values. Complex values (eg, Objects, Arrays, Sets, Maps, etc) are traversed recursively. Important: key order within Objects does not matter value order within Arrays does matter values within Sets and Maps use value equality keys within Maps use value equality Install $ npm install --save dequal Modes There are two \"versions\" of dequal available: dequal Size (gzip): 489 bytes Availability: CommonJS, ES Module, UMD dequal/lite Size (gzip): 304 bytes Availability: CommonJS, ES Module IE9+ Number String Date RegExp Object Array Class Set Map ArrayBuffer TypedArray DataView dequal ❌ ✅ ✅ ✅ ✅ ✅ ✅ ✅ ✅ ✅ ✅ ✅ ✅ dequal/lite \uD83D\uDC4D ✅ ✅ ✅ ✅ ✅ ✅ ✅ ❌ ❌ ❌ ❌ ❌ Note: Table scrolls horizontally! Usage import { dequal } from 'dequal'; dequal(1, 1); //=> true dequal({}, {}); //=> true dequal('foo', 'foo'); //=> true dequal([1, 2, 3], [1, 2, 3]); //=> true dequal(dequal, dequal); //=> true dequal(/foo/, /foo/); //=> true dequal(null, null); //=> true dequal(NaN, NaN); //=> true dequal([], []); //=> true dequal( [{ a:1 }, [{ b:{ c:[1] } }]], [{ a:1 }, [{ b:{ c:[1] } }]] ); //=> true dequal(1, '1'); //=> false dequal(null, undefined); //=> false dequal({ a:1, b:[2,3] }, { a:1, b:[2,5] }); //=> false dequal(/foo/i, /bar/g); //=> false API dequal(foo, bar) Returns: Boolean Both foo and bar can be of any type. A Boolean is returned indicating if the two were deeply equal. Benchmarks Running Node v10.13.0 The benchmarks can be found in the /bench directory. They are separated into two categories: basic – compares an object comprised of String, Number, Date, Array, and Object values. complex – like basic, but adds RegExp, Map, Set, and Uint8Array values. Note: Only candidates that pass validation step(s) are listed. For example, fast-deep-equal/es6 handles Set and Map values, but uses referential equality while those listed use value equality. Load times: assert 0.109ms util 0.006ms fast-deep-equal 0.479ms lodash/isequal 22.826ms nano-equal 0.417ms dequal 0.396ms dequal/lite 0.264ms Benchmark :: basic assert.deepStrictEqual x 325,262 ops/sec ±0.57% (94 runs sampled) util.isDeepStrictEqual x 318,812 ops/sec ±0.87% (94 runs sampled) fast-deep-equal x 1,332,393 ops/sec ±0.36% (93 runs sampled) lodash.isEqual x 269,129 ops/sec ±0.59% (95 runs sampled) nano-equal x 1,122,053 ops/sec ±0.36% (96 runs sampled) dequal/lite x 1,700,972 ops/sec ±0.31% (94 runs sampled) dequal x 1,698,972 ops/sec ±0.63% (97 runs sampled) Benchmark :: complex assert.deepStrictEqual x 124,518 ops/sec ±0.64% (96 runs sampled) util.isDeepStrictEqual x 125,113 ops/sec ±0.24% (96 runs sampled) lodash.isEqual x 58,677 ops/sec ±0.49% (96 runs sampled) dequal x 345,386 ops/sec ±0.27% (96 runs sampled) License MIT © Luke Edwards"
  },
  "src/frontend/app-client/node_modules/destroy/README.html": {
    "href": "src/frontend/app-client/node_modules/destroy/README.html",
    "title": "destroy",
    "summary": "destroy Destroy a stream. This module is meant to ensure a stream gets destroyed, handling different APIs and Node.js bugs. API var destroy = require('destroy') destroy(stream [, suppress]) Destroy the given stream, and optionally suppress any future error events. In most cases, this is identical to a simple stream.destroy() call. The rules are as follows for a given stream: If the stream is an instance of ReadStream, then call stream.destroy() and add a listener to the open event to call stream.close() if it is fired. This is for a Node.js bug that will leak a file descriptor if .destroy() is called before open. If the stream is an instance of a zlib stream, then call stream.destroy() and close the underlying zlib handle if open, otherwise call stream.close(). This is for consistency across Node.js versions and a Node.js bug that will leak a native zlib handle. If the stream is not an instance of Stream, then nothing happens. If the stream has a .destroy() method, then call it. The function returns the stream passed in as the argument. Example var destroy = require('destroy') var fs = require('fs') var stream = fs.createReadStream('package.json') // ... and later destroy(stream)"
  },
  "src/frontend/app-client/node_modules/detect-libc/README.html": {
    "href": "src/frontend/app-client/node_modules/detect-libc/README.html",
    "title": "detect-libc",
    "summary": "detect-libc Node.js module to detect details of the C standard library (libc) implementation provided by a given Linux system. Currently supports detection of GNU glibc and MUSL libc. Provides asychronous and synchronous functions for the family (e.g. glibc, musl) and version (e.g. 1.23, 1.2.3). The version numbers of libc implementations are not guaranteed to be semver-compliant. For previous v1.x releases, please see the v1 branch. Install npm install detect-libc API GLIBC const GLIBC: string = 'glibc'; A String constant containing the value glibc. MUSL const MUSL: string = 'musl'; A String constant containing the value musl. family function family(): Promise<string | null>; Resolves asychronously with: glibc or musl when the libc family can be determined null when the libc family cannot be determined null when run on a non-Linux platform const { family, GLIBC, MUSL } = require('detect-libc'); switch (await family()) { case GLIBC: ... case MUSL: ... case null: ... } familySync function familySync(): string | null; Synchronous version of family(). const { familySync, GLIBC, MUSL } = require('detect-libc'); switch (familySync()) { case GLIBC: ... case MUSL: ... case null: ... } version function version(): Promise<string | null>; Resolves asychronously with: The version when it can be determined null when the libc family cannot be determined null when run on a non-Linux platform const { version } = require('detect-libc'); const v = await version(); if (v) { const [major, minor, patch] = v.split('.'); } versionSync function versionSync(): string | null; Synchronous version of version(). const { versionSync } = require('detect-libc'); const v = versionSync(); if (v) { const [major, minor, patch] = v.split('.'); } isNonGlibcLinux function isNonGlibcLinux(): Promise<boolean>; Resolves asychronously with: false when the libc family is glibc true when the libc family is not glibc false when run on a non-Linux platform const { isNonGlibcLinux } = require('detect-libc'); if (await isNonGlibcLinux()) { ... } isNonGlibcLinuxSync function isNonGlibcLinuxSync(): boolean; Synchronous version of isNonGlibcLinux(). const { isNonGlibcLinuxSync } = require('detect-libc'); if (isNonGlibcLinuxSync()) { ... } Licensing Copyright 2017 Lovell Fuller and others. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
  },
  "src/frontend/app-client/node_modules/detect-node-es/Readme.html": {
    "href": "src/frontend/app-client/node_modules/detect-node-es/Readme.html",
    "title": "",
    "summary": "detect-node This is a fork of detect-node. Differences: uses named export {isNode} has d.ts integrated supports ESM Install npm install --save detect-node-es Usage: -var isNode = require('detect-node'); +var {isNode} = require('detect-node-es'); if (isNode) { console.log(\"Running under Node.JS\"); } else { alert(\"Hello from browser (or whatever not-a-node env)\"); } The check is performed as: module.exports = false; // Only Node.JS has a process variable that is of [[Class]] process try { module.exports = Object.prototype.toString.call(global.process) === '[object process]' } catch(e) {} Thanks to Ingvar Stepanyan for the initial idea. This check is both the most reliable I could find and it does not use process env directly, which would cause browserify to include it into the build."
  },
  "src/frontend/app-client/node_modules/diff/CONTRIBUTING.html": {
    "href": "src/frontend/app-client/node_modules/diff/CONTRIBUTING.html",
    "title": "How to Contribute",
    "summary": "How to Contribute Pull Requests We also accept [pull requests][pull-request]! Generally we like to see pull requests that Maintain the existing code style Are focused on a single change (i.e. avoid large refactoring or style adjustments in untouched code if not the primary goal of the pull request) Have good commit messages Have tests Don't decrease the current code coverage (see coverage/lcov-report/index.html) Building yarn yarn test Running yarn test -- dev will watch for tests within Node and karma start may be used for manual testing in browsers. If you notice any problems, please report them to the GitHub issue tracker at http://github.com/kpdecker/jsdiff/issues. Releasing A full release may be completed with the following: yarn clean yarn grunt yarn grunt uglify yarn publish"
  },
  "src/frontend/app-client/node_modules/diff/README.html": {
    "href": "src/frontend/app-client/node_modules/diff/README.html",
    "title": "jsdiff",
    "summary": "jsdiff A JavaScript text differencing implementation. Try it out in the online demo. Based on the algorithm proposed in \"An O(ND) Difference Algorithm and its Variations\" (Myers, 1986). Installation npm install diff --save Usage Broadly, jsdiff's diff functions all take an old text and a new text and perform three steps: Split both texts into arrays of \"tokens\". What constitutes a token varies; in diffChars, each character is a token, while in diffLines, each line is a token. Find the smallest set of single-token insertions and deletions needed to transform the first array of tokens into the second. This step depends upon having some notion of a token from the old array being \"equal\" to one from the new array, and this notion of equality affects the results. Usually two tokens are equal if === considers them equal, but some of the diff functions use an alternative notion of equality or have options to configure it. For instance, by default diffChars(\"Foo\", \"FOOD\") will require two deletions (o, o) and three insertions (O, O, D), but diffChars(\"Foo\", \"FOOD\", {ignoreCase: true}) will require just one insertion (of a D), since ignoreCase causes o and O to be considered equal. Return an array representing the transformation computed in the previous step as a series of change objects. The array is ordered from the start of the input to the end, and each change object represents inserting one or more tokens, deleting one or more tokens, or keeping one or more tokens. API Diff.diffChars(oldStr, newStr[, options]) - diffs two blocks of text, treating each character as a token. Returns a list of change objects. Options ignoreCase: If true, the uppercase and lowercase forms of a character are considered equal. Defaults to false. Diff.diffWords(oldStr, newStr[, options]) - diffs two blocks of text, treating each word and each word separator (punctuation, newline, or run of whitespace) as a token. (Whitespace-only tokens are automatically treated as equal to each other, so changes like changing a space to a newline or a run of multiple spaces will be ignored.) Returns a list of change objects. Options ignoreCase: Same as in diffChars. Defaults to false. Diff.diffWordsWithSpace(oldStr, newStr[, options]) - same as diffWords, except whitespace-only tokens are not automatically considered equal, so e.g. changing a space to a tab is considered a change. Diff.diffLines(oldStr, newStr[, options]) - diffs two blocks of text, treating each line as a token. Options ignoreWhitespace: true to strip all leading and trailing whitespace characters from each line before performing the diff. Defaults to false. stripTrailingCr: true to remove all trailing CR (\\r) characters before performing the diff. Defaults to false. This helps to get a useful diff when diffing UNIX text files against Windows text files. newlineIsToken: true to treat the newline character at the end of each line as its own token. This allows for changes to the newline structure to occur independently of the line content and to be treated as such. In general this is the more human friendly form of diffLines; the default behavior with this option turned off is better suited for patches and other computer friendly output. Defaults to false. Returns a list of change objects. Diff.diffTrimmedLines(oldStr, newStr[, options]) - diffs two blocks of text, comparing line by line, after stripping leading and trailing whitespace. Equivalent to calling diffLines with ignoreWhitespace: true. Options stripTrailingCr: Same as in diffLines. Defaults to false. newlineIsToken: Same as in diffLines. Defaults to false. Returns a list of change objects. Diff.diffSentences(oldStr, newStr[, options]) - diffs two blocks of text, treating each sentence as a token. Returns a list of change objects. Diff.diffCss(oldStr, newStr[, options]) - diffs two blocks of text, comparing CSS tokens. Returns a list of change objects. Diff.diffJson(oldObj, newObj[, options]) - diffs two JSON-serializable objects by first serializing them to prettily-formatted JSON and then treating each line of the JSON as a token. Object properties are ordered alphabetically in the serialized JSON, so the order of properties in the objects being compared doesn't affect the result. Returns a list of change objects. Options stringifyReplacer: A custom replacer function. Operates similarly to the replacer parameter to JSON.stringify(), but must be a function. undefinedReplacement: A value to replace undefined with. Ignored if a stringifyReplacer is provided. Diff.diffArrays(oldArr, newArr[, options]) - diffs two arrays of tokens, comparing each item for strict equality (===). Options comparator: function(left, right) for custom equality checks Returns a list of change objects. Diff.createTwoFilesPatch(oldFileName, newFileName, oldStr, newStr[, oldHeader[, newHeader[, options]]]) - creates a unified diff patch by first computing a diff with diffLines and then serializing it to unified diff format. Parameters: oldFileName : String to be output in the filename section of the patch for the removals newFileName : String to be output in the filename section of the patch for the additions oldStr : Original string value newStr : New string value oldHeader : Optional additional information to include in the old file header. Default: undefined. newHeader : Optional additional information to include in the new file header. Default: undefined. options : An object with options. context describes how many lines of context should be included. You can set this to Number.MAX_SAFE_INTEGER or Infinity to include the entire file content in one hunk. ignoreWhitespace: Same as in diffLines. Defaults to false. stripTrailingCr: Same as in diffLines. Defaults to false. newlineIsToken: Same as in diffLines. Defaults to false. Diff.createPatch(fileName, oldStr, newStr[, oldHeader[, newHeader[, options]]]) - creates a unified diff patch. Just like Diff.createTwoFilesPatch, but with oldFileName being equal to newFileName. Diff.formatPatch(patch) - creates a unified diff patch. patch may be either a single structured patch object (as returned by structuredPatch) or an array of them (as returned by parsePatch). Diff.structuredPatch(oldFileName, newFileName, oldStr, newStr[, oldHeader[, newHeader[, options]]]) - returns an object with an array of hunk objects. This method is similar to createTwoFilesPatch, but returns a data structure suitable for further processing. Parameters are the same as createTwoFilesPatch. The data structure returned may look like this: { oldFileName: 'oldfile', newFileName: 'newfile', oldHeader: 'header1', newHeader: 'header2', hunks: [{ oldStart: 1, oldLines: 3, newStart: 1, newLines: 3, lines: [' line2', ' line3', '-line4', '+line5', '\\\\ No newline at end of file'], }] } Diff.applyPatch(source, patch[, options]) - attempts to apply a unified diff patch. If the patch was applied successfully, returns a string containing the patched text. If the patch could not be applied (because some hunks in the patch couldn't be fitted to the text in source), returns false. patch may be a string diff or the output from the parsePatch or structuredPatch methods. The optional options object may have the following keys: fuzzFactor: Number of lines that are allowed to differ before rejecting a patch. Defaults to 0. compareLine(lineNumber, line, operation, patchContent): Callback used to compare to given lines to determine if they should be considered equal when patching. Defaults to strict equality but may be overridden to provide fuzzier comparison. Should return false if the lines should be rejected. Diff.applyPatches(patch, options) - applies one or more patches. patch may be either an array of structured patch objects, or a string representing a patch in unified diff format (which may patch one or more files). This method will iterate over the contents of the patch and apply to data provided through callbacks. The general flow for each patch index is: options.loadFile(index, callback) is called. The caller should then load the contents of the file and then pass that to the callback(err, data) callback. Passing an err will terminate further patch execution. options.patched(index, content, callback) is called once the patch has been applied. content will be the return value from applyPatch. When it's ready, the caller should call callback(err) callback. Passing an err will terminate further patch execution. Once all patches have been applied or an error occurs, the options.complete(err) callback is made. Diff.parsePatch(diffStr) - Parses a patch into structured data Return a JSON object representation of the a patch, suitable for use with the applyPatch method. This parses to the same structure returned by Diff.structuredPatch. Diff.reversePatch(patch) - Returns a new structured patch which when applied will undo the original patch. patch may be either a single structured patch object (as returned by structuredPatch) or an array of them (as returned by parsePatch). Diff.convertChangesToXML(changes) - converts a list of change objects to a serialized XML format Diff.convertChangesToDMP(changes) - converts a list of change objects to the format returned by Google's diff-match-patch library Universal options Certain options can be provided in the options object of any method that calculates a diff: callback: if provided, the diff will be computed in async mode to avoid blocking the event loop while the diff is calculated. The value of the callback option should be a function and will be passed the result of the diff as its second argument. The first argument will always be undefined. Only works with functions that return change objects, like diffLines, not those that return patches, like structuredPatch or createPatch. (Note that if the ONLY option you want to provide is a callback, you can pass the callback function directly as the options parameter instead of passing an object with a callback property.) maxEditLength: a number specifying the maximum edit distance to consider between the old and new texts. If the edit distance is higher than this, jsdiff will return undefined instead of a diff. You can use this to limit the computational cost of diffing large, very different texts by giving up early if the cost will be huge. Works for functions that return change objects and also for structuredPatch, but not other patch-generation functions. timeout: a number of milliseconds after which the diffing algorithm will abort and return undefined. Supported by the same functions as maxEditLength. Defining custom diffing behaviors If you need behavior a little different to what any of the text diffing functions above offer, you can roll your own by customizing both the tokenization behavior used and the notion of equality used to determine if two tokens are equal. The simplest way to customize tokenization behavior is to simply tokenize the texts you want to diff yourself, with your own code, then pass the arrays of tokens to diffArrays. For instance, if you wanted a semantically-aware diff of some code, you could try tokenizing it using a parser specific to the programming language the code is in, then passing the arrays of tokens to diffArrays. To customize the notion of token equality used, use the comparator option to diffArrays. For even more customisation of the diffing behavior, you can create a new Diff.Diff() object, overwrite its castInput, tokenize, removeEmpty, equals, and join properties with your own functions, then call its diff(oldString, newString[, options]) method. The methods you can overwrite are used as follows: castInput(value): used to transform the oldString and newString before any other steps in the diffing algorithm happen. For instance, diffJson uses castInput to serialize the objects being diffed to JSON. Defaults to a no-op. tokenize(value): used to convert each of oldString and newString (after they've gone through castInput) to an array of tokens. Defaults to returning value.split('') (returning an array of individual characters). removeEmpty(array): called on the arrays of tokens returned by tokenize and can be used to modify them. Defaults to stripping out falsey tokens, such as empty strings. diffArrays overrides this to simply return the array, which means that falsey values like empty strings can be handled like any other token by diffArrays. equals(left, right): called to determine if two tokens (one from the old string, one from the new string) should be considered equal. Defaults to comparing them with ===. join(tokens): gets called with an array of consecutive tokens that have either all been added, all been removed, or are all common. Needs to join them into a single value that can be used as the value property of the change object for these tokens. Defaults to simply returning tokens.join(''). Change Objects Many of the methods above return change objects. These objects consist of the following fields: value: The concatenated content of all the tokens represented by this change object - i.e. generally the text that is either added, deleted, or common, as a single string. In cases where tokens are considered common but are non-identical (e.g. because an option like ignoreCase or a custom comparator was used), the value from the new string will be provided here. added: True if the value was inserted into the new string removed: True if the value was removed from the old string count: How many tokens (e.g. chars for diffChars, lines for diffLines) the value in the change object consists of (Change objects where added and removed are both falsey represent content that is common to the old and new strings.) Note that some cases may omit a particular flag field. Comparison on the flag fields should always be done in a truthy or falsy manner. Examples Basic example in Node require('colors'); const Diff = require('diff'); const one = 'beep boop'; const other = 'beep boob blah'; const diff = Diff.diffChars(one, other); diff.forEach((part) => { // green for additions, red for deletions let text = part.added ? part.value.bgGreen : part.removed ? part.value.bgRed : part.value; process.stderr.write(text); }); console.log(); Running the above program should yield Basic example in a web page <pre id=\"display\"></pre> <script src=\"diff.js\"></script> <script> const one = 'beep boop', other = 'beep boob blah', color = ''; let span = null; const diff = Diff.diffChars(one, other), display = document.getElementById('display'), fragment = document.createDocumentFragment(); diff.forEach((part) => { // green for additions, red for deletions // grey for common parts const color = part.added ? 'green' : part.removed ? 'red' : 'grey'; span = document.createElement('span'); span.style.color = color; span.appendChild(document .createTextNode(part.value)); fragment.appendChild(span); }); display.appendChild(fragment); </script> Open the above .html file in a browser and you should see Example of generating a patch from Node The code below is roughly equivalent to the Unix command diff -u file1.txt file2.txt > mydiff.patch: const Diff = require('diff'); const file1Contents = fs.readFileSync(\"file1.txt\").toString(); const file2Contents = fs.readFileSync(\"file2.txt\").toString(); const patch = Diff.createTwoFilesPatch(\"file1.txt\", \"file2.txt\", file1Contents, file2Contents); fs.writeFileSync(\"mydiff.patch\", patch); Examples of parsing and applying a patch from Node Applying a patch to a specified file The code below is roughly equivalent to the Unix command patch file1.txt mydiff.patch: const Diff = require('diff'); const file1Contents = fs.readFileSync(\"file1.txt\").toString(); const patch = fs.readFileSync(\"mydiff.patch\").toString(); const patchedFile = Diff.applyPatch(file1Contents, patch); fs.writeFileSync(\"file1.txt\", patchedFile); Applying a multi-file patch to the files specified by the patch file itself The code below is roughly equivalent to the Unix command patch < mydiff.patch: const Diff = require('diff'); const patch = fs.readFileSync(\"mydiff.patch\").toString(); Diff.applyPatches(patch, { loadFile: (patch, callback) => { let fileContents; try { fileContents = fs.readFileSync(patch.oldFileName).toString(); } catch (e) { callback(`No such file: ${patch.oldFileName}`); return; } callback(undefined, fileContents); }, patched: (patch, patchedContent, callback) => { if (patchedContent === false) { callback(`Failed to apply patch to ${patch.oldFileName}`) return; } fs.writeFileSync(patch.oldFileName, patchedContent); callback(); }, complete: (err) => { if (err) { console.log(\"Failed with error:\", err); } } }); Compatibility jsdiff supports all ES3 environments with some known issues on IE8 and below. Under these browsers some diff algorithms such as word diff and others may fail due to lack of support for capturing groups in the split operation. License See LICENSE. Deviations from the published Myers diff algorithm jsdiff deviates from the published algorithm in a couple of ways that don't affect results but do affect performance: jsdiff keeps track of the diff for each diagonal using a linked list of change objects for each diagonal, rather than the historical array of furthest-reaching D-paths on each diagonal contemplated on page 8 of Myers's paper. jsdiff skips considering diagonals where the furthest-reaching D-path would go off the edge of the edit graph. This dramatically reduces the time cost (from quadratic to linear) in cases where the new text just appends or truncates content at the end of the old text."
  },
  "src/frontend/app-client/node_modules/diff/release-notes.html": {
    "href": "src/frontend/app-client/node_modules/diff/release-notes.html",
    "title": "Release Notes",
    "summary": "Release Notes v5.2.0 Commits #411 Big performance improvement. Previously an O(n) array-copying operation inside the innermost loop of jsdiff's base diffing code increased the overall worst-case time complexity of computing a diff from O(n²) to O(n³). This is now fixed, bringing the worst-case time complexity down to what it theoretically should be for a Myers diff implementation. #448 Performance improvement. Diagonals whose furthest-reaching D-path would go off the edge of the edit graph are now skipped, rather than being pointlessly considered as called for by the original Myers diff algorithm. This dramatically speeds up computing diffs where the new text just appends or truncates content at the end of the old text. #351 Importing from the lib folder - e.g. require(\"diff/lib/diff/word.js\") - will work again now. This had been broken for users on the latest version of Node since Node 17.5.0, which changed how Node interprets the exports property in jsdiff's package.json file. #344 diffLines, createTwoFilesPatch, and other patch-creation methods now take an optional stripTrailingCr: true option which causes Windows-style \\r\\n line endings to be replaced with Unix-style \\n line endings before calculating the diff, just like GNU diff's --strip-trailing-cr flag. #451 Added diff.formatPatch. #450 Added diff.reversePatch. #478 Added timeout option. v5.1.0 #365 Allow early termination to limit execution time with degenerate cases Commits v5.0.0 Breaking: UMD export renamed from JsDiff to Diff. Breaking: Newlines separated into separate tokens for word diff. Breaking: Unified diffs now match \"quirks\" Commits v4.0.1 - January 6th, 2019 Fix main reference path - b826104 Commits v4.0.0 - January 5th, 2019 #94 - Missing \"No newline at end of file\" when comparing two texts that do not end in newlines (@federicotdn) #227 - Licence #199 - Import statement for jsdiff #159 - applyPatch affecting wrong line number with with new lines #8 - A new state \"replace\" Drop ie9 from karma targets - 79c31bd Upgrade deps. Convert from webpack to rollup - 2c1a29c Make ()[]\"' as word boundaries between each other - f27b899 jsdiff: Replaced phantomJS by chrome - ec3114e Add yarn.lock to .npmignore - 29466d8 Compatibility notes: Bower and Component packages no longer supported Commits v3.5.0 - March 4th, 2018 Omit redundant slice in join method of diffArrays - 1023590 Support patches with empty lines - fb0f208 Accept a custom JSON replacer function for JSON diffing - 69c7f0a Optimize parch header parser - 2aec429 Fix typos - e89c832 Commits v3.4.0 - October 7th, 2017 #183 - Feature request: ability to specify a custom equality checker for diffArrays #173 - Bug: diffArrays gives wrong result on array of booleans #158 - diffArrays will not compare the empty string in array? comparator for custom equality checks - 30e141e count oldLines and newLines when there are conflicts - 53bf384 Fix: diffArrays can compare falsey items - 9e24284 Docs: Replace grunt with npm test - 00e2f94 Commits v3.3.1 - September 3rd, 2017 #141 - Cannot apply patch because my file delimiter is \"/r/n\" instead of \"/n\" #192 - Fix: Bad merge when adding new files (#189) correct spelling mistake - 21fa478 Commits v3.3.0 - July 5th, 2017 #114 - /patch/merge not exported Gracefully accept invalid newStart in hunks, same as patch(1) does. - d8a3635 Use regex rather than starts/ends with for parsePatch - 6cab62c Add browser flag - e64f674 refactor: simplified code a bit more - 8f8e0f2 refactor: simplified code a bit - b094a6f fix: some corrections re ignoreCase option - 3c78fd0 ignoreCase option - 3cbfbb5 Sanitize filename while parsing patches - 2fe8129 Added better installation methods - aced50b Simple export of functionality - 8690f31 Commits v3.2.0 - December 26th, 2016 #156 - Add undefinedReplacement option to diffJson (@ewnd9) #154 - Add examples and images to .npmignore. (@wtgtybhertgeghgtwtg) #153 - feat(structuredPatch): Pass options to diffLines (@Kiougar) Commits v3.1.0 - November 27th, 2016 #146 - JsDiff.diffArrays to compare arrays (@wvanderdeijl) #144 - Split file using all possible line delimiter instead of hard-coded \"/n\" and join lines back using the original delimiters (@soulbeing) Commits v3.0.1 - October 9th, 2016 #139 - Make README.md look nicer in npmjs.com (@takenspc) #135 - parsePatch combines patches from multiple files into a single IUniDiff when there is no \"Index\" line (@ramya-rao-a) #124 - IE7/IE8 failure since 2.0.0 (@boneskull) Commits v3.0.0 - August 23rd, 2016 #130 - Add callback argument to applyPatches patched option (@piranna) #120 - Correctly handle file names containing spaces (@adius) #119 - Do single reflow (@wifiextender) #117 - Make more usable with long strings. (@abnbgist) Compatibility notes: applyPatches patch callback now is async and requires the callback be called to continue operation Commits v2.2.3 - May 31st, 2016 #118 - Add a fix for applying 0-length destination patches (@chaaz) #115 - Fixed grammar in README (@krizalys) #113 - fix typo (@vmazare) Commits v2.2.2 - March 13th, 2016 #102 - diffJson with dates, returns empty curly braces (@dr-dimitru) #97 - Whitespaces & diffWords (@faiwer) #92 - Fixes typo in the readme (@bg451) Commits v2.2.1 - November 12th, 2015 #89 - add in display selector to readme (@FranDias) #88 - Split diffs based on file headers instead of 'Index:' metadata (@piranna) Commits v2.2.0 - October 29th, 2015 #80 - Fix a typo: applyPath -> applyPatch (@fluxxu) #83 - Add basic fuzzy matching to applyPatch (@piranna) Commits v2.2.0 - October 29th, 2015 #80 - Fix a typo: applyPath -> applyPatch (@fluxxu) #83 - Add basic fuzzy matching to applyPatch (@piranna) Commits v2.1.3 - September 30th, 2015 #78 - fix: error throwing when apply patch to empty string (@21paradox) Commits v2.1.2 - September 23rd, 2015 #76 - diff headers give error (@piranna) Commits v2.1.1 - September 9th, 2015 #73 - Is applyPatches() exposed in the API? (@davidparsson) Commits v2.1.0 - August 27th, 2015 #72 - Consider using options object API for flag permutations (@kpdecker) #70 - diffWords treats \\n at the end as significant whitespace (@nesQuick) #69 - Missing count (@wfalkwallace) #68 - diffLines seems broken (@wfalkwallace) #60 - Support multiple diff hunks (@piranna) #54 - Feature Request: 3-way merge (@mog422) #42 - Fuzz factor for applyPatch (@stuartpb) Move whitespace ignore out of equals method - 542063c Include source maps in babel output - 7f7ab21 Merge diff/line and diff/patch implementations - 1597705 Drop map utility method - 1ddc939 Documentation for parsePatch and applyPatches - 27c4b77 Compatibility notes: The undocumented ignoreWhitespace flag has been removed from the Diff equality check directly. This implementation may be copied to diff utilities if dependencies existed on this functionality. Commits v2.0.2 - August 8th, 2015 #67 - cannot require from npm module in node (@commenthol) Convert to chai since we don’t support IE8 - a96bbad Commits v2.0.1 - August 7th, 2015 Add release build at proper step - 57542fd Commits v2.0.0 - August 7th, 2015 #66 - Add karma and sauce tests (@kpdecker) #65 - Create component repository for bower (@kpdecker) #64 - Automatically call removeEmpty for all tokenizer calls (@kpdecker) #62 - Allow access to structured object representation of patch data (@bittrance) #61 - Use svg instead of png to get better image quality (@PeterDaveHello) #29 - word tokenizer works only for 7 bit ascii (@plasmagunman) Compatibility notes: this.removeEmpty is now called automatically for all instances. If this is not desired, this may be overridden on a per instance basis. The library has been refactored to use some ES6 features. The external APIs should remain the same, but bower projects that directly referenced the repository will now have to point to the components/jsdiff repository. Commits v1.4.0 - May 6th, 2015 #57 - createPatch -> applyPatch failed. (@mog422) #56 - Two files patch (@rgeissert) #14 - Flip added and removed order? (@jakesandlund) Commits v1.3.2 - March 30th, 2015 #53 - Updated README.MD with Bower installation instructions (@ofbriggs) #49 - Cannot read property 'oldlines' of undefined (@nwtn) #44 - invalid-meta jsdiff is missing \"main\" entry in bower.json Commits v1.3.1 - March 13th, 2015 #52 - Fix for #51 Wrong result of JsDiff.diffLines (@felicienfrancois) Commits v1.3.0 - March 2nd, 2015 #47 - Adding Diff Trimmed Lines (@JamesGould123) Commits v1.2.2 - January 26th, 2015 #45 - Fix AMD module loading (@pedrocarrico) #43 - added a bower file (@nbrustein) Commits v1.2.1 - December 26th, 2014 #41 - change condition of using node export system. (@ironhee) Commits v1.2.0 - November 29th, 2014 #37 - Add support for sentences. (@vmariano) #28 - Implemented diffJson (@papandreou) #27 - Slow to execute over diffs with a large number of changes (@termi) Allow for optional async diffing - 19385b9 Fix diffChars implementation - eaa44ed Commits v1.1.0 - November 25th, 2014 #33 - AMD and global exports (@ovcharik) #32 - Add support for component (@vmariano) #31 - Don't rely on Array.prototype.map (@papandreou) Commits v1.0.8 - December 22nd, 2013 #24 - Handle windows newlines on non windows machines. (@benogle) #23 - Prettied up the API formatting a little, and added basic node and web examples (@airportyh) Commits v1.0.7 - September 11th, 2013 #22 - Added variant of WordDiff that doesn't ignore whitespace differences (@papandreou Add 0.10 to travis tests - 243a526 Commits v1.0.6 - August 30th, 2013 #19 - Explicitly define contents of npm package (@sindresorhus Commits"
  },
  "src/frontend/app-client/node_modules/dom-helpers/README.html": {
    "href": "src/frontend/app-client/node_modules/dom-helpers/README.html",
    "title": "dom-helpers",
    "summary": "dom-helpers tiny modular DOM lib for ie8+ Install npm i -S dom-helpers Mostly just naive wrappers around common DOM API inconsistencies, Cross browser work is minimal and mostly taken from jQuery. This library doesn't do a lot to normalize behavior across browsers, it mostly seeks to provide a common interface, and eliminate the need to write the same damn if (ie8) statements in every project. For example events.on works in all browsers ie8+ but it uses the native event system so actual event oddities will continue to exist. If you need robust cross-browser support, use jQuery. If you are just tired of rewriting: if (document.addEventListener) return (node, eventName, handler, capture) => node.addEventListener(eventName, handler, capture || false); else if (document.attachEvent) return (node, eventName, handler) => node.attachEvent('on' + eventName, handler); over and over again, or you need a ok getComputedStyle polyfill but don't want to include all of jQuery, use this. dom-helpers does expect certain, polyfillable, es5 features to be present for which you can use es5-shim for ie8 The real advantage to this collection is that any method can be required individually, meaning tools like Browserify or webpack will only include the exact methods you use. This is great for environments where jQuery doesn't make sense, such as React where you only occasionally need to do direct DOM manipulation. Each level of the module can be required as a whole or you can drill down for a specific method or section: var helpers = require('dom-helpers') var query = require('dom-helpers/query') var offset = require('dom-helpers/query/offset') // style is a function require('dom-helpers/style')(node, { width: '40px' }) //and a namespace var gcs = require('dom-helpers/style/getComputedStyle') dom-helpers ownerDocument(element): returns the element's document owner ownerWindow(element): returns the element's document window activeElement: return focused element safely query querySelectorAll(element, selector): optimized qsa, uses getElementBy{Id|TagName|ClassName} if it can. contains(container, element) height(element, useClientHeight) width(element, useClientWidth) matches(element, selector): matches() polyfill that works in ie8 offset(element) -> { top: Number, left: Number, height: Number, width: Number} offsetParent(element): return the parent node that the element is offset from position(element, [offsetParent]: return \"offset\" of the node to its offsetParent, optionally you can specify the offset parent if different than the \"real\" one scrollTop(element, [value]) scrollLeft(element, [value]) scrollParent(element) class addClass(element, className) removeClass(element, className) hasClass(element, className) style(element, propName, [value]) or style(element, objectOfPropValues) removeStyle(element, styleName) getComputedStyle(element) -> getPropertyValue(name) transition animate(node, properties, duration, easing, callback) programmatically start css transitions end(node, handler, [duration]) listens for transition end, and ensures that the handler if called even if the transition fails to fire its end event. Will attempt to read duration from the element, otherwise one can be provided properties: Object containing the various vendor specific transition and transform properties for your browser { transform: // transform property: 'transform' end: // transitionend property: // transition-property timing: // transition-timing delay: // transition-delay duration: // transition-duration } events on(node, eventName, handler, [capture]): capture is silently ignored in ie8 off(node, eventName, handler, [capture]): capture is silently ignored in ie8 listen(node, eventName, handler, [capture]): wraps on and returns a function that calls off for you filter(selector, fn): returns a function handler that only fires when the target matches or is contained in the selector ex: events.on(list, 'click', events.filter('li > a', handler)) util requestAnimationFrame(cb) returns an ID for canceling requestAnimationFrame.cancel(id) scrollbarSize([recalc]) returns the scrollbar's width size in pixels scrollTo(element, [scrollParent])"
  },
  "src/frontend/app-client/node_modules/dunder-proto/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/dunder-proto/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.1 - 2024-12-16 Commits [Fix] do not crash when --disable-proto=throw 6c367d9 [Tests] ensure noproto tests only use the current version of dunder-proto b02365b [Dev Deps] update @arethetypeswrong/cli, @types/tape e3c5c3b [Deps] update call-bind-apply-helpers 19f1da0 v1.0.0 - 2024-12-06 Commits Initial implementation, tests, readme, types a5b74b0 Initial commit 73fb5a3 npm init 80152dc Only apps should have lockfiles 03e6660"
  },
  "src/frontend/app-client/node_modules/dunder-proto/README.html": {
    "href": "src/frontend/app-client/node_modules/dunder-proto/README.html",
    "title": "dunder-proto",
    "summary": "dunder-proto If available, the Object.prototype.__proto__ accessor and mutator, call-bound. Getting started npm install --save dunder-proto Usage/Examples const assert = require('assert'); const getDunder = require('dunder-proto/get'); const setDunder = require('dunder-proto/set'); const obj = {}; assert.equal('toString' in obj, true); assert.equal(getDunder(obj), Object.prototype); setDunder(obj, null); assert.equal('toString' in obj, false); assert.equal(getDunder(obj), null); Tests Clone the repo, npm install, and run npm test"
  },
  "src/frontend/app-client/node_modules/eastasianwidth/README.html": {
    "href": "src/frontend/app-client/node_modules/eastasianwidth/README.html",
    "title": "East Asian Width",
    "summary": "East Asian Width Get East Asian Width from a character. 'F'(Fullwidth), 'H'(Halfwidth), 'W'(Wide), 'Na'(Narrow), 'A'(Ambiguous) or 'N'(Natural). Original Code is 東アジアの文字幅 (East Asian Width) の判定 - 中途. Install $ npm install eastasianwidth Usage var eaw = require('eastasianwidth'); console.log(eaw.eastAsianWidth('￦')) // 'F' console.log(eaw.eastAsianWidth('｡')) // 'H' console.log(eaw.eastAsianWidth('뀀')) // 'W' console.log(eaw.eastAsianWidth('a')) // 'Na' console.log(eaw.eastAsianWidth('①')) // 'A' console.log(eaw.eastAsianWidth('ف')) // 'N' console.log(eaw.characterLength('￦')) // 2 console.log(eaw.characterLength('｡')) // 1 console.log(eaw.characterLength('뀀')) // 2 console.log(eaw.characterLength('a')) // 1 console.log(eaw.characterLength('①')) // 2 console.log(eaw.characterLength('ف')) // 1 console.log(eaw.length('あいうえお')) // 10 console.log(eaw.length('abcdefg')) // 7 console.log(eaw.length('￠￦｡ￜㄅ뀀¢⟭a⊙①بف')) // 19"
  },
  "src/frontend/app-client/node_modules/editorconfig/node_modules/minimatch/README.html": {
    "href": "src/frontend/app-client/node_modules/editorconfig/node_modules/minimatch/README.html",
    "title": "minimatch",
    "summary": "minimatch A minimal matching utility. This is the matching library used internally by npm. It works by converting glob expressions into JavaScript RegExp objects. Usage // hybrid module, load with require() or import import { minimatch } from 'minimatch' // or: const { minimatch } = require('minimatch') minimatch('bar.foo', '*.foo') // true! minimatch('bar.foo', '*.bar') // false! minimatch('bar.foo', '*.+(bar|foo)', { debug: true }) // true, and noisy! Features Supports these glob features: Brace Expansion Extended glob matching \"Globstar\" ** matching Posix character classes, like [[:alpha:]], supporting the full range of Unicode characters. For example, [[:alpha:]] will match against 'é', though [a-zA-Z] will not. Collating symbol and set matching is not supported, so [[=e=]] will not match 'é' and [[.ch.]] will not match 'ch' in locales where ch is considered a single character. See: man sh man bash Pattern Matching man 3 fnmatch man 5 gitignore Windows Please only use forward-slashes in glob expressions. Though windows uses either / or \\ as its path separator, only / characters are used by this glob implementation. You must use forward-slashes only in glob expressions. Back-slashes in patterns will always be interpreted as escape characters, not path separators. Note that \\ or / will be interpreted as path separators in paths on Windows, and will match against / in glob expressions. So just always use / in patterns. UNC Paths On Windows, UNC paths like //?/c:/... or //ComputerName/Share/... are handled specially. Patterns starting with a double-slash followed by some non-slash characters will preserve their double-slash. As a result, a pattern like //* will match //x, but not /x. Patterns staring with //?/<drive letter>: will not treat the ? as a wildcard character. Instead, it will be treated as a normal string. Patterns starting with //?/<drive letter>:/... will match file paths starting with <drive letter>:/..., and vice versa, as if the //?/ was not present. This behavior only is present when the drive letters are a case-insensitive match to one another. The remaining portions of the path/pattern are compared case sensitively, unless nocase:true is set. Note that specifying a UNC path using \\ characters as path separators is always allowed in the file path argument, but only allowed in the pattern argument when windowsPathsNoEscape: true is set in the options. Minimatch Class Create a minimatch object by instantiating the minimatch.Minimatch class. var Minimatch = require('minimatch').Minimatch var mm = new Minimatch(pattern, options) Properties pattern The original pattern the minimatch object represents. options The options supplied to the constructor. set A 2-dimensional array of regexp or string expressions. Each row in the array corresponds to a brace-expanded pattern. Each item in the row corresponds to a single path-part. For example, the pattern {a,b/c}/d would expand to a set of patterns like: [ [ a, d ] , [ b, c, d ] ] If a portion of the pattern doesn't have any \"magic\" in it (that is, it's something like \"foo\" rather than fo*o?), then it will be left as a string rather than converted to a regular expression. regexp Created by the makeRe method. A single regular expression expressing the entire pattern. This is useful in cases where you wish to use the pattern somewhat like fnmatch(3) with FNM_PATH enabled. negate True if the pattern is negated. comment True if the pattern is a comment. empty True if the pattern is \"\". Methods makeRe() Generate the regexp member if necessary, and return it. Will return false if the pattern is invalid. match(fname) Return true if the filename matches the pattern, or false otherwise. matchOne(fileArray, patternArray, partial) Take a /-split filename, and match it against a single row in the regExpSet. This method is mainly for internal use, but is exposed so that it can be used by a glob-walker that needs to avoid excessive filesystem calls. hasMagic() Returns true if the parsed pattern contains any magic characters. Returns false if all comparator parts are string literals. If the magicalBraces option is set on the constructor, then it will consider brace expansions which are not otherwise magical to be magic. If not set, then a pattern like a{b,c}d will return false, because neither abd nor acd contain any special glob characters. This does not mean that the pattern string can be used as a literal filename, as it may contain magic glob characters that are escaped. For example, the pattern \\\\* or [*] would not be considered to have magic, as the matching portion parses to the literal string '*' and would match a path named '*', not '\\\\*' or '[*]'. The minimatch.unescape() method may be used to remove escape characters. All other methods are internal, and will be called as necessary. minimatch(path, pattern, options) Main export. Tests a path against the pattern using the options. var isJS = minimatch(file, '*.js', { matchBase: true }) minimatch.filter(pattern, options) Returns a function that tests its supplied argument, suitable for use with Array.filter. Example: var javascripts = fileList.filter(minimatch.filter('*.js', { matchBase: true })) minimatch.escape(pattern, options = {}) Escape all magic characters in a glob pattern, so that it will only ever match literal strings If the windowsPathsNoEscape option is used, then characters are escaped by wrapping in [], because a magic character wrapped in a character class can only be satisfied by that exact character. Slashes (and backslashes in windowsPathsNoEscape mode) cannot be escaped or unescaped. minimatch.unescape(pattern, options = {}) Un-escape a glob string that may contain some escaped characters. If the windowsPathsNoEscape option is used, then square-brace escapes are removed, but not backslash escapes. For example, it will turn the string '[*]' into *, but it will not turn '\\\\*' into '*', because \\ is a path separator in windowsPathsNoEscape mode. When windowsPathsNoEscape is not set, then both brace escapes and backslash escapes are removed. Slashes (and backslashes in windowsPathsNoEscape mode) cannot be escaped or unescaped. minimatch.match(list, pattern, options) Match against the list of files, in the style of fnmatch or glob. If nothing is matched, and options.nonull is set, then return a list containing the pattern itself. var javascripts = minimatch.match(fileList, '*.js', { matchBase: true }) minimatch.makeRe(pattern, options) Make a regular expression object from the pattern. Options All options are false by default. debug Dump a ton of stuff to stderr. nobrace Do not expand {a,b} and {1..3} brace sets. noglobstar Disable ** matching against multiple folder names. dot Allow patterns to match filenames starting with a period, even if the pattern does not explicitly have a period in that spot. Note that by default, a/**/b will not match a/.d/b, unless dot is set. noext Disable \"extglob\" style patterns like +(a|b). nocase Perform a case-insensitive match. nocaseMagicOnly When used with {nocase: true}, create regular expressions that are case-insensitive, but leave string match portions untouched. Has no effect when used without {nocase: true} Useful when some other form of case-insensitive matching is used, or if the original string representation is useful in some other way. nonull When a match is not found by minimatch.match, return a list containing the pattern itself if this option is set. When not set, an empty list is returned if there are no matches. magicalBraces This only affects the results of the Minimatch.hasMagic method. If the pattern contains brace expansions, such as a{b,c}d, but no other magic characters, then the Minipass.hasMagic() method will return false by default. When this option set, it will return true for brace expansion as well as other magic glob characters. matchBase If set, then patterns without slashes will be matched against the basename of the path if it contains slashes. For example, a?b would match the path /xyz/123/acb, but not /xyz/acb/123. nocomment Suppress the behavior of treating # at the start of a pattern as a comment. nonegate Suppress the behavior of treating a leading ! character as negation. flipNegate Returns from negate expressions the same as if they were not negated. (Ie, true on a hit, false on a miss.) partial Compare a partial path to a pattern. As long as the parts of the path that are present are not contradicted by the pattern, it will be treated as a match. This is useful in applications where you're walking through a folder structure, and don't yet have the full path, but want to ensure that you do not walk down paths that can never be a match. For example, minimatch('/a/b', '/a/*/c/d', { partial: true }) // true, might be /a/b/c/d minimatch('/a/b', '/**/d', { partial: true }) // true, might be /a/b/.../d minimatch('/x/y/z', '/a/**/z', { partial: true }) // false, because x !== a windowsPathsNoEscape Use \\\\ as a path separator only, and never as an escape character. If set, all \\\\ characters are replaced with / in the pattern. Note that this makes it impossible to match against paths containing literal glob pattern characters, but allows matching with patterns constructed using path.join() and path.resolve() on Windows platforms, mimicking the (buggy!) behavior of earlier versions on Windows. Please use with caution, and be mindful of the caveat about Windows paths. For legacy reasons, this is also set if options.allowWindowsEscape is set to the exact value false. windowsNoMagicRoot When a pattern starts with a UNC path or drive letter, and in nocase:true mode, do not convert the root portions of the pattern into a case-insensitive regular expression, and instead leave them as strings. This is the default when the platform is win32 and nocase:true is set. preserveMultipleSlashes By default, multiple / characters (other than the leading // in a UNC path, see \"UNC Paths\" above) are treated as a single /. That is, a pattern like a///b will match the file path a/b. Set preserveMultipleSlashes: true to suppress this behavior. optimizationLevel A number indicating the level of optimization that should be done to the pattern prior to parsing and using it for matches. Globstar parts ** are always converted to * when noglobstar is set, and multiple adjascent ** parts are converted into a single ** (ie, a/**/**/b will be treated as a/**/b, as this is equivalent in all cases). 0 - Make no further changes. In this mode, . and .. are maintained in the pattern, meaning that they must also appear in the same position in the test path string. Eg, a pattern like a/*/../c will match the string a/b/../c but not the string a/c. 1 - (default) Remove cases where a double-dot .. follows a pattern portion that is not **, ., .., or empty ''. For example, the pattern ./a/b/../* is converted to ./a/*, and so it will match the path string ./a/c, but not the path string ./a/b/../c. Dots and empty path portions in the pattern are preserved. 2 (or higher) - Much more aggressive optimizations, suitable for use with file-walking cases: Remove cases where a double-dot .. follows a pattern portion that is not **, ., or empty ''. Remove empty and . portions of the pattern, where safe to do so (ie, anywhere other than the last position, the first position, or the second position in a pattern starting with /, as this may indicate a UNC path on Windows). Convert patterns containing <pre>/**/../<p>/<rest> into the equivalent <pre>/{..,**}/<p>/<rest>, where <p> is a a pattern portion other than ., .., **, or empty ''. Dedupe patterns where a ** portion is present in one and omitted in another, and it is not the final path portion, and they are otherwise equivalent. So {a/**/b,a/b} becomes a/**/b, because ** matches against an empty path portion. Dedupe patterns where a * portion is present in one, and a non-dot pattern other than **, ., .., or '' is in the same position in the other. So a/{*,x}/b becomes a/*/b, because * can match against x. While these optimizations improve the performance of file-walking use cases such as glob (ie, the reason this module exists), there are cases where it will fail to match a literal string that would have been matched in optimization level 1 or 0. Specifically, while the Minimatch.match() method will optimize the file path string in the same ways, resulting in the same matches, it will fail when tested with the regular expression provided by Minimatch.makeRe(), unless the path string is first processed with minimatch.levelTwoFileOptimize() or similar. platform When set to win32, this will trigger all windows-specific behaviors (special handling for UNC paths, and treating \\ as separators in file paths for comparison.) Defaults to the value of process.platform. Comparisons to other fnmatch/glob implementations While strict compliance with the existing standards is a worthwhile goal, some discrepancies exist between minimatch and other implementations. Some are intentional, and some are unavoidable. If the pattern starts with a ! character, then it is negated. Set the nonegate flag to suppress this behavior, and treat leading ! characters normally. This is perhaps relevant if you wish to start the pattern with a negative extglob pattern like !(a|B). Multiple ! characters at the start of a pattern will negate the pattern multiple times. If a pattern starts with #, then it is treated as a comment, and will not match anything. Use \\# to match a literal # at the start of a line, or set the nocomment flag to suppress this behavior. The double-star character ** is supported by default, unless the noglobstar flag is set. This is supported in the manner of bsdglob and bash 4.1, where ** only has special significance if it is the only thing in a path part. That is, a/**/b will match a/x/y/b, but a/**b will not. If an escaped pattern has no matches, and the nonull flag is set, then minimatch.match returns the pattern as-provided, rather than interpreting the character escapes. For example, minimatch.match([], \"\\\\*a\\\\?\") will return \"\\\\*a\\\\?\" rather than \"*a?\". This is akin to setting the nullglob option in bash, except that it does not resolve escaped pattern characters. If brace expansion is not disabled, then it is performed before any other interpretation of the glob pattern. Thus, a pattern like +(a|{b),c)}, which would not be valid in bash or zsh, is expanded first into the set of +(a|b) and +(a|c), and those patterns are checked for validity. Since those two are valid, matching proceeds. Negated extglob patterns are handled as closely as possible to Bash semantics, but there are some cases with negative extglobs which are exceedingly difficult to express in a JavaScript regular expression. In particular the negated pattern <start>!(<pattern>*|)* will in bash match anything that does not start with <start><pattern>. However, <start>!(<pattern>*)* will match paths starting with <start><pattern>, because the empty string can match against the negated portion. In this library, <start>!(<pattern>*|)* will not match any pattern starting with <start>, due to a difference in precisely which patterns are considered \"greedy\" in Regular Expressions vs bash path expansion. This may be fixable, but not without incurring some complexity and performance costs, and the trade-off seems to not be worth pursuing. Note that fnmatch(3) in libc is an extremely naive string comparison matcher, which does not do anything special for slashes. This library is designed to be used in glob searching and file walkers, and so it does do special things with /. Thus, foo* will not match foo/bar in this library, even though it would in fnmatch(3)."
  },
  "src/frontend/app-client/node_modules/editorconfig/README.html": {
    "href": "src/frontend/app-client/node_modules/editorconfig/README.html",
    "title": "EditorConfig JavaScript Core",
    "summary": "EditorConfig JavaScript Core The EditorConfig JavaScript core will provide the same functionality as the EditorConfig C Core and EditorConfig Python Core. Installation You need node to use this package. To install the package locally: $ npm install editorconfig To install the package system-wide: $ npm install -g editorconfig Usage Options Most of the API takes an options object, which has the following defaults: { config: '.editorconfig', version: pkg.version, root: '/', files: undefined, cache: undefined, }; config The name of the config file to look for in the current and every parent directory. version Which editorconfig spec version to use. Earlier versions had different defaults. root What directory to stop processing in, even if we haven't found a file containing root=true. Defaults to the root of the filesystem containing `process.cwd()`. files Pass in an empty array, which will be filled with one object for each config file processed. The objects will have the shape `{filename: \"[DIRECTORY]/.editorconfig\", glob: \"*\"}` cache If you are going to process more than one file in the same project, pass in a cache object. It must have `get(string): object|undefined` and `set(string, object)` methods, like a JavaScript Map. A long-running process might want to consider that this cache might grow over time, and that the config files might change over time. However, we leave any complexity of that nature to the caller, since there are so many different approaches that might be taken based on latency, memory, and CPU trade-offs. Note that some of the objects in the cache will be for files that did not exist. Those objects will have a `notfound: true` property. All of the objects will have a `name: string` property that contains the fully-qualified file name of the config file and a `root: boolean` property that describes if the config file had a `root=true` at the top. Any other properties in the objects should be treated as opaque. in Node.js: parse(filePath[, options]) Search for .editorconfig files starting from the current directory to the root directory. Combine all of the sections whose section names match filePath into a single object. Example: const editorconfig = require('editorconfig'); const path = require('path'); const filePath = path.join(__dirname, 'sample.js'); (async () => { console.log(await editorconfig.parse(filePath, {files: []})); })(); /* { indent_style: 'space', indent_size: 2, end_of_line: 'lf', charset: 'utf-8', trim_trailing_whitespace: true, insert_final_newline: true, tab_width: 2 }; assert.deepEqual(files, [ { fileName: '[DIRECTORY]/.editorconfig', glob: '*' }, { fileName: '[DIRECTORY]/.editorconfig', glob: '*.js' } ]) */ parseSync(filePath[, options]) Synchronous version of editorconfig.parse(). parseBuffer(fileContent) The parse() function above uses parseBuffer() under the hood. If you have the contents of a config file, and want to see what is being processed for just that file rather than the full directory hierarchy, this might be useful. parseString(fileContent) This is a thin wrapper around parseBuffer() for backward-compatibility. Prefer parseBuffer() to avoid an unnecessary UTF8-to-UTF16-to-UTF8 conversion. Deprecated. parseFromFiles(filePath, configs[, options]) Low-level interface, which exists only for backward-compatibility. Deprecated. Example: const editorconfig = require('editorconfig'); const fs = require('fs'); const path = require('path'); const configPath = path.join(__dirname, '.editorconfig'); const configs = [ { name: configPath, contents: fs.readFileSync(configPath, 'utf8') } ]; const filePath = path.join(__dirname, '/sample.js'); (async () => { console.log(await editorconfig.parseFromFiles(filePath, Promise.resolve(configs))) })(); /* { indent_style: 'space', indent_size: 2, end_of_line: 'lf', charset: 'utf-8', trim_trailing_whitespace: true, insert_final_newline: true, tab_width: 2 }; */ parseFromFilesSync(filePath, configs[, options]) Synchronous version of editorconfig.parseFromFiles(). Deprecated. in Command Line $ ./bin/editorconfig Usage: editorconfig [options] <FILEPATH...> Arguments: FILEPATH Files to find configuration for. Can be a hyphen (-) if you want path(s) to be read from stdin. Options: -v, --version Display version information from the package -f <path> Specify conf filename other than '.editorconfig' -b <version> Specify version (used by devs to test compatibility) --files Output file names that contributed to the configuration, rather than the configuation itself -h, --help display help for command Example: $ ./bin/editorconfig /home/zoidberg/humans/anatomy.md charset=utf-8 insert_final_newline=true end_of_line=lf tab_width=8 trim_trailing_whitespace=sometimes $ ./bin/editorconfig --files /home/zoidberg/humans/anatomy.md /home/zoidberg/.editorconfig [*] /home/zoidberg/.editorconfig [*.md] /home/zoidberg/humans/.editorconfig [*] Development To install dependencies for this package run this in the package directory: $ npm install Next, run the following commands: $ npm run build $ npm link The global editorconfig will now point to the files in your development repository instead of a globally-installed version from npm. You can now use editorconfig directly to test your changes. If you ever update from the central repository and there are errors, it might be because you are missing some dependencies. If that happens, just run npm link again to get the latest dependencies. To test the command line interface: $ editorconfig <filepath> Testing CMake must be installed to run the tests. To run the tests: $ npm test To run the tests with increased verbosity (for debugging test failures): $ npm run ci"
  },
  "src/frontend/app-client/node_modules/ee-first/README.html": {
    "href": "src/frontend/app-client/node_modules/ee-first/README.html",
    "title": "EE First",
    "summary": "EE First Get the first event in a set of event emitters and event pairs, then clean up after itself. Install $ npm install ee-first API var first = require('ee-first') first(arr, listener) Invoke listener on the first event from the list specified in arr. arr is an array of arrays, with each array in the format [ee, ...event]. listener will be called only once, the first time any of the given events are emitted. If error is one of the listened events, then if that fires first, the listener will be given the err argument. The listener is invoked as listener(err, ee, event, args), where err is the first argument emitted from an error event, if applicable; ee is the event emitter that fired; event is the string event name that fired; and args is an array of the arguments that were emitted on the event. var ee1 = new EventEmitter() var ee2 = new EventEmitter() first([ [ee1, 'close', 'end', 'error'], [ee2, 'error'] ], function (err, ee, event, args) { // listener invoked }) .cancel() The group of listeners can be cancelled before being invoked and have all the event listeners removed from the underlying event emitters. var thunk = first([ [ee1, 'close', 'end', 'error'], [ee2, 'error'] ], function (err, ee, event, args) { // listener invoked }) // cancel and clean up thunk.cancel()"
  },
  "src/frontend/app-client/node_modules/electron-to-chromium/README.html": {
    "href": "src/frontend/app-client/node_modules/electron-to-chromium/README.html",
    "title": "Electron-to-Chromium",
    "summary": "Made by @kilianvalkhof Other projects: \uD83D\uDCBB Polypane - Develop responsive websites and apps twice as fast on multiple screens at once \uD83D\uDD8C️ Superposition - Kickstart your design system by extracting design tokens from your website \uD83D\uDDD2️ FromScratch - A smart but simple autosaving scratchpad Electron-to-Chromium This repository provides a mapping of Electron versions to the Chromium version that it uses. This package is used in Browserslist, so you can use e.g. electron >= 1.4 in Autoprefixer, Stylelint, babel-preset-env and eslint-plugin-compat. Supported by: Install Install using npm install electron-to-chromium. Usage To include Electron-to-Chromium, require it: var e2c = require('electron-to-chromium'); Properties The Electron-to-Chromium object has 4 properties to use: versions An object of key-value pairs with a major Electron version as the key, and the corresponding major Chromium version as the value. var versions = e2c.versions; console.log(versions['1.4']); // returns \"53\" fullVersions An object of key-value pairs with a Electron version as the key, and the corresponding full Chromium version as the value. var versions = e2c.fullVersions; console.log(versions['1.4.11']); // returns \"53.0.2785.143\" chromiumVersions An object of key-value pairs with a major Chromium version as the key, and the corresponding major Electron version as the value. var versions = e2c.chromiumVersions; console.log(versions['54']); // returns \"1.4\" fullChromiumVersions An object of key-value pairs with a Chromium version as the key, and an array of the corresponding major Electron versions as the value. var versions = e2c.fullChromiumVersions; console.log(versions['54.0.2840.101']); // returns [\"1.5.1\", \"1.5.0\"] Functions electronToChromium(query) Arguments: Query: string or number, required. A major or full Electron version. A function that returns the corresponding Chromium version for a given Electron function. Returns a string. If you provide it with a major Electron version, it will return a major Chromium version: var chromeVersion = e2c.electronToChromium('1.4'); // chromeVersion is \"53\" If you provide it with a full Electron version, it will return the full Chromium version. var chromeVersion = e2c.electronToChromium('1.4.11'); // chromeVersion is \"53.0.2785.143\" If a query does not match a Chromium version, it will return undefined. var chromeVersion = e2c.electronToChromium('9000'); // chromeVersion is undefined chromiumToElectron(query) Arguments: Query: string or number, required. A major or full Chromium version. Returns a string with the corresponding Electron version for a given Chromium query. If you provide it with a major Chromium version, it will return a major Electron version: var electronVersion = e2c.chromiumToElectron('54'); // electronVersion is \"1.4\" If you provide it with a full Chrome version, it will return an array of full Electron versions. var electronVersions = e2c.chromiumToElectron('56.0.2924.87'); // electronVersions is [\"1.6.3\", \"1.6.2\", \"1.6.1\", \"1.6.0\"] If a query does not match an Electron version, it will return undefined. var electronVersion = e2c.chromiumToElectron('10'); // electronVersion is undefined electronToBrowserList(query) DEPRECATED Arguments: Query: string or number, required. A major Electron version. Deprecated: Browserlist already includes electron-to-chromium. A function that returns a Browserslist query that matches the given major Electron version. Returns a string. If you provide it with a major Electron version, it will return a Browserlist query string that matches the Chromium capabilities: var query = e2c.electronToBrowserList('1.4'); // query is \"Chrome >= 53\" If a query does not match a Chromium version, it will return undefined. var query = e2c.electronToBrowserList('9000'); // query is undefined Importing just versions, fullVersions, chromiumVersions and fullChromiumVersions All lists can be imported on their own, if file size is a concern. versions var versions = require('electron-to-chromium/versions'); fullVersions var fullVersions = require('electron-to-chromium/full-versions'); chromiumVersions var chromiumVersions = require('electron-to-chromium/chromium-versions'); fullChromiumVersions var fullChromiumVersions = require('electron-to-chromium/full-chromium-versions'); Updating This package will be updated with each new Electron release. To update the list, run npm run build.js. Requires internet access as it downloads from the canonical list of Electron versions. To verify correct behaviour, run npm test. License"
  },
  "src/frontend/app-client/node_modules/emoji-regex/README.html": {
    "href": "src/frontend/app-client/node_modules/emoji-regex/README.html",
    "title": "emoji-regex",
    "summary": "emoji-regex emoji-regex offers a regular expression to match all emoji symbols and sequences (including textual representations of emoji) as per the Unicode Standard. This repository contains a script that generates this regular expression based on Unicode data. Because of this, the regular expression can easily be updated whenever new emoji are added to the Unicode standard. Installation Via npm: npm install emoji-regex In Node.js: const emojiRegex = require('emoji-regex/RGI_Emoji.js'); // Note: because the regular expression has the global flag set, this module // exports a function that returns the regex rather than exporting the regular // expression itself, to make it impossible to (accidentally) mutate the // original regular expression. const text = ` \\u{231A}: ⌚ default emoji presentation character (Emoji_Presentation) \\u{2194}\\u{FE0F}: ↔️ default text presentation character rendered as emoji \\u{1F469}: \uD83D\uDC69 emoji modifier base (Emoji_Modifier_Base) \\u{1F469}\\u{1F3FF}: \uD83D\uDC69\uD83C\uDFFF emoji modifier base followed by a modifier `; const regex = emojiRegex(); let match; while (match = regex.exec(text)) { const emoji = match[0]; console.log(`Matched sequence ${ emoji } — code points: ${ [...emoji].length }`); } Console output: Matched sequence ⌚ — code points: 1 Matched sequence ⌚ — code points: 1 Matched sequence ↔️ — code points: 2 Matched sequence ↔️ — code points: 2 Matched sequence \uD83D\uDC69 — code points: 1 Matched sequence \uD83D\uDC69 — code points: 1 Matched sequence \uD83D\uDC69\uD83C\uDFFF — code points: 2 Matched sequence \uD83D\uDC69\uD83C\uDFFF — code points: 2 Regular expression flavors The package comes with three distinct regular expressions: // This is the recommended regular expression to use. It matches all // emoji recommended for general interchange, as defined via the // `RGI_Emoji` property in the Unicode Standard. // https://unicode.org/reports/tr51/#def_rgi_set // When in doubt, use this! const emojiRegexRGI = require('emoji-regex/RGI_Emoji.js'); // This is the old regular expression, prior to `RGI_Emoji` being // standardized. In addition to all `RGI_Emoji` sequences, it matches // some emoji you probably don’t want to match (such as emoji component // symbols that are not meant to be used separately). const emojiRegex = require('emoji-regex/index.js'); // This regular expression matches even more emoji than the previous // one, including emoji that render as text instead of icons (i.e. // emoji that are not `Emoji_Presentation` symbols and that aren’t // forced to render as emoji by a variation selector). const emojiRegexText = require('emoji-regex/text.js'); Additionally, in environments which support ES2015 Unicode escapes, you may require ES2015-style versions of the regexes: const emojiRegexRGI = require('emoji-regex/es2015/RGI_Emoji.js'); const emojiRegex = require('emoji-regex/es2015/index.js'); const emojiRegexText = require('emoji-regex/es2015/text.js'); For maintainers How to update emoji-regex after new Unicode Standard releases Update the Unicode data dependency in package.json by running the following commands: # Example: updating from Unicode v12 to Unicode v13. npm uninstall @unicode/unicode-12.0.0 npm install @unicode/unicode-13.0.0 --save-dev Generate the new output: npm run build Verify that tests still pass: npm test Send a pull request with the changes, and get it reviewed & merged. On the main branch, bump the emoji-regex version number in package.json: npm version patch -m 'Release v%s' Instead of patch, use minor or major as needed. Note that this produces a Git commit + tag. Push the release commit and tag: git push Our CI then automatically publishes the new release to npm. Author Mathias Bynens License emoji-regex is available under the MIT license."
  },
  "src/frontend/app-client/node_modules/encodeurl/README.html": {
    "href": "src/frontend/app-client/node_modules/encodeurl/README.html",
    "title": "Encode URL",
    "summary": "Encode URL Encode a URL to a percent-encoded form, excluding already-encoded sequences. Installation npm install encodeurl API var encodeUrl = require('encodeurl') encodeUrl(url) Encode a URL to a percent-encoded form, excluding already-encoded sequences. This function accepts a URL and encodes all the non-URL code points (as UTF-8 byte sequences). It will not encode the \"%\" character unless it is not part of a valid sequence (%20 will be left as-is, but %foo will be encoded as %25foo). This encode is meant to be \"safe\" and does not throw errors. It will try as hard as it can to properly encode the given URL, including replacing any raw, unpaired surrogate pairs with the Unicode replacement character prior to encoding. Examples Encode a URL containing user-controlled data var encodeUrl = require('encodeurl') var escapeHtml = require('escape-html') http.createServer(function onRequest (req, res) { // get encoded form of inbound url var url = encodeUrl(req.url) // create html message var body = '<p>Location ' + escapeHtml(url) + ' not found</p>' // send a 404 res.statusCode = 404 res.setHeader('Content-Type', 'text/html; charset=UTF-8') res.setHeader('Content-Length', String(Buffer.byteLength(body, 'utf-8'))) res.end(body, 'utf-8') }) Encode a URL for use in a header field var encodeUrl = require('encodeurl') var escapeHtml = require('escape-html') var url = require('url') http.createServer(function onRequest (req, res) { // parse inbound url var href = url.parse(req) // set new host for redirect href.host = 'localhost' href.protocol = 'https:' href.slashes = true // create location header var location = encodeUrl(url.format(href)) // create html message var body = '<p>Redirecting to new site: ' + escapeHtml(location) + '</p>' // send a 301 res.statusCode = 301 res.setHeader('Content-Type', 'text/html; charset=UTF-8') res.setHeader('Content-Length', String(Buffer.byteLength(body, 'utf-8'))) res.setHeader('Location', location) res.end(body, 'utf-8') }) Similarities This function is similar to the intrinsic function encodeURI. However, it will not encode: The \\, ^, or | characters The % character when it's part of a valid sequence [ and ] (for IPv6 hostnames) Replaces raw, unpaired surrogate pairs with the Unicode replacement character As a result, the encoding aligns closely with the behavior in the WHATWG URL specification. However, this package only encodes strings and does not do any URL parsing or formatting. It is expected that any output from new URL(url) will not change when used with this package, as the output has already been encoded. Additionally, if we were to encode before new URL(url), we do not expect the before and after encoded formats to be parsed any differently. Testing $ npm test $ npm run lint References RFC 3986: Uniform Resource Identifier (URI): Generic Syntax WHATWG URL Living Standard License MIT"
  },
  "src/frontend/app-client/node_modules/enhanced-resolve/README.html": {
    "href": "src/frontend/app-client/node_modules/enhanced-resolve/README.html",
    "title": "enhanced-resolve",
    "summary": "enhanced-resolve Offers an async require.resolve function. It's highly configurable. Features plugin system provide a custom filesystem sync and async node.js filesystems included Getting Started Install # npm npm install enhanced-resolve # or Yarn yarn add enhanced-resolve Resolve There is a Node.js API which allows to resolve requests according to the Node.js resolving rules. Sync and async APIs are offered. A create method allows to create a custom resolve function. const resolve = require(\"enhanced-resolve\"); resolve(\"/some/path/to/folder\", \"module/dir\", (err, result) => { result; // === \"/some/path/node_modules/module/dir/index.js\" }); resolve.sync(\"/some/path/to/folder\", \"../../dir\"); // === \"/some/path/dir/index.js\" const myResolve = resolve.create({ // or resolve.create.sync extensions: [\".ts\", \".js\"] // see more options below }); myResolve(\"/some/path/to/folder\", \"ts-module\", (err, result) => { result; // === \"/some/node_modules/ts-module/index.ts\" }); Creating a Resolver The easiest way to create a resolver is to use the createResolver function on ResolveFactory, along with one of the supplied File System implementations. const fs = require(\"fs\"); const { CachedInputFileSystem, ResolverFactory } = require(\"enhanced-resolve\"); // create a resolver const myResolver = ResolverFactory.createResolver({ // Typical usage will consume the `fs` + `CachedInputFileSystem`, which wraps Node.js `fs` to add caching. fileSystem: new CachedInputFileSystem(fs, 4000), extensions: [\".js\", \".json\"] /* any other resolver options here. Options/defaults can be seen below */ }); // resolve a file with the new resolver const context = {}; const lookupStartPath = \"/Users/webpack/some/root/dir\"; const request = \"./path/to-look-up.js\"; const resolveContext = {}; myResolver.resolve(context, lookupStartPath, request, resolveContext, ( err /*Error*/, filepath /*string*/ ) => { // Do something with the path }); Resolver Options Field Default Description alias [] A list of module alias configurations or an object which maps key to value aliasFields [] A list of alias fields in description files extensionAlias {} An object which maps extension to extension aliases cachePredicate function() { return true }; A function which decides whether a request should be cached or not. An object is passed to the function with path and request properties. cacheWithContext true If unsafe cache is enabled, includes request.context in the cache key conditionNames [] A list of exports field condition names descriptionFiles [\"package.json\"] A list of description files to read from enforceExtension false Enforce that a extension from extensions must be used exportsFields [\"exports\"] A list of exports fields in description files extensions [\".js\", \".json\", \".node\"] A list of extensions which should be tried for files fallback [] Same as alias, but only used if default resolving fails fileSystem The file system which should be used fullySpecified false Request passed to resolve is already fully specified and extensions or main files are not resolved for it (they are still resolved for internal requests) mainFields [\"main\"] A list of main fields in description files mainFiles [\"index\"] A list of main files in directories modules [\"node_modules\"] A list of directories to resolve modules from, can be absolute path or folder name plugins [] A list of additional resolve plugins which should be applied resolver undefined A prepared Resolver to which the plugins are attached resolveToContext false Resolve to a context instead of a file preferRelative false Prefer to resolve module requests as relative request and fallback to resolving as module preferAbsolute false Prefer to resolve server-relative urls as absolute paths before falling back to resolve in roots restrictions [] A list of resolve restrictions roots [] A list of root paths symlinks true Whether to resolve symlinks to their symlinked location unsafeCache false Use this cache object to unsafely cache the successful requests Plugins Similar to webpack, the core of enhanced-resolve functionality is implemented as individual plugins that are executed using tapable. These plugins can extend the functionality of the library, adding other ways for files/contexts to be resolved. A plugin should be a class (or its ES5 equivalent) with an apply method. The apply method will receive a resolver instance, that can be used to hook in to the event system. Plugin Boilerplate class MyResolverPlugin { constructor(source, target) { this.source = source; this.target = target; } apply(resolver) { const target = resolver.ensureHook(this.target); resolver .getHook(this.source) .tapAsync(\"MyResolverPlugin\", (request, resolveContext, callback) => { // Any logic you need to create a new `request` can go here resolver.doResolve(target, request, null, resolveContext, callback); }); } } Plugins are executed in a pipeline, and register which event they should be executed before/after. In the example above, source is the name of the event that starts the pipeline, and target is what event this plugin should fire, which is what continues the execution of the pipeline. For an example of how these different plugin events create a chain, see lib/ResolverFactory.js, in the //// pipeline //// section. Escaping It's allowed to escape # as \\0# to avoid parsing it as fragment. enhanced-resolve will try to resolve requests containing # as path and as fragment, so it will automatically figure out if ./some#thing means .../some.js#thing or .../some#thing.js. When a # is resolved as path it will be escaped in the result. Here: .../some\\0#thing.js. Tests yarn test Passing options from webpack If you are using webpack, and you want to pass custom options to enhanced-resolve, the options are passed from the resolve key of your webpack configuration e.g.: resolve: { extensions: ['.js', '.jsx'], modules: [path.resolve(__dirname, 'src'), 'node_modules'], plugins: [new DirectoryNamedWebpackPlugin()] ... }, License Copyright (c) 2012-2019 JS Foundation and other contributors MIT (http://www.opensource.org/licenses/mit-license.php)"
  },
  "src/frontend/app-client/node_modules/err-code/README.html": {
    "href": "src/frontend/app-client/node_modules/err-code/README.html",
    "title": "err-code",
    "summary": "err-code Create new error instances with a code and additional properties. Installation $ npm install err-code // or $ bower install err-code The browser file is named index.umd.js which supports CommonJS, AMD and globals (errCode). Why I find myself doing this repeatedly: var err = new Error('My message'); err.code = 'SOMECODE'; err.detail = 'Additional information about the error'; throw err; Usage Simple usage. var errcode = require('err-code'); // fill error with message + code throw errcode(new Error('My message'), 'ESOMECODE'); // fill error with message + code + props throw errcode(new Error('My message'), 'ESOMECODE', { detail: 'Additional information about the error' }); // fill error with message + props throw errcode(new Error('My message'), { detail: 'Additional information about the error' }); Pre-existing fields If the passed Error already has a .code field, or fields specified in the third argument to errcode they will be overwritten, unless the fields are read only or otherwise throw during assignment in which case a new object will be created that shares a prototype chain with the original Error. The .stack and .message properties will be carried over from the original error and .code or any passed properties will be set on it. Tests $ npm test License Released under the MIT License."
  },
  "src/frontend/app-client/node_modules/error-ex/README.html": {
    "href": "src/frontend/app-client/node_modules/error-ex/README.html",
    "title": "node-error-ex",
    "summary": "node-error-ex Easily subclass and customize new Error types Examples To include in your project: var errorEx = require('error-ex'); To create an error message type with a specific name (note, that ErrorFn.name will not reflect this): var JSONError = errorEx('JSONError'); var err = new JSONError('error'); err.name; //-> JSONError throw err; //-> JSONError: error To add a stack line: var JSONError = errorEx('JSONError', {fileName: errorEx.line('in %s')}); var err = new JSONError('error') err.fileName = '/a/b/c/foo.json'; throw err; //-> (line 2)-> in /a/b/c/foo.json To append to the error message: var JSONError = errorEx('JSONError', {fileName: errorEx.append('in %s')}); var err = new JSONError('error'); err.fileName = '/a/b/c/foo.json'; throw err; //-> JSONError: error in /a/b/c/foo.json API errorEx([name], [properties]) Creates a new ErrorEx error type name: the name of the new type (appears in the error message upon throw; defaults to Error.name) properties: if supplied, used as a key/value dictionary of properties to use when building up the stack message. Keys are property names that are looked up on the error message, and then passed to function values. line: if specified and is a function, return value is added as a stack entry (error-ex will indent for you). Passed the property value given the key. stack: if specified and is a function, passed the value of the property using the key, and the raw stack lines as a second argument. Takes no return value (but the stack can be modified directly). message: if specified and is a function, return value is used as new .message value upon get. Passed the property value of the property named by key, and the existing message is passed as the second argument as an array of lines (suitable for multi-line messages). Returns a constructor (Function) that can be used just like the regular Error constructor. var errorEx = require('error-ex'); var BasicError = errorEx(); var NamedError = errorEx('NamedError'); // -- var AdvancedError = errorEx('AdvancedError', { foo: { line: function (value, stack) { if (value) { return 'bar ' + value; } return null; } } } var err = new AdvancedError('hello, world'); err.foo = 'baz'; throw err; /* AdvancedError: hello, world bar baz at tryReadme() (readme.js:20:1) */ errorEx.line(str) Creates a stack line using a delimiter This is a helper function. It is to be used in lieu of writing a value object for properties values. str: The string to create Use the delimiter %s to specify where in the string the value should go var errorEx = require('error-ex'); var FileError = errorEx('FileError', {fileName: errorEx.line('in %s')}); var err = new FileError('problem reading file'); err.fileName = '/a/b/c/d/foo.js'; throw err; /* FileError: problem reading file in /a/b/c/d/foo.js at tryReadme() (readme.js:7:1) */ errorEx.append(str) Appends to the error.message string This is a helper function. It is to be used in lieu of writing a value object for properties values. str: The string to append Use the delimiter %s to specify where in the string the value should go var errorEx = require('error-ex'); var SyntaxError = errorEx('SyntaxError', {fileName: errorEx.append('in %s')}); var err = new SyntaxError('improper indentation'); err.fileName = '/a/b/c/d/foo.js'; throw err; /* SyntaxError: improper indentation in /a/b/c/d/foo.js at tryReadme() (readme.js:7:1) */ License Licensed under the MIT License. You can find a copy of it in LICENSE."
  },
  "src/frontend/app-client/node_modules/es-define-property/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/es-define-property/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.1 - 2024-12-06 Commits [types] use shared tsconfig 954a663 [actions] split out node 10-20, and 20+ 3a8e84b [Dev Deps] update @ljharb/eslint-config, @ljharb/tsconfig, @types/get-intrinsic, @types/tape, auto-changelog, gopd, tape 86ae27b [Refactor] avoid using get-intrinsic 02480c0 [Tests] replace aud with npm audit f6093ff [Tests] configure testling 7139e66 [Dev Deps] update tape b901b51 [Tests] fix types in tests 469d269 [Dev Deps] add missing peer dep 733acfb v1.0.0 - 2024-02-12 Commits Initial implementation, tests, readme, types 3e154e1 Initial commit 07d98de npm init c4eb634 Only apps should have lockfiles 7af86ec"
  },
  "src/frontend/app-client/node_modules/es-define-property/README.html": {
    "href": "src/frontend/app-client/node_modules/es-define-property/README.html",
    "title": "es-define-property",
    "summary": "es-define-property Object.defineProperty, but not IE 8's broken one. Example const assert = require('assert'); const $defineProperty = require('es-define-property'); if ($defineProperty) { assert.equal($defineProperty, Object.defineProperty); } else if (Object.defineProperty) { assert.equal($defineProperty, false, 'this is IE 8'); } else { assert.equal($defineProperty, false, 'this is an ES3 engine'); } Tests Simply clone the repo, npm install, and run npm test Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report."
  },
  "src/frontend/app-client/node_modules/es-errors/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/es-errors/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.3.0 - 2024-02-05 Commits [New] add EvalError and URIError 1927627 v1.2.1 - 2024-02-04 Commits [Fix] add missing exports entry 5bb5f28 v1.2.0 - 2024-02-04 Commits [New] add ReferenceError 6d8cf5b v1.1.0 - 2024-02-04 Commits [New] add base Error 2983ab6 v1.0.0 - 2024-02-03 Commits Initial implementation, tests, readme, type 8f47631 Initial commit ea5d099 npm init 6f5ebf9 Only apps should have lockfiles e1a0aeb [meta] add sideEffects flag a9c7d46"
  },
  "src/frontend/app-client/node_modules/es-errors/README.html": {
    "href": "src/frontend/app-client/node_modules/es-errors/README.html",
    "title": "es-errors",
    "summary": "es-errors A simple cache for a few of the JS Error constructors. Example const assert = require('assert'); const Base = require('es-errors'); const Eval = require('es-errors/eval'); const Range = require('es-errors/range'); const Ref = require('es-errors/ref'); const Syntax = require('es-errors/syntax'); const Type = require('es-errors/type'); const URI = require('es-errors/uri'); assert.equal(Base, Error); assert.equal(Eval, EvalError); assert.equal(Range, RangeError); assert.equal(Ref, ReferenceError); assert.equal(Syntax, SyntaxError); assert.equal(Type, TypeError); assert.equal(URI, URIError); Tests Simply clone the repo, npm install, and run npm test Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report."
  },
  "src/frontend/app-client/node_modules/es-module-lexer/README.html": {
    "href": "src/frontend/app-client/node_modules/es-module-lexer/README.html",
    "title": "ES Module Lexer",
    "summary": "ES Module Lexer A JS module syntax lexer used in es-module-shims. Outputs the list of exports and locations of import specifiers, including dynamic import and import meta handling. Supports new syntax features including import attributes and source phase imports. A very small single JS file (4KiB gzipped) that includes inlined Web Assembly for very fast source analysis of ECMAScript module syntax only. For an example of the performance, Angular 1 (720KiB) is fully parsed in 5ms, in comparison to the fastest JS parser, Acorn which takes over 100ms. Comprehensively handles the JS language grammar while remaining small and fast. - ~10ms per MB of JS cold and ~5ms per MB of JS warm, see benchmarks for more info. Built with Chomp Usage npm install es-module-lexer See src/lexer.ts for the type definitions. For use in CommonJS: const { init, parse } = require('es-module-lexer'); (async () => { // either await init, or call parse asynchronously // this is necessary for the Web Assembly boot await init; const source = 'export var p = 5'; const [imports, exports] = parse(source); // Returns \"p\" source.slice(exports[0].s, exports[0].e); // Returns \"p\" source.slice(exports[0].ls, exports[0].le); })(); An ES module version is also available: import { init, parse } from 'es-module-lexer'; (async () => { await init; const source = ` import { name } from 'mod\\\\u1011'; import json from './json.json' assert { type: 'json' } export var p = 5; export function q () { }; export { x as 'external name' } from 'external'; // Comments provided to demonstrate edge cases import /*comment!*/ ( 'asdf', { assert: { type: 'json' }}); import /*comment!*/.meta.asdf; // Source phase imports: import source mod from './mod.wasm'; import.source('./mod.wasm'); `; const [imports, exports] = parse(source, 'optional-sourcename'); // Returns \"modထ\" imports[0].n // Returns \"mod\\u1011\" source.slice(imports[0].s, imports[0].e); // \"s\" = start // \"e\" = end // Returns \"import { name } from 'mod'\" source.slice(imports[0].ss, imports[0].se); // \"ss\" = statement start // \"se\" = statement end // Returns \"{ type: 'json' }\" source.slice(imports[1].a, imports[1].se); // \"a\" = assert, -1 for no assertion // Returns \"external\" source.slice(imports[2].s, imports[2].e); // Returns \"p\" source.slice(exports[0].s, exports[0].e); // Returns \"p\" source.slice(exports[0].ls, exports[0].le); // Returns \"q\" source.slice(exports[1].s, exports[1].e); // Returns \"q\" source.slice(exports[1].ls, exports[1].le); // Returns \"'external name'\" source.slice(exports[2].s, exports[2].e); // Returns -1 exports[2].ls; // Returns -1 exports[2].le; // Import type is provided by `t` value // (1 for static, 2, for dynamic) // Returns true imports[2].t == 2; // Returns \"asdf\" (only for string literal dynamic imports) imports[2].n // Returns \"import /*comment!*/ ( 'asdf', { assert: { type: 'json' } })\" source.slice(imports[3].ss, imports[3].se); // Returns \"'asdf'\" source.slice(imports[3].s, imports[3].e); // Returns \"( 'asdf', { assert: { type: 'json' } })\" source.slice(imports[3].d, imports[3].se); // Returns \"{ assert: { type: 'json' } }\" source.slice(imports[3].a, imports[3].se - 1); // For non-string dynamic import expressions: // - n will be undefined // - a is currently -1 even if there is an assertion // - e is currently the character before the closing ) // For nested dynamic imports, the se value of the outer import is -1 as end tracking does not // currently support nested dynamic immports // import.meta is indicated by imports[3].d === -2 // Returns true imports[4].d === -2; // Returns \"import /*comment!*/.meta\" source.slice(imports[4].s, imports[4].e); // ss and se are the same for import meta // Returns \"'./mod.wasm'\" source.slice(imports[5].s, imports[5].e); // Import type 4 and 5 for static and dynamic source phase imports[5].t === 4; imports[6].t === 5; })(); CSP asm.js Build The default version of the library uses Wasm and (safe) eval usage for performance and a minimal footprint. Neither of these represent security escalation possibilities since there are no execution string injection vectors, but that can still violate existing CSP policies for applications. For a version that works with CSP eval disabled, use the es-module-lexer/js build: import { parse } from 'es-module-lexer/js'; Instead of Web Assembly, this uses an asm.js build which is almost as fast as the Wasm version (see benchmarks below). Escape Sequences To handle escape sequences in specifier strings, the .n field of imported specifiers will be provided where possible. For dynamic import expressions, this field will be empty if not a valid JS string. Facade Detection Facade modules that only use import / export syntax can be detected via the third return value: const [,, facade] = parse(` export * from 'external'; import * as ns from 'external2'; export { a as b } from 'external3'; export { ns }; `); facade === true; ESM Detection Modules that uses ESM syntaxes can be detected via the fourth return value: const [,,, hasModuleSyntax] = parse(` export {} `); hasModuleSyntax === true; Dynamic imports are ignored since they can be used in Non-ESM files. const [,,, hasModuleSyntax] = parse(` import('./foo.js') `); hasModuleSyntax === false; Environment Support Node.js 10+, and all browsers with Web Assembly support. Grammar Support Token state parses all line comments, block comments, strings, template strings, blocks, parens and punctuators. Division operator / regex token ambiguity is handled via backtracking checks against punctuator prefixes, including closing brace or paren backtracking. Always correctly parses valid JS source, but may parse invalid JS source without errors. Limitations The lexing approach is designed to deal with the full language grammar including RegEx / division operator ambiguity through backtracking and paren / brace tracking. The only limitation to the reduced parser is that the \"exports\" list may not correctly gather all export identifiers in the following edge cases: // Only \"a\" is detected as an export, \"q\" isn't export var a = 'asdf', q = z; // \"b\" is not detected as an export export var { a: b } = asdf; The above cases are handled gracefully in that the lexer will keep going fine, it will just not properly detect the export names above. Benchmarks Benchmarks can be run with npm run bench. Current results for a high spec machine: Wasm Build Module load time > 5ms Cold Run, All Samples test/samples/*.js (3123 KiB) > 18ms Warm Runs (average of 25 runs) test/samples/angular.js (739 KiB) > 3ms test/samples/angular.min.js (188 KiB) > 1ms test/samples/d3.js (508 KiB) > 3ms test/samples/d3.min.js (274 KiB) > 2ms test/samples/magic-string.js (35 KiB) > 0ms test/samples/magic-string.min.js (20 KiB) > 0ms test/samples/rollup.js (929 KiB) > 4.32ms test/samples/rollup.min.js (429 KiB) > 2.16ms Warm Runs, All Samples (average of 25 runs) test/samples/*.js (3123 KiB) > 14.16ms JS Build (asm.js) Module load time > 2ms Cold Run, All Samples test/samples/*.js (3123 KiB) > 34ms Warm Runs (average of 25 runs) test/samples/angular.js (739 KiB) > 3ms test/samples/angular.min.js (188 KiB) > 1ms test/samples/d3.js (508 KiB) > 3ms test/samples/d3.min.js (274 KiB) > 2ms test/samples/magic-string.js (35 KiB) > 0ms test/samples/magic-string.min.js (20 KiB) > 0ms test/samples/rollup.js (929 KiB) > 5ms test/samples/rollup.min.js (429 KiB) > 3.04ms Warm Runs, All Samples (average of 25 runs) test/samples/*.js (3123 KiB) > 17.12ms Building This project uses Chomp for building. With Chomp installed, download the WASI SDK 12.0 from https://github.com/WebAssembly/wasi-sdk/releases/tag/wasi-sdk-12. Linux Windows (MinGW) macOS Locate the WASI-SDK as a sibling folder, or customize the path via the WASI_PATH environment variable. Emscripten emsdk is also assumed to be a sibling folder or via the EMSDK_PATH environment variable. Example setup: git clone https://github.com:guybedford/es-module-lexer git clone https://github.com/emscripten-core/emsdk cd emsdk git checkout 1.40.1-fastcomp ./emsdk install 1.40.1-fastcomp cd .. wget https://github.com/WebAssembly/wasi-sdk/releases/download/wasi-sdk-12/wasi-sdk-12.0-linux.tar.gz gunzip wasi-sdk-12.0-linux.tar.gz tar -xf wasi-sdk-12.0-linux.tar mv wasi-sdk-12.0-linux.tar wasi-sdk-12.0 cargo install chompbuild cd es-module-lexer chomp test For the asm.js build, git clone emsdk from is assumed to be a sibling folder as well. License MIT"
  },
  "src/frontend/app-client/node_modules/es-object-atoms/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/es-object-atoms/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.1.1 - 2025-01-14 Commits [types] ToObject: improve types cfe8c8a v1.1.0 - 2025-01-14 Commits [New] add isObject 51e4042 v1.0.1 - 2025-01-13 Commits [Dev Deps] update @ljharb/eslint-config, @ljharb/tsconfig, @types/tape, auto-changelog, tape 38ab9eb [types] improve types 7d1beb8 [Tests] replace aud with npm audit 25863ba [Dev Deps] add missing peer dep c012309 v1.0.0 - 2024-03-16 Commits Initial implementation, tests, readme, types f1499db Initial commit 99eedc7 [meta] rename repo fc851fa npm init b909377 Only apps should have lockfiles 7249edd"
  },
  "src/frontend/app-client/node_modules/es-object-atoms/README.html": {
    "href": "src/frontend/app-client/node_modules/es-object-atoms/README.html",
    "title": "es-object-atoms",
    "summary": "es-object-atoms ES Object-related atoms: Object, ToObject, RequireObjectCoercible. Example const assert = require('assert'); const $Object = require('es-object-atoms'); const isObject = require('es-object-atoms/isObject'); const ToObject = require('es-object-atoms/ToObject'); const RequireObjectCoercible = require('es-object-atoms/RequireObjectCoercible'); assert.equal($Object, Object); assert.throws(() => ToObject(null), TypeError); assert.throws(() => ToObject(undefined), TypeError); assert.throws(() => RequireObjectCoercible(null), TypeError); assert.throws(() => RequireObjectCoercible(undefined), TypeError); assert.equal(isObject(undefined), false); assert.equal(isObject(null), false); assert.equal(isObject({}), true); assert.equal(isObject([]), true); assert.equal(isObject(function () {}), true); assert.deepEqual(RequireObjectCoercible(true), true); assert.deepEqual(ToObject(true), Object(true)); const obj = {}; assert.equal(RequireObjectCoercible(obj), obj); assert.equal(ToObject(obj), obj); Tests Simply clone the repo, npm install, and run npm test Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report."
  },
  "src/frontend/app-client/node_modules/esbuild/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/esbuild/LICENSE.html",
    "title": "",
    "summary": "MIT License Copyright (c) 2020 Evan Wallace Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/esbuild/README.html": {
    "href": "src/frontend/app-client/node_modules/esbuild/README.html",
    "title": "esbuild",
    "summary": "esbuild This is a JavaScript bundler and minifier. See https://github.com/evanw/esbuild and the JavaScript API documentation for details."
  },
  "src/frontend/app-client/node_modules/escalade/readme.html": {
    "href": "src/frontend/app-client/node_modules/escalade/readme.html",
    "title": "escalade",
    "summary": "escalade A tiny (183B to 210B) and fast utility to ascend parent directories With escalade, you can scale parent directories until you've found what you're looking for. Given an input file or directory, escalade will continue executing your callback function until either: the callback returns a truthy value escalade has reached the system root directory (eg, /) Important: Please note that escalade only deals with direct ancestry – it will not dive into parents' sibling directories. Notice: As of v3.1.0, escalade now includes Deno support! Please see Deno Usage below. Install $ npm install --save escalade Modes There are two \"versions\" of escalade available: \"async\" Node.js: >= 8.x Size (gzip): 210 bytes Availability: CommonJS, ES Module This is the primary/default mode. It makes use of async/await and util.promisify. \"sync\" Node.js: >= 6.x Size (gzip): 183 bytes Availability: CommonJS, ES Module This is the opt-in mode, ideal for scenarios where async usage cannot be supported. Usage Example Structure /Users/lukeed └── oss ├── license └── escalade ├── package.json └── test └── fixtures ├── index.js └── foobar └── demo.js Example Usage //~> demo.js import { join } from 'path'; import escalade from 'escalade'; const input = join(__dirname, 'demo.js'); // or: const input = __dirname; const pkg = await escalade(input, (dir, names) => { console.log('~> dir:', dir); console.log('~> names:', names); console.log('---'); if (names.includes('package.json')) { // will be resolved into absolute return 'package.json'; } }); //~> dir: /Users/lukeed/oss/escalade/test/fixtures/foobar //~> names: ['demo.js'] //--- //~> dir: /Users/lukeed/oss/escalade/test/fixtures //~> names: ['index.js', 'foobar'] //--- //~> dir: /Users/lukeed/oss/escalade/test //~> names: ['fixtures'] //--- //~> dir: /Users/lukeed/oss/escalade //~> names: ['package.json', 'test'] //--- console.log(pkg); //=> /Users/lukeed/oss/escalade/package.json // Now search for \"missing123.txt\" // (Assume it doesn't exist anywhere!) const missing = await escalade(input, (dir, names) => { console.log('~> dir:', dir); return names.includes('missing123.txt') && 'missing123.txt'; }); //~> dir: /Users/lukeed/oss/escalade/test/fixtures/foobar //~> dir: /Users/lukeed/oss/escalade/test/fixtures //~> dir: /Users/lukeed/oss/escalade/test //~> dir: /Users/lukeed/oss/escalade //~> dir: /Users/lukeed/oss //~> dir: /Users/lukeed //~> dir: /Users //~> dir: / console.log(missing); //=> undefined Note: To run the above example with \"sync\" mode, import from escalade/sync and remove the await keyword. API escalade(input, callback) Returns: string|void or Promise<string|void> When your callback locates a file, escalade will resolve/return with an absolute path. If your callback was never satisfied, then escalade will resolve/return with nothing (undefined). Important: The sync and async versions share the same API. The only difference is that sync is not Promise-based. input Type: string The path from which to start ascending. This may be a file or a directory path. However, when input is a file, escalade will begin with its parent directory. Important: Unless given an absolute path, input will be resolved from process.cwd() location. callback Type: Function The callback to execute for each ancestry level. It always is given two arguments: dir - an absolute path of the current parent directory names - a list (string[]) of contents relative to the dir parent Note: The names list can contain names of files and directories. When your callback returns a falsey value, then escalade will continue with dir's parent directory, re-invoking your callback with new argument values. When your callback returns a string, then escalade stops iteration immediately. If the string is an absolute path, then it's left as is. Otherwise, the string is resolved into an absolute path from the dir that housed the satisfying condition. Important: Your callback can be a Promise/AsyncFunction when using the \"async\" version of escalade. Benchmarks Running on Node.js v10.13.0 # Load Time find-up 3.891ms escalade 0.485ms escalade/sync 0.309ms # Levels: 6 (target = \"foo.txt\"): find-up x 24,856 ops/sec ±6.46% (55 runs sampled) escalade x 73,084 ops/sec ±4.23% (73 runs sampled) find-up.sync x 3,663 ops/sec ±1.12% (83 runs sampled) escalade/sync x 9,360 ops/sec ±0.62% (88 runs sampled) # Levels: 12 (target = \"package.json\"): find-up x 29,300 ops/sec ±10.68% (70 runs sampled) escalade x 73,685 ops/sec ± 5.66% (66 runs sampled) find-up.sync x 1,707 ops/sec ± 0.58% (91 runs sampled) escalade/sync x 4,667 ops/sec ± 0.68% (94 runs sampled) # Levels: 18 (target = \"missing123.txt\"): find-up x 21,818 ops/sec ±17.37% (14 runs sampled) escalade x 67,101 ops/sec ±21.60% (20 runs sampled) find-up.sync x 1,037 ops/sec ± 2.86% (88 runs sampled) escalade/sync x 1,248 ops/sec ± 0.50% (93 runs sampled) Deno As of v3.1.0, escalade is available on the Deno registry. Please note that the API is identical and that there are still two modes from which to choose: // Choose \"async\" mode import escalade from 'https://deno.land/escalade/async.ts'; // Choose \"sync\" mode import escalade from 'https://deno.land/escalade/sync.ts'; Important: The allow-read permission is required! Related premove - A tiny (247B) utility to remove items recursively totalist - A tiny (195B to 224B) utility to recursively list all (total) files in a directory mk-dirs - A tiny (420B) utility to make a directory and its parents, recursively License MIT © Luke Edwards"
  },
  "src/frontend/app-client/node_modules/escape-html/Readme.html": {
    "href": "src/frontend/app-client/node_modules/escape-html/Readme.html",
    "title": "escape-html",
    "summary": "escape-html Escape string for use in HTML Example var escape = require('escape-html'); var html = escape('foo & bar'); // -> foo &amp; bar Benchmark $ npm run-script bench > escape-html@1.0.3 bench nodejs-escape-html > node benchmark/index.js http_parser@1.0 node@0.10.33 v8@3.14.5.9 ares@1.9.0-DEV uv@0.10.29 zlib@1.2.3 modules@11 openssl@1.0.1j 1 test completed. 2 tests completed. 3 tests completed. no special characters x 19,435,271 ops/sec ±0.85% (187 runs sampled) single special character x 6,132,421 ops/sec ±0.67% (194 runs sampled) many special characters x 3,175,826 ops/sec ±0.65% (193 runs sampled) License MIT"
  },
  "src/frontend/app-client/node_modules/escape-string-regexp/readme.html": {
    "href": "src/frontend/app-client/node_modules/escape-string-regexp/readme.html",
    "title": "escape-string-regexp",
    "summary": "escape-string-regexp Escape RegExp special characters Install $ npm install escape-string-regexp Usage const escapeStringRegexp = require('escape-string-regexp'); const escapedString = escapeStringRegexp('How much $ for a \uD83E\uDD84?'); //=> 'How much \\\\$ for a \uD83E\uDD84\\\\?' new RegExp(escapedString); You can also use this to escape a string that is inserted into the middle of a regex, for example, into a character class. Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "src/frontend/app-client/node_modules/etag/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/etag/HISTORY.html",
    "title": "1.8.1 / 2017-09-12",
    "summary": "1.8.1 / 2017-09-12 perf: replace regular expression with substring 1.8.0 / 2017-02-18 Use SHA1 instead of MD5 for ETag hashing Improves performance for larger entities Works with FIPS 140-2 OpenSSL configuration 1.7.0 / 2015-06-08 Always include entity length in ETags for hash length extensions Generate non-Stats ETags using MD5 only (no longer CRC32) Improve stat performance by removing hashing Remove base64 padding in ETags to shorten Use MD5 instead of MD4 in weak ETags over 1KB 1.6.0 / 2015-05-10 Improve support for JXcore Remove requirement of atime in the stats object Support \"fake\" stats objects in environments without fs 1.5.1 / 2014-11-19 deps: crc@3.2.1 Minor fixes 1.5.0 / 2014-10-14 Improve string performance Slightly improve speed for weak ETags over 1KB 1.4.0 / 2014-09-21 Support \"fake\" stats objects Support Node.js 0.6 1.3.1 / 2014-09-14 Use the (new and improved) crc for crc32 1.3.0 / 2014-08-29 Default strings to strong ETags Improve speed for weak ETags over 1KB 1.2.1 / 2014-08-29 Use the (much faster) buffer-crc32 for crc32 1.2.0 / 2014-08-24 Add support for file stat objects 1.1.0 / 2014-08-24 Add fast-path for empty entity Add weak ETag generation Shrink size of generated ETags 1.0.1 / 2014-08-24 Fix behavior of string containing Unicode 1.0.0 / 2014-05-18 Initial release"
  },
  "src/frontend/app-client/node_modules/etag/README.html": {
    "href": "src/frontend/app-client/node_modules/etag/README.html",
    "title": "etag",
    "summary": "etag Create simple HTTP ETags This module generates HTTP ETags (as defined in RFC 7232) for use in HTTP responses. Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install etag API var etag = require('etag') etag(entity, [options]) Generate a strong ETag for the given entity. This should be the complete body of the entity. Strings, Buffers, and fs.Stats are accepted. By default, a strong ETag is generated except for fs.Stats, which will generate a weak ETag (this can be overwritten by options.weak). res.setHeader('ETag', etag(body)) Options etag accepts these properties in the options object. weak Specifies if the generated ETag will include the weak validator mark (that is, the leading W/). The actual entity tag is the same. The default value is false, unless the entity is fs.Stats, in which case it is true. Testing $ npm test Benchmark $ npm run-script bench > etag@1.8.1 bench nodejs-etag > node benchmark/index.js http_parser@2.7.0 node@6.11.1 v8@5.1.281.103 uv@1.11.0 zlib@1.2.11 ares@1.10.1-DEV icu@58.2 modules@48 openssl@1.0.2k > node benchmark/body0-100b.js 100B body 4 tests completed. buffer - strong x 258,647 ops/sec ±1.07% (180 runs sampled) buffer - weak x 263,812 ops/sec ±0.61% (184 runs sampled) string - strong x 259,955 ops/sec ±1.19% (185 runs sampled) string - weak x 264,356 ops/sec ±1.09% (184 runs sampled) > node benchmark/body1-1kb.js 1KB body 4 tests completed. buffer - strong x 189,018 ops/sec ±1.12% (182 runs sampled) buffer - weak x 190,586 ops/sec ±0.81% (186 runs sampled) string - strong x 144,272 ops/sec ±0.96% (188 runs sampled) string - weak x 145,380 ops/sec ±1.43% (187 runs sampled) > node benchmark/body2-5kb.js 5KB body 4 tests completed. buffer - strong x 92,435 ops/sec ±0.42% (188 runs sampled) buffer - weak x 92,373 ops/sec ±0.58% (189 runs sampled) string - strong x 48,850 ops/sec ±0.56% (186 runs sampled) string - weak x 49,380 ops/sec ±0.56% (190 runs sampled) > node benchmark/body3-10kb.js 10KB body 4 tests completed. buffer - strong x 55,989 ops/sec ±0.93% (188 runs sampled) buffer - weak x 56,148 ops/sec ±0.55% (190 runs sampled) string - strong x 27,345 ops/sec ±0.43% (188 runs sampled) string - weak x 27,496 ops/sec ±0.45% (190 runs sampled) > node benchmark/body4-100kb.js 100KB body 4 tests completed. buffer - strong x 7,083 ops/sec ±0.22% (190 runs sampled) buffer - weak x 7,115 ops/sec ±0.26% (191 runs sampled) string - strong x 3,068 ops/sec ±0.34% (190 runs sampled) string - weak x 3,096 ops/sec ±0.35% (190 runs sampled) > node benchmark/stats.js stat 4 tests completed. real - strong x 871,642 ops/sec ±0.34% (189 runs sampled) real - weak x 867,613 ops/sec ±0.39% (190 runs sampled) fake - strong x 401,051 ops/sec ±0.40% (189 runs sampled) fake - weak x 400,100 ops/sec ±0.47% (188 runs sampled) License MIT"
  },
  "src/frontend/app-client/node_modules/exit-hook/readme.html": {
    "href": "src/frontend/app-client/node_modules/exit-hook/readme.html",
    "title": "exit-hook",
    "summary": "exit-hook Run some code when the process exits The process.on('exit') event doesn't catch all the ways a process can exit. This package is useful for cleaning up before exiting. Install $ npm install exit-hook Usage const exitHook = require('exit-hook'); exitHook(() => { console.log('Exiting'); }); // You can add multiple hooks, even across files exitHook(() => { console.log('Exiting 2'); }); throw new Error('\uD83E\uDD84'); //=> 'Exiting' //=> 'Exiting 2' Removing an exit hook: const exitHook = require('exit-hook'); const unsubscribe = exitHook(() => {}); unsubscribe(); API exitHook(callback) Returns a function that removes the hook when called. callback Type: Function The callback to execute when the process exits. Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "src/frontend/app-client/node_modules/express/History.html": {
    "href": "src/frontend/app-client/node_modules/express/History.html",
    "title": "4.21.2 / 2024-11-06",
    "summary": "4.21.2 / 2024-11-06 deps: path-to-regexp@0.1.12 Fix backtracking protection deps: path-to-regexp@0.1.11 Throws an error on invalid path values 4.21.1 / 2024-10-08 Backported a fix for CVE-2024-47764 4.21.0 / 2024-09-11 Deprecate res.location(\"back\") and res.redirect(\"back\") magic string deps: serve-static@1.16.2 includes send@0.19.0 deps: finalhandler@1.3.1 deps: qs@6.13.0 4.20.0 / 2024-09-10 deps: serve-static@0.16.0 Remove link renderization in html while redirecting deps: send@0.19.0 Remove link renderization in html while redirecting deps: body-parser@0.6.0 add depth option to customize the depth level in the parser IMPORTANT: The default depth level for parsing URL-encoded data is now 32 (previously was Infinity) Remove link renderization in html while using res.redirect deps: path-to-regexp@0.1.10 Adds support for named matching groups in the routes using a regex Adds backtracking protection to parameters without regexes defined deps: encodeurl@~2.0.0 Removes encoding of \\, |, and ^ to align better with URL spec Deprecate passing options.maxAge and options.expires to res.clearCookie Will be ignored in v5, clearCookie will set a cookie with an expires in the past to instruct clients to delete the cookie 4.19.2 / 2024-03-25 Improved fix for open redirect allow list bypass 4.19.1 / 2024-03-20 Allow passing non-strings to res.location with new encoding handling checks 4.19.0 / 2024-03-20 Prevent open redirect allow list bypass due to encodeurl deps: cookie@0.6.0 4.18.3 / 2024-02-29 Fix routing requests without method deps: body-parser@1.20.2 Fix strict json error message on Node.js 19+ deps: content-type@~1.0.5 deps: raw-body@2.5.2 deps: cookie@0.6.0 Add partitioned option 4.18.2 / 2022-10-08 Fix regression routing a large stack in a single route deps: body-parser@1.20.1 deps: qs@6.11.0 perf: remove unnecessary object clone deps: qs@6.11.0 4.18.1 / 2022-04-29 Fix hanging on large stack of sync routes 4.18.0 / 2022-04-25 Add \"root\" option to res.download Allow options without filename in res.download Deprecate string and non-integer arguments to res.status Fix behavior of null/undefined as maxAge in res.cookie Fix handling very large stacks of sync middleware Ignore Object.prototype values in settings through app.set/app.get Invoke default with same arguments as types in res.format Support proper 205 responses using res.send Use http-errors for res.format error deps: body-parser@1.20.0 Fix error message for json parse whitespace in strict Fix internal error when inflated body exceeds limit Prevent loss of async hooks context Prevent hanging when request already read deps: depd@2.0.0 deps: http-errors@2.0.0 deps: on-finished@2.4.1 deps: qs@6.10.3 deps: raw-body@2.5.1 deps: cookie@0.5.0 Add priority option Fix expires option to reject invalid dates deps: depd@2.0.0 Replace internal eval usage with Function constructor Use instance methods on process to check for listeners deps: finalhandler@1.2.0 Remove set content headers that break response deps: on-finished@2.4.1 deps: statuses@2.0.1 deps: on-finished@2.4.1 Prevent loss of async hooks context deps: qs@6.10.3 deps: send@0.18.0 Fix emitted 416 error missing headers property Limit the headers removed for 304 response deps: depd@2.0.0 deps: destroy@1.2.0 deps: http-errors@2.0.0 deps: on-finished@2.4.1 deps: statuses@2.0.1 deps: serve-static@1.15.0 deps: send@0.18.0 deps: statuses@2.0.1 Remove code 306 Rename 425 Unordered Collection to standard 425 Too Early 4.17.3 / 2022-02-16 deps: accepts@~1.3.8 deps: mime-types@~2.1.34 deps: negotiator@0.6.3 deps: body-parser@1.19.2 deps: bytes@3.1.2 deps: qs@6.9.7 deps: raw-body@2.4.3 deps: cookie@0.4.2 deps: qs@6.9.7 Fix handling of __proto__ keys pref: remove unnecessary regexp for trust proxy 4.17.2 / 2021-12-16 Fix handling of undefined in res.jsonp Fix handling of undefined when \"json escape\" is enabled Fix incorrect middleware execution with unanchored RegExps Fix res.jsonp(obj, status) deprecation message Fix typo in res.is JSDoc deps: body-parser@1.19.1 deps: bytes@3.1.1 deps: http-errors@1.8.1 deps: qs@6.9.6 deps: raw-body@2.4.2 deps: safe-buffer@5.2.1 deps: type-is@~1.6.18 deps: content-disposition@0.5.4 deps: safe-buffer@5.2.1 deps: cookie@0.4.1 Fix maxAge option to reject invalid values deps: proxy-addr@~2.0.7 Use req.socket over deprecated req.connection deps: forwarded@0.2.0 deps: ipaddr.js@1.9.1 deps: qs@6.9.6 deps: safe-buffer@5.2.1 deps: send@0.17.2 deps: http-errors@1.8.1 deps: ms@2.1.3 pref: ignore empty http tokens deps: serve-static@1.14.2 deps: send@0.17.2 deps: setprototypeof@1.2.0 4.17.1 / 2019-05-25 Revert \"Improve error message for null/undefined to res.status\" 4.17.0 / 2019-05-16 Add express.raw to parse bodies into Buffer Add express.text to parse bodies into string Improve error message for non-strings to res.sendFile Improve error message for null/undefined to res.status Support multiple hosts in X-Forwarded-Host deps: accepts@~1.3.7 deps: body-parser@1.19.0 Add encoding MIK Add petabyte (pb) support Fix parsing array brackets after index deps: bytes@3.1.0 deps: http-errors@1.7.2 deps: iconv-lite@0.4.24 deps: qs@6.7.0 deps: raw-body@2.4.0 deps: type-is@~1.6.17 deps: content-disposition@0.5.3 deps: cookie@0.4.0 Add SameSite=None support deps: finalhandler@~1.1.2 Set stricter Content-Security-Policy header deps: parseurl@~1.3.3 deps: statuses@~1.5.0 deps: parseurl@~1.3.3 deps: proxy-addr@~2.0.5 deps: ipaddr.js@1.9.0 deps: qs@6.7.0 Fix parsing array brackets after index deps: range-parser@~1.2.1 deps: send@0.17.1 Set stricter CSP header in redirect & error responses deps: http-errors@~1.7.2 deps: mime@1.6.0 deps: ms@2.1.1 deps: range-parser@~1.2.1 deps: statuses@~1.5.0 perf: remove redundant path.normalize call deps: serve-static@1.14.1 Set stricter CSP header in redirect response deps: parseurl@~1.3.3 deps: send@0.17.1 deps: setprototypeof@1.1.1 deps: statuses@~1.5.0 Add 103 Early Hints deps: type-is@~1.6.18 deps: mime-types@~2.1.24 perf: prevent internal throw on invalid type 4.16.4 / 2018-10-10 Fix issue where \"Request aborted\" may be logged in res.sendfile Fix JSDoc for Router constructor deps: body-parser@1.18.3 Fix deprecation warnings on Node.js 10+ Fix stack trace for strict json parse error deps: depd@~1.1.2 deps: http-errors@~1.6.3 deps: iconv-lite@0.4.23 deps: qs@6.5.2 deps: raw-body@2.3.3 deps: type-is@~1.6.16 deps: proxy-addr@~2.0.4 deps: ipaddr.js@1.8.0 deps: qs@6.5.2 deps: safe-buffer@5.1.2 4.16.3 / 2018-03-12 deps: accepts@~1.3.5 deps: mime-types@~2.1.18 deps: depd@~1.1.2 perf: remove argument reassignment deps: encodeurl@~1.0.2 Fix encoding % as last character deps: finalhandler@1.1.1 Fix 404 output for bad / missing pathnames deps: encodeurl@~1.0.2 deps: statuses@~1.4.0 deps: proxy-addr@~2.0.3 deps: ipaddr.js@1.6.0 deps: send@0.16.2 Fix incorrect end tag in default error & redirects deps: depd@~1.1.2 deps: encodeurl@~1.0.2 deps: statuses@~1.4.0 deps: serve-static@1.13.2 Fix incorrect end tag in redirects deps: encodeurl@~1.0.2 deps: send@0.16.2 deps: statuses@~1.4.0 deps: type-is@~1.6.16 deps: mime-types@~2.1.18 4.16.2 / 2017-10-09 Fix TypeError in res.send when given Buffer and ETag header set perf: skip parsing of entire X-Forwarded-Proto header 4.16.1 / 2017-09-29 deps: send@0.16.1 deps: serve-static@1.13.1 Fix regression when root is incorrectly set to a file deps: send@0.16.1 4.16.0 / 2017-09-28 Add \"json escape\" setting for res.json and res.jsonp Add express.json and express.urlencoded to parse bodies Add options argument to res.download Improve error message when autoloading invalid view engine Improve error messages when non-function provided as middleware Skip Buffer encoding when not generating ETag for small response Use safe-buffer for improved Buffer API deps: accepts@~1.3.4 deps: mime-types@~2.1.16 deps: content-type@~1.0.4 perf: remove argument reassignment perf: skip parameter parsing when no parameters deps: etag@~1.8.1 perf: replace regular expression with substring deps: finalhandler@1.1.0 Use res.headersSent when available deps: parseurl@~1.3.2 perf: reduce overhead for full URLs perf: unroll the \"fast-path\" RegExp deps: proxy-addr@~2.0.2 Fix trimming leading / trailing OWS in X-Forwarded-For deps: forwarded@~0.1.2 deps: ipaddr.js@1.5.2 perf: reduce overhead when no X-Forwarded-For header deps: qs@6.5.1 Fix parsing & compacting very deep objects deps: send@0.16.0 Add 70 new types for file extensions Add immutable option Fix missing </html> in default error & redirects Set charset as \"UTF-8\" for .js and .json Use instance methods on steam to check for listeners deps: mime@1.4.1 perf: improve path validation speed deps: serve-static@1.13.0 Add 70 new types for file extensions Add immutable option Set charset as \"UTF-8\" for .js and .json deps: send@0.16.0 deps: setprototypeof@1.1.0 deps: utils-merge@1.0.1 deps: vary@~1.1.2 perf: improve header token parsing speed perf: re-use options object when generating ETags perf: remove dead .charset set in res.jsonp 4.15.5 / 2017-09-24 deps: debug@2.6.9 deps: finalhandler@~1.0.6 deps: debug@2.6.9 deps: parseurl@~1.3.2 deps: fresh@0.5.2 Fix handling of modified headers with invalid dates perf: improve ETag match loop perf: improve If-None-Match token parsing deps: send@0.15.6 Fix handling of modified headers with invalid dates deps: debug@2.6.9 deps: etag@~1.8.1 deps: fresh@0.5.2 perf: improve If-Match token parsing deps: serve-static@1.12.6 deps: parseurl@~1.3.2 deps: send@0.15.6 perf: improve slash collapsing 4.15.4 / 2017-08-06 deps: debug@2.6.8 deps: depd@~1.1.1 Remove unnecessary Buffer loading deps: finalhandler@~1.0.4 deps: debug@2.6.8 deps: proxy-addr@~1.1.5 Fix array argument being altered deps: ipaddr.js@1.4.0 deps: qs@6.5.0 deps: send@0.15.4 deps: debug@2.6.8 deps: depd@~1.1.1 deps: http-errors@~1.6.2 deps: serve-static@1.12.4 deps: send@0.15.4 4.15.3 / 2017-05-16 Fix error when res.set cannot add charset to Content-Type deps: debug@2.6.7 Fix DEBUG_MAX_ARRAY_LENGTH deps: ms@2.0.0 deps: finalhandler@~1.0.3 Fix missing </html> in HTML document deps: debug@2.6.7 deps: proxy-addr@~1.1.4 deps: ipaddr.js@1.3.0 deps: send@0.15.3 deps: debug@2.6.7 deps: ms@2.0.0 deps: serve-static@1.12.3 deps: send@0.15.3 deps: type-is@~1.6.15 deps: mime-types@~2.1.15 deps: vary@~1.1.1 perf: hoist regular expression 4.15.2 / 2017-03-06 deps: qs@6.4.0 Fix regression parsing keys starting with [ 4.15.1 / 2017-03-05 deps: send@0.15.1 Fix issue when Date.parse does not return NaN on invalid date Fix strict violation in broken environments deps: serve-static@1.12.1 Fix issue when Date.parse does not return NaN on invalid date deps: send@0.15.1 4.15.0 / 2017-03-01 Add debug message when loading view engine Add next(\"router\") to exit from router Fix case where router.use skipped requests routes did not Remove usage of res._headers private field Improves compatibility with Node.js 8 nightly Skip routing when req.url is not set Use %o in path debug to tell types apart Use Object.create to setup request & response prototypes Use setprototypeof module to replace __proto__ setting Use statuses instead of http module for status messages deps: debug@2.6.1 Allow colors in workers Deprecated DEBUG_FD environment variable set to 3 or higher Fix error when running under React Native Use same color for same namespace deps: ms@0.7.2 deps: etag@~1.8.0 Use SHA1 instead of MD5 for ETag hashing Works with FIPS 140-2 OpenSSL configuration deps: finalhandler@~1.0.0 Fix exception when err cannot be converted to a string Fully URL-encode the pathname in the 404 Only include the pathname in the 404 message Send complete HTML document Set Content-Security-Policy: default-src 'self' header deps: debug@2.6.1 deps: fresh@0.5.0 Fix false detection of no-cache request directive Fix incorrect result when If-None-Match has both * and ETags Fix weak ETag matching to match spec perf: delay reading header values until needed perf: enable strict mode perf: hoist regular expressions perf: remove duplicate conditional perf: remove unnecessary boolean coercions perf: skip checking modified time if ETag check failed perf: skip parsing If-None-Match when no ETag header perf: use Date.parse instead of new Date deps: qs@6.3.1 Fix array parsing from skipping empty values Fix compacting nested arrays deps: send@0.15.0 Fix false detection of no-cache request directive Fix incorrect result when If-None-Match has both * and ETags Fix weak ETag matching to match spec Remove usage of res._headers private field Support If-Match and If-Unmodified-Since headers Use res.getHeaderNames() when available Use res.headersSent when available deps: debug@2.6.1 deps: etag@~1.8.0 deps: fresh@0.5.0 deps: http-errors@~1.6.1 deps: serve-static@1.12.0 Fix false detection of no-cache request directive Fix incorrect result when If-None-Match has both * and ETags Fix weak ETag matching to match spec Remove usage of res._headers private field Send complete HTML document in redirect response Set default CSP header in redirect response Support If-Match and If-Unmodified-Since headers Use res.getHeaderNames() when available Use res.headersSent when available deps: send@0.15.0 perf: add fast match path for * route perf: improve req.ips performance 4.14.1 / 2017-01-28 deps: content-disposition@0.5.2 deps: finalhandler@0.5.1 Fix exception when err.headers is not an object deps: statuses@~1.3.1 perf: hoist regular expressions perf: remove duplicate validation path deps: proxy-addr@~1.1.3 deps: ipaddr.js@1.2.0 deps: send@0.14.2 deps: http-errors@~1.5.1 deps: ms@0.7.2 deps: statuses@~1.3.1 deps: serve-static@~1.11.2 deps: send@0.14.2 deps: type-is@~1.6.14 deps: mime-types@~2.1.13 4.14.0 / 2016-06-16 Add acceptRanges option to res.sendFile/res.sendfile Add cacheControl option to res.sendFile/res.sendfile Add options argument to req.range Includes the combine option Encode URL in res.location/res.redirect if not already encoded Fix some redirect handling in res.sendFile/res.sendfile Fix Windows absolute path check using forward slashes Improve error with invalid arguments to req.get() Improve performance for res.json/res.jsonp in most cases Improve Range header handling in res.sendFile/res.sendfile deps: accepts@~1.3.3 Fix including type extensions in parameters in Accept parsing Fix parsing Accept parameters with quoted equals Fix parsing Accept parameters with quoted semicolons Many performance improvements deps: mime-types@~2.1.11 deps: negotiator@0.6.1 deps: content-type@~1.0.2 perf: enable strict mode deps: cookie@0.3.1 Add sameSite option Fix cookie Max-Age to never be a floating point number Improve error message when encode is not a function Improve error message when expires is not a Date Throw better error for invalid argument to parse Throw on invalid values provided to serialize perf: enable strict mode perf: hoist regular expression perf: use for loop in parse perf: use string concatenation for serialization deps: finalhandler@0.5.0 Change invalid or non-numeric status code to 500 Overwrite status message to match set status code Prefer err.statusCode if err.status is invalid Set response headers from err.headers object Use statuses instead of http module for status messages deps: proxy-addr@~1.1.2 Fix accepting various invalid netmasks Fix IPv6-mapped IPv4 validation edge cases IPv4 netmasks must be contiguous IPv6 addresses cannot be used as a netmask deps: ipaddr.js@1.1.1 deps: qs@6.2.0 Add decoder option in parse function deps: range-parser@~1.2.0 Add combine option to combine overlapping ranges Fix incorrectly returning -1 when there is at least one valid range perf: remove internal function deps: send@0.14.1 Add acceptRanges option Add cacheControl option Attempt to combine multiple ranges into single range Correctly inherit from Stream class Fix Content-Range header in 416 responses when using start/end options Fix Content-Range header missing from default 416 responses Fix redirect error when path contains raw non-URL characters Fix redirect when path starts with multiple forward slashes Ignore non-byte Range headers deps: http-errors@~1.5.0 deps: range-parser@~1.2.0 deps: statuses@~1.3.0 perf: remove argument reassignment deps: serve-static@~1.11.1 Add acceptRanges option Add cacheControl option Attempt to combine multiple ranges into single range Fix redirect error when req.url contains raw non-URL characters Ignore non-byte Range headers Use status code 301 for redirects deps: send@0.14.1 deps: type-is@~1.6.13 Fix type error when given invalid type to match against deps: mime-types@~2.1.11 deps: vary@~1.1.0 Only accept valid field names in the field argument perf: use strict equality when possible 4.13.4 / 2016-01-21 deps: content-disposition@0.5.1 perf: enable strict mode deps: cookie@0.1.5 Throw on invalid values provided to serialize deps: depd@~1.1.0 Support web browser loading perf: enable strict mode deps: escape-html@~1.0.3 perf: enable strict mode perf: optimize string replacement perf: use faster string coercion deps: finalhandler@0.4.1 deps: escape-html@~1.0.3 deps: merge-descriptors@1.0.1 perf: enable strict mode deps: methods@~1.1.2 perf: enable strict mode deps: parseurl@~1.3.1 perf: enable strict mode deps: proxy-addr@~1.0.10 deps: ipaddr.js@1.0.5 perf: enable strict mode deps: range-parser@~1.0.3 perf: enable strict mode deps: send@0.13.1 deps: depd@~1.1.0 deps: destroy@~1.0.4 deps: escape-html@~1.0.3 deps: range-parser@~1.0.3 deps: serve-static@~1.10.2 deps: escape-html@~1.0.3 deps: parseurl@~1.3.0 deps: send@0.13.1 4.13.3 / 2015-08-02 Fix infinite loop condition using mergeParams: true Fix inner numeric indices incorrectly altering parent req.params 4.13.2 / 2015-07-31 deps: accepts@~1.2.12 deps: mime-types@~2.1.4 deps: array-flatten@1.1.1 perf: enable strict mode deps: path-to-regexp@0.1.7 Fix regression with escaped round brackets and matching groups deps: type-is@~1.6.6 deps: mime-types@~2.1.4 4.13.1 / 2015-07-05 deps: accepts@~1.2.10 deps: mime-types@~2.1.2 deps: qs@4.0.0 Fix dropping parameters like hasOwnProperty Fix various parsing edge cases deps: type-is@~1.6.4 deps: mime-types@~2.1.2 perf: enable strict mode perf: remove argument reassignment 4.13.0 / 2015-06-20 Add settings to debug output Fix res.format error when only default provided Fix issue where next('route') in app.param would incorrectly skip values Fix hiding platform issues with decodeURIComponent Only URIErrors are a 400 Fix using * before params in routes Fix using capture groups before params in routes Simplify res.cookie to call res.append Use array-flatten module for flattening arrays deps: accepts@~1.2.9 deps: mime-types@~2.1.1 perf: avoid argument reassignment & argument slice perf: avoid negotiator recursive construction perf: enable strict mode perf: remove unnecessary bitwise operator deps: cookie@0.1.3 perf: deduce the scope of try-catch deopt perf: remove argument reassignments deps: escape-html@1.0.2 deps: etag@~1.7.0 Always include entity length in ETags for hash length extensions Generate non-Stats ETags using MD5 only (no longer CRC32) Improve stat performance by removing hashing Improve support for JXcore Remove base64 padding in ETags to shorten Support \"fake\" stats objects in environments without fs Use MD5 instead of MD4 in weak ETags over 1KB deps: finalhandler@0.4.0 Fix a false-positive when unpiping in Node.js 0.8 Support statusCode property on Error objects Use unpipe module for unpiping requests deps: escape-html@1.0.2 deps: on-finished@~2.3.0 perf: enable strict mode perf: remove argument reassignment deps: fresh@0.3.0 Add weak ETag matching support deps: on-finished@~2.3.0 Add defined behavior for HTTP CONNECT requests Add defined behavior for HTTP Upgrade requests deps: ee-first@1.1.1 deps: path-to-regexp@0.1.6 deps: send@0.13.0 Allow Node.js HTTP server to set Date response header Fix incorrectly removing Content-Location on 304 response Improve the default redirect response headers Send appropriate headers on default error response Use http-errors for standard emitted errors Use statuses instead of http module for status messages deps: escape-html@1.0.2 deps: etag@~1.7.0 deps: fresh@0.3.0 deps: on-finished@~2.3.0 perf: enable strict mode perf: remove unnecessary array allocations deps: serve-static@~1.10.0 Add fallthrough option Fix reading options from options prototype Improve the default redirect response headers Malformed URLs now next() instead of 400 deps: escape-html@1.0.2 deps: send@0.13.0 perf: enable strict mode perf: remove argument reassignment deps: type-is@~1.6.3 deps: mime-types@~2.1.1 perf: reduce try block size perf: remove bitwise operations perf: enable strict mode perf: isolate app.render try block perf: remove argument reassignments in application perf: remove argument reassignments in request prototype perf: remove argument reassignments in response prototype perf: remove argument reassignments in routing perf: remove argument reassignments in View perf: skip attempting to decode zero length string perf: use saved reference to http.STATUS_CODES 4.12.4 / 2015-05-17 deps: accepts@~1.2.7 deps: mime-types@~2.0.11 deps: negotiator@0.5.3 deps: debug@~2.2.0 deps: ms@0.7.1 deps: depd@~1.0.1 deps: etag@~1.6.0 Improve support for JXcore Support \"fake\" stats objects in environments without fs deps: finalhandler@0.3.6 deps: debug@~2.2.0 deps: on-finished@~2.2.1 deps: on-finished@~2.2.1 Fix isFinished(req) when data buffered deps: proxy-addr@~1.0.8 deps: ipaddr.js@1.0.1 deps: qs@2.4.2 Fix allowing parameters like constructor deps: send@0.12.3 deps: debug@~2.2.0 deps: depd@~1.0.1 deps: etag@~1.6.0 deps: ms@0.7.1 deps: on-finished@~2.2.1 deps: serve-static@~1.9.3 deps: send@0.12.3 deps: type-is@~1.6.2 deps: mime-types@~2.0.11 4.12.3 / 2015-03-17 deps: accepts@~1.2.5 deps: mime-types@~2.0.10 deps: debug@~2.1.3 Fix high intensity foreground color for bold deps: ms@0.7.0 deps: finalhandler@0.3.4 deps: debug@~2.1.3 deps: proxy-addr@~1.0.7 deps: ipaddr.js@0.1.9 deps: qs@2.4.1 Fix error when parameter hasOwnProperty is present deps: send@0.12.2 Throw errors early for invalid extensions or index options deps: debug@~2.1.3 deps: serve-static@~1.9.2 deps: send@0.12.2 deps: type-is@~1.6.1 deps: mime-types@~2.0.10 4.12.2 / 2015-03-02 Fix regression where \"Request aborted\" is logged using res.sendFile 4.12.1 / 2015-03-01 Fix constructing application with non-configurable prototype properties Fix ECONNRESET errors from res.sendFile usage Fix req.host when using \"trust proxy\" hops count Fix req.protocol/req.secure when using \"trust proxy\" hops count Fix wrong code on aborted connections from res.sendFile deps: merge-descriptors@1.0.0 4.12.0 / 2015-02-23 Fix \"trust proxy\" setting to inherit when app is mounted Generate ETags for all request responses No longer restricted to only responses for GET and HEAD requests Use content-type to parse Content-Type headers deps: accepts@~1.2.4 Fix preference sorting to be stable for long acceptable lists deps: mime-types@~2.0.9 deps: negotiator@0.5.1 deps: cookie-signature@1.0.6 deps: send@0.12.1 Always read the stat size from the file Fix mutating passed-in options deps: mime@1.3.4 deps: serve-static@~1.9.1 deps: send@0.12.1 deps: type-is@~1.6.0 fix argument reassignment fix false-positives in hasBody Transfer-Encoding check support wildcard for both type and subtype (*/*) deps: mime-types@~2.0.9 4.11.2 / 2015-02-01 Fix res.redirect double-calling res.end for HEAD requests deps: accepts@~1.2.3 deps: mime-types@~2.0.8 deps: proxy-addr@~1.0.6 deps: ipaddr.js@0.1.8 deps: type-is@~1.5.6 deps: mime-types@~2.0.8 4.11.1 / 2015-01-20 deps: send@0.11.1 Fix root path disclosure deps: serve-static@~1.8.1 Fix redirect loop in Node.js 0.11.14 Fix root path disclosure deps: send@0.11.1 4.11.0 / 2015-01-13 Add res.append(field, val) to append headers Deprecate leading : in name for app.param(name, fn) Deprecate req.param() -- use req.params, req.body, or req.query instead Deprecate app.param(fn) Fix OPTIONS responses to include the HEAD method properly Fix res.sendFile not always detecting aborted connection Match routes iteratively to prevent stack overflows deps: accepts@~1.2.2 deps: mime-types@~2.0.7 deps: negotiator@0.5.0 deps: send@0.11.0 deps: debug@~2.1.1 deps: etag@~1.5.1 deps: ms@0.7.0 deps: on-finished@~2.2.0 deps: serve-static@~1.8.0 deps: send@0.11.0 4.10.8 / 2015-01-13 Fix crash from error within OPTIONS response handler deps: proxy-addr@~1.0.5 deps: ipaddr.js@0.1.6 4.10.7 / 2015-01-04 Fix Allow header for OPTIONS to not contain duplicate methods Fix incorrect \"Request aborted\" for res.sendFile when HEAD or 304 deps: debug@~2.1.1 deps: finalhandler@0.3.3 deps: debug@~2.1.1 deps: on-finished@~2.2.0 deps: methods@~1.1.1 deps: on-finished@~2.2.0 deps: serve-static@~1.7.2 Fix potential open redirect when mounted at root deps: type-is@~1.5.5 deps: mime-types@~2.0.7 4.10.6 / 2014-12-12 Fix exception in req.fresh/req.stale without response headers 4.10.5 / 2014-12-10 Fix res.send double-calling res.end for HEAD requests deps: accepts@~1.1.4 deps: mime-types@~2.0.4 deps: type-is@~1.5.4 deps: mime-types@~2.0.4 4.10.4 / 2014-11-24 Fix res.sendfile logging standard write errors 4.10.3 / 2014-11-23 Fix res.sendFile logging standard write errors deps: etag@~1.5.1 deps: proxy-addr@~1.0.4 deps: ipaddr.js@0.1.5 deps: qs@2.3.3 Fix arrayLimit behavior 4.10.2 / 2014-11-09 Correctly invoke async router callback asynchronously deps: accepts@~1.1.3 deps: mime-types@~2.0.3 deps: type-is@~1.5.3 deps: mime-types@~2.0.3 4.10.1 / 2014-10-28 Fix handling of URLs containing :// in the path deps: qs@2.3.2 Fix parsing of mixed objects and values 4.10.0 / 2014-10-23 Add support for app.set('views', array) Views are looked up in sequence in array of directories Fix res.send(status) to mention res.sendStatus(status) Fix handling of invalid empty URLs Use content-disposition module for res.attachment/res.download Sends standards-compliant Content-Disposition header Full Unicode support Use path.resolve in view lookup deps: debug@~2.1.0 Implement DEBUG_FD env variable support deps: depd@~1.0.0 deps: etag@~1.5.0 Improve string performance Slightly improve speed for weak ETags over 1KB deps: finalhandler@0.3.2 Terminate in progress response only on error Use on-finished to determine request status deps: debug@~2.1.0 deps: on-finished@~2.1.1 deps: on-finished@~2.1.1 Fix handling of pipelined requests deps: qs@2.3.0 Fix parsing of mixed implicit and explicit arrays deps: send@0.10.1 deps: debug@~2.1.0 deps: depd@~1.0.0 deps: etag@~1.5.0 deps: on-finished@~2.1.1 deps: serve-static@~1.7.1 deps: send@0.10.1 4.9.8 / 2014-10-17 Fix res.redirect body when redirect status specified deps: accepts@~1.1.2 Fix error when media type has invalid parameter deps: negotiator@0.4.9 4.9.7 / 2014-10-10 Fix using same param name in array of paths 4.9.6 / 2014-10-08 deps: accepts@~1.1.1 deps: mime-types@~2.0.2 deps: negotiator@0.4.8 deps: serve-static@~1.6.4 Fix redirect loop when index file serving disabled deps: type-is@~1.5.2 deps: mime-types@~2.0.2 4.9.5 / 2014-09-24 deps: etag@~1.4.0 deps: proxy-addr@~1.0.3 Use forwarded npm module deps: send@0.9.3 deps: etag@~1.4.0 deps: serve-static@~1.6.3 deps: send@0.9.3 4.9.4 / 2014-09-19 deps: qs@2.2.4 Fix issue with object keys starting with numbers truncated 4.9.3 / 2014-09-18 deps: proxy-addr@~1.0.2 Fix a global leak when multiple subnets are trusted deps: ipaddr.js@0.1.3 4.9.2 / 2014-09-17 Fix regression for empty string path in app.use Fix router.use to accept array of middleware without path Improve error message for bad app.use arguments 4.9.1 / 2014-09-16 Fix app.use to accept array of middleware without path deps: depd@0.4.5 deps: etag@~1.3.1 deps: send@0.9.2 deps: depd@0.4.5 deps: etag@~1.3.1 deps: range-parser@~1.0.2 deps: serve-static@~1.6.2 deps: send@0.9.2 4.9.0 / 2014-09-08 Add res.sendStatus Invoke callback for sendfile when client aborts Applies to res.sendFile, res.sendfile, and res.download err will be populated with request aborted error Support IP address host in req.subdomains Use etag to generate ETag headers deps: accepts@~1.1.0 update mime-types deps: cookie-signature@1.0.5 deps: debug@~2.0.0 deps: finalhandler@0.2.0 Set X-Content-Type-Options: nosniff header deps: debug@~2.0.0 deps: fresh@0.2.4 deps: media-typer@0.3.0 Throw error when parameter format invalid on parse deps: qs@2.2.3 Fix issue where first empty value in array is discarded deps: range-parser@~1.0.2 deps: send@0.9.1 Add lastModified option Use etag to generate ETag header deps: debug@~2.0.0 deps: fresh@0.2.4 deps: serve-static@~1.6.1 Add lastModified option deps: send@0.9.1 deps: type-is@~1.5.1 fix hasbody to be true for content-length: 0 deps: media-typer@0.3.0 deps: mime-types@~2.0.1 deps: vary@~1.0.0 Accept valid Vary header string as field 4.8.8 / 2014-09-04 deps: send@0.8.5 Fix a path traversal issue when using root Fix malicious path detection for empty string path deps: serve-static@~1.5.4 deps: send@0.8.5 4.8.7 / 2014-08-29 deps: qs@2.2.2 Remove unnecessary cloning 4.8.6 / 2014-08-27 deps: qs@2.2.0 Array parsing fix Performance improvements 4.8.5 / 2014-08-18 deps: send@0.8.3 deps: destroy@1.0.3 deps: on-finished@2.1.0 deps: serve-static@~1.5.3 deps: send@0.8.3 4.8.4 / 2014-08-14 deps: qs@1.2.2 deps: send@0.8.2 Work around fd leak in Node.js 0.10 for fs.ReadStream deps: serve-static@~1.5.2 deps: send@0.8.2 4.8.3 / 2014-08-10 deps: parseurl@~1.3.0 deps: qs@1.2.1 deps: serve-static@~1.5.1 Fix parsing of weird req.originalUrl values deps: parseurl@~1.3.0 deps: utils-merge@1.0.0 4.8.2 / 2014-08-07 deps: qs@1.2.0 Fix parsing array of objects 4.8.1 / 2014-08-06 fix incorrect deprecation warnings on res.download deps: qs@1.1.0 Accept urlencoded square brackets Accept empty values in implicit array notation 4.8.0 / 2014-08-05 add res.sendFile accepts a file system path instead of a URL requires an absolute path or root option specified deprecate res.sendfile -- use res.sendFile instead support mounted app as any argument to app.use() deps: qs@1.0.2 Complete rewrite Limits array length to 20 Limits object depth to 5 Limits parameters to 1,000 deps: send@0.8.1 Add extensions option deps: serve-static@~1.5.0 Add extensions option deps: send@0.8.1 4.7.4 / 2014-08-04 fix res.sendfile regression for serving directory index files deps: send@0.7.4 Fix incorrect 403 on Windows and Node.js 0.11 Fix serving index files without root dir deps: serve-static@~1.4.4 deps: send@0.7.4 4.7.3 / 2014-08-04 deps: send@0.7.3 Fix incorrect 403 on Windows and Node.js 0.11 deps: serve-static@~1.4.3 Fix incorrect 403 on Windows and Node.js 0.11 deps: send@0.7.3 4.7.2 / 2014-07-27 deps: depd@0.4.4 Work-around v8 generating empty stack traces deps: send@0.7.2 deps: depd@0.4.4 deps: serve-static@~1.4.2 4.7.1 / 2014-07-26 deps: depd@0.4.3 Fix exception when global Error.stackTraceLimit is too low deps: send@0.7.1 deps: depd@0.4.3 deps: serve-static@~1.4.1 4.7.0 / 2014-07-25 fix req.protocol for proxy-direct connections configurable query parser with app.set('query parser', parser) app.set('query parser', 'extended') parse with \"qs\" module app.set('query parser', 'simple') parse with \"querystring\" core module app.set('query parser', false) disable query string parsing app.set('query parser', true) enable simple parsing deprecate res.json(status, obj) -- use res.status(status).json(obj) instead deprecate res.jsonp(status, obj) -- use res.status(status).jsonp(obj) instead deprecate res.send(status, body) -- use res.status(status).send(body) instead deps: debug@1.0.4 deps: depd@0.4.2 Add TRACE_DEPRECATION environment variable Remove non-standard grey color from color output Support --no-deprecation argument Support --trace-deprecation argument deps: finalhandler@0.1.0 Respond after request fully read deps: debug@1.0.4 deps: parseurl@~1.2.0 Cache URLs based on original value Remove no-longer-needed URL mis-parse work-around Simplify the \"fast-path\" RegExp deps: send@0.7.0 Add dotfiles option Cap maxAge value to 1 year deps: debug@1.0.4 deps: depd@0.4.2 deps: serve-static@~1.4.0 deps: parseurl@~1.2.0 deps: send@0.7.0 perf: prevent multiple Buffer creation in res.send 4.6.1 / 2014-07-12 fix subapp.mountpath regression for app.use(subapp) 4.6.0 / 2014-07-11 accept multiple callbacks to app.use() add explicit \"Rosetta Flash JSONP abuse\" protection previous versions are not vulnerable; this is just explicit protection catch errors in multiple req.param(name, fn) handlers deprecate res.redirect(url, status) -- use res.redirect(status, url) instead fix res.send(status, num) to send num as json (not error) remove unnecessary escaping when res.jsonp returns JSON response support non-string path in app.use(path, fn) supports array of paths supports RegExp router: fix optimization on router exit router: refactor location of try blocks router: speed up standard app.use(fn) deps: debug@1.0.3 Add support for multiple wildcards in namespaces deps: finalhandler@0.0.3 deps: debug@1.0.3 deps: methods@1.1.0 add CONNECT deps: parseurl@~1.1.3 faster parsing of href-only URLs deps: path-to-regexp@0.1.3 deps: send@0.6.0 deps: debug@1.0.3 deps: serve-static@~1.3.2 deps: parseurl@~1.1.3 deps: send@0.6.0 perf: fix arguments reassign deopt in some res methods 4.5.1 / 2014-07-06 fix routing regression when altering req.method 4.5.0 / 2014-07-04 add deprecation message to non-plural req.accepts* add deprecation message to res.send(body, status) add deprecation message to res.vary() add headers option to res.sendfile use to set headers on successful file transfer add mergeParams option to Router merges req.params from parent routes add req.hostname -- correct name for what req.host returns deprecate things with depd module deprecate req.host -- use req.hostname instead fix behavior when handling request without routes fix handling when route.all is only route invoke router.param() only when route matches restore req.params after invoking router use finalhandler for final response handling use media-typer to alter content-type charset deps: accepts@~1.0.7 deps: send@0.5.0 Accept string for maxage (converted by ms) Include link in default redirect response deps: serve-static@~1.3.0 Accept string for maxAge (converted by ms) Add setHeaders option Include HTML link in redirect response deps: send@0.5.0 deps: type-is@~1.3.2 4.4.5 / 2014-06-26 deps: cookie-signature@1.0.4 fix for timing attacks 4.4.4 / 2014-06-20 fix res.attachment Unicode filenames in Safari fix \"trim prefix\" debug message in express:router deps: accepts@~1.0.5 deps: buffer-crc32@0.2.3 4.4.3 / 2014-06-11 fix persistence of modified req.params[name] from app.param() deps: accepts@1.0.3 deps: negotiator@0.4.6 deps: debug@1.0.2 deps: send@0.4.3 Do not throw uncatchable error on file open race condition Use escape-html for HTML escaping deps: debug@1.0.2 deps: finished@1.2.2 deps: fresh@0.2.2 deps: serve-static@1.2.3 Do not throw uncatchable error on file open race condition deps: send@0.4.3 4.4.2 / 2014-06-09 fix catching errors from top-level handlers use vary module for res.vary deps: debug@1.0.1 deps: proxy-addr@1.0.1 deps: send@0.4.2 fix \"event emitter leak\" warnings deps: debug@1.0.1 deps: finished@1.2.1 deps: serve-static@1.2.2 fix \"event emitter leak\" warnings deps: send@0.4.2 deps: type-is@1.2.1 4.4.1 / 2014-06-02 deps: methods@1.0.1 deps: send@0.4.1 Send max-age in Cache-Control in correct format deps: serve-static@1.2.1 use escape-html for escaping deps: send@0.4.1 4.4.0 / 2014-05-30 custom etag control with app.set('etag', val) app.set('etag', function(body, encoding){ return '\"etag\"' }) custom etag generation app.set('etag', 'weak') weak tag app.set('etag', 'strong') strong etag app.set('etag', false) turn off app.set('etag', true) standard etag mark res.send ETag as weak and reduce collisions update accepts to 1.0.2 Fix interpretation when header not in request update send to 0.4.0 Calculate ETag with md5 for reduced collisions Ignore stream errors after request ends deps: debug@0.8.1 update serve-static to 1.2.0 Calculate ETag with md5 for reduced collisions Ignore stream errors after request ends deps: send@0.4.0 4.3.2 / 2014-05-28 fix handling of errors from router.param() callbacks 4.3.1 / 2014-05-23 revert \"fix behavior of multiple app.VERB for the same path\" this caused a regression in the order of route execution 4.3.0 / 2014-05-21 add req.baseUrl to access the path stripped from req.url in routes fix behavior of multiple app.VERB for the same path fix issue routing requests among sub routers invoke router.param() only when necessary instead of every match proper proxy trust with app.set('trust proxy', trust) app.set('trust proxy', 1) trust first hop app.set('trust proxy', 'loopback') trust loopback addresses app.set('trust proxy', '10.0.0.1') trust single IP app.set('trust proxy', '10.0.0.1/16') trust subnet app.set('trust proxy', '10.0.0.1, 10.0.0.2') trust list app.set('trust proxy', false) turn off app.set('trust proxy', true) trust everything set proper charset in Content-Type for res.send update type-is to 1.2.0 support suffix matching 4.2.0 / 2014-05-11 deprecate app.del() -- use app.delete() instead deprecate res.json(obj, status) -- use res.json(status, obj) instead the edge-case res.json(status, num) requires res.status(status).json(num) deprecate res.jsonp(obj, status) -- use res.jsonp(status, obj) instead the edge-case res.jsonp(status, num) requires res.status(status).jsonp(num) fix req.next when inside router instance include ETag header in HEAD requests keep previous Content-Type for res.jsonp support PURGE method add app.purge add router.purge include PURGE in app.all update debug to 0.8.0 add enable() method change from stderr to stdout update methods to 1.0.0 add PURGE 4.1.2 / 2014-05-08 fix req.host for IPv6 literals fix res.jsonp error if callback param is object 4.1.1 / 2014-04-27 fix package.json to reflect supported node version 4.1.0 / 2014-04-24 pass options from res.sendfile to send preserve casing of headers in res.header and res.set support unicode file names in res.attachment and res.download update accepts to 1.0.1 deps: negotiator@0.4.0 update cookie to 0.1.2 Fix for maxAge == 0 made compat with expires field update send to 0.3.0 Accept API options in options object Coerce option types Control whether to generate etags Default directory access to 403 when index disabled Fix sending files with dots without root set Include file path in etag Make \"Can't set headers after they are sent.\" catchable Send full entity-body for multi range requests Set etags to \"weak\" Support \"If-Range\" header Support multiple index paths deps: mime@1.2.11 update serve-static to 1.1.0 Accept options directly to send module Resolve relative paths at middleware setup Use parseurl to parse the URL from request deps: send@0.3.0 update type-is to 1.1.0 add non-array values support add multipart as a shorthand 4.0.0 / 2014-04-09 remove: node 0.8 support connect and connect's patches except for charset handling express(1) - moved to express-generator express.createServer() - it has been deprecated for a long time. Use express() app.configure - use logic in your own app code app.router - is removed req.auth - use basic-auth instead req.accepted* - use req.accepts*() instead res.location - relative URL resolution is removed res.charset - include the charset in the content type when using res.set() all bundled middleware except static change: app.route -> app.mountpath when mounting an express app in another express app json spaces no longer enabled by default in development req.accepts* -> req.accepts*s - i.e. req.acceptsEncoding -> req.acceptsEncodings req.params is now an object instead of an array res.locals is no longer a function. It is a plain js object. Treat it as such. res.headerSent -> res.headersSent to match node.js ServerResponse object refactor: req.accepts* with accepts req.is with type-is path-to-regexp add: app.router() - returns the app Router instance app.route() - Proxy to the app's Router#route() method to create a new route Router & Route - public API 3.21.2 / 2015-07-31 deps: connect@2.30.2 deps: body-parser@~1.13.3 deps: compression@~1.5.2 deps: errorhandler@~1.4.2 deps: method-override@~2.3.5 deps: serve-index@~1.7.2 deps: type-is@~1.6.6 deps: vhost@~3.0.1 deps: vary@~1.0.1 Fix setting empty header from empty field perf: enable strict mode perf: remove argument reassignments 3.21.1 / 2015-07-05 deps: basic-auth@~1.0.3 deps: connect@2.30.1 deps: body-parser@~1.13.2 deps: compression@~1.5.1 deps: errorhandler@~1.4.1 deps: morgan@~1.6.1 deps: pause@0.1.0 deps: qs@4.0.0 deps: serve-index@~1.7.1 deps: type-is@~1.6.4 3.21.0 / 2015-06-18 deps: basic-auth@1.0.2 perf: enable strict mode perf: hoist regular expression perf: parse with regular expressions perf: remove argument reassignment deps: connect@2.30.0 deps: body-parser@~1.13.1 deps: bytes@2.1.0 deps: compression@~1.5.0 deps: cookie@0.1.3 deps: cookie-parser@~1.3.5 deps: csurf@~1.8.3 deps: errorhandler@~1.4.0 deps: express-session@~1.11.3 deps: finalhandler@0.4.0 deps: fresh@0.3.0 deps: morgan@~1.6.0 deps: serve-favicon@~2.3.0 deps: serve-index@~1.7.0 deps: serve-static@~1.10.0 deps: type-is@~1.6.3 deps: cookie@0.1.3 perf: deduce the scope of try-catch deopt perf: remove argument reassignments deps: escape-html@1.0.2 deps: etag@~1.7.0 Always include entity length in ETags for hash length extensions Generate non-Stats ETags using MD5 only (no longer CRC32) Improve stat performance by removing hashing Improve support for JXcore Remove base64 padding in ETags to shorten Support \"fake\" stats objects in environments without fs Use MD5 instead of MD4 in weak ETags over 1KB deps: fresh@0.3.0 Add weak ETag matching support deps: mkdirp@0.5.1 Work in global strict mode deps: send@0.13.0 Allow Node.js HTTP server to set Date response header Fix incorrectly removing Content-Location on 304 response Improve the default redirect response headers Send appropriate headers on default error response Use http-errors for standard emitted errors Use statuses instead of http module for status messages deps: escape-html@1.0.2 deps: etag@~1.7.0 deps: fresh@0.3.0 deps: on-finished@~2.3.0 perf: enable strict mode perf: remove unnecessary array allocations 3.20.3 / 2015-05-17 deps: connect@2.29.2 deps: body-parser@~1.12.4 deps: compression@~1.4.4 deps: connect-timeout@~1.6.2 deps: debug@~2.2.0 deps: depd@~1.0.1 deps: errorhandler@~1.3.6 deps: finalhandler@0.3.6 deps: method-override@~2.3.3 deps: morgan@~1.5.3 deps: qs@2.4.2 deps: response-time@~2.3.1 deps: serve-favicon@~2.2.1 deps: serve-index@~1.6.4 deps: serve-static@~1.9.3 deps: type-is@~1.6.2 deps: debug@~2.2.0 deps: ms@0.7.1 deps: depd@~1.0.1 deps: proxy-addr@~1.0.8 deps: ipaddr.js@1.0.1 deps: send@0.12.3 deps: debug@~2.2.0 deps: depd@~1.0.1 deps: etag@~1.6.0 deps: ms@0.7.1 deps: on-finished@~2.2.1 3.20.2 / 2015-03-16 deps: connect@2.29.1 deps: body-parser@~1.12.2 deps: compression@~1.4.3 deps: connect-timeout@~1.6.1 deps: debug@~2.1.3 deps: errorhandler@~1.3.5 deps: express-session@~1.10.4 deps: finalhandler@0.3.4 deps: method-override@~2.3.2 deps: morgan@~1.5.2 deps: qs@2.4.1 deps: serve-index@~1.6.3 deps: serve-static@~1.9.2 deps: type-is@~1.6.1 deps: debug@~2.1.3 Fix high intensity foreground color for bold deps: ms@0.7.0 deps: merge-descriptors@1.0.0 deps: proxy-addr@~1.0.7 deps: ipaddr.js@0.1.9 deps: send@0.12.2 Throw errors early for invalid extensions or index options deps: debug@~2.1.3 3.20.1 / 2015-02-28 Fix req.host when using \"trust proxy\" hops count Fix req.protocol/req.secure when using \"trust proxy\" hops count 3.20.0 / 2015-02-18 Fix \"trust proxy\" setting to inherit when app is mounted Generate ETags for all request responses No longer restricted to only responses for GET and HEAD requests Use content-type to parse Content-Type headers deps: connect@2.29.0 Use content-type to parse Content-Type headers deps: body-parser@~1.12.0 deps: compression@~1.4.1 deps: connect-timeout@~1.6.0 deps: cookie-parser@~1.3.4 deps: cookie-signature@1.0.6 deps: csurf@~1.7.0 deps: errorhandler@~1.3.4 deps: express-session@~1.10.3 deps: http-errors@~1.3.1 deps: response-time@~2.3.0 deps: serve-index@~1.6.2 deps: serve-static@~1.9.1 deps: type-is@~1.6.0 deps: cookie-signature@1.0.6 deps: send@0.12.1 Always read the stat size from the file Fix mutating passed-in options deps: mime@1.3.4 3.19.2 / 2015-02-01 deps: connect@2.28.3 deps: compression@~1.3.1 deps: csurf@~1.6.6 deps: errorhandler@~1.3.3 deps: express-session@~1.10.2 deps: serve-index@~1.6.1 deps: type-is@~1.5.6 deps: proxy-addr@~1.0.6 deps: ipaddr.js@0.1.8 3.19.1 / 2015-01-20 deps: connect@2.28.2 deps: body-parser@~1.10.2 deps: serve-static@~1.8.1 deps: send@0.11.1 Fix root path disclosure 3.19.0 / 2015-01-09 Fix OPTIONS responses to include the HEAD method property Use readline for prompt in express(1) deps: commander@2.6.0 deps: connect@2.28.1 deps: body-parser@~1.10.1 deps: compression@~1.3.0 deps: connect-timeout@~1.5.0 deps: csurf@~1.6.4 deps: debug@~2.1.1 deps: errorhandler@~1.3.2 deps: express-session@~1.10.1 deps: finalhandler@0.3.3 deps: method-override@~2.3.1 deps: morgan@~1.5.1 deps: serve-favicon@~2.2.0 deps: serve-index@~1.6.0 deps: serve-static@~1.8.0 deps: type-is@~1.5.5 deps: debug@~2.1.1 deps: methods@~1.1.1 deps: proxy-addr@~1.0.5 deps: ipaddr.js@0.1.6 deps: send@0.11.0 deps: debug@~2.1.1 deps: etag@~1.5.1 deps: ms@0.7.0 deps: on-finished@~2.2.0 3.18.6 / 2014-12-12 Fix exception in req.fresh/req.stale without response headers 3.18.5 / 2014-12-11 deps: connect@2.27.6 deps: compression@~1.2.2 deps: express-session@~1.9.3 deps: http-errors@~1.2.8 deps: serve-index@~1.5.3 deps: type-is@~1.5.4 3.18.4 / 2014-11-23 deps: connect@2.27.4 deps: body-parser@~1.9.3 deps: compression@~1.2.1 deps: errorhandler@~1.2.3 deps: express-session@~1.9.2 deps: qs@2.3.3 deps: serve-favicon@~2.1.7 deps: serve-static@~1.5.1 deps: type-is@~1.5.3 deps: etag@~1.5.1 deps: proxy-addr@~1.0.4 deps: ipaddr.js@0.1.5 3.18.3 / 2014-11-09 deps: connect@2.27.3 Correctly invoke async callback asynchronously deps: csurf@~1.6.3 3.18.2 / 2014-10-28 deps: connect@2.27.2 Fix handling of URLs containing :// in the path deps: body-parser@~1.9.2 deps: qs@2.3.2 3.18.1 / 2014-10-22 Fix internal utils.merge deprecation warnings deps: connect@2.27.1 deps: body-parser@~1.9.1 deps: express-session@~1.9.1 deps: finalhandler@0.3.2 deps: morgan@~1.4.1 deps: qs@2.3.0 deps: serve-static@~1.7.1 deps: send@0.10.1 deps: on-finished@~2.1.1 3.18.0 / 2014-10-17 Use content-disposition module for res.attachment/res.download Sends standards-compliant Content-Disposition header Full Unicode support Use etag module to generate ETag headers deps: connect@2.27.0 Use http-errors module for creating errors Use utils-merge module for merging objects deps: body-parser@~1.9.0 deps: compression@~1.2.0 deps: connect-timeout@~1.4.0 deps: debug@~2.1.0 deps: depd@~1.0.0 deps: express-session@~1.9.0 deps: finalhandler@0.3.1 deps: method-override@~2.3.0 deps: morgan@~1.4.0 deps: response-time@~2.2.0 deps: serve-favicon@~2.1.6 deps: serve-index@~1.5.0 deps: serve-static@~1.7.0 deps: debug@~2.1.0 Implement DEBUG_FD env variable support deps: depd@~1.0.0 deps: send@0.10.0 deps: debug@~2.1.0 deps: depd@~1.0.0 deps: etag@~1.5.0 3.17.8 / 2014-10-15 deps: connect@2.26.6 deps: compression@~1.1.2 deps: csurf@~1.6.2 deps: errorhandler@~1.2.2 3.17.7 / 2014-10-08 deps: connect@2.26.5 Fix accepting non-object arguments to logger deps: serve-static@~1.6.4 3.17.6 / 2014-10-02 deps: connect@2.26.4 deps: morgan@~1.3.2 deps: type-is@~1.5.2 3.17.5 / 2014-09-24 deps: connect@2.26.3 deps: body-parser@~1.8.4 deps: serve-favicon@~2.1.5 deps: serve-static@~1.6.3 deps: proxy-addr@~1.0.3 Use forwarded npm module deps: send@0.9.3 deps: etag@~1.4.0 3.17.4 / 2014-09-19 deps: connect@2.26.2 deps: body-parser@~1.8.3 deps: qs@2.2.4 3.17.3 / 2014-09-18 deps: proxy-addr@~1.0.2 Fix a global leak when multiple subnets are trusted deps: ipaddr.js@0.1.3 3.17.2 / 2014-09-15 Use crc instead of buffer-crc32 for speed deps: connect@2.26.1 deps: body-parser@~1.8.2 deps: depd@0.4.5 deps: express-session@~1.8.2 deps: morgan@~1.3.1 deps: serve-favicon@~2.1.3 deps: serve-static@~1.6.2 deps: depd@0.4.5 deps: send@0.9.2 deps: depd@0.4.5 deps: etag@~1.3.1 deps: range-parser@~1.0.2 3.17.1 / 2014-09-08 Fix error in req.subdomains on empty host 3.17.0 / 2014-09-08 Support X-Forwarded-Host in req.subdomains Support IP address host in req.subdomains deps: connect@2.26.0 deps: body-parser@~1.8.1 deps: compression@~1.1.0 deps: connect-timeout@~1.3.0 deps: cookie-parser@~1.3.3 deps: cookie-signature@1.0.5 deps: csurf@~1.6.1 deps: debug@~2.0.0 deps: errorhandler@~1.2.0 deps: express-session@~1.8.1 deps: finalhandler@0.2.0 deps: fresh@0.2.4 deps: media-typer@0.3.0 deps: method-override@~2.2.0 deps: morgan@~1.3.0 deps: qs@2.2.3 deps: serve-favicon@~2.1.3 deps: serve-index@~1.2.1 deps: serve-static@~1.6.1 deps: type-is@~1.5.1 deps: vhost@~3.0.0 deps: cookie-signature@1.0.5 deps: debug@~2.0.0 deps: fresh@0.2.4 deps: media-typer@0.3.0 Throw error when parameter format invalid on parse deps: range-parser@~1.0.2 deps: send@0.9.1 Add lastModified option Use etag to generate ETag header deps: debug@~2.0.0 deps: fresh@0.2.4 deps: vary@~1.0.0 Accept valid Vary header string as field 3.16.10 / 2014-09-04 deps: connect@2.25.10 deps: serve-static@~1.5.4 deps: send@0.8.5 Fix a path traversal issue when using root Fix malicious path detection for empty string path 3.16.9 / 2014-08-29 deps: connect@2.25.9 deps: body-parser@~1.6.7 deps: qs@2.2.2 3.16.8 / 2014-08-27 deps: connect@2.25.8 deps: body-parser@~1.6.6 deps: csurf@~1.4.1 deps: qs@2.2.0 3.16.7 / 2014-08-18 deps: connect@2.25.7 deps: body-parser@~1.6.5 deps: express-session@~1.7.6 deps: morgan@~1.2.3 deps: serve-static@~1.5.3 deps: send@0.8.3 deps: destroy@1.0.3 deps: on-finished@2.1.0 3.16.6 / 2014-08-14 deps: connect@2.25.6 deps: body-parser@~1.6.4 deps: qs@1.2.2 deps: serve-static@~1.5.2 deps: send@0.8.2 Work around fd leak in Node.js 0.10 for fs.ReadStream 3.16.5 / 2014-08-11 deps: connect@2.25.5 Fix backwards compatibility in logger 3.16.4 / 2014-08-10 Fix original URL parsing in res.location deps: connect@2.25.4 Fix query middleware breaking with argument deps: body-parser@~1.6.3 deps: compression@~1.0.11 deps: connect-timeout@~1.2.2 deps: express-session@~1.7.5 deps: method-override@~2.1.3 deps: on-headers@~1.0.0 deps: parseurl@~1.3.0 deps: qs@1.2.1 deps: response-time@~2.0.1 deps: serve-index@~1.1.6 deps: serve-static@~1.5.1 deps: parseurl@~1.3.0 3.16.3 / 2014-08-07 deps: connect@2.25.3 deps: multiparty@3.3.2 3.16.2 / 2014-08-07 deps: connect@2.25.2 deps: body-parser@~1.6.2 deps: qs@1.2.0 3.16.1 / 2014-08-06 deps: connect@2.25.1 deps: body-parser@~1.6.1 deps: qs@1.1.0 3.16.0 / 2014-08-05 deps: connect@2.25.0 deps: body-parser@~1.6.0 deps: compression@~1.0.10 deps: csurf@~1.4.0 deps: express-session@~1.7.4 deps: qs@1.0.2 deps: serve-static@~1.5.0 deps: send@0.8.1 Add extensions option 3.15.3 / 2014-08-04 fix res.sendfile regression for serving directory index files deps: connect@2.24.3 deps: serve-index@~1.1.5 deps: serve-static@~1.4.4 deps: send@0.7.4 Fix incorrect 403 on Windows and Node.js 0.11 Fix serving index files without root dir 3.15.2 / 2014-07-27 deps: connect@2.24.2 deps: body-parser@~1.5.2 deps: depd@0.4.4 deps: express-session@~1.7.2 deps: morgan@~1.2.2 deps: serve-static@~1.4.2 deps: depd@0.4.4 Work-around v8 generating empty stack traces deps: send@0.7.2 deps: depd@0.4.4 3.15.1 / 2014-07-26 deps: connect@2.24.1 deps: body-parser@~1.5.1 deps: depd@0.4.3 deps: express-session@~1.7.1 deps: morgan@~1.2.1 deps: serve-index@~1.1.4 deps: serve-static@~1.4.1 deps: depd@0.4.3 Fix exception when global Error.stackTraceLimit is too low deps: send@0.7.1 deps: depd@0.4.3 3.15.0 / 2014-07-22 Fix req.protocol for proxy-direct connections Pass options from res.sendfile to send deps: connect@2.24.0 deps: body-parser@~1.5.0 deps: compression@~1.0.9 deps: connect-timeout@~1.2.1 deps: debug@1.0.4 deps: depd@0.4.2 deps: express-session@~1.7.0 deps: finalhandler@0.1.0 deps: method-override@~2.1.2 deps: morgan@~1.2.0 deps: multiparty@3.3.1 deps: parseurl@~1.2.0 deps: serve-static@~1.4.0 deps: debug@1.0.4 deps: depd@0.4.2 Add TRACE_DEPRECATION environment variable Remove non-standard grey color from color output Support --no-deprecation argument Support --trace-deprecation argument deps: parseurl@~1.2.0 Cache URLs based on original value Remove no-longer-needed URL mis-parse work-around Simplify the \"fast-path\" RegExp deps: send@0.7.0 Add dotfiles option Cap maxAge value to 1 year deps: debug@1.0.4 deps: depd@0.4.2 3.14.0 / 2014-07-11 add explicit \"Rosetta Flash JSONP abuse\" protection previous versions are not vulnerable; this is just explicit protection deprecate res.redirect(url, status) -- use res.redirect(status, url) instead fix res.send(status, num) to send num as json (not error) remove unnecessary escaping when res.jsonp returns JSON response deps: basic-auth@1.0.0 support empty password support empty username deps: connect@2.23.0 deps: debug@1.0.3 deps: express-session@~1.6.4 deps: method-override@~2.1.0 deps: parseurl@~1.1.3 deps: serve-static@~1.3.1 deps: debug@1.0.3 Add support for multiple wildcards in namespaces deps: methods@1.1.0 add CONNECT deps: parseurl@~1.1.3 faster parsing of href-only URLs 3.13.0 / 2014-07-03 add deprecation message to app.configure add deprecation message to req.auth use basic-auth to parse Authorization header deps: connect@2.22.0 deps: csurf@~1.3.0 deps: express-session@~1.6.1 deps: multiparty@3.3.0 deps: serve-static@~1.3.0 deps: send@0.5.0 Accept string for maxage (converted by ms) Include link in default redirect response 3.12.1 / 2014-06-26 deps: connect@2.21.1 deps: cookie-parser@1.3.2 deps: cookie-signature@1.0.4 deps: express-session@~1.5.2 deps: type-is@~1.3.2 deps: cookie-signature@1.0.4 fix for timing attacks 3.12.0 / 2014-06-21 use media-typer to alter content-type charset deps: connect@2.21.0 deprecate connect(middleware) -- use app.use(middleware) instead deprecate connect.createServer() -- use connect() instead fix res.setHeader() patch to work with get -> append -> set pattern deps: compression@~1.0.8 deps: errorhandler@~1.1.1 deps: express-session@~1.5.0 deps: serve-index@~1.1.3 3.11.0 / 2014-06-19 deprecate things with depd module deps: buffer-crc32@0.2.3 deps: connect@2.20.2 deprecate verify option to json -- use body-parser npm module instead deprecate verify option to urlencoded -- use body-parser npm module instead deprecate things with depd module use finalhandler for final response handling use media-typer to parse content-type for charset deps: body-parser@1.4.3 deps: connect-timeout@1.1.1 deps: cookie-parser@1.3.1 deps: csurf@1.2.2 deps: errorhandler@1.1.0 deps: express-session@1.4.0 deps: multiparty@3.2.9 deps: serve-index@1.1.2 deps: type-is@1.3.1 deps: vhost@2.0.0 3.10.5 / 2014-06-11 deps: connect@2.19.6 deps: body-parser@1.3.1 deps: compression@1.0.7 deps: debug@1.0.2 deps: serve-index@1.1.1 deps: serve-static@1.2.3 deps: debug@1.0.2 deps: send@0.4.3 Do not throw uncatchable error on file open race condition Use escape-html for HTML escaping deps: debug@1.0.2 deps: finished@1.2.2 deps: fresh@0.2.2 3.10.4 / 2014-06-09 deps: connect@2.19.5 fix \"event emitter leak\" warnings deps: csurf@1.2.1 deps: debug@1.0.1 deps: serve-static@1.2.2 deps: type-is@1.2.1 deps: debug@1.0.1 deps: send@0.4.2 fix \"event emitter leak\" warnings deps: finished@1.2.1 deps: debug@1.0.1 3.10.3 / 2014-06-05 use vary module for res.vary deps: connect@2.19.4 deps: errorhandler@1.0.2 deps: method-override@2.0.2 deps: serve-favicon@2.0.1 deps: debug@1.0.0 3.10.2 / 2014-06-03 deps: connect@2.19.3 deps: compression@1.0.6 3.10.1 / 2014-06-03 deps: connect@2.19.2 deps: compression@1.0.4 deps: proxy-addr@1.0.1 3.10.0 / 2014-06-02 deps: connect@2.19.1 deprecate methodOverride() -- use method-override npm module instead deps: body-parser@1.3.0 deps: method-override@2.0.1 deps: multiparty@3.2.8 deps: response-time@2.0.0 deps: serve-static@1.2.1 deps: methods@1.0.1 deps: send@0.4.1 Send max-age in Cache-Control in correct format 3.9.0 / 2014-05-30 custom etag control with app.set('etag', val) app.set('etag', function(body, encoding){ return '\"etag\"' }) custom etag generation app.set('etag', 'weak') weak tag app.set('etag', 'strong') strong etag app.set('etag', false) turn off app.set('etag', true) standard etag Include ETag in HEAD requests mark res.send ETag as weak and reduce collisions update connect to 2.18.0 deps: compression@1.0.3 deps: serve-index@1.1.0 deps: serve-static@1.2.0 update send to 0.4.0 Calculate ETag with md5 for reduced collisions Ignore stream errors after request ends deps: debug@0.8.1 3.8.1 / 2014-05-27 update connect to 2.17.3 deps: body-parser@1.2.2 deps: express-session@1.2.1 deps: method-override@1.0.2 3.8.0 / 2014-05-21 keep previous Content-Type for res.jsonp set proper charset in Content-Type for res.send update connect to 2.17.1 fix res.charset appending charset when content-type has one deps: express-session@1.2.0 deps: morgan@1.1.1 deps: serve-index@1.0.3 3.7.0 / 2014-05-18 proper proxy trust with app.set('trust proxy', trust) app.set('trust proxy', 1) trust first hop app.set('trust proxy', 'loopback') trust loopback addresses app.set('trust proxy', '10.0.0.1') trust single IP app.set('trust proxy', '10.0.0.1/16') trust subnet app.set('trust proxy', '10.0.0.1, 10.0.0.2') trust list app.set('trust proxy', false) turn off app.set('trust proxy', true) trust everything update connect to 2.16.2 deprecate res.headerSent -- use res.headersSent deprecate res.on(\"header\") -- use on-headers module instead fix edge-case in res.appendHeader that would append in wrong order json: use body-parser urlencoded: use body-parser dep: bytes@1.0.0 dep: cookie-parser@1.1.0 dep: csurf@1.2.0 dep: express-session@1.1.0 dep: method-override@1.0.1 3.6.0 / 2014-05-09 deprecate app.del() -- use app.delete() instead deprecate res.json(obj, status) -- use res.json(status, obj) instead the edge-case res.json(status, num) requires res.status(status).json(num) deprecate res.jsonp(obj, status) -- use res.jsonp(status, obj) instead the edge-case res.jsonp(status, num) requires res.status(status).jsonp(num) support PURGE method add app.purge add router.purge include PURGE in app.all update connect to 2.15.0 Add res.appendHeader Call error stack even when response has been sent Patch res.headerSent to return Boolean Patch res.headersSent for node.js 0.8 Prevent default 404 handler after response sent dep: compression@1.0.2 dep: connect-timeout@1.1.0 dep: debug@^0.8.0 dep: errorhandler@1.0.1 dep: express-session@1.0.4 dep: morgan@1.0.1 dep: serve-favicon@2.0.0 dep: serve-index@1.0.2 update debug to 0.8.0 add enable() method change from stderr to stdout update methods to 1.0.0 add PURGE update mkdirp to 0.5.0 3.5.3 / 2014-05-08 fix req.host for IPv6 literals fix res.jsonp error if callback param is object 3.5.2 / 2014-04-24 update connect to 2.14.5 update cookie to 0.1.2 update mkdirp to 0.4.0 update send to 0.3.0 3.5.1 / 2014-03-25 pin less-middleware in generated app 3.5.0 / 2014-03-06 bump deps 3.4.8 / 2014-01-13 prevent incorrect automatic OPTIONS responses #1868 @dpatti update binary and examples for jade 1.0 #1876 @yossi, #1877 @reqshark, #1892 @matheusazzi throw 400 in case of malformed paths @rlidwka 3.4.7 / 2013-12-10 update connect 3.4.6 / 2013-12-01 update connect (raw-body) 3.4.5 / 2013-11-27 update connect res.location: remove leading ./ #1802 @kapouer res.redirect: fix `res.redirect('toString') #1829 @michaelficarra res.send: always send ETag when content-length > 0 router: add Router.all() method 3.4.4 / 2013-10-29 update connect update supertest update methods express(1): replace bodyParser() with urlencoded() and json() #1795 @chirag04 3.4.3 / 2013-10-23 update connect 3.4.2 / 2013-10-18 update connect downgrade commander 3.4.1 / 2013-10-15 update connect update commander jsonp: check if callback is a function router: wrap encodeURIComponent in a try/catch #1735 (@lxe) res.format: now includes charset @1747 (@sorribas) res.links: allow multiple calls @1746 (@sorribas) 3.4.0 / 2013-09-07 add res.vary(). Closes #1682 update connect 3.3.8 / 2013-09-02 update connect 3.3.7 / 2013-08-28 update connect 3.3.6 / 2013-08-27 Revert \"remove charset from json responses. Closes #1631\" (causes issues in some clients) add: req.accepts take an argument list 3.3.4 / 2013-07-08 update send and connect 3.3.3 / 2013-07-04 update connect 3.3.2 / 2013-07-03 update connect update send remove .version export 3.3.1 / 2013-06-27 update connect 3.3.0 / 2013-06-26 update connect add support for multiple X-Forwarded-Proto values. Closes #1646 change: remove charset from json responses. Closes #1631 change: return actual booleans from req.accept* functions fix jsonp callback array throw 3.2.6 / 2013-06-02 update connect 3.2.5 / 2013-05-21 update connect update node-cookie add: throw a meaningful error when there is no default engine change generation of ETags with res.send() to GET requests only. Closes #1619 3.2.4 / 2013-05-09 fix req.subdomains when no Host is present fix req.host when no Host is present, return undefined 3.2.3 / 2013-05-07 update connect / qs 3.2.2 / 2013-05-03 update qs 3.2.1 / 2013-04-29 add app.VERB() paths array deprecation warning update connect update qs and remove all ~ semver crap fix: accept number as value of Signed Cookie 3.2.0 / 2013-04-15 add \"view\" constructor setting to override view behaviour add req.acceptsEncoding(name) add req.acceptedEncodings revert cookie signature change causing session race conditions fix sorting of Accept values of the same quality 3.1.2 / 2013-04-12 add support for custom Accept parameters update cookie-signature 3.1.1 / 2013-04-01 add X-Forwarded-Host support to req.host fix relative redirects update mkdirp update buffer-crc32 remove legacy app.configure() method from app template. 3.1.0 / 2013-01-25 add support for leading \".\" in \"view engine\" setting add array support to res.set() add node 0.8.x to travis.yml add \"subdomain offset\" setting for tweaking req.subdomains add res.location(url) implementing res.redirect()-like setting of Location use app.get() for x-powered-by setting for inheritance fix colons in passwords for req.auth 3.0.6 / 2013-01-04 add http verb methods to Router update connect fix mangling of the res.cookie() options object fix jsonp whitespace escape. Closes #1132 3.0.5 / 2012-12-19 add throwing when a non-function is passed to a route fix: explicitly remove Transfer-Encoding header from 204 and 304 responses revert \"add 'etag' option\" 3.0.4 / 2012-12-05 add 'etag' option to disable res.send() Etags add escaping of urls in text/plain in res.redirect() for old browsers interpreting as html change crc32 module for a more liberal license update connect 3.0.3 / 2012-11-13 update connect update cookie module fix cookie max-age 3.0.2 / 2012-11-08 add OPTIONS to cors example. Closes #1398 fix route chaining regression. Closes #1397 3.0.1 / 2012-11-01 update connect 3.0.0 / 2012-10-23 add make clean add \"Basic\" check to req.auth add req.auth test coverage add cb && cb(payload) to res.jsonp(). Closes #1374 add backwards compat for res.redirect() status. Closes #1336 add support for res.json() to retain previously defined Content-Types. Closes #1349 update connect change res.redirect() to utilize a pathname-relative Location again. Closes #1382 remove non-primitive string support for res.send() fix view-locals example. Closes #1370 fix route-separation example 3.0.0rc5 / 2012-09-18 update connect add redis search example add static-files example add \"x-powered-by\" setting (app.disable('x-powered-by')) add \"application/octet-stream\" redirect Accept test case. Closes #1317 3.0.0rc4 / 2012-08-30 add res.jsonp(). Closes #1307 add \"verbose errors\" option to error-pages example add another route example to express(1) so people are not so confused add redis online user activity tracking example update connect dep fix etag quoting. Closes #1310 fix error-pages 404 status fix jsonp callback char restrictions remove old OPTIONS default response 3.0.0rc3 / 2012-08-13 update connect dep fix signed cookies to work with connect.cookieParser() (\"s:\" prefix was missing) [tnydwrds] fix res.render() clobbering of \"locals\" 3.0.0rc2 / 2012-08-03 add CORS example update connect dep deprecate .createServer() & remove old stale examples fix: escape res.redirect() link fix vhost example 3.0.0rc1 / 2012-07-24 add more examples to view-locals add scheme-relative redirects (res.redirect(\"//foo.com\")) support update cookie dep update connect dep update send dep fix express(1) -h flag, use -H for hogan. Closes #1245 fix res.sendfile() socket error handling regression 3.0.0beta7 / 2012-07-16 update connect dep for send() root normalization regression 3.0.0beta6 / 2012-07-13 add err.view property for view errors. Closes #1226 add \"jsonp callback name\" setting add support for \"/foo/:bar*\" non-greedy matches change res.sendfile() to use send() module change res.send to use \"response-send\" module remove app.locals.use and res.locals.use, use regular middleware 3.0.0beta5 / 2012-07-03 add \"make check\" support add route-map example add res.json(obj, status) support back for BC add \"methods\" dep, remove internal methods module update connect dep update auth example to utilize cores pbkdf2 updated tests to use \"supertest\" 3.0.0beta4 / 2012-06-25 Added req.auth Added req.range(size) Added res.links(obj) Added res.send(body, status) support back for backwards compat Added .default() support to res.format() Added 2xx / 304 check to req.fresh Revert \"Added + support to the router\" Fixed res.send() freshness check, respect res.statusCode 3.0.0beta3 / 2012-06-15 Added hogan --hjs to express(1) [nullfirm] Added another example to content-negotiation Added fresh dep Changed: res.send() always checks freshness Fixed: expose connects mime module. Closes #1165 3.0.0beta2 / 2012-06-06 Added + support to the router Added req.host Changed req.param() to check route first Update connect dep 3.0.0beta1 / 2012-06-01 Added res.format() callback to override default 406 behaviour Fixed res.redirect() 406. Closes #1154 3.0.0alpha5 / 2012-05-30 Added req.ip Added { signed: true } option to res.cookie() Removed res.signedCookie() Changed: dont reverse req.ips Fixed \"trust proxy\" setting check for req.ips 3.0.0alpha4 / 2012-05-09 Added: allow [] in jsonp callback. Closes #1128 Added PORT env var support in generated template. Closes #1118 [benatkin] Updated: connect 2.2.2 3.0.0alpha3 / 2012-05-04 Added public app.routes. Closes #887 Added view-locals example Added mvc example Added res.locals.use(). Closes #1120 Added conditional-GET support to res.send() Added: coerce res.set() values to strings Changed: moved static() in generated apps below router Changed: res.send() only set ETag when not previously set Changed connect 2.2.1 dep Changed: make test now runs unit / acceptance tests Fixed req/res proto inheritance 3.0.0alpha2 / 2012-04-26 Added make benchmark back Added res.send() support for String objects Added client-side data exposing example Added res.header() and req.header() aliases for BC Added express.createServer() for BC Perf: memoize parsed urls Perf: connect 2.2.0 dep Changed: make expressInit() middleware self-aware Fixed: use app.get() for all core settings Fixed redis session example Fixed session example. Closes #1105 Fixed generated express dep. Closes #1078 3.0.0alpha1 / 2012-04-15 Added app.locals.use(callback) Added app.locals object Added app.locals(obj) Added res.locals object Added res.locals(obj) Added res.format() for content-negotiation Added app.engine() Added res.cookie() JSON cookie support Added \"trust proxy\" setting Added req.subdomains Added req.protocol Added req.secure Added req.path Added req.ips Added req.fresh Added req.stale Added comma-delimited / array support for req.accepts() Added debug instrumentation Added res.set(obj) Added res.set(field, value) Added res.get(field) Added app.get(setting). Closes #842 Added req.acceptsLanguage() Added req.acceptsCharset() Added req.accepted Added req.acceptedLanguages Added req.acceptedCharsets Added \"json replacer\" setting Added \"json spaces\" setting Added X-Forwarded-Proto support to res.redirect(). Closes #92 Added --less support to express(1) Added express.response prototype Added express.request prototype Added express.application prototype Added app.path() Added app.render() Added res.type() to replace res.contentType() Changed: res.redirect() to add relative support Changed: enable \"jsonp callback\" by default Changed: renamed \"case sensitive routes\" to \"case sensitive routing\" Rewrite of all tests with mocha Removed \"root\" setting Removed res.redirect('home') support Removed req.notify() Removed app.register() Removed app.redirect() Removed app.is() Removed app.helpers() Removed app.dynamicHelpers() Fixed res.sendfile() with non-GET. Closes #723 Fixed express(1) public dir for windows. Closes #866 2.5.9/ 2012-04-02 Added support for PURGE request method [pbuyle] Fixed express(1) generated app app.address() before listening [mmalecki] 2.5.8 / 2012-02-08 Update mkdirp dep. Closes #991 2.5.7 / 2012-02-06 Fixed app.all duplicate DELETE requests [mscdex] 2.5.6 / 2012-01-13 Updated hamljs dev dep. Closes #953 2.5.5 / 2012-01-08 Fixed: set filename on cached templates [matthewleon] 2.5.4 / 2012-01-02 Fixed express(1) eol on 0.4.x. Closes #947 2.5.3 / 2011-12-30 Fixed req.is() when a charset is present 2.5.2 / 2011-12-10 Fixed: express(1) LF -> CRLF for windows 2.5.1 / 2011-11-17 Changed: updated connect to 1.8.x Removed sass.js support from express(1) 2.5.0 / 2011-10-24 Added ./routes dir for generated app by default Added npm install reminder to express(1) app gen Added 0.5.x support Removed make test-cov since it wont work with node 0.5.x Fixed express(1) public dir for windows. Closes #866 2.4.7 / 2011-10-05 Added mkdirp to express(1). Closes #795 Added simple json-config example Added shorthand for the parsed request's pathname via req.path Changed connect dep to 1.7.x to fix npm issue... Fixed res.redirect() HEAD support. [reported by xerox] Fixed req.flash(), only escape args Fixed absolute path checking on windows. Closes #829 [reported by andrewpmckenzie] 2.4.6 / 2011-08-22 Fixed multiple param callback regression. Closes #824 [reported by TroyGoode] 2.4.5 / 2011-08-19 Added support for routes to handle errors. Closes #809 Added app.routes.all(). Closes #803 Added \"basepath\" setting to work in conjunction with reverse proxies etc. Refactored Route to use a single array of callbacks Added support for multiple callbacks for app.param(). Closes #801 Closes #805 Changed: removed .call(self) for route callbacks Dependency: qs >= 0.3.1 Fixed res.redirect() on windows due to join() usage. Closes #808 2.4.4 / 2011-08-05 Fixed res.header() intention of a set, even when undefined Fixed *, value no longer required Fixed res.send(204) support. Closes #771 2.4.3 / 2011-07-14 Added docs for status option special-case. Closes #739 Fixed options.filename, exposing the view path to template engines 2.4.2. / 2011-07-06 Revert \"removed jsonp stripping\" for XSS 2.4.1 / 2011-07-06 Added res.json() JSONP support. Closes #737 Added extending-templates example. Closes #730 Added \"strict routing\" setting for trailing slashes Added support for multiple envs in app.configure() calls. Closes #735 Changed: res.send() using res.json() Changed: when cookie path === null don't default it Changed; default cookie path to \"home\" setting. Closes #731 Removed pids/logs creation from express(1) 2.4.0 / 2011-06-28 Added chainable res.status(code) Added res.json(), an explicit version of res.send(obj) Added simple web-service example 2.3.12 / 2011-06-22 #express is now on freenode! come join! Added req.get(field, param) Added links to Japanese documentation, thanks @hideyukisaito! Added; the express(1) generated app outputs the env Added content-negotiation example Dependency: connect >= 1.5.1 < 2.0.0 Fixed view layout bug. Closes #720 Fixed; ignore body on 304. Closes #701 2.3.11 / 2011-06-04 Added npm test Removed generation of dummy test file from express(1) Fixed; express(1) adds express as a dep Fixed; prune on prepublish 2.3.10 / 2011-05-27 Added req.route, exposing the current route Added package.json generation support to express(1) Fixed call to app.param() function for optional params. Closes #682 2.3.9 / 2011-05-25 Fixed bug-ish with ../' in res.partial()` calls 2.3.8 / 2011-05-24 Fixed app.options() 2.3.7 / 2011-05-23 Added route Collection, ex: app.get('/user/:id').remove(); Added support for app.param(fn) to define param logic Removed app.param() support for callback with return value Removed module.parent check from express(1) generated app. Closes #670 Refactored router. Closes #639 2.3.6 / 2011-05-20 Changed; using devDependencies instead of git submodules Fixed redis session example Fixed markdown example Fixed view caching, should not be enabled in development 2.3.5 / 2011-05-20 Added export .view as alias for .View 2.3.4 / 2011-05-08 Added ./examples/say Fixed res.sendfile() bug preventing the transfer of files with spaces 2.3.3 / 2011-05-03 Added \"case sensitive routes\" option. Changed; split methods supported per rfc [slaskis] Fixed route-specific middleware when using the same callback function several times 2.3.2 / 2011-04-27 Fixed view hints 2.3.1 / 2011-04-26 Added app.match() as app.match.all() Added app.lookup() as app.lookup.all() Added app.remove() for app.remove.all() Added app.remove.VERB() Fixed template caching collision issue. Closes #644 Moved router over from connect and started refactor 2.3.0 / 2011-04-25 Added options support to res.clearCookie() Added res.helpers() as alias of res.locals() Added; json defaults to UTF-8 with res.send(). Closes #632. [Daniel * Dependency connect >= 1.4.0 Changed; auto set Content-Type in res.attachement [Aaron Heckmann] Renamed \"cache views\" to \"view cache\". Closes #628 Fixed caching of views when using several apps. Closes #637 Fixed gotcha invoking app.param() callbacks once per route middleware. Closes #638 Fixed partial lookup precedence. Closes #631 Shaw] 2.2.2 / 2011-04-12 Added second callback support for res.download() connection errors Fixed filename option passing to template engine 2.2.1 / 2011-04-04 Added layout(path) helper to change the layout within a view. Closes #610 Fixed partial() collection object support. Previously only anything with .length would work. When .length is present one must still be aware of holes, however now { collection: {foo: 'bar'}} is valid, exposes keyInCollection and keysInCollection. Performance improved with better view caching Removed request and response locals Changed; errorHandler page title is now Express instead of Connect 2.2.0 / 2011-03-30 Added app.lookup.VERB(), ex app.lookup.put('/user/:id'). Closes #606 Added app.match.VERB(), ex app.match.put('/user/12'). Closes #606 Added app.VERB(path) as alias of app.lookup.VERB(). Dependency connect >= 1.2.0 2.1.1 / 2011-03-29 Added; expose err.view object when failing to locate a view Fixed res.partial() call next(err) when no callback is given [reported by aheckmann] Fixed; res.send(undefined) responds with 204 [aheckmann] 2.1.0 / 2011-03-24 Added <root>/_?<name> partial lookup support. Closes #447 Added request, response, and app local variables Added settings local variable, containing the app's settings Added req.flash() exception if req.session is not available Added res.send(bool) support (json response) Fixed stylus example for latest version Fixed; wrap try/catch around res.render() 2.0.0 / 2011-03-17 Fixed up index view path alternative. Changed; res.locals() without object returns the locals 2.0.0rc3 / 2011-03-17 Added res.locals(obj) to compliment res.local(key, val) Added res.partial() callback support Fixed recursive error reporting issue in res.render() 2.0.0rc2 / 2011-03-17 Changed; partial() \"locals\" are now optional Fixed SlowBuffer support. Closes #584 [reported by tyrda01] Fixed .filename view engine option [reported by drudge] Fixed blog example Fixed {req,res}.app reference when mounting [Ben Weaver] 2.0.0rc / 2011-03-14 Fixed; expose HTTPSServer constructor Fixed express(1) default test charset. Closes #579 [reported by secoif] Fixed; default charset to utf-8 instead of utf8 for lame IE [reported by NickP] 2.0.0beta3 / 2011-03-09 Added support for res.contentType() literal The original res.contentType('.json'), res.contentType('application/json'), and res.contentType('json') will work now. Added res.render() status option support back Added charset option for res.render() Added .charset support (via connect 1.0.4) Added view resolution hints when in development and a lookup fails Added layout lookup support relative to the page view. For example while rendering ./views/user/index.jade if you create ./views/user/layout.jade it will be used in favour of the root layout. Fixed res.redirect(). RFC states absolute url [reported by unlink] Fixed; default res.send() string charset to utf8 Removed Partial constructor (not currently used) 2.0.0beta2 / 2011-03-07 Added res.render() .locals support back to aid in migration process Fixed flash example 2.0.0beta / 2011-03-03 Added HTTPS support Added res.cookie() maxAge support Added req.header() Referrer / Referer special-case, either works Added mount support for res.redirect(), now respects the mount-point Added union() util, taking place of merge(clone()) combo Added stylus support to express(1) generated app Added secret to session middleware used in examples and generated app Added res.local(name, val) for progressive view locals Added default param support to req.param(name, default) Added app.disabled() and app.enabled() Added app.register() support for omitting leading \".\", either works Added res.partial(), using the same interface as partial() within a view. Closes #539 Added app.param() to map route params to async/sync logic Added; aliased app.helpers() as app.locals(). Closes #481 Added extname with no leading \".\" support to res.contentType() Added cache views setting, defaulting to enabled in \"production\" env Added index file partial resolution, eg: partial('user') may try views/user/index.jade. Added req.accepts() support for extensions Changed; res.download() and res.sendfile() now utilize Connect's static file server connect.static.send(). Changed; replaced connect.utils.mime() with npm mime module Changed; allow req.query to be pre-defined (via middleware or other parent Changed view partial resolution, now relative to parent view Changed view engine signature. no longer engine.render(str, options, callback), now engine.compile(str, options) -> Function, the returned function accepts fn(locals). Fixed req.param() bug returning Array.prototype methods. Closes #552 Fixed; using Stream#pipe() instead of sys.pump() in res.sendfile() Fixed; using qs module instead of querystring Fixed; strip unsafe chars from jsonp callbacks Removed \"stream threshold\" setting 1.0.8 / 2011-03-01 Allow req.query to be pre-defined (via middleware or other parent app) \"connect\": \">= 0.5.0 < 1.0.0\". Closes #547 Removed the long deprecated EXPRESS_ENV support 1.0.7 / 2011-02-07 Fixed render() setting inheritance. Mounted apps would not inherit \"view engine\" 1.0.6 / 2011-02-07 Fixed view engine setting bug when period is in dirname 1.0.5 / 2011-02-05 Added secret to generated app session() call 1.0.4 / 2011-02-05 Added qs dependency to package.json Fixed namespaced require()s for latest connect support 1.0.3 / 2011-01-13 Remove unsafe characters from JSONP callback names [Ryan Grove] 1.0.2 / 2011-01-10 Removed nested require, using connect.router 1.0.1 / 2010-12-29 Fixed for middleware stacked via createServer() previously the foo middleware passed to createServer(foo) would not have access to Express methods such as res.send() or props like req.query etc. 1.0.0 / 2010-11-16 Added; deduce partial object names from the last segment. For example by default partial('forum/post', postObject) will give you the post object, providing a meaningful default. Added http status code string representation to res.redirect() body Added; res.redirect() supporting text/plain and text/html via Accept. Added req.is() to aid in content negotiation Added partial local inheritance [suggested by masylum]. Closes #102 providing access to parent template locals. Added -s, --session[s] flag to express(1) to add session related middleware Added --template flag to express(1) to specify the template engine to use. Added --css flag to express(1) to specify the stylesheet engine to use (or just plain css by default). Added app.all() support [thanks aheckmann] Added partial direct object support. You may now partial('user', user) providing the \"user\" local, vs previously partial('user', { object: user }). Added route-separation example since many people question ways to do this with CommonJS modules. Also view the blog example for an alternative. Performance; caching view path derived partial object names Fixed partial local inheritance precedence. [reported by Nick Poulden] Closes #454 Fixed jsonp support; text/javascript as per mailinglist discussion 1.0.0rc4 / 2010-10-14 Added NODE_ENV support, EXPRESS_ENV is deprecated and will be removed in 1.0.0 Added route-middleware support (very helpful, see the docs) Added jsonp callback setting to enable/disable jsonp autowrapping [Dav Glass] Added callback query check on response.send to autowrap JSON objects for simple webservice implementations [Dav Glass] Added partial() support for array-like collections. Closes #434 Added support for swappable querystring parsers Added session usage docs. Closes #443 Added dynamic helper caching. Closes #439 [suggested by maritz] Added authentication example Added basic Range support to res.sendfile() (and res.download() etc) Changed; express(1) generated app using 2 spaces instead of 4 Default env to \"development\" again [aheckmann] Removed context option is no more, use \"scope\" Fixed; exposing ./support libs to examples so they can run without installs Fixed mvc example 1.0.0rc3 / 2010-09-20 Added confirmation for express(1) app generation. Closes #391 Added extending of flash formatters via app.flashFormatters Added flash formatter support. Closes #411 Added streaming support to res.sendfile() using sys.pump() when >= \"stream threshold\" Added stream threshold setting for res.sendfile() Added res.send() HEAD support Added res.clearCookie() Added res.cookie() Added res.render() headers option Added res.redirect() response bodies Added res.render() status option support. Closes #425 [thanks aheckmann] Fixed res.sendfile() responding with 403 on malicious path Fixed res.download() bug; when an error occurs remove Content-Disposition Fixed; mounted apps settings now inherit from parent app [aheckmann] Fixed; stripping Content-Length / Content-Type when 204 Fixed res.send() 204. Closes #419 Fixed multiple Set-Cookie headers via res.header(). Closes #402 Fixed bug messing with error handlers when listenFD() is called instead of listen(). [thanks guillermo] 1.0.0rc2 / 2010-08-17 Added app.register() for template engine mapping. Closes #390 Added res.render() callback support as second argument (no options) Added callback support to res.download() Added callback support for res.sendfile() Added support for middleware access via express.middlewareName() vs connect.middlewareName() Added \"partials\" setting to docs Added default expresso tests to express(1) generated app. Closes #384 Fixed res.sendfile() error handling, defer via next() Fixed res.render() callback when a layout is used [thanks guillermo] Fixed; make install creating ~/.node_libraries when not present Fixed issue preventing error handlers from being defined anywhere. Closes #387 1.0.0rc / 2010-07-28 Added mounted hook. Closes #369 Added connect dependency to package.json Removed \"reload views\" setting and support code development env never caches, production always caches. Removed param in route callbacks, signature is now simply (req, res, next), previously (req, res, params, next). Use req.params for path captures, req.query for GET params. Fixed \"home\" setting Fixed middleware/router precedence issue. Closes #366 Fixed; configure() callbacks called immediately. Closes #368 1.0.0beta2 / 2010-07-23 Added more examples Added; exporting Server constructor Added Server#helpers() for view locals Added Server#dynamicHelpers() for dynamic view locals. Closes #349 Added support for absolute view paths Added; home setting defaults to Server#route for mounted apps. Closes #363 Added Guillermo Rauch to the contributor list Added support for \"as\" for non-collection partials. Closes #341 Fixed install.sh, ensuring ~/.node_libraries exists. Closes #362 [thanks jf] Fixed res.render() exceptions, now passed to next() when no callback is given [thanks guillermo] Fixed instanceof Array checks, now Array.isArray() Fixed express(1) expansion of public dirs. Closes #348 Fixed middleware precedence. Closes #345 Fixed view watcher, now async [thanks aheckmann] 1.0.0beta / 2010-07-15 Re-write much faster much lighter Check ExpressJS.com for migration guide and updated docs 0.14.0 / 2010-06-15 Utilize relative requires Added Static bufferSize option [aheckmann] Fixed caching of view and partial subdirectories [aheckmann] Fixed mime.type() comments now that \".ext\" is not supported Updated haml submodule Updated class submodule Removed bin/express 0.13.0 / 2010-06-01 Added node v0.1.97 compatibility Added support for deleting cookies via Request#cookie('key', null) Updated haml submodule Fixed not-found page, now using charset utf-8 Fixed show-exceptions page, now using charset utf-8 Fixed view support due to fs.readFile Buffers Changed; mime.type() no longer accepts \".type\" due to node extname() changes 0.12.0 / 2010-05-22 Added node v0.1.96 compatibility Added view helpers export which act as additional local variables Updated haml submodule Changed ETag; removed inode, modified time only Fixed LF to CRLF for setting multiple cookies Fixed cookie compilation; values are now urlencoded Fixed cookies parsing; accepts quoted values and url escaped cookies 0.11.0 / 2010-05-06 Added support for layouts using different engines this.render('page.html.haml', { layout: 'super-cool-layout.html.ejs' }) this.render('page.html.haml', { layout: 'foo' }) // assumes 'foo.html.haml' this.render('page.html.haml', { layout: false }) // no layout Updated ext submodule Updated haml submodule Fixed EJS partial support by passing along the context. Issue #307 0.10.1 / 2010-05-03 Fixed binary uploads. 0.10.0 / 2010-04-30 Added charset support via Request#charset (automatically assigned to 'UTF-8' when respond()'s encoding is set to 'utf8' or 'utf-8'). Added \"encoding\" option to Request#render(). Closes #299 Added \"dump exceptions\" setting, which is enabled by default. Added simple ejs template engine support Added error response support for text/plain, application/json. Closes #297 Added callback function param to Request#error() Added Request#sendHead() Added Request#stream() Added support for Request#respond(304, null) for empty response bodies Added ETag support to Request#sendfile() Added options to Request#sendfile(), passed to fs.createReadStream() Added filename arg to Request#download() Performance enhanced due to pre-reversing plugins so that plugins.reverse() is not called on each request Performance enhanced by preventing several calls to toLowerCase() in Router#match() Changed; Request#sendfile() now streams Changed; Renamed Request#halt() to Request#respond(). Closes #289 Changed; Using sys.inspect() instead of JSON.encode() for error output Changed; run() returns the http.Server instance. Closes #298 Changed; Defaulting Server#host to null (INADDR_ANY) Changed; Logger \"common\" format scale of 0.4f Removed Logger \"request\" format Fixed; Catching ENOENT in view caching, preventing error when \"views/partials\" is not found Fixed several issues with http client Fixed Logger Content-Length output Fixed bug preventing Opera from retaining the generated session id. Closes #292 0.9.0 / 2010-04-14 Added DSL level error() route support Added DSL level notFound() route support Added Request#error() Added Request#notFound() Added Request#render() callback function. Closes #258 Added \"max upload size\" setting Added \"magic\" variables to collection partials (__index__, __length__, __isFirst__, __isLast__). Closes #254 Added haml.js submodule; removed haml-js Added callback function support to Request#halt() as 3rd/4th arg Added preprocessing of route param wildcards using param(). Closes #251 Added view partial support (with collections etc.) Fixed bug preventing falsey params (such as ?page=0). Closes #286 Fixed setting of multiple cookies. Closes #199 Changed; view naming convention is now NAME.TYPE.ENGINE (for example page.html.haml) Changed; session cookie is now httpOnly Changed; Request is no longer global Changed; Event is no longer global Changed; \"sys\" module is no longer global Changed; moved Request#download to Static plugin where it belongs Changed; Request instance created before body parsing. Closes #262 Changed; Pre-caching views in memory when \"cache view contents\" is enabled. Closes #253 Changed; Pre-caching view partials in memory when \"cache view partials\" is enabled Updated support to node --version 0.1.90 Updated dependencies Removed set(\"session cookie\") in favour of use(Session, { cookie: { ... }}) Removed utils.mixin(); use Object#mergeDeep() 0.8.0 / 2010-03-19 Added coffeescript example app. Closes #242 Changed; cache api now async friendly. Closes #240 Removed deprecated 'express/static' support. Use 'express/plugins/static' 0.7.6 / 2010-03-19 Added Request#isXHR. Closes #229 Added make install (for the executable) Added express executable for setting up simple app templates Added \"GET /public/*\" to Static plugin, defaulting to /public Added Static plugin Fixed; Request#render() only calls cache.get() once Fixed; Namespacing View caches with \"view:\" Fixed; Namespacing Static caches with \"static:\" Fixed; Both example apps now use the Static plugin Fixed set(\"views\"). Closes #239 Fixed missing space for combined log format Deprecated Request#sendfile() and 'express/static' Removed Server#running 0.7.5 / 2010-03-16 Added Request#flash() support without args, now returns all flashes Updated ext submodule 0.7.4 / 2010-03-16 Fixed session reaper Changed; class.js replacing js-oo Class implementation (quite a bit faster, no browser cruft) 0.7.3 / 2010-03-16 Added package.json Fixed requiring of haml / sass due to kiwi removal 0.7.2 / 2010-03-16 Fixed GIT submodules (HAH!) 0.7.1 / 2010-03-16 Changed; Express now using submodules again until a PM is adopted Changed; chat example using millisecond conversions from ext 0.7.0 / 2010-03-15 Added Request#pass() support (finds the next matching route, or the given path) Added Logger plugin (default \"common\" format replaces CommonLogger) Removed Profiler plugin Removed CommonLogger plugin 0.6.0 / 2010-03-11 Added seed.yml for kiwi package management support Added HTTP client query string support when method is GET. Closes #205 Added support for arbitrary view engines. For example \"foo.engine.html\" will now require('engine'), the exports from this module are cached after the first require(). Added async plugin support Removed usage of RESTful route funcs as http client get() etc, use http.get() and friends Removed custom exceptions 0.5.0 / 2010-03-10 Added ext dependency (library of js extensions) Removed extname() / basename() utils. Use path module Removed toArray() util. Use arguments.values Removed escapeRegexp() util. Use RegExp.escape() Removed process.mixin() dependency. Use utils.mixin() Removed Collection Removed ElementCollection Shameless self promotion of ebook \"Advanced JavaScript\" (http://dev-mag.com) ;) 0.4.0 / 2010-02-11 Added flash() example to sample upload app Added high level restful http client module (express/http) Changed; RESTful route functions double as HTTP clients. Closes #69 Changed; throwing error when routes are added at runtime Changed; defaulting render() context to the current Request. Closes #197 Updated haml submodule 0.3.0 / 2010-02-11 Updated haml / sass submodules. Closes #200 Added flash message support. Closes #64 Added accepts() now allows multiple args. fixes #117 Added support for plugins to halt. Closes #189 Added alternate layout support. Closes #119 Removed Route#run(). Closes #188 Fixed broken specs due to use(Cookie) missing 0.2.1 / 2010-02-05 Added \"plot\" format option for Profiler (for gnuplot processing) Added request number to Profiler plugin Fixed binary encoding for multipart file uploads, was previously defaulting to UTF8 Fixed issue with routes not firing when not files are present. Closes #184 Fixed process.Promise -> events.Promise 0.2.0 / 2010-02-03 Added parseParam() support for name[] etc. (allows for file inputs with \"multiple\" attr) Closes #180 Added Both Cache and Session option \"reapInterval\" may be \"reapEvery\". Closes #174 Added expiration support to cache api with reaper. Closes #133 Added cache Store.Memory#reap() Added Cache; cache api now uses first class Cache instances Added abstract session Store. Closes #172 Changed; cache Memory.Store#get() utilizing Collection Renamed MemoryStore -> Store.Memory Fixed use() of the same plugin several time will always use latest options. Closes #176 0.1.0 / 2010-02-03 Changed; Hooks (before / after) pass request as arg as well as evaluated in their context Updated node support to 0.1.27 Closes #169 Updated dirname(__filename) -> __dirname Updated libxmljs support to v0.2.0 Added session support with memory store / reaping Added quick uid() helper Added multi-part upload support Added Sass.js support / submodule Added production env caching view contents and static files Added static file caching. Closes #136 Added cache plugin with memory stores Added support to StaticFile so that it works with non-textual files. Removed dirname() helper Removed several globals (now their modules must be required) 0.0.2 / 2010-01-10 Added view benchmarks; currently haml vs ejs Added Request#attachment() specs. Closes #116 Added use of node's parseQuery() util. Closes #123 Added make init for submodules Updated Haml Updated sample chat app to show messages on load Updated libxmljs parseString -> parseHtmlString Fixed make init to work with older versions of git Fixed specs can now run independent specs for those who can't build deps. Closes #127 Fixed issues introduced by the node url module changes. Closes 126. Fixed two assertions failing due to Collection#keys() returning strings Fixed faulty Collection#toArray() spec due to keys() returning strings Fixed make test now builds libxmljs.node before testing 0.0.1 / 2010-01-03 Initial release"
  },
  "src/frontend/app-client/node_modules/express/node_modules/debug/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/express/node_modules/debug/CHANGELOG.html",
    "title": "2.6.9 / 2017-09-22",
    "summary": "2.6.9 / 2017-09-22 remove ReDoS regexp in %o formatter (#504) 2.6.8 / 2017-05-18 Fix: Check for undefined on browser globals (#462, @marbemac) 2.6.7 / 2017-05-16 Fix: Update ms to 2.0.0 to fix regular expression denial of service vulnerability (#458, @hubdotcom) Fix: Inline extend function in node implementation (#452, @dougwilson) Docs: Fix typo (#455, @msasad) 2.6.5 / 2017-04-27 Fix: null reference check on window.documentElement.style.WebkitAppearance (#447, @thebigredgeek) Misc: clean up browser reference checks (#447, @thebigredgeek) Misc: add npm-debug.log to .gitignore (@thebigredgeek) 2.6.4 / 2017-04-20 Fix: bug that would occure if process.env.DEBUG is a non-string value. (#444, @LucianBuzzo) Chore: ignore bower.json in npm installations. (#437, @joaovieira) Misc: update \"ms\" to v0.7.3 (@tootallnate) 2.6.3 / 2017-03-13 Fix: Electron reference to process.env.DEBUG (#431, @paulcbetts) Docs: Changelog fix (@thebigredgeek) 2.6.2 / 2017-03-10 Fix: DEBUG_MAX_ARRAY_LENGTH (#420, @slavaGanzin) Docs: Add backers and sponsors from Open Collective (#422, @piamancini) Docs: Add Slackin invite badge (@tootallnate) 2.6.1 / 2017-02-10 Fix: Module's export default syntax fix for IE8 Expected identifier error Fix: Whitelist DEBUG_FD for values 1 and 2 only (#415, @pi0) Fix: IE8 \"Expected identifier\" error (#414, @vgoma) Fix: Namespaces would not disable once enabled (#409, @musikov) 2.6.0 / 2016-12-28 Fix: added better null pointer checks for browser useColors (@thebigredgeek) Improvement: removed explicit window.debug export (#404, @tootallnate) Improvement: deprecated DEBUG_FD environment variable (#405, @tootallnate) 2.5.2 / 2016-12-25 Fix: reference error on window within webworkers (#393, @KlausTrainer) Docs: fixed README typo (#391, @lurch) Docs: added notice about v3 api discussion (@thebigredgeek) 2.5.1 / 2016-12-20 Fix: babel-core compatibility 2.5.0 / 2016-12-20 Fix: wrong reference in bower file (@thebigredgeek) Fix: webworker compatibility (@thebigredgeek) Fix: output formatting issue (#388, @kribblo) Fix: babel-loader compatibility (#383, @escwald) Misc: removed built asset from repo and publications (@thebigredgeek) Misc: moved source files to /src (#378, @yamikuronue) Test: added karma integration and replaced babel with browserify for browser tests (#378, @yamikuronue) Test: coveralls integration (#378, @yamikuronue) Docs: simplified language in the opening paragraph (#373, @yamikuronue) 2.4.5 / 2016-12-17 Fix: navigator undefined in Rhino (#376, @jochenberger) Fix: custom log function (#379, @hsiliev) Improvement: bit of cleanup + linting fixes (@thebigredgeek) Improvement: rm non-maintainted dist/ dir (#375, @freewil) Docs: simplified language in the opening paragraph. (#373, @yamikuronue) 2.4.4 / 2016-12-14 Fix: work around debug being loaded in preload scripts for electron (#368, @paulcbetts) 2.4.3 / 2016-12-14 Fix: navigation.userAgent error for react native (#364, @escwald) 2.4.2 / 2016-12-14 Fix: browser colors (#367, @tootallnate) Misc: travis ci integration (@thebigredgeek) Misc: added linting and testing boilerplate with sanity check (@thebigredgeek) 2.4.1 / 2016-12-13 Fix: typo that broke the package (#356) 2.4.0 / 2016-12-13 Fix: bower.json references unbuilt src entry point (#342, @justmatt) Fix: revert \"handle regex special characters\" (@tootallnate) Feature: configurable util.inspect()`options for NodeJS (#327, @tootallnate) Feature: %O`(big O) pretty-prints objects (#322, @tootallnate) Improvement: allow colors in workers (#335, @botverse) Improvement: use same color for same namespace. (#338, @lchenay) 2.3.3 / 2016-11-09 Fix: Catch JSON.stringify() errors (#195, Jovan Alleyne) Fix: Returning localStorage saved values (#331, Levi Thomason) Improvement: Don't create an empty object when no process (Nathan Rajlich) 2.3.2 / 2016-11-09 Fix: be super-safe in index.js as well (@TooTallNate) Fix: should check whether process exists (Tom Newby) 2.3.1 / 2016-11-09 Fix: Added electron compatibility (#324, @paulcbetts) Improvement: Added performance optimizations (@tootallnate) Readme: Corrected PowerShell environment variable example (#252, @gimre) Misc: Removed yarn lock file from source control (#321, @fengmk2) 2.3.0 / 2016-11-07 Fix: Consistent placement of ms diff at end of output (#215, @gorangajic) Fix: Escaping of regex special characters in namespace strings (#250, @zacronos) Fix: Fixed bug causing crash on react-native (#282, @vkarpov15) Feature: Enabled ES6+ compatible import via default export (#212 @bucaran) Feature: Added %O formatter to reflect Chrome's console.log capability (#279, @oncletom) Package: Update \"ms\" to 0.7.2 (#315, @DevSide) Package: removed superfluous version property from bower.json (#207 @kkirsche) Readme: fix USE_COLORS to DEBUG_COLORS Readme: Doc fixes for format string sugar (#269, @mlucool) Readme: Updated docs for DEBUG_FD and DEBUG_COLORS environment variables (#232, @mattlyons0) Readme: doc fixes for PowerShell (#271 #243, @exoticknight @unreadable) Readme: better docs for browser support (#224, @matthewmueller) Tooling: Added yarn integration for development (#317, @thebigredgeek) Misc: Renamed History.md to CHANGELOG.md (@thebigredgeek) Misc: Added license file (#226 #274, @CantemoInternal @sdaitzman) Misc: Updated contributors (@thebigredgeek) 2.2.0 / 2015-05-09 package: update \"ms\" to v0.7.1 (#202, @dougwilson) README: add logging to file example (#193, @DanielOchoa) README: fixed a typo (#191, @amir-s) browser: expose storage (#190, @stephenmathieson) Makefile: add a distclean target (#189, @stephenmathieson) 2.1.3 / 2015-03-13 Updated stdout/stderr example (#186) Updated example/stdout.js to match debug current behaviour Renamed example/stderr.js to stdout.js Update Readme.md (#184) replace high intensity foreground color for bold (#182, #183) 2.1.2 / 2015-03-01 dist: recompile update \"ms\" to v0.7.0 package: update \"browserify\" to v9.0.3 component: fix \"ms.js\" repo location changed bower package name updated documentation about using debug in a browser fix: security error on safari (#167, #168, @yields) 2.1.1 / 2014-12-29 browser: use typeof to check for console existence browser: check for console.log truthiness (fix IE 8/9) browser: add support for Chrome apps Readme: added Windows usage remarks Add bower.json to properly support bower install 2.1.0 / 2014-10-15 node: implement DEBUG_FD env variable support package: update \"browserify\" to v6.1.0 package: add \"license\" field to package.json (#135, @panuhorsmalahti) 2.0.0 / 2014-09-01 package: update \"browserify\" to v5.11.0 node: use stderr rather than stdout for logging (#29, @stephenmathieson) 1.0.4 / 2014-07-15 dist: recompile example: remove console.info() log usage example: add \"Content-Type\" UTF-8 header to browser example browser: place %c marker after the space character browser: reset the \"content\" color via color: inherit browser: add colors support for Firefox >= v31 debug: prefer an instance log() function over the global one (#119) Readme: update documentation about styled console logs for FF v31 (#116, @wryk) 1.0.3 / 2014-07-09 Add support for multiple wildcards in namespaces (#122, @seegno) browser: fix lint 1.0.2 / 2014-06-10 browser: update color palette (#113, @gscottolson) common: make console logging function configurable (#108, @timoxley) node: fix %o colors on old node <= 0.8.x Makefile: find node path using shell/which (#109, @timoxley) 1.0.1 / 2014-06-06 browser: use removeItem() to clear localStorage browser, node: don't set DEBUG if namespaces is undefined (#107, @leedm777) package: add \"contributors\" section node: fix comment typo README: list authors 1.0.0 / 2014-06-04 make ms diff be global, not be scope debug: ignore empty strings in enable() node: make DEBUG_COLORS able to disable coloring *: export the colors array npmignore: don't publish the dist dir Makefile: refactor to use browserify package: add \"browserify\" as a dev dependency Readme: add Web Inspector Colors section node: reset terminal color for the debug content node: map \"%o\" to util.inspect() browser: map \"%j\" to JSON.stringify() debug: add custom \"formatters\" debug: use \"ms\" module for humanizing the diff Readme: add \"bash\" syntax highlighting browser: add Firebug color support browser: add colors for WebKit browsers node: apply log to console rewrite: abstract common logic for Node & browsers add .jshintrc file 0.8.1 / 2014-04-14 package: re-add the \"component\" section 0.8.0 / 2014-03-30 add enable() method for nodejs. Closes #27 change from stderr to stdout remove unnecessary index.js file 0.7.4 / 2013-11-13 remove \"browserify\" key from package.json (fixes something in browserify) 0.7.3 / 2013-10-30 fix: catch localStorage security error when cookies are blocked (Chrome) add debug(err) support. Closes #46 add .browser prop to package.json. Closes #42 0.7.2 / 2013-02-06 fix package.json fix: Mobile Safari (private mode) is broken with debug fix: Use unicode to send escape character to shell instead of octal to work with strict mode javascript 0.7.1 / 2013-02-05 add repository URL to package.json add DEBUG_COLORED to force colored output add browserify support fix component. Closes #24 0.7.0 / 2012-05-04 Added .component to package.json Added debug.component.js build 0.6.0 / 2012-03-16 Added support for \"-\" prefix in DEBUG [Vinay Pulim] Added .enabled flag to the node version [TooTallNate] 0.5.0 / 2012-02-02 Added: humanize diffs. Closes #8 Added debug.disable() to the CS variant Removed padding. Closes #10 Fixed: persist client-side variant again. Closes #9 0.4.0 / 2012-02-01 Added browser variant support for older browsers [TooTallNate] Added debug.enable('project:*') to browser variant [TooTallNate] Added padding to diff (moved it to the right) 0.3.0 / 2012-01-26 Added millisecond diff when isatty, otherwise UTC string 0.2.0 / 2012-01-22 Added wildcard support 0.1.0 / 2011-12-02 Added: remove colors unless stderr isatty [TooTallNate] 0.0.1 / 2010-01-03 Initial release"
  },
  "src/frontend/app-client/node_modules/express/node_modules/debug/README.html": {
    "href": "src/frontend/app-client/node_modules/express/node_modules/debug/README.html",
    "title": "debug",
    "summary": "debug A tiny node.js debugging utility modelled after node core's debugging technique. Discussion around the V3 API is under way here Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %s', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var debug = require('debug')('worker'); setInterval(function(){ debug('doing some work'); }, 1000); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows note On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Note that PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Then, run the program to be debugged as usual. Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toUTCString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); Web Inspector Colors Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Colored output looks something like: Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2016 TJ Holowaychuk <tj@vision-media.ca&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/express/node_modules/ms/license.html": {
    "href": "src/frontend/app-client/node_modules/express/node_modules/ms/license.html",
    "title": "",
    "summary": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/express/node_modules/ms/readme.html": {
    "href": "src/frontend/app-client/node_modules/express/node_modules/ms/readme.html",
    "title": "ms",
    "summary": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 Convert from milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(ms('10 hours')) // \"10h\" Time format written-out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in node and in the browser. If a number is supplied to ms, a string with a unit is returned. If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100'). If you pass a string with a number and a valid unit, the number of equivalent ms is returned. Caught a bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, node will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "src/frontend/app-client/node_modules/express/Readme.html": {
    "href": "src/frontend/app-client/node_modules/express/Readme.html",
    "title": "",
    "summary": "Fast, unopinionated, minimalist web framework for Node.js. This project has a Code of Conduct. Table of contents Installation Features Docs & Community Quick Start Running Tests Philosophy Examples Contributing to Express TC (Technical Committee) Triagers License const express = require('express') const app = express() app.get('/', function (req, res) { res.send('Hello World') }) app.listen(3000) Installation This is a Node.js module available through the npm registry. Before installing, download and install Node.js. Node.js 0.10 or higher is required. If this is a brand new project, make sure to create a package.json first with the npm init command. Installation is done using the npm install command: $ npm install express Follow our installing guide for more information. Features Robust routing Focus on high performance Super-high test coverage HTTP helpers (redirection, caching, etc) View system supporting 14+ template engines Content negotiation Executable for generating applications quickly Docs & Community Website and Documentation - [website repo] #express on Libera Chat IRC GitHub Organization for Official Middleware & Modules Visit the Wiki Google Group for discussion Gitter for support and discussion PROTIP Be sure to read Migrating from 3.x to 4.x as well as New features in 4.x. Quick Start The quickest way to get started with express is to utilize the executable express(1) to generate an application as shown below: Install the executable. The executable's major version will match Express's: $ npm install -g express-generator@4 Create the app: $ express /tmp/foo && cd /tmp/foo Install dependencies: $ npm install Start the server: $ npm start View the website at: http://localhost:3000 Philosophy The Express philosophy is to provide small, robust tooling for HTTP servers, making it a great solution for single page applications, websites, hybrids, or public HTTP APIs. Express does not force you to use any specific ORM or template engine. With support for over 14 template engines via Consolidate.js, you can quickly craft your perfect framework. Examples To view the examples, clone the Express repo and install the dependencies: $ git clone https://github.com/expressjs/express.git --depth 1 $ cd express $ npm install Then run whichever example you want: $ node examples/content-negotiation Contributing The Express.js project welcomes all constructive contributions. Contributions take many forms, from code for bug fixes and enhancements, to additions and fixes to documentation, additional tests, triaging incoming pull requests and issues, and more! See the Contributing Guide for more technical details on contributing. Security Issues If you discover a security vulnerability in Express, please see Security Policies and Procedures. Running Tests To run the test suite, first install the dependencies, then run npm test: $ npm install $ npm test People The original author of Express is TJ Holowaychuk List of all contributors TC (Technical Committee) UlisesGascon - Ulises Gascón (he/him) jonchurch - Jon Church wesleytodd - Wes Todd LinusU - Linus Unnebäck blakeembrey - Blake Embrey sheplu - Jean Burellier crandmck - Rand McKinney ctcpip - Chris de Almeida TC emeriti members TC emeriti members dougwilson - Douglas Wilson hacksparrow - Hage Yaapa jonathanong - jongleberry niftylettuce - niftylettuce troygoode - Troy Goode Triagers aravindvnair99 - Aravind Nair carpasse - Carlos Serrano CBID2 - Christine Belzie enyoghasim - David Enyoghasim UlisesGascon - Ulises Gascón (he/him) mertcanaltin - Mert Can Altin 0ss - Salah import-brain - Eric Cheng (he/him) 3imed-jaberi - Imed Jaberi dakshkhetan - Daksh Khetan (he/him) lucasraziel - Lucas Soares Do Rego IamLizu - S M Mahmudul Hasan (he/him) Sushmeet - Sushmeet Sunger Triagers emeriti members Emeritus Triagers AuggieH - Auggie Hudak G-Rath - Gareth Jones MohammadXroid - Mohammad Ayashi NawafSwe - Nawaf Alsharqi NotMoni - Moni VigneshMurugan - Vignesh Murugan davidmashe - David Ashe digitaIfabric - David e-l-i-s-e - Elise Bonner fed135 - Frederic Charette firmanJS - Firman Abdul Hakim getspooky - Yasser Ameur ghinks - Glenn ghousemohamed - Ghouse Mohamed gireeshpunathil - Gireesh Punathil jake32321 - Jake Reed jonchurch - Jon Church lekanikotun - Troy Goode marsonya - Lekan Ikotun mastermatt - Matt R. Wilson maxakuru - Max Edell mlrawlings - Michael Rawlings rodion-arr - Rodion Abdurakhimov sheplu - Jean Burellier tarunyadav1 - Tarun yadav tunniclm - Mike Tunnicliffe License MIT"
  },
  "src/frontend/app-client/node_modules/finalhandler/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/finalhandler/HISTORY.html",
    "title": "v1.3.1 / 2024-09-11",
    "summary": "v1.3.1 / 2024-09-11 deps: encodeurl@~2.0.0 v1.3.0 / 2024-09-03 ignore status message for HTTP/2 (#53) v1.2.1 / 2024-09-02 Gracefully handle when handling an error and socket is null 1.2.0 / 2022-03-22 Remove set content headers that break response deps: on-finished@2.4.1 deps: statuses@2.0.1 Rename 425 Unordered Collection to standard 425 Too Early 1.1.2 / 2019-05-09 Set stricter Content-Security-Policy header deps: parseurl@~1.3.3 deps: statuses@~1.5.0 1.1.1 / 2018-03-06 Fix 404 output for bad / missing pathnames deps: encodeurl@~1.0.2 Fix encoding % as last character deps: statuses@~1.4.0 1.1.0 / 2017-09-24 Use res.headersSent when available 1.0.6 / 2017-09-22 deps: debug@2.6.9 1.0.5 / 2017-09-15 deps: parseurl@~1.3.2 perf: reduce overhead for full URLs perf: unroll the \"fast-path\" RegExp 1.0.4 / 2017-08-03 deps: debug@2.6.8 1.0.3 / 2017-05-16 deps: debug@2.6.7 deps: ms@2.0.0 1.0.2 / 2017-04-22 deps: debug@2.6.4 deps: ms@0.7.3 1.0.1 / 2017-03-21 Fix missing </html> in HTML document deps: debug@2.6.3 Fix: DEBUG_MAX_ARRAY_LENGTH 1.0.0 / 2017-02-15 Fix exception when err cannot be converted to a string Fully URL-encode the pathname in the 404 message Only include the pathname in the 404 message Send complete HTML document Set Content-Security-Policy: default-src 'self' header deps: debug@2.6.1 Allow colors in workers Deprecated DEBUG_FD environment variable set to 3 or higher Fix error when running under React Native Use same color for same namespace deps: ms@0.7.2 0.5.1 / 2016-11-12 Fix exception when err.headers is not an object deps: statuses@~1.3.1 perf: hoist regular expressions perf: remove duplicate validation path 0.5.0 / 2016-06-15 Change invalid or non-numeric status code to 500 Overwrite status message to match set status code Prefer err.statusCode if err.status is invalid Set response headers from err.headers object Use statuses instead of http module for status messages Includes all defined status messages 0.4.1 / 2015-12-02 deps: escape-html@~1.0.3 perf: enable strict mode perf: optimize string replacement perf: use faster string coercion 0.4.0 / 2015-06-14 Fix a false-positive when unpiping in Node.js 0.8 Support statusCode property on Error objects Use unpipe module for unpiping requests deps: escape-html@1.0.2 deps: on-finished@~2.3.0 Add defined behavior for HTTP CONNECT requests Add defined behavior for HTTP Upgrade requests deps: ee-first@1.1.1 perf: enable strict mode perf: remove argument reassignment 0.3.6 / 2015-05-11 deps: debug@~2.2.0 deps: ms@0.7.1 0.3.5 / 2015-04-22 deps: on-finished@~2.2.1 Fix isFinished(req) when data buffered 0.3.4 / 2015-03-15 deps: debug@~2.1.3 Fix high intensity foreground color for bold deps: ms@0.7.0 0.3.3 / 2015-01-01 deps: debug@~2.1.1 deps: on-finished@~2.2.0 0.3.2 / 2014-10-22 deps: on-finished@~2.1.1 Fix handling of pipelined requests 0.3.1 / 2014-10-16 deps: debug@~2.1.0 Implement DEBUG_FD env variable support 0.3.0 / 2014-09-17 Terminate in progress response only on error Use on-finished to determine request status 0.2.0 / 2014-09-03 Set X-Content-Type-Options: nosniff header deps: debug@~2.0.0 0.1.0 / 2014-07-16 Respond after request fully read prevents hung responses and socket hang ups deps: debug@1.0.4 0.0.3 / 2014-07-11 deps: debug@1.0.3 Add support for multiple wildcards in namespaces 0.0.2 / 2014-06-19 Handle invalid status codes 0.0.1 / 2014-06-05 deps: debug@1.0.2 0.0.0 / 2014-06-05 Extracted from connect/express"
  },
  "src/frontend/app-client/node_modules/finalhandler/node_modules/debug/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/finalhandler/node_modules/debug/CHANGELOG.html",
    "title": "2.6.9 / 2017-09-22",
    "summary": "2.6.9 / 2017-09-22 remove ReDoS regexp in %o formatter (#504) 2.6.8 / 2017-05-18 Fix: Check for undefined on browser globals (#462, @marbemac) 2.6.7 / 2017-05-16 Fix: Update ms to 2.0.0 to fix regular expression denial of service vulnerability (#458, @hubdotcom) Fix: Inline extend function in node implementation (#452, @dougwilson) Docs: Fix typo (#455, @msasad) 2.6.5 / 2017-04-27 Fix: null reference check on window.documentElement.style.WebkitAppearance (#447, @thebigredgeek) Misc: clean up browser reference checks (#447, @thebigredgeek) Misc: add npm-debug.log to .gitignore (@thebigredgeek) 2.6.4 / 2017-04-20 Fix: bug that would occure if process.env.DEBUG is a non-string value. (#444, @LucianBuzzo) Chore: ignore bower.json in npm installations. (#437, @joaovieira) Misc: update \"ms\" to v0.7.3 (@tootallnate) 2.6.3 / 2017-03-13 Fix: Electron reference to process.env.DEBUG (#431, @paulcbetts) Docs: Changelog fix (@thebigredgeek) 2.6.2 / 2017-03-10 Fix: DEBUG_MAX_ARRAY_LENGTH (#420, @slavaGanzin) Docs: Add backers and sponsors from Open Collective (#422, @piamancini) Docs: Add Slackin invite badge (@tootallnate) 2.6.1 / 2017-02-10 Fix: Module's export default syntax fix for IE8 Expected identifier error Fix: Whitelist DEBUG_FD for values 1 and 2 only (#415, @pi0) Fix: IE8 \"Expected identifier\" error (#414, @vgoma) Fix: Namespaces would not disable once enabled (#409, @musikov) 2.6.0 / 2016-12-28 Fix: added better null pointer checks for browser useColors (@thebigredgeek) Improvement: removed explicit window.debug export (#404, @tootallnate) Improvement: deprecated DEBUG_FD environment variable (#405, @tootallnate) 2.5.2 / 2016-12-25 Fix: reference error on window within webworkers (#393, @KlausTrainer) Docs: fixed README typo (#391, @lurch) Docs: added notice about v3 api discussion (@thebigredgeek) 2.5.1 / 2016-12-20 Fix: babel-core compatibility 2.5.0 / 2016-12-20 Fix: wrong reference in bower file (@thebigredgeek) Fix: webworker compatibility (@thebigredgeek) Fix: output formatting issue (#388, @kribblo) Fix: babel-loader compatibility (#383, @escwald) Misc: removed built asset from repo and publications (@thebigredgeek) Misc: moved source files to /src (#378, @yamikuronue) Test: added karma integration and replaced babel with browserify for browser tests (#378, @yamikuronue) Test: coveralls integration (#378, @yamikuronue) Docs: simplified language in the opening paragraph (#373, @yamikuronue) 2.4.5 / 2016-12-17 Fix: navigator undefined in Rhino (#376, @jochenberger) Fix: custom log function (#379, @hsiliev) Improvement: bit of cleanup + linting fixes (@thebigredgeek) Improvement: rm non-maintainted dist/ dir (#375, @freewil) Docs: simplified language in the opening paragraph. (#373, @yamikuronue) 2.4.4 / 2016-12-14 Fix: work around debug being loaded in preload scripts for electron (#368, @paulcbetts) 2.4.3 / 2016-12-14 Fix: navigation.userAgent error for react native (#364, @escwald) 2.4.2 / 2016-12-14 Fix: browser colors (#367, @tootallnate) Misc: travis ci integration (@thebigredgeek) Misc: added linting and testing boilerplate with sanity check (@thebigredgeek) 2.4.1 / 2016-12-13 Fix: typo that broke the package (#356) 2.4.0 / 2016-12-13 Fix: bower.json references unbuilt src entry point (#342, @justmatt) Fix: revert \"handle regex special characters\" (@tootallnate) Feature: configurable util.inspect()`options for NodeJS (#327, @tootallnate) Feature: %O`(big O) pretty-prints objects (#322, @tootallnate) Improvement: allow colors in workers (#335, @botverse) Improvement: use same color for same namespace. (#338, @lchenay) 2.3.3 / 2016-11-09 Fix: Catch JSON.stringify() errors (#195, Jovan Alleyne) Fix: Returning localStorage saved values (#331, Levi Thomason) Improvement: Don't create an empty object when no process (Nathan Rajlich) 2.3.2 / 2016-11-09 Fix: be super-safe in index.js as well (@TooTallNate) Fix: should check whether process exists (Tom Newby) 2.3.1 / 2016-11-09 Fix: Added electron compatibility (#324, @paulcbetts) Improvement: Added performance optimizations (@tootallnate) Readme: Corrected PowerShell environment variable example (#252, @gimre) Misc: Removed yarn lock file from source control (#321, @fengmk2) 2.3.0 / 2016-11-07 Fix: Consistent placement of ms diff at end of output (#215, @gorangajic) Fix: Escaping of regex special characters in namespace strings (#250, @zacronos) Fix: Fixed bug causing crash on react-native (#282, @vkarpov15) Feature: Enabled ES6+ compatible import via default export (#212 @bucaran) Feature: Added %O formatter to reflect Chrome's console.log capability (#279, @oncletom) Package: Update \"ms\" to 0.7.2 (#315, @DevSide) Package: removed superfluous version property from bower.json (#207 @kkirsche) Readme: fix USE_COLORS to DEBUG_COLORS Readme: Doc fixes for format string sugar (#269, @mlucool) Readme: Updated docs for DEBUG_FD and DEBUG_COLORS environment variables (#232, @mattlyons0) Readme: doc fixes for PowerShell (#271 #243, @exoticknight @unreadable) Readme: better docs for browser support (#224, @matthewmueller) Tooling: Added yarn integration for development (#317, @thebigredgeek) Misc: Renamed History.md to CHANGELOG.md (@thebigredgeek) Misc: Added license file (#226 #274, @CantemoInternal @sdaitzman) Misc: Updated contributors (@thebigredgeek) 2.2.0 / 2015-05-09 package: update \"ms\" to v0.7.1 (#202, @dougwilson) README: add logging to file example (#193, @DanielOchoa) README: fixed a typo (#191, @amir-s) browser: expose storage (#190, @stephenmathieson) Makefile: add a distclean target (#189, @stephenmathieson) 2.1.3 / 2015-03-13 Updated stdout/stderr example (#186) Updated example/stdout.js to match debug current behaviour Renamed example/stderr.js to stdout.js Update Readme.md (#184) replace high intensity foreground color for bold (#182, #183) 2.1.2 / 2015-03-01 dist: recompile update \"ms\" to v0.7.0 package: update \"browserify\" to v9.0.3 component: fix \"ms.js\" repo location changed bower package name updated documentation about using debug in a browser fix: security error on safari (#167, #168, @yields) 2.1.1 / 2014-12-29 browser: use typeof to check for console existence browser: check for console.log truthiness (fix IE 8/9) browser: add support for Chrome apps Readme: added Windows usage remarks Add bower.json to properly support bower install 2.1.0 / 2014-10-15 node: implement DEBUG_FD env variable support package: update \"browserify\" to v6.1.0 package: add \"license\" field to package.json (#135, @panuhorsmalahti) 2.0.0 / 2014-09-01 package: update \"browserify\" to v5.11.0 node: use stderr rather than stdout for logging (#29, @stephenmathieson) 1.0.4 / 2014-07-15 dist: recompile example: remove console.info() log usage example: add \"Content-Type\" UTF-8 header to browser example browser: place %c marker after the space character browser: reset the \"content\" color via color: inherit browser: add colors support for Firefox >= v31 debug: prefer an instance log() function over the global one (#119) Readme: update documentation about styled console logs for FF v31 (#116, @wryk) 1.0.3 / 2014-07-09 Add support for multiple wildcards in namespaces (#122, @seegno) browser: fix lint 1.0.2 / 2014-06-10 browser: update color palette (#113, @gscottolson) common: make console logging function configurable (#108, @timoxley) node: fix %o colors on old node <= 0.8.x Makefile: find node path using shell/which (#109, @timoxley) 1.0.1 / 2014-06-06 browser: use removeItem() to clear localStorage browser, node: don't set DEBUG if namespaces is undefined (#107, @leedm777) package: add \"contributors\" section node: fix comment typo README: list authors 1.0.0 / 2014-06-04 make ms diff be global, not be scope debug: ignore empty strings in enable() node: make DEBUG_COLORS able to disable coloring *: export the colors array npmignore: don't publish the dist dir Makefile: refactor to use browserify package: add \"browserify\" as a dev dependency Readme: add Web Inspector Colors section node: reset terminal color for the debug content node: map \"%o\" to util.inspect() browser: map \"%j\" to JSON.stringify() debug: add custom \"formatters\" debug: use \"ms\" module for humanizing the diff Readme: add \"bash\" syntax highlighting browser: add Firebug color support browser: add colors for WebKit browsers node: apply log to console rewrite: abstract common logic for Node & browsers add .jshintrc file 0.8.1 / 2014-04-14 package: re-add the \"component\" section 0.8.0 / 2014-03-30 add enable() method for nodejs. Closes #27 change from stderr to stdout remove unnecessary index.js file 0.7.4 / 2013-11-13 remove \"browserify\" key from package.json (fixes something in browserify) 0.7.3 / 2013-10-30 fix: catch localStorage security error when cookies are blocked (Chrome) add debug(err) support. Closes #46 add .browser prop to package.json. Closes #42 0.7.2 / 2013-02-06 fix package.json fix: Mobile Safari (private mode) is broken with debug fix: Use unicode to send escape character to shell instead of octal to work with strict mode javascript 0.7.1 / 2013-02-05 add repository URL to package.json add DEBUG_COLORED to force colored output add browserify support fix component. Closes #24 0.7.0 / 2012-05-04 Added .component to package.json Added debug.component.js build 0.6.0 / 2012-03-16 Added support for \"-\" prefix in DEBUG [Vinay Pulim] Added .enabled flag to the node version [TooTallNate] 0.5.0 / 2012-02-02 Added: humanize diffs. Closes #8 Added debug.disable() to the CS variant Removed padding. Closes #10 Fixed: persist client-side variant again. Closes #9 0.4.0 / 2012-02-01 Added browser variant support for older browsers [TooTallNate] Added debug.enable('project:*') to browser variant [TooTallNate] Added padding to diff (moved it to the right) 0.3.0 / 2012-01-26 Added millisecond diff when isatty, otherwise UTC string 0.2.0 / 2012-01-22 Added wildcard support 0.1.0 / 2011-12-02 Added: remove colors unless stderr isatty [TooTallNate] 0.0.1 / 2010-01-03 Initial release"
  },
  "src/frontend/app-client/node_modules/finalhandler/node_modules/debug/README.html": {
    "href": "src/frontend/app-client/node_modules/finalhandler/node_modules/debug/README.html",
    "title": "debug",
    "summary": "debug A tiny node.js debugging utility modelled after node core's debugging technique. Discussion around the V3 API is under way here Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %s', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var debug = require('debug')('worker'); setInterval(function(){ debug('doing some work'); }, 1000); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows note On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Note that PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Then, run the program to be debugged as usual. Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toUTCString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); Web Inspector Colors Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Colored output looks something like: Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2016 TJ Holowaychuk <tj@vision-media.ca&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/finalhandler/node_modules/ms/license.html": {
    "href": "src/frontend/app-client/node_modules/finalhandler/node_modules/ms/license.html",
    "title": "",
    "summary": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/finalhandler/node_modules/ms/readme.html": {
    "href": "src/frontend/app-client/node_modules/finalhandler/node_modules/ms/readme.html",
    "title": "ms",
    "summary": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 Convert from milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(ms('10 hours')) // \"10h\" Time format written-out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in node and in the browser. If a number is supplied to ms, a string with a unit is returned. If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100'). If you pass a string with a number and a valid unit, the number of equivalent ms is returned. Caught a bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, node will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "src/frontend/app-client/node_modules/finalhandler/README.html": {
    "href": "src/frontend/app-client/node_modules/finalhandler/README.html",
    "title": "finalhandler",
    "summary": "finalhandler Node.js function to invoke as the final step to respond to HTTP request. Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install finalhandler API var finalhandler = require('finalhandler') finalhandler(req, res, [options]) Returns function to be invoked as the final step for the given req and res. This function is to be invoked as fn(err). If err is falsy, the handler will write out a 404 response to the res. If it is truthy, an error response will be written out to the res or res will be terminated if a response has already started. When an error is written, the following information is added to the response: The res.statusCode is set from err.status (or err.statusCode). If this value is outside the 4xx or 5xx range, it will be set to 500. The res.statusMessage is set according to the status code. The body will be the HTML of the status code message if env is 'production', otherwise will be err.stack. Any headers specified in an err.headers object. The final handler will also unpipe anything from req when it is invoked. options.env By default, the environment is determined by NODE_ENV variable, but it can be overridden by this option. options.onerror Provide a function to be called with the err when it exists. Can be used for writing errors to a central location without excessive function generation. Called as onerror(err, req, res). Examples always 404 var finalhandler = require('finalhandler') var http = require('http') var server = http.createServer(function (req, res) { var done = finalhandler(req, res) done() }) server.listen(3000) perform simple action var finalhandler = require('finalhandler') var fs = require('fs') var http = require('http') var server = http.createServer(function (req, res) { var done = finalhandler(req, res) fs.readFile('index.html', function (err, buf) { if (err) return done(err) res.setHeader('Content-Type', 'text/html') res.end(buf) }) }) server.listen(3000) use with middleware-style functions var finalhandler = require('finalhandler') var http = require('http') var serveStatic = require('serve-static') var serve = serveStatic('public') var server = http.createServer(function (req, res) { var done = finalhandler(req, res) serve(req, res, done) }) server.listen(3000) keep log of all errors var finalhandler = require('finalhandler') var fs = require('fs') var http = require('http') var server = http.createServer(function (req, res) { var done = finalhandler(req, res, { onerror: logerror }) fs.readFile('index.html', function (err, buf) { if (err) return done(err) res.setHeader('Content-Type', 'text/html') res.end(buf) }) }) server.listen(3000) function logerror (err) { console.error(err.stack || err.toString()) } License MIT"
  },
  "src/frontend/app-client/node_modules/finalhandler/SECURITY.html": {
    "href": "src/frontend/app-client/node_modules/finalhandler/SECURITY.html",
    "title": "Security Policies and Procedures",
    "summary": "Security Policies and Procedures Reporting a Bug The finalhandler team and community take all security bugs seriously. Thank you for improving the security of Express. We appreciate your efforts and responsible disclosure and will make every effort to acknowledge your contributions. Report security bugs by emailing the current owner(s) of finalhandler. This information can be found in the npm registry using the command npm owner ls finalhandler. If unsure or unable to get the information from the above, open an issue in the project issue tracker asking for the current contact information. To ensure the timely response to your report, please ensure that the entirety of the report is contained within the email body and not solely behind a web link or an attachment. At least one owner will acknowledge your email within 48 hours, and will send a more detailed response within 48 hours indicating the next steps in handling your report. After the initial reply to your report, the owners will endeavor to keep you informed of the progress towards a fix and full announcement, and may ask for additional information or guidance."
  },
  "src/frontend/app-client/node_modules/find-root/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/find-root/LICENSE.html",
    "title": "",
    "summary": "Copyright © 2017 jsdnxx Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/find-root/README.html": {
    "href": "src/frontend/app-client/node_modules/find-root/README.html",
    "title": "find-root",
    "summary": "find-root recursively find the closest package.json usage Say you want to check if the directory name of a project matches its module name in package.json: const path = require('path') const findRoot = require('find-root') // from a starting directory, recursively search for the nearest // directory containing package.json const root = findRoot('/Users/jsdnxx/Code/find-root/tests') // => '/Users/jsdnxx/Code/find-root' const dirname = path.basename(root) console.log('is it the same?') console.log(dirname === require(path.join(root, 'package.json')).name) You can also pass in a custom check function (by default, it checks for the existence of package.json in a directory). In this example, we traverse up to find the root of a git repo: const fs = require('fs') const gitRoot = findRoot('/Users/jsdnxx/Code/find-root/tests', function (dir) { return fs.existsSync(path.resolve(dir, '.git')) }) api findRoot: (startingPath : string, check?: (dir: string) => boolean) => string Returns the path for the nearest directory to startingPath containing a package.json file, eg /foo/module. If check is provided, returns the path for the closest parent directory where check returns true. Throws an error if no package.json is found at any level in the startingPath. installation > npm install find-root running the tests From package root: > npm install > npm test contributors jsdnxx license MIT. (c) 2017 jsdnxx"
  },
  "src/frontend/app-client/node_modules/foreground-child/README.html": {
    "href": "src/frontend/app-client/node_modules/foreground-child/README.html",
    "title": "foreground-child",
    "summary": "foreground-child Run a child as if it's the foreground process. Give it stdio. Exit when it exits. Mostly this module is here to support some use cases around wrapping child processes for test coverage and such. But it's also generally useful any time you want one program to execute another as if it's the \"main\" process, for example, if a program takes a --cmd argument to execute in some way. USAGE import { foregroundChild } from 'foreground-child' // hybrid module, this also works: // const { foregroundChild } = require('foreground-child') // cats out this file const child = foregroundChild('cat', [__filename]) // At this point, it's best to just do nothing else. // return or whatever. // If the child gets a signal, or just exits, then this // parent process will exit in the same way. You can provide custom spawn options by passing an object after the program and arguments: const child = foregroundChild(`cat ${__filename}`, { shell: true }) A callback can optionally be provided, if you want to perform an action before your foreground-child exits: const child = foregroundChild('cat', [__filename], spawnOptions, () => { doSomeActions() }) The callback can return a Promise in order to perform asynchronous actions. If the callback does not return a promise, then it must complete its actions within a single JavaScript tick. const child = foregroundChild('cat', [__filename], async () => { await doSomeAsyncActions() }) If the callback throws or rejects, then it will be unhandled, and node will exit in error. If the callback returns a string value, then that will be used as the signal to exit the parent process. If it returns a number, then that number will be used as the parent exit status code. If it returns boolean false, then the parent process will not be terminated. If it returns undefined, then it will exit with the same signal/code as the child process. Caveats The \"normal\" standard IO file descriptors (0, 1, and 2 for stdin, stdout, and stderr respectively) are shared with the child process. Additionally, if there is an IPC channel set up in the parent, then messages are proxied to the child on file descriptor 3. In Node, it's possible to also map arbitrary file descriptors into a child process. In these cases, foreground-child will not map the file descriptors into the child. If file descriptors 0, 1, or 2 are used for the IPC channel, then strange behavior may happen (like printing IPC messages to stderr, for example). Note that a SIGKILL will always kill the parent process, but will not proxy the signal to the child process, because SIGKILL cannot be caught. In order to address this, a special \"watchdog\" child process is spawned which will send a SIGKILL to the child process if it does not terminate within half a second after the watchdog receives a SIGHUP due to its parent terminating. On Windows, issuing a process.kill(process.pid, signal) with a fatal termination signal may cause the process to exit with a 1 status code rather than reporting the signal properly. This module tries to do the right thing, but on Windows systems, you may see that incorrect result. There is as far as I'm aware no workaround for this. util: foreground-child/proxy-signals If you just want to proxy the signals to a child process that the main process receives, you can use the proxy-signals export from this package. import { proxySignals } from 'foreground-child/proxy-signals' const childProcess = spawn('command', ['some', 'args']) proxySignals(childProcess) Now, any fatal signal received by the current process will be proxied to the child process. It doesn't go in the other direction; ie, signals sent to the child process will not affect the parent. For that, listen to the child exit or close events, and handle them appropriately. util: foreground-child/watchdog If you are spawning a child process, and want to ensure that it isn't left dangling if the parent process exits, you can use the watchdog utility exported by this module. import { watchdog } from 'foreground-child/watchdog' const childProcess = spawn('command', ['some', 'args']) const watchdogProcess = watchdog(childProcess) // watchdogProcess is a reference to the process monitoring the // parent and child. There's usually no reason to do anything // with it, as it's silent and will terminate // automatically when it's no longer needed."
  },
  "src/frontend/app-client/node_modules/forwarded/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/forwarded/HISTORY.html",
    "title": "0.2.0 / 2021-05-31",
    "summary": "0.2.0 / 2021-05-31 Use req.socket over deprecated req.connection 0.1.2 / 2017-09-14 perf: improve header parsing perf: reduce overhead when no X-Forwarded-For header 0.1.1 / 2017-09-10 Fix trimming leading / trailing OWS perf: hoist regular expression 0.1.0 / 2014-09-21 Initial release"
  },
  "src/frontend/app-client/node_modules/forwarded/README.html": {
    "href": "src/frontend/app-client/node_modules/forwarded/README.html",
    "title": "forwarded",
    "summary": "forwarded Parse HTTP X-Forwarded-For header Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install forwarded API var forwarded = require('forwarded') forwarded(req) var addresses = forwarded(req) Parse the X-Forwarded-For header from the request. Returns an array of the addresses, including the socket address for the req, in reverse order (i.e. index 0 is the socket address and the last index is the furthest address, typically the end-user). Testing $ npm test License MIT"
  },
  "src/frontend/app-client/node_modules/framer-motion/client/README.html": {
    "href": "src/frontend/app-client/node_modules/framer-motion/client/README.html",
    "title": "",
    "summary": "This directory is a fallback for exports[\"./client\"] in the root framer-motion package.json."
  },
  "src/frontend/app-client/node_modules/framer-motion/dom/README.html": {
    "href": "src/frontend/app-client/node_modules/framer-motion/dom/README.html",
    "title": "",
    "summary": "This directory is a fallback for exports[\"./dom\"] in the root framer-motion package.json."
  },
  "src/frontend/app-client/node_modules/framer-motion/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/framer-motion/LICENSE.html",
    "title": "",
    "summary": "The MIT License (MIT) Copyright (c) 2018 Framer B.V. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/framer-motion/README.html": {
    "href": "src/frontend/app-client/node_modules/framer-motion/README.html",
    "title": "Motion for React",
    "summary": "Motion for React Motion for React is an open source, production-ready library that’s designed for all creative developers. It's the only animation library with a hybrid engine, combining the power of JavaScript animations with the performance of native browser APIs. It looks like this: <motion.div animate={{ x: 0 }} /> It does all this: Springs Keyframes Layout animations Shared layout animations Gestures (drag/tap/hover) Scroll animations SVG paths Exit animations Server-side rendering Independent transforms Orchestrate animations across components CSS variables ...and a whole lot more. Get started \uD83D\uDC07 Quick start Install motion via your package manager: npm install motion Then import the motion component: import { motion } from \"motion/react\" export function Component({ isVisible }) { return <motion.div animate={{ opacity: isVisible ? 1 : 0 }} /> } \uD83D\uDC8E Contribute Want to contribute to Motion? Our contributing guide has you covered. \uD83D\uDC69\uD83C\uDFFB‍⚖️ License Motion for React is MIT licensed. ✨ Sponsors Motion is sustainable thanks to the kind support of its sponsors. Partners Framer Motion powers Framer animations, the web builder for creative pros. Design and ship your dream site. Zero code, maximum speed. Platinum Gold Silver Personal Nusu OlegWock Lambert Weller Jake LeBoeuf Han Lee"
  },
  "src/frontend/app-client/node_modules/fresh/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/fresh/HISTORY.html",
    "title": "0.5.2 / 2017-09-13",
    "summary": "0.5.2 / 2017-09-13 Fix regression matching multiple ETags in If-None-Match perf: improve If-None-Match token parsing 0.5.1 / 2017-09-11 Fix handling of modified headers with invalid dates perf: improve ETag match loop 0.5.0 / 2017-02-21 Fix incorrect result when If-None-Match has both * and ETags Fix weak ETag matching to match spec perf: delay reading header values until needed perf: skip checking modified time if ETag check failed perf: skip parsing If-None-Match when no ETag header perf: use Date.parse instead of new Date 0.4.0 / 2017-02-05 Fix false detection of no-cache request directive perf: enable strict mode perf: hoist regular expressions perf: remove duplicate conditional perf: remove unnecessary boolean coercions 0.3.0 / 2015-05-12 Add weak ETag matching support 0.2.4 / 2014-09-07 Support Node.js 0.6 0.2.3 / 2014-09-07 Move repository to jshttp 0.2.2 / 2014-02-19 Revert \"Fix for blank page on Safari reload\" 0.2.1 / 2014-01-29 Fix for blank page on Safari reload 0.2.0 / 2013-08-11 Return stale for Cache-Control: no-cache 0.1.0 / 2012-06-15 Add If-None-Match: * support 0.0.1 / 2012-06-10 Initial release"
  },
  "src/frontend/app-client/node_modules/fresh/README.html": {
    "href": "src/frontend/app-client/node_modules/fresh/README.html",
    "title": "fresh",
    "summary": "fresh HTTP response freshness testing Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install fresh API var fresh = require('fresh') fresh(reqHeaders, resHeaders) Check freshness of the response using request and response headers. When the response is still \"fresh\" in the client's cache true is returned, otherwise false is returned to indicate that the client cache is now stale and the full response should be sent. When a client sends the Cache-Control: no-cache request header to indicate an end-to-end reload request, this module will return false to make handling these requests transparent. Known Issues This module is designed to only follow the HTTP specifications, not to work-around all kinda of client bugs (especially since this module typically does not recieve enough information to understand what the client actually is). There is a known issue that in certain versions of Safari, Safari will incorrectly make a request that allows this module to validate freshness of the resource even when Safari does not have a representation of the resource in the cache. The module jumanji can be used in an Express application to work-around this issue and also provides links to further reading on this Safari bug. Example API usage var reqHeaders = { 'if-none-match': '\"foo\"' } var resHeaders = { 'etag': '\"bar\"' } fresh(reqHeaders, resHeaders) // => false var reqHeaders = { 'if-none-match': '\"foo\"' } var resHeaders = { 'etag': '\"foo\"' } fresh(reqHeaders, resHeaders) // => true Using with Node.js http server var fresh = require('fresh') var http = require('http') var server = http.createServer(function (req, res) { // perform server logic // ... including adding ETag / Last-Modified response headers if (isFresh(req, res)) { // client has a fresh copy of resource res.statusCode = 304 res.end() return } // send the resource res.statusCode = 200 res.end('hello, world!') }) function isFresh (req, res) { return fresh(req.headers, { 'etag': res.getHeader('ETag'), 'last-modified': res.getHeader('Last-Modified') }) } server.listen(3000) License MIT"
  },
  "src/frontend/app-client/node_modules/fs-extra/README.html": {
    "href": "src/frontend/app-client/node_modules/fs-extra/README.html",
    "title": "Node.js: fs-extra",
    "summary": "Node.js: fs-extra fs-extra adds file system methods that aren't included in the native fs module and adds promise support to the fs methods. It also uses graceful-fs to prevent EMFILE errors. It should be a drop in replacement for fs. Why? I got tired of including mkdirp, rimraf, and ncp in most of my projects. Installation npm install fs-extra Usage fs-extra is a drop in replacement for native fs. All methods in fs are attached to fs-extra. All fs methods return promises if the callback isn't passed. You don't ever need to include the original fs module again: const fs = require('fs') // this is no longer necessary you can now do this: const fs = require('fs-extra') or if you prefer to make it clear that you're using fs-extra and not fs, you may want to name your fs variable fse like so: const fse = require('fs-extra') you can also keep both, but it's redundant: const fs = require('fs') const fse = require('fs-extra') Sync vs Async vs Async/Await Most methods are async by default. All async methods will return a promise if the callback isn't passed. Sync methods on the other hand will throw if an error occurs. Also Async/Await will throw an error if one occurs. Example: const fs = require('fs-extra') // Async with promises: fs.copy('/tmp/myfile', '/tmp/mynewfile') .then(() => console.log('success!')) .catch(err => console.error(err)) // Async with callbacks: fs.copy('/tmp/myfile', '/tmp/mynewfile', err => { if (err) return console.error(err) console.log('success!') }) // Sync: try { fs.copySync('/tmp/myfile', '/tmp/mynewfile') console.log('success!') } catch (err) { console.error(err) } // Async/Await: async function copyFiles () { try { await fs.copy('/tmp/myfile', '/tmp/mynewfile') console.log('success!') } catch (err) { console.error(err) } } copyFiles() Methods Async copy emptyDir ensureFile ensureDir ensureLink ensureSymlink mkdirp mkdirs move outputFile outputJson pathExists readJson remove writeJson Sync copySync emptyDirSync ensureFileSync ensureDirSync ensureLinkSync ensureSymlinkSync mkdirpSync mkdirsSync moveSync outputFileSync outputJsonSync pathExistsSync readJsonSync removeSync writeJsonSync NOTE: You can still use the native Node.js methods. They are promisified and copied over to fs-extra. See notes on fs.read(), fs.write(), & fs.writev() What happened to walk() and walkSync()? They were removed from fs-extra in v2.0.0. If you need the functionality, walk and walkSync are available as separate packages, klaw and klaw-sync. Third Party CLI fse-cli allows you to run fs-extra from a console or from npm scripts. TypeScript If you like TypeScript, you can use fs-extra with it: https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/fs-extra File / Directory Watching If you want to watch for changes to files or directories, then you should use chokidar. Obtain Filesystem (Devices, Partitions) Information fs-filesystem allows you to read the state of the filesystem of the host on which it is run. It returns information about both the devices and the partitions (volumes) of the system. Misc. fs-extra-debug - Send your fs-extra calls to debug. mfs - Monitor your fs-extra calls. Hacking on fs-extra Wanna hack on fs-extra? Great! Your help is needed! fs-extra is one of the most depended upon Node.js packages. This project uses JavaScript Standard Style - if the name or style choices bother you, you're gonna have to get over it :) If standard is good enough for npm, it's good enough for fs-extra. What's needed? First, take a look at existing issues. Those are probably going to be where the priority lies. More tests for edge cases. Specifically on different platforms. There can never be enough tests. Improve test coverage. Note: If you make any big changes, you should definitely file an issue for discussion first. Running the Test Suite fs-extra contains hundreds of tests. npm run lint: runs the linter (standard) npm run unit: runs the unit tests npm test: runs both the linter and the tests Windows If you run the tests on the Windows and receive a lot of symbolic link EPERM permission errors, it's because on Windows you need elevated privilege to create symbolic links. You can add this to your Windows's account by following the instructions here: http://superuser.com/questions/104845/permission-to-make-symbolic-links-in-windows-7 However, I didn't have much luck doing this. Since I develop on Mac OS X, I use VMWare Fusion for Windows testing. I create a shared folder that I map to a drive on Windows. I open the Node.js command prompt and run as Administrator. I then map the network drive running the following command: net use z: \"\\\\vmware-host\\Shared Folders\" I can then navigate to my fs-extra directory and run the tests. Naming I put a lot of thought into the naming of these functions. Inspired by @coolaj86's request. So he deserves much of the credit for raising the issue. See discussion(s) here: https://github.com/jprichardson/node-fs-extra/issues/2 https://github.com/flatiron/utile/issues/11 https://github.com/ryanmcgrath/wrench-js/issues/29 https://github.com/substack/node-mkdirp/issues/17 First, I believe that in as many cases as possible, the Node.js naming schemes should be chosen. However, there are problems with the Node.js own naming schemes. For example, fs.readFile() and fs.readdir(): the F is capitalized in File and the d is not capitalized in dir. Perhaps a bit pedantic, but they should still be consistent. Also, Node.js has chosen a lot of POSIX naming schemes, which I believe is great. See: fs.mkdir(), fs.rmdir(), fs.chown(), etc. We have a dilemma though. How do you consistently name methods that perform the following POSIX commands: cp, cp -r, mkdir -p, and rm -rf? My perspective: when in doubt, err on the side of simplicity. A directory is just a hierarchical grouping of directories and files. Consider that for a moment. So when you want to copy it or remove it, in most cases you'll want to copy or remove all of its contents. When you want to create a directory, if the directory that it's suppose to be contained in does not exist, then in most cases you'll want to create that too. So, if you want to remove a file or a directory regardless of whether it has contents, just call fs.remove(path). If you want to copy a file or a directory whether it has contents, just call fs.copy(source, destination). If you want to create a directory regardless of whether its parent directories exist, just call fs.mkdirs(path) or fs.mkdirp(path). Credit fs-extra wouldn't be possible without using the modules from the following authors: Isaac Shlueter Charlie McConnel James Halliday Andrew Kelley License Licensed under MIT Copyright (c) 2011-2017 JP Richardson"
  },
  "src/frontend/app-client/node_modules/function-bind/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/function-bind/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.1.2 - 2023-10-12 Merged Point to the correct file #16 Commits [Tests] migrate tests to Github Actions 4f8b57c [Tests] remove jscs 90eb2ed [meta] update .gitignore 53fcdc3 [Tests] up to node v11.10, v10.15, v9.11, v8.15, v6.16, v4.9; use nvm install-latest-npm; run audit script in tests 1fe8f6e [meta] add auto-changelog 1921fcb [Robustness] remove runtime dependency on all builtins except .apply f743e61 Docs: enable badges; update wording 503cb12 [readme] update badges 290c5db [Tests] switch to nyc for coverage ea360ba [Dev Deps] update eslint, @ljharb/eslint-config, tape cae5e9e [meta] add funding field; create FUNDING.yml c9f4274 [Tests] fix eslint errors from #15 f69aaa2 [actions] fix permissions 99a0cd9 [meta] use npmignore to autogenerate an npmignore file f03b524 [Dev Deps] update @ljharb/eslint‑config, eslint, tape 7af9300 [Dev Deps] update eslint, @ljharb/eslint-config, covert, tape 64a9127 [Tests] use aud instead of npm audit e75069c [Dev Deps] update @ljharb/eslint-config, aud, tape d03555c [meta] add safe-publish-latest 9c8f809 [Dev Deps] update @ljharb/eslint-config, tape baf6893 [meta] create SECURITY.md 4db1779 [Tests] add npm run audit c8b38ec Revert \"Point to the correct file\" 05cdf0f v1.1.1 - 2017-08-28 Commits [Tests] up to node v8; newer npm breaks on older node; fix scripts 817f7d2 [Dev Deps] update eslint, jscs, tape, @ljharb/eslint-config 854288b [Dev Deps] update tape, jscs, eslint, @ljharb/eslint-config 83e639f Only apps should have lockfiles 5ed97f5 Use a SPDX-compliant “license” field. 5feefea v1.1.0 - 2016-02-14 Commits Update eslint, tape; use my personal shared eslint config 9c9062a Add npm run eslint dd96c56 [New] return the native bind when available. 82186e0 [Dev Deps] update tape, jscs, eslint, @ljharb/eslint-config a3dd767 Update eslint 3dae2f7 Update tape, covert, jscs a181eee [Tests] up to node v5.6, v4.3 964929a Test up to io.js v2.1 2be7310 Update tape, jscs, eslint, @ljharb/eslint-config 45f3d68 [Dev Deps] update tape, jscs 6e1340d [Tests] up to io.js v3.3, node v4.1 d9bad2b Update eslint 935590c [Dev Deps] update jscs, eslint, @ljharb/eslint-config 8c9a1ef Test on io.js v2.2 9a3a38c Run travis-ci tests on iojs and node v0.12; speed up builds; allow 0.8 failures. 69afc26 [Dev Deps] Update tape, eslint 36c1be0 Update tape, jscs 98d8303 Update jscs 9633a4e Update tape, jscs c80ef0f Test up to io.js v3.0 7e2c853 Test on io.js v2.4 5a199a2 Test on io.js v2.3 a511b88 Fixing a typo from 822b4e1938db02dc9584aa434fd3a45cb20caf43 732d6b6 Update jscs da52a48 Lock covert to v1.0.0. d6150fd v1.0.2 - 2014-10-04 v1.0.1 - 2014-10-03 Merged make CI build faster #3 Commits Using my standard jscs.json d8ee94c Adding npm run lint 7571ab7 Using consistent indentation e91a1b1 Updating jscs 7e17892 Using consistent quotes c50b57f Adding keywords cb94631 Directly export a function expression instead of using a declaration, and relying on hoisting. 5a33c5f Naming npm URL and badge in README; use SVG 2aef8fc Naming deps URLs in README 04228d7 Naming travis-ci URLs in README; using SVG 62c810c Make sure functions are invoked correctly (also passing coverage tests) 2b289b4 Removing the strict mode pragmas; they make tests fail. 1aa701d Adding myself as a contributor 85fd57b Adding strict mode pragmas 915b08e Adding devDeps URLs to README 4ccc731 Fixing the description. a7a472c Using a function expression instead of a function declaration. b5d3e4e Updating tape f086be6 Updating jscs 5f9bdb3 Updating jscs 9b409ba Run coverage as part of tests. 8e1b6d4 Run linter as part of tests c1ca83f Updating covert 701e837 v1.0.0 - 2014-08-09 Commits Make sure old and unstable nodes don't fail Travis 27adca3 Fixing an issue when the bound function is called as a constructor in ES3. e20122d Adding npm run coverage a2e29c4 Updating tape b741168 Upgrading tape 63631a0 Updating tape 363cb46 v0.2.0 - 2014-03-23 Commits Updating test coverage to match es5-shim. aa94d44 initial 942ee07 Setting the bound function's length properly. 079f46a Ensuring that some older browsers will throw when given a regex. 36ac55b Removing npm scripts that don't have dependencies 9d2be60 Updating tape 297a4ac Skipping length tests for now. d9891ea don't take my tea dccd930"
  },
  "src/frontend/app-client/node_modules/function-bind/README.html": {
    "href": "src/frontend/app-client/node_modules/function-bind/README.html",
    "title": "function-bind",
    "summary": "function-bind Implementation of function.prototype.bind Old versions of phantomjs, Internet Explorer < 9, and node < 0.6 don't support Function.prototype.bind. Example Function.prototype.bind = require(\"function-bind\") Installation npm install function-bind Contributors Raynos MIT Licenced"
  },
  "src/frontend/app-client/node_modules/gensync/README.html": {
    "href": "src/frontend/app-client/node_modules/gensync/README.html",
    "title": "gensync",
    "summary": "gensync This module allows for developers to write common code that can share implementation details, hiding whether an underlying request happens synchronously or asynchronously. This is in contrast with many current Node APIs which explicitly implement the same API twice, once with calls to synchronous functions, and once with asynchronous functions. Take for example fs.readFile and fs.readFileSync, if you're writing an API that loads a file and then performs a synchronous operation on the data, it can be frustrating to maintain two parallel functions. Example const fs = require(\"fs\"); const gensync = require(\"gensync\"); const readFile = gensync({ sync: fs.readFileSync, errback: fs.readFile, }); const myOperation = gensync(function* (filename) { const code = yield* readFile(filename, \"utf8\"); return \"// some custom prefix\\n\" + code; }); // Load and add the prefix synchronously: const result = myOperation.sync(\"./some-file.js\"); // Load and add the prefix asynchronously with promises: myOperation.async(\"./some-file.js\").then(result => { }); // Load and add the prefix asynchronously with promises: myOperation.errback(\"./some-file.js\", (err, result) => { }); This could even be exposed as your official API by doing // Using the common 'Sync' suffix for sync functions, and 'Async' suffix for // promise-returning versions. exports.myOperationSync = myOperation.sync; exports.myOperationAsync = myOperation.async; exports.myOperation = myOperation.errback; or potentially expose one of the async versions as the default, with a .sync property on the function to expose the synchronous version. module.exports = myOperation.errback; module.exports.sync = myOperation.sync; API gensync(generatorFnOrOptions) Returns a function that can be \"await\"-ed in another gensync generator function, or executed via .sync(...args) - Returns the computed value, or throws. .async(...args) - Returns a promise for the computed value. .errback(...args, (err, result) => {}) - Calls the callback with the computed value, or error. Passed a generator Wraps the generator to populate the .sync/.async/.errback helpers above to allow for evaluation of the generator for the final value. Example const readFile = function* () { return 42; }; const readFileAndMore = gensync(function* (){ const val = yield* readFile(); return 42 + val; }); // In general cases const code = readFileAndMore.sync(\"./file.js\", \"utf8\"); readFileAndMore.async(\"./file.js\", \"utf8\").then(code => {}) readFileAndMore.errback(\"./file.js\", \"utf8\", (err, code) => {}); // In a generator being called indirectly with .sync/.async/.errback const code = yield* readFileAndMore(\"./file.js\", \"utf8\"); Passed an options object opts.sync Example: (...args) => 4 A function that will be called when .sync() is called on the gensync() result, or when the result is passed to yield* in another generator that is being run synchronously. Also called for .async() calls if no async handlers are provided. opts.async Example: async (...args) => 4 A function that will be called when .async() or .errback() is called on the gensync() result, or when the result is passed to yield* in another generator that is being run asynchronously. opts.errback Example: (...args, cb) => cb(null, 4) A function that will be called when .async() or .errback() is called on the gensync() result, or when the result is passed to yield* in another generator that is being run asynchronously. This option allows for simpler compatibility with many existing Node APIs, and also avoids introducing the extra even loop turns that promises introduce to access the result value. opts.name Example: \"readFile\" A string name to apply to the returned function. If no value is provided, the name of errback/async/sync functions will be used, with any Sync or Async suffix stripped off. If the callback is simply named with ES6 inference (same name as the options property), the name is ignored. opts.arity Example: 4 A number for the length to set on the returned function. If no value is provided, the length will be carried over from the sync function's length value. Example const readFile = gensync({ sync: fs.readFileSync, errback: fs.readFile, }); const code = readFile.sync(\"./file.js\", \"utf8\"); readFile.async(\"./file.js\", \"utf8\").then(code => {}) readFile.errback(\"./file.js\", \"utf8\", (err, code) => {}); gensync.all(iterable) Promise.all-like combinator that works with an iterable of generator objects that could be passed to yield* within a gensync generator. Example const loadFiles = gensync(function* () { return yield* gensync.all([ readFile(\"./one.js\"), readFile(\"./two.js\"), readFile(\"./three.js\"), ]); }); gensync.race(iterable) Promise.race-like combinator that works with an iterable of generator objects that could be passed to yield* within a gensync generator. Example const loadFiles = gensync(function* () { return yield* gensync.race([ readFile(\"./one.js\"), readFile(\"./two.js\"), readFile(\"./three.js\"), ]); });"
  },
  "src/frontend/app-client/node_modules/get-intrinsic/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/get-intrinsic/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.3.0 - 2025-02-22 Commits [Dev Deps] update es-abstract, es-value-fixtures, for-each, object-inspect 9b61553 [Deps] update call-bind-apply-helpers, es-object-atoms, get-proto a341fee [New] add Float16Array de22116 v1.2.7 - 2025-01-02 Commits [Refactor] use get-proto directly 00ab955 [Deps] update math-intrinsics c716cdd [Dev Deps] update call-bound, es-abstract dc648a6 v1.2.6 - 2024-12-11 Commits [Refactor] use math-intrinsics 841be86 [Refactor] use es-object-atoms 42057df [Deps] update call-bind-apply-helpers 45afa24 [Dev Deps] update call-bound 9cba9c6 v1.2.5 - 2024-12-06 Commits [actions] split out node 10-20, and 20+ 6e2b9dd [Refactor] use dunder-proto and call-bind-apply-helpers instead of has-proto c095d17 [Refactor] use gopd 9841d5b [Dev Deps] update @ljharb/eslint-config, auto-changelog, es-abstract, es-value-fixtures, gopd, mock-property, object-inspect, tape 2d07e01 [Deps] update gopd, has-proto, has-symbols, hasown 974d8bf [Dev Deps] update call-bind, es-abstract, tape df9dde1 [Refactor] cache es-define-property as well 43ef543 [Deps] update has-proto, has-symbols, hasown ad4949d [Tests] use call-bound directly ad5c406 [Deps] update has-proto, hasown 45414ca [Tests] replace aud with npm audit 18d3509 [Deps] update es-define-property aadaa3b [Dev Deps] add missing peer dep c296a16 v1.2.4 - 2024-02-05 Commits [Refactor] use all 7 <+ ES6 Errors from es-errors bcac811 v1.2.3 - 2024-02-03 Commits [Refactor] use es-errors, so things that only need those do not need get-intrinsic f11db9c [Dev Deps] update aud, es-abstract, mock-property, npmignore b7ac7d1 [meta] simplify exports faa0cc6 [meta] add missing engines.node 774dd0b [Dev Deps] update tape 5828e8e [Robustness] use null objects for lookups eb9a11f [meta] add sideEffects flag 89bcc7a v1.2.2 - 2023-10-20 Commits [Dev Deps] update @ljharb/eslint-config, aud, call-bind, es-abstract, mock-property, object-inspect, tape f51bcf2 [Refactor] use hasown instead of has 18d14b7 [Deps] update function-bind 6e109c8 v1.2.1 - 2023-05-13 Commits [Fix] avoid a crash in envs without __proto__ 7bad8d0 [Dev Deps] update es-abstract c60e6b7 v1.2.0 - 2023-01-19 Commits [actions] update checkout action ca6b12f [Dev Deps] update @ljharb/eslint-config, es-abstract, object-inspect, tape 41a3727 [Fix] ensure Error.prototype is undeniable c511e97 [Dev Deps] update aud, es-abstract, tape 1bef8a8 [Dev Deps] update aud, es-abstract 0d41f16 [New] add BigInt64Array and BigUint64Array a6cca25 [Tests] use gopd ecf7722 v1.1.3 - 2022-09-12 Commits [Dev Deps] update es-abstract, es-value-fixtures, tape 07ff291 [Fix] properly check for % signs 50ac176 v1.1.2 - 2022-06-08 Fixed [Fix] properly validate against extra % signs #16 Commits [actions] reuse common workflows 0972547 [meta] use npmignore to autogenerate an npmignore file 5ba0b51 [actions] use node/install instead of node/run; use codecov action c364492 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, es-abstract, object-inspect, tape dc04dad [Dev Deps] update eslint, @ljharb/eslint-config, es-abstract, object-inspect, safe-publish-latest, tape 1c14059 [Tests] use mock-property b396ef0 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, object-inspect, tape c2c758d [Dev Deps] update eslint, @ljharb/eslint-config, aud, es-abstract, es-value-fixtures, object-inspect, tape 29e3c09 [actions] update codecov uploader 8cbc141 [Dev Deps] update @ljharb/eslint-config, es-abstract, es-value-fixtures, object-inspect, tape 10b6f5c [readme] add github actions/codecov badges 4e25400 [Tests] use for-each instead of foreach c05b957 [Dev Deps] update es-abstract 29b05ae [meta] use prepublishOnly script for npm 7+ 95c285d [Deps] update has-symbols 593cb4f [readme] fix repo URLs 1c8305b [Deps] update has-symbols c7138b6 [Dev Deps] remove unused has-bigints bd63aff v1.1.1 - 2021-02-03 Fixed [meta] export ./package.json #9 Commits [readme] flesh out the readme; use evalmd d12f12c [eslint] set up proper globals config 5a8c098 [Dev Deps] update eslint 7b9a5c0 v1.1.0 - 2021-01-25 Fixed [Refactor] delay Function eval until syntax-derived values are requested #3 Commits [Tests] migrate tests to Github Actions 2ab762b [meta] do not publish github action workflow files 5e7108e [Tests] add some coverage 01ac7a8 [Dev Deps] update eslint, @ljharb/eslint-config, call-bind, es-abstract, tape; add call-bind 911b672 [Refactor] rearrange evalled constructors a bit 7e7e4bf [meta] add Automatic Rebase and Require Allow Edits workflows 0199968 v1.0.2 - 2020-12-17 Commits [Fix] Throw for non‑existent intrinsics 68f873b [Fix] Throw for non‑existent segments in the intrinsic path 8325dee [Dev Deps] update eslint, @ljharb/eslint-config, aud, has-bigints, object-inspect 0c227a7 [meta] do not lint coverage output 70d2419 v1.0.1 - 2020-10-30 Commits [Tests] gather coverage data on every job d1d280d [Fix] add missing dependencies 5031771 [Tests] use es-value-fixtures af48765 v1.0.0 - 2020-10-29 Commits Implementation bbce57c Tests 17b4f0d Initial commit 3153294 npm init fb326c4 [meta] add Automatic Rebase and Require Allow Edits workflows 48862fb [meta] add auto-changelog 5f28ad0 [meta] add \"funding\"; create FUNDING.yml c2bbdde [Tests] add npm run lint 0a84b98 Only apps should have lockfiles 9586c75"
  },
  "src/frontend/app-client/node_modules/get-intrinsic/README.html": {
    "href": "src/frontend/app-client/node_modules/get-intrinsic/README.html",
    "title": "get-intrinsic",
    "summary": "get-intrinsic Get and robustly cache all JS language-level intrinsics at first require time. See the syntax described in the JS spec for reference. Example var GetIntrinsic = require('get-intrinsic'); var assert = require('assert'); // static methods assert.equal(GetIntrinsic('%Math.pow%'), Math.pow); assert.equal(Math.pow(2, 3), 8); assert.equal(GetIntrinsic('%Math.pow%')(2, 3), 8); delete Math.pow; assert.equal(GetIntrinsic('%Math.pow%')(2, 3), 8); // instance methods var arr = [1]; assert.equal(GetIntrinsic('%Array.prototype.push%'), Array.prototype.push); assert.deepEqual(arr, [1]); arr.push(2); assert.deepEqual(arr, [1, 2]); GetIntrinsic('%Array.prototype.push%').call(arr, 3); assert.deepEqual(arr, [1, 2, 3]); delete Array.prototype.push; GetIntrinsic('%Array.prototype.push%').call(arr, 4); assert.deepEqual(arr, [1, 2, 3, 4]); // missing features delete JSON.parse; // to simulate a real intrinsic that is missing in the environment assert.throws(() => GetIntrinsic('%JSON.parse%')); assert.equal(undefined, GetIntrinsic('%JSON.parse%', true)); Tests Simply clone the repo, npm install, and run npm test Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report."
  },
  "src/frontend/app-client/node_modules/get-nonce/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/get-nonce/CHANGELOG.html",
    "title": "1.0.0 (2020-04-16)",
    "summary": "1.0.0 (2020-04-16)"
  },
  "src/frontend/app-client/node_modules/get-nonce/README.html": {
    "href": "src/frontend/app-client/node_modules/get-nonce/README.html",
    "title": "get-nonce",
    "summary": "get-nonce just returns a nonce (number used once). No batteries included in those 46 bytes of this library. ✅ build in webpack support via __webpack_nonce__ API getNonce(): string|undefined - returns the current nonce setNonce(newValue) - set's nonce value Why? Why we need a library to access __webpack_nonce__? Abstractions! \"I\", as a library author, don't want to \"predict\" the platform \"you\" going to use. \"I\", as well, want an easier way to test and control nonce value. Like - nonce is supported out of the box only by webpack, what you are going to do? This is why this \"man-in-the-middle\" was created. Yep, think about left-pad :) Webpack https://webpack.js.org/guides/csp/ To activate the feature set a webpack_nonce variable needs to be included in your entry script. __webpack_nonce__ = uuid(); // for example Without webpack __webpack_nonce__ is actually just a global variable, which makes it actually bundler independent, however \"other bundlers\" are able to replicate it only setting it as a global variable (as here in tests) which violates a \"secure\" nature of nonce. get-nonce is not global. Used in react-style-singleton <- react-remove-scroll <- react-focus-on Inspiration this issue styled-components Licence MIT"
  },
  "src/frontend/app-client/node_modules/get-port/readme.html": {
    "href": "src/frontend/app-client/node_modules/get-port/readme.html",
    "title": "get-port",
    "summary": "get-port Get an available TCP port Install $ npm install get-port Usage const getPort = require('get-port'); (async () => { console.log(await getPort()); //=> 51402 })(); Pass in a preferred port: (async () => { console.log(await getPort({port: 3000})); // Will use 3000 if available, otherwise fall back to a random port })(); Pass in an array of preferred ports: (async () => { console.log(await getPort({port: [3000, 3001, 3002]})); // Will use any element in the preferred ports array if available, otherwise fall back to a random port })(); Use the makeRange() helper in case you need a port in a certain range: (async () => { console.log(await getPort({port: getPort.makeRange(3000, 3100)})); // Will use any port from 3000 to 3100, otherwise fall back to a random port })(); API getPort(options?) Returns a Promise for a port number. options Type: object port Type: number | Iterable<number> A preferred port or an iterable of preferred ports to use. host Type: string The host on which port resolution should be performed. Can be either an IPv4 or IPv6 address. getPort.makeRange(from, to) Make a range of ports from...to. Returns an Iterable for ports in the given range. from Type: number First port of the range. Must be in the range 1024...65535. to Type: number Last port of the range. Must be in the range 1024...65535 and must be greater than from. Beware There is a very tiny chance of a race condition if another process starts using the same port number as you in between the time you get the port number and you actually start using it. Race conditions in the same process are mitigated against by using a lightweight locking mechanism where a port will be held for a minimum of 15 seconds and a maximum of 30 seconds before being released again. Related get-port-cli - CLI for this module Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "src/frontend/app-client/node_modules/get-proto/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/get-proto/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.1 - 2025-01-02 Commits [Fix] for the Object.getPrototypeOf window, throw for non-objects 7fe6508 v1.0.0 - 2025-01-01 Commits Initial implementation, tests, readme, types 5c70775 Initial commit 7c65c2a npm init 0b8cf82 Only apps should have lockfiles a6d1bff"
  },
  "src/frontend/app-client/node_modules/get-proto/README.html": {
    "href": "src/frontend/app-client/node_modules/get-proto/README.html",
    "title": "get-proto",
    "summary": "get-proto Robustly get the [[Prototype]] of an object. Uses the best available method. Getting started npm install --save get-proto Usage/Examples const assert = require('assert'); const getProto = require('get-proto'); const a = { a: 1, b: 2, [Symbol.toStringTag]: 'foo' }; const b = { c: 3, __proto__: a }; assert.equal(getProto(b), a); assert.equal(getProto(a), Object.prototype); assert.equal(getProto({ __proto__: null }), null); Tests Clone the repo, npm install, and run npm test"
  },
  "src/frontend/app-client/node_modules/glob/README.html": {
    "href": "src/frontend/app-client/node_modules/glob/README.html",
    "title": "Glob",
    "summary": "Glob Match files using the patterns the shell uses. The most correct and second fastest glob implementation in JavaScript. (See Comparison to Other JavaScript Glob Implementations at the bottom of this readme.) Usage Install with npm npm i glob Note the npm package name is not node-glob that's a different thing that was abandoned years ago. Just glob. // load using import import { glob, globSync, globStream, globStreamSync, Glob } from 'glob' // or using commonjs, that's fine, too const { glob, globSync, globStream, globStreamSync, Glob, } = require('glob') // the main glob() and globSync() resolve/return array of filenames // all js files, but don't look in node_modules const jsfiles = await glob('**/*.js', { ignore: 'node_modules/**' }) // pass in a signal to cancel the glob walk const stopAfter100ms = await glob('**/*.css', { signal: AbortSignal.timeout(100), }) // multiple patterns supported as well const images = await glob(['css/*.{png,jpeg}', 'public/*.{png,jpeg}']) // but of course you can do that with the glob pattern also // the sync function is the same, just returns a string[] instead // of Promise<string[]> const imagesAlt = globSync('{css,public}/*.{png,jpeg}') // you can also stream them, this is a Minipass stream const filesStream = globStream(['**/*.dat', 'logs/**/*.log']) // construct a Glob object if you wanna do it that way, which // allows for much faster walks if you have to look in the same // folder multiple times. const g = new Glob('**/foo', {}) // glob objects are async iterators, can also do globIterate() or // g.iterate(), same deal for await (const file of g) { console.log('found a foo file:', file) } // pass a glob as the glob options to reuse its settings and caches const g2 = new Glob('**/bar', g) // sync iteration works as well for (const file of g2) { console.log('found a bar file:', file) } // you can also pass withFileTypes: true to get Path objects // these are like a Dirent, but with some more added powers // check out http://npm.im/path-scurry for more info on their API const g3 = new Glob('**/baz/**', { withFileTypes: true }) g3.stream().on('data', path => { console.log( 'got a path object', path.fullpath(), path.isDirectory(), path.readdirSync().map(e => e.name), ) }) // if you use stat:true and withFileTypes, you can sort results // by things like modified time, filter by permission mode, etc. // All Stats fields will be available in that case. Slightly // slower, though. // For example: const results = await glob('**', { stat: true, withFileTypes: true }) const timeSortedFiles = results .sort((a, b) => a.mtimeMs - b.mtimeMs) .map(path => path.fullpath()) const groupReadableFiles = results .filter(path => path.mode & 0o040) .map(path => path.fullpath()) // custom ignores can be done like this, for example by saying // you'll ignore all markdown files, and all folders named 'docs' const customIgnoreResults = await glob('**', { ignore: { ignored: p => /\\.md$/.test(p.name), childrenIgnored: p => p.isNamed('docs'), }, }) // another fun use case, only return files with the same name as // their parent folder, plus either `.ts` or `.js` const folderNamedModules = await glob('**/*.{ts,js}', { ignore: { ignored: p => { const pp = p.parent return !(p.isNamed(pp.name + '.ts') || p.isNamed(pp.name + '.js')) }, }, }) // find all files edited in the last hour, to do this, we ignore // all of them that are more than an hour old const newFiles = await glob('**', { // need stat so we have mtime stat: true, // only want the files, not the dirs nodir: true, ignore: { ignored: p => { return new Date() - p.mtime > 60 * 60 * 1000 }, // could add similar childrenIgnored here as well, but // directory mtime is inconsistent across platforms, so // probably better not to, unless you know the system // tracks this reliably. }, }) Note Glob patterns should always use / as a path separator, even on Windows systems, as \\ is used to escape glob characters. If you wish to use \\ as a path separator instead of using it as an escape character on Windows platforms, you may set windowsPathsNoEscape:true in the options. In this mode, special glob characters cannot be escaped, making it impossible to match a literal * ? and so on in filenames. Command Line Interface $ glob -h Usage: glob [options] [<pattern> [<pattern> ...]] Expand the positional glob expression arguments into any matching file system paths found. -c<command> --cmd=<command> Run the command provided, passing the glob expression matches as arguments. -A --all By default, the glob cli command will not expand any arguments that are an exact match to a file on disk. This prevents double-expanding, in case the shell expands an argument whose filename is a glob expression. For example, if 'app/*.ts' would match 'app/[id].ts', then on Windows powershell or cmd.exe, 'glob app/*.ts' will expand to 'app/[id].ts', as expected. However, in posix shells such as bash or zsh, the shell will first expand 'app/*.ts' to a list of filenames. Then glob will look for a file matching 'app/[id].ts' (ie, 'app/i.ts' or 'app/d.ts'), which is unexpected. Setting '--all' prevents this behavior, causing glob to treat ALL patterns as glob expressions to be expanded, even if they are an exact match to a file on disk. When setting this option, be sure to enquote arguments so that the shell will not expand them prior to passing them to the glob command process. -a --absolute Expand to absolute paths -d --dot-relative Prepend './' on relative matches -m --mark Append a / on any directories matched -x --posix Always resolve to posix style paths, using '/' as the directory separator, even on Windows. Drive letter absolute matches on Windows will be expanded to their full resolved UNC maths, eg instead of 'C:\\foo\\bar', it will expand to '//?/C:/foo/bar'. -f --follow Follow symlinked directories when expanding '**' -R --realpath Call 'fs.realpath' on all of the results. In the case of an entry that cannot be resolved, the entry is omitted. This incurs a slight performance penalty, of course, because of the added system calls. -s --stat Call 'fs.lstat' on all entries, whether required or not to determine if it's a valid match. -b --match-base Perform a basename-only match if the pattern does not contain any slash characters. That is, '*.js' would be treated as equivalent to '**/*.js', matching js files in all directories. --dot Allow patterns to match files/directories that start with '.', even if the pattern does not start with '.' --nobrace Do not expand {...} patterns --nocase Perform a case-insensitive match. This defaults to 'true' on macOS and Windows platforms, and false on all others. Note: 'nocase' should only be explicitly set when it is known that the filesystem's case sensitivity differs from the platform default. If set 'true' on case-insensitive file systems, then the walk may return more or less results than expected. --nodir Do not match directories, only files. Note: to *only* match directories, append a '/' at the end of the pattern. --noext Do not expand extglob patterns, such as '+(a|b)' --noglobstar Do not expand '**' against multiple path portions. Ie, treat it as a normal '*' instead. --windows-path-no-escape Use '\\' as a path separator *only*, and *never* as an escape character. If set, all '\\' characters are replaced with '/' in the pattern. -D<n> --max-depth=<n> Maximum depth to traverse from the current working directory -C<cwd> --cwd=<cwd> Current working directory to execute/match in -r<root> --root=<root> A string path resolved against the 'cwd', which is used as the starting point for absolute patterns that start with '/' (but not drive letters or UNC paths on Windows). Note that this *doesn't* necessarily limit the walk to the 'root' directory, and doesn't affect the cwd starting point for non-absolute patterns. A pattern containing '..' will still be able to traverse out of the root directory, if it is not an actual root directory on the filesystem, and any non-absolute patterns will still be matched in the 'cwd'. To start absolute and non-absolute patterns in the same path, you can use '--root=' to set it to the empty string. However, be aware that on Windows systems, a pattern like 'x:/*' or '//host/share/*' will *always* start in the 'x:/' or '//host/share/' directory, regardless of the --root setting. --platform=<platform> Defaults to the value of 'process.platform' if available, or 'linux' if not. Setting --platform=win32 on non-Windows systems may cause strange behavior! -i<ignore> --ignore=<ignore> Glob patterns to ignore Can be set multiple times -v --debug Output a huge amount of noisy debug information about patterns as they are parsed and used to match files. -h --help Show this usage information glob(pattern: string | string[], options?: GlobOptions) => Promise<string[] | Path[]> Perform an asynchronous glob search for the pattern(s) specified. Returns Path objects if the withFileTypes option is set to true. See below for full options field desciptions. globSync(pattern: string | string[], options?: GlobOptions) => string[] | Path[] Synchronous form of glob(). Alias: glob.sync() globIterate(pattern: string | string[], options?: GlobOptions) => AsyncGenerator<string> Return an async iterator for walking glob pattern matches. Alias: glob.iterate() globIterateSync(pattern: string | string[], options?: GlobOptions) => Generator<string> Return a sync iterator for walking glob pattern matches. Alias: glob.iterate.sync(), glob.sync.iterate() globStream(pattern: string | string[], options?: GlobOptions) => Minipass<string | Path> Return a stream that emits all the strings or Path objects and then emits end when completed. Alias: glob.stream() globStreamSync(pattern: string | string[], options?: GlobOptions) => Minipass<string | Path> Syncronous form of globStream(). Will read all the matches as fast as you consume them, even all in a single tick if you consume them immediately, but will still respond to backpressure if they're not consumed immediately. Alias: glob.stream.sync(), glob.sync.stream() hasMagic(pattern: string | string[], options?: GlobOptions) => boolean Returns true if the provided pattern contains any \"magic\" glob characters, given the options provided. Brace expansion is not considered \"magic\" unless the magicalBraces option is set, as brace expansion just turns one string into an array of strings. So a pattern like 'x{a,b}y' would return false, because 'xay' and 'xby' both do not contain any magic glob characters, and it's treated the same as if you had called it on ['xay', 'xby']. When magicalBraces:true is in the options, brace expansion is treated as a pattern having magic. escape(pattern: string, options?: GlobOptions) => string Escape all magic characters in a glob pattern, so that it will only ever match literal strings If the windowsPathsNoEscape option is used, then characters are escaped by wrapping in [], because a magic character wrapped in a character class can only be satisfied by that exact character. Slashes (and backslashes in windowsPathsNoEscape mode) cannot be escaped or unescaped. unescape(pattern: string, options?: GlobOptions) => string Un-escape a glob string that may contain some escaped characters. If the windowsPathsNoEscape option is used, then square-brace escapes are removed, but not backslash escapes. For example, it will turn the string '[*]' into *, but it will not turn '\\\\*' into '*', because \\ is a path separator in windowsPathsNoEscape mode. When windowsPathsNoEscape is not set, then both brace escapes and backslash escapes are removed. Slashes (and backslashes in windowsPathsNoEscape mode) cannot be escaped or unescaped. Class Glob An object that can perform glob pattern traversals. const g = new Glob(pattern: string | string[], options: GlobOptions) Options object is required. See full options descriptions below. Note that a previous Glob object can be passed as the GlobOptions to another Glob instantiation to re-use settings and caches with a new pattern. Traversal functions can be called multiple times to run the walk again. g.stream() Stream results asynchronously, g.streamSync() Stream results synchronously. g.iterate() Default async iteration function. Returns an AsyncGenerator that iterates over the results. g.iterateSync() Default sync iteration function. Returns a Generator that iterates over the results. g.walk() Returns a Promise that resolves to the results array. g.walkSync() Returns a results array. Properties All options are stored as properties on the Glob object. opts The options provided to the constructor. patterns An array of parsed immutable Pattern objects. Options Exported as GlobOptions TypeScript interface. A GlobOptions object may be provided to any of the exported methods, and must be provided to the Glob constructor. All options are optional, boolean, and false by default, unless otherwise noted. All resolved options are added to the Glob object as properties. If you are running many glob operations, you can pass a Glob object as the options argument to a subsequent operation to share the previously loaded cache. cwd String path or file:// string or URL object. The current working directory in which to search. Defaults to process.cwd(). See also: \"Windows, CWDs, Drive Letters, and UNC Paths\", below. This option may be either a string path or a file:// URL object or string. root A string path resolved against the cwd option, which is used as the starting point for absolute patterns that start with /, (but not drive letters or UNC paths on Windows). Note that this doesn't necessarily limit the walk to the root directory, and doesn't affect the cwd starting point for non-absolute patterns. A pattern containing .. will still be able to traverse out of the root directory, if it is not an actual root directory on the filesystem, and any non-absolute patterns will be matched in the cwd. For example, the pattern /../* with {root:'/some/path'} will return all files in /some, not all files in /some/path. The pattern * with {root:'/some/path'} will return all the entries in the cwd, not the entries in /some/path. To start absolute and non-absolute patterns in the same path, you can use {root:''}. However, be aware that on Windows systems, a pattern like x:/* or //host/share/* will always start in the x:/ or //host/share directory, regardless of the root setting. windowsPathsNoEscape Use \\\\ as a path separator only, and never as an escape character. If set, all \\\\ characters are replaced with / in the pattern. Note that this makes it impossible to match against paths containing literal glob pattern characters, but allows matching with patterns constructed using path.join() and path.resolve() on Windows platforms, mimicking the (buggy!) behavior of Glob v7 and before on Windows. Please use with caution, and be mindful of the caveat below about Windows paths. (For legacy reasons, this is also set if allowWindowsEscape is set to the exact value false.) dot Include .dot files in normal matches and globstar matches. Note that an explicit dot in a portion of the pattern will always match dot files. magicalBraces Treat brace expansion like {a,b} as a \"magic\" pattern. Has no effect if {@link nobrace} is set. Only has effect on the {@link hasMagic} function, no effect on glob pattern matching itself. dotRelative Prepend all relative path strings with ./ (or .\\ on Windows). Without this option, returned relative paths are \"bare\", so instead of returning './foo/bar', they are returned as 'foo/bar'. Relative patterns starting with '../' are not prepended with ./, even if this option is set. mark Add a / character to directory matches. Note that this requires additional stat calls. nobrace Do not expand {a,b} and {1..3} brace sets. noglobstar Do not match ** against multiple filenames. (Ie, treat it as a normal * instead.) noext Do not match \"extglob\" patterns such as +(a|b). nocase Perform a case-insensitive match. This defaults to true on macOS and Windows systems, and false on all others. Note nocase should only be explicitly set when it is known that the filesystem's case sensitivity differs from the platform default. If set true on case-sensitive file systems, or false on case-insensitive file systems, then the walk may return more or less results than expected. maxDepth Specify a number to limit the depth of the directory traversal to this many levels below the cwd. matchBase Perform a basename-only match if the pattern does not contain any slash characters. That is, *.js would be treated as equivalent to **/*.js, matching all js files in all directories. nodir Do not match directories, only files. (Note: to match only directories, put a / at the end of the pattern.) Note: when follow and nodir are both set, then symbolic links to directories are also omitted. stat Call lstat() on all entries, whether required or not to determine whether it's a valid match. When used with withFileTypes, this means that matches will include data such as modified time, permissions, and so on. Note that this will incur a performance cost due to the added system calls. ignore string or string[], or an object with ignore and ignoreChildren methods. If a string or string[] is provided, then this is treated as a glob pattern or array of glob patterns to exclude from matches. To ignore all children within a directory, as well as the entry itself, append '/**' to the ignore pattern. Note ignore patterns are always in dot:true mode, regardless of any other settings. If an object is provided that has ignored(path) and/or childrenIgnored(path) methods, then these methods will be called to determine whether any Path is a match or if its children should be traversed, respectively. follow Follow symlinked directories when expanding ** patterns. This can result in a lot of duplicate references in the presence of cyclic links, and make performance quite bad. By default, a ** in a pattern will follow 1 symbolic link if it is not the first item in the pattern, or none if it is the first item in the pattern, following the same behavior as Bash. Note: when follow and nodir are both set, then symbolic links to directories are also omitted. realpath Set to true to call fs.realpath on all of the results. In the case of an entry that cannot be resolved, the entry is omitted. This incurs a slight performance penalty, of course, because of the added system calls. absolute Set to true to always receive absolute paths for matched files. Set to false to always receive relative paths for matched files. By default, when this option is not set, absolute paths are returned for patterns that are absolute, and otherwise paths are returned that are relative to the cwd setting. This does not make an extra system call to get the realpath, it only does string path resolution. absolute may not be used along with withFileTypes. posix Set to true to use / as the path separator in returned results. On posix systems, this has no effect. On Windows systems, this will return / delimited path results, and absolute paths will be returned in their full resolved UNC path form, eg insted of 'C:\\\\foo\\\\bar', it will return //?/C:/foo/bar. platform Defaults to value of process.platform if available, or 'linux' if not. Setting platform:'win32' on non-Windows systems may cause strange behavior. withFileTypes Return PathScurry Path objects instead of strings. These are similar to a NodeJS Dirent object, but with additional methods and properties. withFileTypes may not be used along with absolute. signal An AbortSignal which will cancel the Glob walk when triggered. fs An override object to pass in custom filesystem methods. See PathScurry docs for what can be overridden. scurry A PathScurry object used to traverse the file system. If the nocase option is set explicitly, then any provided scurry object must match this setting. includeChildMatches boolean, default true. Do not match any children of any matches. For example, the pattern **\\/foo would match a/foo, but not a/foo/b/foo in this mode. This is especially useful for cases like \"find all node_modules folders, but not the ones in node_modules\". In order to support this, the Ignore implementation must support an add(pattern: string) method. If using the default Ignore class, then this is fine, but if this is set to false, and a custom Ignore is provided that does not have an add() method, then it will throw an error. Caveat It only ignores matches that would be a descendant of a previous match, and only if that descendant is matched after the ancestor is encountered. Since the file system walk happens in indeterminate order, it's possible that a match will already be added before its ancestor, if multiple or braced patterns are used. For example: const results = await glob( [ // likely to match first, since it's just a stat 'a/b/c/d/e/f', // this pattern is more complicated! It must to various readdir() // calls and test the results against a regular expression, and that // is certainly going to take a little bit longer. // // So, later on, it encounters a match at 'a/b/c/d/e', but it's too // late to ignore a/b/c/d/e/f, because it's already been emitted. 'a/[bdf]/?/[a-z]/*', ], { includeChildMatches: false }, ) It's best to only set this to false if you can be reasonably sure that no components of the pattern will potentially match one another's file system descendants, or if the occasional included child entry will not cause problems. Glob Primer Much more information about glob pattern expansion can be found by running man bash and searching for Pattern Matching. \"Globs\" are the patterns you type when you do stuff like ls *.js on the command line, or put build/* in a .gitignore file. Before parsing the path part patterns, braced sections are expanded into a set. Braced sections start with { and end with }, with 2 or more comma-delimited sections within. Braced sections may contain slash characters, so a{/b/c,bcd} would expand into a/b/c and abcd. The following characters have special magic meaning when used in a path portion. With the exception of **, none of these match path separators (ie, / on all platforms, and \\ on Windows). * Matches 0 or more characters in a single path portion. When alone in a path portion, it must match at least 1 character. If dot:true is not specified, then * will not match against a . character at the start of a path portion. ? Matches 1 character. If dot:true is not specified, then ? will not match against a . character at the start of a path portion. [...] Matches a range of characters, similar to a RegExp range. If the first character of the range is ! or ^ then it matches any character not in the range. If the first character is ], then it will be considered the same as \\], rather than the end of the character class. !(pattern|pattern|pattern) Matches anything that does not match any of the patterns provided. May not contain / characters. Similar to *, if alone in a path portion, then the path portion must have at least one character. ?(pattern|pattern|pattern) Matches zero or one occurrence of the patterns provided. May not contain / characters. +(pattern|pattern|pattern) Matches one or more occurrences of the patterns provided. May not contain / characters. *(a|b|c) Matches zero or more occurrences of the patterns provided. May not contain / characters. @(pattern|pat*|pat?erN) Matches exactly one of the patterns provided. May not contain / characters. ** If a \"globstar\" is alone in a path portion, then it matches zero or more directories and subdirectories searching for matches. It does not crawl symlinked directories, unless {follow:true} is passed in the options object. A pattern like a/b/** will only match a/b if it is a directory. Follows 1 symbolic link if not the first item in the pattern, or 0 if it is the first item, unless follow:true is set, in which case it follows all symbolic links. [:class:] patterns are supported by this implementation, but [=c=] and [.symbol.] style class patterns are not. Dots If a file or directory path portion has a . as the first character, then it will not match any glob pattern unless that pattern's corresponding path part also has a . as its first character. For example, the pattern a/.*/c would match the file at a/.b/c. However the pattern a/*/c would not, because * does not start with a dot character. You can make glob treat dots as normal characters by setting dot:true in the options. Basename Matching If you set matchBase:true in the options, and the pattern has no slashes in it, then it will seek for any file anywhere in the tree with a matching basename. For example, *.js would match test/simple/basic.js. Empty Sets If no matching files are found, then an empty array is returned. This differs from the shell, where the pattern itself is returned. For example: $ echo a*s*d*f a*s*d*f Comparisons to other fnmatch/glob implementations While strict compliance with the existing standards is a worthwhile goal, some discrepancies exist between node-glob and other implementations, and are intentional. The double-star character ** is supported by default, unless the noglobstar flag is set. This is supported in the manner of bsdglob and bash 5, where ** only has special significance if it is the only thing in a path part. That is, a/**/b will match a/x/y/b, but a/**b will not. Note that symlinked directories are not traversed as part of a **, though their contents may match against subsequent portions of the pattern. This prevents infinite loops and duplicates and the like. You can force glob to traverse symlinks with ** by setting {follow:true} in the options. There is no equivalent of the nonull option. A pattern that does not find any matches simply resolves to nothing. (An empty array, immediately ended stream, etc.) If brace expansion is not disabled, then it is performed before any other interpretation of the glob pattern. Thus, a pattern like +(a|{b),c)}, which would not be valid in bash or zsh, is expanded first into the set of +(a|b) and +(a|c), and those patterns are checked for validity. Since those two are valid, matching proceeds. The character class patterns [:class:] (posix standard named classes) style class patterns are supported and unicode-aware, but [=c=] (locale-specific character collation weight), and [.symbol.] (collating symbol), are not. Repeated Slashes Unlike Bash and zsh, repeated / are always coalesced into a single path separator. Comments and Negation Previously, this module let you mark a pattern as a \"comment\" if it started with a # character, or a \"negated\" pattern if it started with a ! character. These options were deprecated in version 5, and removed in version 6. To specify things that should not match, use the ignore option. Windows Please only use forward-slashes in glob expressions. Though windows uses either / or \\ as its path separator, only / characters are used by this glob implementation. You must use forward-slashes only in glob expressions. Back-slashes will always be interpreted as escape characters, not path separators. Results from absolute patterns such as /foo/* are mounted onto the root setting using path.join. On windows, this will by default result in /foo/* matching C:\\foo\\bar.txt. To automatically coerce all \\ characters to / in pattern strings, thus making it impossible to escape literal glob characters, you may set the windowsPathsNoEscape option to true. Windows, CWDs, Drive Letters, and UNC Paths On posix systems, when a pattern starts with /, any cwd option is ignored, and the traversal starts at /, plus any non-magic path portions specified in the pattern. On Windows systems, the behavior is similar, but the concept of an \"absolute path\" is somewhat more involved. UNC Paths A UNC path may be used as the start of a pattern on Windows platforms. For example, a pattern like: //?/x:/* will return all file entries in the root of the x: drive. A pattern like //ComputerName/Share/* will return all files in the associated share. UNC path roots are always compared case insensitively. Drive Letters A pattern starting with a drive letter, like c:/*, will search in that drive, regardless of any cwd option provided. If the pattern starts with /, and is not a UNC path, and there is an explicit cwd option set with a drive letter, then the drive letter in the cwd is used as the root of the directory traversal. For example, glob('/tmp', { cwd: 'c:/any/thing' }) will return ['c:/tmp'] as the result. If an explicit cwd option is not provided, and the pattern starts with /, then the traversal will run on the root of the drive provided as the cwd option. (That is, it is the result of path.resolve('/').) Race Conditions Glob searching, by its very nature, is susceptible to race conditions, since it relies on directory walking. As a result, it is possible that a file that exists when glob looks for it may have been deleted or modified by the time it returns the result. By design, this implementation caches all readdir calls that it makes, in order to cut down on system overhead. However, this also makes it even more susceptible to races, especially if the cache object is reused between glob calls. Users are thus advised not to use a glob result as a guarantee of filesystem state in the face of rapid changes. For the vast majority of operations, this is never a problem. See Also: man sh man bash Pattern Matching man 3 fnmatch man 5 gitignore minimatch documentation Glob Logo Glob's logo was created by Tanya Brassie. Logo files can be found here. The logo is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. Contributing Any change to behavior (including bugfixes) must come with a test. Patches that fail tests or reduce performance will be rejected. # to run tests npm test # to re-generate test fixtures npm run test-regen # run the benchmarks npm run bench # to profile javascript npm run prof Comparison to Other JavaScript Glob Implementations tl;dr If you want glob matching that is as faithful as possible to Bash pattern expansion semantics, and as fast as possible within that constraint, use this module. If you are reasonably sure that the patterns you will encounter are relatively simple, and want the absolutely fastest glob matcher out there, use fast-glob. If you are reasonably sure that the patterns you will encounter are relatively simple, and want the convenience of automatically respecting .gitignore files, use globby. There are some other glob matcher libraries on npm, but these three are (in my opinion, as of 2023) the best. full explanation Every library reflects a set of opinions and priorities in the trade-offs it makes. Other than this library, I can personally recommend both globby and fast-glob, though they differ in their benefits and drawbacks. Both have very nice APIs and are reasonably fast. fast-glob is, as far as I am aware, the fastest glob implementation in JavaScript today. However, there are many cases where the choices that fast-glob makes in pursuit of speed mean that its results differ from the results returned by Bash and other sh-like shells, which may be surprising. In my testing, fast-glob is around 10-20% faster than this module when walking over 200k files nested 4 directories deep1. However, there are some inconsistencies with Bash matching behavior that this module does not suffer from: ** only matches files, not directories .. path portions are not handled unless they appear at the start of the pattern ./!(<pattern>) will not match any files that start with <pattern>, even if they do not match <pattern>. For example, !(9).txt will not match 9999.txt. Some brace patterns in the middle of a pattern will result in failing to find certain matches. Extglob patterns are allowed to contain / characters. Globby exhibits all of the same pattern semantics as fast-glob, (as it is a wrapper around fast-glob) and is slightly slower than node-glob (by about 10-20% in the benchmark test set, or in other words, anywhere from 20-50% slower than fast-glob). However, it adds some API conveniences that may be worth the costs. Support for .gitignore and other ignore files. Support for negated globs (ie, patterns starting with ! rather than using a separate ignore option). The priority of this module is \"correctness\" in the sense of performing a glob pattern expansion as faithfully as possible to the behavior of Bash and other sh-like shells, with as much speed as possible. Note that prior versions of node-glob are not on this list. Former versions of this module are far too slow for any cases where performance matters at all, and were designed with APIs that are extremely dated by current JavaScript standards. [1]: In the cases where this module returns results and fast-glob doesn't, it's even faster, of course. Benchmark Results First number is time, smaller is better. Second number is the count of results returned. --- pattern: '**' --- ~~ sync ~~ node fast-glob sync 0m0.598s 200364 node globby sync 0m0.765s 200364 node current globSync mjs 0m0.683s 222656 node current glob syncStream 0m0.649s 222656 ~~ async ~~ node fast-glob async 0m0.350s 200364 node globby async 0m0.509s 200364 node current glob async mjs 0m0.463s 222656 node current glob stream 0m0.411s 222656 --- pattern: '**/..' --- ~~ sync ~~ node fast-glob sync 0m0.486s 0 node globby sync 0m0.769s 200364 node current globSync mjs 0m0.564s 2242 node current glob syncStream 0m0.583s 2242 ~~ async ~~ node fast-glob async 0m0.283s 0 node globby async 0m0.512s 200364 node current glob async mjs 0m0.299s 2242 node current glob stream 0m0.312s 2242 --- pattern: './**/0/**/0/**/0/**/0/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.490s 10 node globby sync 0m0.517s 10 node current globSync mjs 0m0.540s 10 node current glob syncStream 0m0.550s 10 ~~ async ~~ node fast-glob async 0m0.290s 10 node globby async 0m0.296s 10 node current glob async mjs 0m0.278s 10 node current glob stream 0m0.302s 10 --- pattern: './**/[01]/**/[12]/**/[23]/**/[45]/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.500s 160 node globby sync 0m0.528s 160 node current globSync mjs 0m0.556s 160 node current glob syncStream 0m0.573s 160 ~~ async ~~ node fast-glob async 0m0.283s 160 node globby async 0m0.301s 160 node current glob async mjs 0m0.306s 160 node current glob stream 0m0.322s 160 --- pattern: './**/0/**/0/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.502s 5230 node globby sync 0m0.527s 5230 node current globSync mjs 0m0.544s 5230 node current glob syncStream 0m0.557s 5230 ~~ async ~~ node fast-glob async 0m0.285s 5230 node globby async 0m0.305s 5230 node current glob async mjs 0m0.304s 5230 node current glob stream 0m0.310s 5230 --- pattern: '**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.580s 200023 node globby sync 0m0.771s 200023 node current globSync mjs 0m0.685s 200023 node current glob syncStream 0m0.649s 200023 ~~ async ~~ node fast-glob async 0m0.349s 200023 node globby async 0m0.509s 200023 node current glob async mjs 0m0.427s 200023 node current glob stream 0m0.388s 200023 --- pattern: '{**/*.txt,**/?/**/*.txt,**/?/**/?/**/*.txt,**/?/**/?/**/?/**/*.txt,**/?/**/?/**/?/**/?/**/*.txt}' --- ~~ sync ~~ node fast-glob sync 0m0.589s 200023 node globby sync 0m0.771s 200023 node current globSync mjs 0m0.716s 200023 node current glob syncStream 0m0.684s 200023 ~~ async ~~ node fast-glob async 0m0.351s 200023 node globby async 0m0.518s 200023 node current glob async mjs 0m0.462s 200023 node current glob stream 0m0.468s 200023 --- pattern: '**/5555/0000/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.496s 1000 node globby sync 0m0.519s 1000 node current globSync mjs 0m0.539s 1000 node current glob syncStream 0m0.567s 1000 ~~ async ~~ node fast-glob async 0m0.285s 1000 node globby async 0m0.299s 1000 node current glob async mjs 0m0.305s 1000 node current glob stream 0m0.301s 1000 --- pattern: './**/0/**/../[01]/**/0/../**/0/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.484s 0 node globby sync 0m0.507s 0 node current globSync mjs 0m0.577s 4880 node current glob syncStream 0m0.586s 4880 ~~ async ~~ node fast-glob async 0m0.280s 0 node globby async 0m0.298s 0 node current glob async mjs 0m0.327s 4880 node current glob stream 0m0.324s 4880 --- pattern: '**/????/????/????/????/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.547s 100000 node globby sync 0m0.673s 100000 node current globSync mjs 0m0.626s 100000 node current glob syncStream 0m0.618s 100000 ~~ async ~~ node fast-glob async 0m0.315s 100000 node globby async 0m0.414s 100000 node current glob async mjs 0m0.366s 100000 node current glob stream 0m0.345s 100000 --- pattern: './{**/?{/**/?{/**/?{/**/?,,,,},,,,},,,,},,,}/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.588s 100000 node globby sync 0m0.670s 100000 node current globSync mjs 0m0.717s 200023 node current glob syncStream 0m0.687s 200023 ~~ async ~~ node fast-glob async 0m0.343s 100000 node globby async 0m0.418s 100000 node current glob async mjs 0m0.519s 200023 node current glob stream 0m0.451s 200023 --- pattern: '**/!(0|9).txt' --- ~~ sync ~~ node fast-glob sync 0m0.573s 160023 node globby sync 0m0.731s 160023 node current globSync mjs 0m0.680s 180023 node current glob syncStream 0m0.659s 180023 ~~ async ~~ node fast-glob async 0m0.345s 160023 node globby async 0m0.476s 160023 node current glob async mjs 0m0.427s 180023 node current glob stream 0m0.388s 180023 --- pattern: './{*/**/../{*/**/../{*/**/../{*/**/../{*/**,,,,},,,,},,,,},,,,},,,,}/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.483s 0 node globby sync 0m0.512s 0 node current globSync mjs 0m0.811s 200023 node current glob syncStream 0m0.773s 200023 ~~ async ~~ node fast-glob async 0m0.280s 0 node globby async 0m0.299s 0 node current glob async mjs 0m0.617s 200023 node current glob stream 0m0.568s 200023 --- pattern: './*/**/../*/**/../*/**/../*/**/../*/**/../*/**/../*/**/../*/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.485s 0 node globby sync 0m0.507s 0 node current globSync mjs 0m0.759s 200023 node current glob syncStream 0m0.740s 200023 ~~ async ~~ node fast-glob async 0m0.281s 0 node globby async 0m0.297s 0 node current glob async mjs 0m0.544s 200023 node current glob stream 0m0.464s 200023 --- pattern: './*/**/../*/**/../*/**/../*/**/../*/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.486s 0 node globby sync 0m0.513s 0 node current globSync mjs 0m0.734s 200023 node current glob syncStream 0m0.696s 200023 ~~ async ~~ node fast-glob async 0m0.286s 0 node globby async 0m0.296s 0 node current glob async mjs 0m0.506s 200023 node current glob stream 0m0.483s 200023 --- pattern: './0/**/../1/**/../2/**/../3/**/../4/**/../5/**/../6/**/../7/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.060s 0 node globby sync 0m0.074s 0 node current globSync mjs 0m0.067s 0 node current glob syncStream 0m0.066s 0 ~~ async ~~ node fast-glob async 0m0.060s 0 node globby async 0m0.075s 0 node current glob async mjs 0m0.066s 0 node current glob stream 0m0.067s 0 --- pattern: './**/?/**/?/**/?/**/?/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.568s 100000 node globby sync 0m0.651s 100000 node current globSync mjs 0m0.619s 100000 node current glob syncStream 0m0.617s 100000 ~~ async ~~ node fast-glob async 0m0.332s 100000 node globby async 0m0.409s 100000 node current glob async mjs 0m0.372s 100000 node current glob stream 0m0.351s 100000 --- pattern: '**/*/**/*/**/*/**/*/**' --- ~~ sync ~~ node fast-glob sync 0m0.603s 200113 node globby sync 0m0.798s 200113 node current globSync mjs 0m0.730s 222137 node current glob syncStream 0m0.693s 222137 ~~ async ~~ node fast-glob async 0m0.356s 200113 node globby async 0m0.525s 200113 node current glob async mjs 0m0.508s 222137 node current glob stream 0m0.455s 222137 --- pattern: './**/*/**/*/**/*/**/*/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.622s 200000 node globby sync 0m0.792s 200000 node current globSync mjs 0m0.722s 200000 node current glob syncStream 0m0.695s 200000 ~~ async ~~ node fast-glob async 0m0.369s 200000 node globby async 0m0.527s 200000 node current glob async mjs 0m0.502s 200000 node current glob stream 0m0.481s 200000 --- pattern: '**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.588s 200023 node globby sync 0m0.771s 200023 node current globSync mjs 0m0.684s 200023 node current glob syncStream 0m0.658s 200023 ~~ async ~~ node fast-glob async 0m0.352s 200023 node globby async 0m0.516s 200023 node current glob async mjs 0m0.432s 200023 node current glob stream 0m0.384s 200023 --- pattern: './**/**/**/**/**/**/**/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.589s 200023 node globby sync 0m0.766s 200023 node current globSync mjs 0m0.682s 200023 node current glob syncStream 0m0.652s 200023 ~~ async ~~ node fast-glob async 0m0.352s 200023 node globby async 0m0.523s 200023 node current glob async mjs 0m0.436s 200023 node current glob stream 0m0.380s 200023 --- pattern: '**/*/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.592s 200023 node globby sync 0m0.776s 200023 node current globSync mjs 0m0.691s 200023 node current glob syncStream 0m0.659s 200023 ~~ async ~~ node fast-glob async 0m0.357s 200023 node globby async 0m0.513s 200023 node current glob async mjs 0m0.471s 200023 node current glob stream 0m0.424s 200023 --- pattern: '**/*/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.585s 200023 node globby sync 0m0.766s 200023 node current globSync mjs 0m0.694s 200023 node current glob syncStream 0m0.664s 200023 ~~ async ~~ node fast-glob async 0m0.350s 200023 node globby async 0m0.514s 200023 node current glob async mjs 0m0.472s 200023 node current glob stream 0m0.424s 200023 --- pattern: '**/[0-9]/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.544s 100000 node globby sync 0m0.636s 100000 node current globSync mjs 0m0.626s 100000 node current glob syncStream 0m0.621s 100000 ~~ async ~~ node fast-glob async 0m0.322s 100000 node globby async 0m0.404s 100000 node current glob async mjs 0m0.360s 100000 node current glob stream 0m0.352s 100000"
  },
  "src/frontend/app-client/node_modules/globals/readme.html": {
    "href": "src/frontend/app-client/node_modules/globals/readme.html",
    "title": "globals",
    "summary": "globals Global identifiers from different JavaScript environments Extracted from JSHint and ESLint and merged. It's just a JSON file, so use it in whatever environment you like. This module no longer accepts new environments. If you need it for ESLint, just create a plugin. Install $ npm install globals Usage const globals = require('globals'); console.log(globals.browser); /* { addEventListener: false, applicationCache: false, ArrayBuffer: false, atob: false, ... } */ Each global is given a value of true or false. A value of true indicates that the variable may be overwritten. A value of false indicates that the variable should be considered read-only. This information is used by static analysis tools to flag incorrect behavior. We assume all variables should be false unless we hear otherwise. License MIT © Sindre Sorhus"
  },
  "src/frontend/app-client/node_modules/globrex/readme.html": {
    "href": "src/frontend/app-client/node_modules/globrex/readme.html",
    "title": "globrex",
    "summary": "globrex Simple but powerful glob to regular expression compiler. Install npm install globrex --save Core Features \uD83D\uDCAA extended globbing: transform advance ExtGlob features \uD83D\uDCE6 simple: no dependencies \uD83D\uDEE3️ paths: split paths into multiple RegExp segments Usage const globrex = require('globrex'); const result = globrex('p*uck') // => { regex: /^p.*uck$/, string: '^p.*uck$', segments: [ /^p.*uck$/ ] } result.regex.test('pluck'); // true API globrex(glob, options) Type: function Returns: Object Transform globs intp regular expressions. Returns object with the following properties: regex Type: RegExp JavaScript RegExp instance. Note: Read more about how to use RegExp on MDN. path This property only exists if the option filepath is true. Note: filepath is false by default path.segments Type: Array Array of RegExp instances seperated by /. This can be usable when working with file paths or urls. Example array could be: [ /^foo$/, /^bar$/, /^([^\\/]*)$/, '^baz\\\\.(md|js|txt)$' ] path.regex Type: RegExp JavaScript RegExp instance build for testign against paths. The regex have different path seperators depending on host OS. glob Type: String Glob string to transform. options.extended Type: Boolean Default: false Enable all advanced features from extglob. Matching so called \"extended\" globs pattern like single character matching, matching ranges of characters, group matching, etc. Note: Interprets [a-d] as [abcd]. To match a literal -, include it as first or last character. options.globstar Type: Boolean Default: false When globstar is false globs like '/foo/*' are transformed to the following '^\\/foo\\/.*$' which will match any string beginning with '/foo/'. When the globstar option is true, the same '/foo/*' glob is transformed to '^\\/foo\\/[^/]*$' which will match any string beginning with '/foo/' that does not have a '/' to the right of it. '/foo/*' will match: '/foo/bar', '/foo/bar.txt' but not '/foo/bar/baz' or '/foo/bar/baz.txt'. Note: When globstar is true, '/foo/**' is equivelant to '/foo/*' when globstar is false. options.strict Type: Boolean Default: false Be forgiving about mutiple slashes, like /// and make everything after the first / optional. This is how bash glob works. options.flags Type: String Default: '' RegExp flags (e.g. 'i' ) to pass to the RegExp constructor. options.filepath Type: Boolean Default: false Parse input strings as it was a file path for special path related features. This feature only makes sense if the input is a POSIX path like /foo/bar/hello.js or URLs. When true the returned object will have an additional path object. segment: Array containing a RegExp object for each path segment. regex: OS specific file path RegExp. Path seperator used is based on the operating system. globstar: Regex string used to test for globstars. Note: Please only use forward-slashes in file path glob expressions Though windows uses either / or \\ as its path separator, only / characters are used by this glob implementation. You must use forward-slashes only in glob expressions. Back-slashes will always be interpreted as escape characters, not path separators. References Learn more about advanced globbing here mywiki.wooledge.org/glob linuxjournal License MIT © Terkel Gjervig"
  },
  "src/frontend/app-client/node_modules/gopd/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/gopd/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.2.0 - 2024-12-03 Commits [New] add gOPD entry point; remove get-intrinsic 5b61232 v1.1.0 - 2024-11-29 Commits [New] add types f585e39 [Dev Deps] update @ljharb/eslint-config, auto-changelog, tape 0b8e4fd [Dev Deps] update aud, npmignore, tape 48378b2 [Dev Deps] update @ljharb/eslint-config, aud, tape 78099ee [Tests] replace aud with npm audit 4e0d0ac [meta] add missing engines.node 1443316 [Deps] update get-intrinsic eee5f51 [Deps] update get-intrinsic 550c378 [Dev Deps] add missing peer dep 8c2ecf8 v1.0.1 - 2022-11-01 Commits [Fix] actually export gOPD instead of dP 4b624bf v1.0.0 - 2022-11-01 Commits Initial implementation, tests, readme 0911e01 Initial commit b84e33f [actions] add reusable workflows 12ae28a npm init 280118b [meta] add auto-changelog bb78de5 [meta] create FUNDING.yml; add funding in package.json 11c22e6 [meta] use npmignore to autogenerate an npmignore file 4f4537a Only apps should have lockfiles c567022"
  },
  "src/frontend/app-client/node_modules/gopd/README.html": {
    "href": "src/frontend/app-client/node_modules/gopd/README.html",
    "title": "gopd",
    "summary": "gopd Object.getOwnPropertyDescriptor, but accounts for IE's broken implementation. Usage var gOPD = require('gopd'); var assert = require('assert'); if (gOPD) { assert.equal(typeof gOPD, 'function', 'descriptors supported'); // use gOPD like Object.getOwnPropertyDescriptor here } else { assert.ok(!gOPD, 'descriptors not supported'); }"
  },
  "src/frontend/app-client/node_modules/graceful-fs/README.html": {
    "href": "src/frontend/app-client/node_modules/graceful-fs/README.html",
    "title": "graceful-fs",
    "summary": "graceful-fs graceful-fs functions as a drop-in replacement for the fs module, making various improvements. The improvements are meant to normalize behavior across different platforms and environments, and to make filesystem access more resilient to errors. Improvements over fs module Queues up open and readdir calls, and retries them once something closes if there is an EMFILE error from too many file descriptors. fixes lchmod for Node versions prior to 0.6.2. implements fs.lutimes if possible. Otherwise it becomes a noop. ignores EINVAL and EPERM errors in chown, fchown or lchown if the user isn't root. makes lchmod and lchown become noops, if not available. retries reading a file if read results in EAGAIN error. On Windows, it retries renaming a file for up to one second if EACCESS or EPERM error occurs, likely because antivirus software has locked the directory. USAGE // use just like fs var fs = require('graceful-fs') // now go and do stuff with it... fs.readFile('some-file-or-whatever', (err, data) => { // Do stuff here. }) Sync methods This module cannot intercept or handle EMFILE or ENFILE errors from sync methods. If you use sync methods which open file descriptors then you are responsible for dealing with any errors. This is a known limitation, not a bug. Global Patching If you want to patch the global fs module (or any other fs-like module) you can do this: // Make sure to read the caveat below. var realFs = require('fs') var gracefulFs = require('graceful-fs') gracefulFs.gracefulify(realFs) This should only ever be done at the top-level application layer, in order to delay on EMFILE errors from any fs-using dependencies. You should not do this in a library, because it can cause unexpected delays in other parts of the program. Changes This module is fairly stable at this point, and used by a lot of things. That being said, because it implements a subtle behavior change in a core part of the node API, even modest changes can be extremely breaking, and the versioning is thus biased towards bumping the major when in doubt. The main change between major versions has been switching between providing a fully-patched fs module vs monkey-patching the node core builtin, and the approach by which a non-monkey-patched fs was created. The goal is to trade EMFILE errors for slower fs operations. So, if you try to open a zillion files, rather than crashing, open operations will be queued up and wait for something else to close. There are advantages to each approach. Monkey-patching the fs means that no EMFILE errors can possibly occur anywhere in your application, because everything is using the same core fs module, which is patched. However, it can also obviously cause undesirable side-effects, especially if the module is loaded multiple times. Implementing a separate-but-identical patched fs module is more surgical (and doesn't run the risk of patching multiple times), but also imposes the challenge of keeping in sync with the core module. The current approach loads the fs module, and then creates a lookalike object that has all the same methods, except a few that are patched. It is safe to use in all versions of Node from 0.8 through 7.0. v4 Do not monkey-patch the fs module. This module may now be used as a drop-in dep, and users can opt into monkey-patching the fs builtin if their app requires it. v3 Monkey-patch fs, because the eval approach no longer works on recent node. fixed possible type-error throw if rename fails on windows verify that we never get EMFILE errors Ignore ENOSYS from chmod/chown clarify that graceful-fs must be used as a drop-in v2.1.0 Use eval rather than monkey-patching fs. readdir: Always sort the results win32: requeue a file if error has an OK status v2.0 A return to monkey patching wrap process.cwd v1.1 wrap readFile Wrap fs.writeFile. readdir protection Don't clobber the fs builtin Handle fs.read EAGAIN errors by trying again Expose the curOpen counter No-op lchown/lchmod if not implemented fs.rename patch only for win32 Patch fs.rename to handle AV software on Windows Close #4 Chown should not fail on einval or eperm if non-root Fix isaacs/fstream#1 Only wrap fs one time Fix #3 Start at 1024 max files, then back off on EMFILE lutimes that doens't blow up on Linux A full on-rewrite using a queue instead of just swallowing the EMFILE error Wrap Read/Write streams as well 1.0 Update engines for node 0.6 Be lstat-graceful on Windows first"
  },
  "src/frontend/app-client/node_modules/has-symbols/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/has-symbols/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.1.0 - 2024-12-02 Commits [actions] update workflows 548c0bf [actions] further shard; update action deps bec56bb [meta] use npmignore to autogenerate an npmignore file ac81032 [New] add types 6469cbf [actions] update rebase action to use reusable workflow 9c9d4d0 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape adb5887 [Dev Deps] update @ljharb/eslint-config, aud, tape 13ec198 [Dev Deps] update auto-changelog, core-js, tape 941be52 [Tests] replace aud with npm audit 74f49e9 [Dev Deps] update npmignore 9c0ac04 [Dev Deps] add missing peer dep 52337a5 v1.0.3 - 2022-03-01 Commits [actions] use node/install instead of node/run; use codecov action 518b28f [meta] add bugs and homepage fields; reorder package.json c480b13 [actions] reuse common workflows 01d0ee0 [actions] update codecov uploader 6424ebe [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape dfa7e7f [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape 0c8d436 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 9026554 [readme] add actions and codecov badges eaa9682 [Dev Deps] update eslint, tape bc7a3ba [Dev Deps] update eslint, auto-changelog 0ace00a [meta] use prepublishOnly script for npm 7+ 093f72b [Tests] test on all 16 minors 9b80d3d v1.0.2 - 2021-02-27 Fixed [Fix] use a universal way to get the original Symbol #11 Commits [Tests] migrate tests to Github Actions 90ae798 [meta] do not publish github action workflow files 29e60a1 [Tests] run nyc on all tests 8476b91 [readme] fix repo URLs, remove defunct badges 126288e [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, core-js, get-own-property-symbols d84bdfa [Tests] fix linting errors 0df3070 [actions] add \"Allow Edits\" workflow 1e6bc29 [Dev Deps] update eslint, @ljharb/eslint-config, tape 36cea2a [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 1278338 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 1493254 [Dev Deps] update eslint, @ljharb/eslint-config, core-js b090bf2 [actions] switch Automatic Rebase workflow to pull_request_target event 4addb7a [Dev Deps] update auto-changelog, tape 81d0baf [Dev Deps] update auto-changelog; add aud 1a4e561 [readme] remove unused testling URLs 3000941 [Tests] only audit prod deps 692e974 [Dev Deps] update @ljharb/eslint-config 51c946c v1.0.1 - 2019-11-16 Commits [Tests] use shared travis-ci configs ce396c9 [Tests] up to node v12.4, v11.15, v10.15, v9.11, v8.15, v7.10, v6.17, v4.9; use nvm install-latest-npm 0690732 [meta] add auto-changelog 2163d0b [Dev Deps] update eslint, @ljharb/eslint-config, core-js, safe-publish-latest, tape 8e0951f [actions] add automatic rebasing / merge commit blocking b09cdb7 [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, core-js, get-own-property-symbols, tape 1dd42cd [meta] create FUNDING.yml aa57a17 Only apps should have lockfiles a2d8bea [Tests] use npx aud instead of nsp or npm audit with hoops 9e96cb7 [meta] add funding field a0b32cf [Dev Deps] update safe-publish-latest cb9f0a5 v1.0.0 - 2016-09-19 Commits Tests. ecb6eb9 package.json 88a337c Initial commit 42e1e55 Initial implementation. 33f5cc6 read me 01f1170"
  },
  "src/frontend/app-client/node_modules/has-symbols/README.html": {
    "href": "src/frontend/app-client/node_modules/has-symbols/README.html",
    "title": "has-symbols",
    "summary": "has-symbols Determine if the JS environment has Symbol support. Supports spec, or shams. Example var hasSymbols = require('has-symbols'); hasSymbols() === true; // if the environment has native Symbol support. Not polyfillable, not forgeable. var hasSymbolsKinda = require('has-symbols/shams'); hasSymbolsKinda() === true; // if the environment has a Symbol sham that mostly follows the spec. Supported Symbol shams get-own-property-symbols npm | github core-js npm | github Tests Simply clone the repo, npm install, and run npm test"
  },
  "src/frontend/app-client/node_modules/hasown/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/hasown/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v2.0.2 - 2024-03-10 Commits [types] use shared config 68e9d4d [actions] remove redundant finisher; use reusable workflow 241a68e [Tests] increase coverage 4125c0d [Tests] skip npm ls in old node due to TS 01b9282 [types] improve predicate type d340f85 [Dev Deps] update tape 70089fc [Tests] use @arethetypeswrong/cli 50b272c v2.0.1 - 2024-02-10 Commits [types] use a handwritten d.ts file; fix exported type 012b989 [Dev Deps] update @types/function-bind, @types/mock-property, @types/tape, aud, mock-property, npmignore, tape, typescript 977a56f [meta] add sideEffects flag 3a60b7b v2.0.0 - 2023-10-19 Commits revamped implementation, tests, readme 72bf8b3 [meta] revamp package.json 079775f Only apps should have lockfiles 6640e23 v1.0.1 - 2023-10-10 Commits Initial commit 8dbfde6"
  },
  "src/frontend/app-client/node_modules/hasown/README.html": {
    "href": "src/frontend/app-client/node_modules/hasown/README.html",
    "title": "hasown",
    "summary": "hasown A robust, ES3 compatible, \"has own property\" predicate. Example const assert = require('assert'); const hasOwn = require('hasown'); assert.equal(hasOwn({}, 'toString'), false); assert.equal(hasOwn([], 'length'), true); assert.equal(hasOwn({ a: 42 }, 'a'), true); Tests Simply clone the repo, npm install, and run npm test"
  },
  "src/frontend/app-client/node_modules/hoist-non-react-statics/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/hoist-non-react-statics/CHANGELOG.html",
    "title": "3.3.2 (January 22, 2020)",
    "summary": "3.3.2 (January 22, 2020) Fix React.memo for v16.12+ (#93) 3.3.1 (November 14, 2019) Fix for UMD bundle (#85) Tooling changes (#83, #84, #87) 3.3.0 (January 23, 2019) Prevent hoisting of React.memo statics (#73) 3.2.1 (December 3, 2018) Fixed defaultProps, displayName and propTypes being hoisted from React.forwardRef to React.forwardRef. (#71) 3.2.0 (November 26, 2018) Added support for getDerivedStateFromError. (#68) Added support for React versions less than 0.14. (#69) 3.1.0 (October 30, 2018) Added support for contextType. (#62) Reduced bundle size. (e89c7a6) Removed TypeScript definitions. (#61) 3.0.1 (July 28, 2018) Fixed prop-types warnings. (e0846fe) 3.0.0 (July 27, 2018) Dropped support for React versions less than 0.14. (#55) Added support for React.forwardRef components. (#55)"
  },
  "src/frontend/app-client/node_modules/hoist-non-react-statics/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/hoist-non-react-statics/LICENSE.html",
    "title": "Software License Agreement (BSD License)",
    "summary": "Software License Agreement (BSD License) Copyright (c) 2015, Yahoo! Inc. All rights reserved. Redistribution and use of this software in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of Yahoo! Inc. nor the names of YUI's contributors may be used to endorse or promote products derived from this software without specific prior written permission of Yahoo! Inc. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  "src/frontend/app-client/node_modules/hoist-non-react-statics/README.html": {
    "href": "src/frontend/app-client/node_modules/hoist-non-react-statics/README.html",
    "title": "hoist-non-react-statics",
    "summary": "hoist-non-react-statics Copies non-react specific statics from a child component to a parent component. Similar to Object.assign, but with React static keywords blacklisted from being overridden. $ npm install --save hoist-non-react-statics Usage import hoistNonReactStatics from 'hoist-non-react-statics'; hoistNonReactStatics(targetComponent, sourceComponent); If you have specific statics that you don't want to be hoisted, you can also pass a third parameter to exclude them: hoistNonReactStatics(targetComponent, sourceComponent, { myStatic: true, myOtherStatic: true }); What does this module do? See this explanation from the React docs. Compatible React Versions Please use latest 3.x. Versions prior to 3.x will not support ForwardRefs. hoist-non-react-statics Version Compatible React Version 3.x 0.13-16.x With ForwardRef Support 2.x 0.13-16.x Without ForwardRef Support 1.x 0.13-16.2 Browser Support This package uses Object.defineProperty which has a broken implementation in IE8. In order to use this package in IE8, you will need a polyfill that fixes this method. License This software is free to use under the Yahoo Inc. BSD license. See the LICENSE file for license text and copyright information. Third-party open source code used are listed in our package.json file."
  },
  "src/frontend/app-client/node_modules/hosted-git-info/node_modules/lru-cache/README.html": {
    "href": "src/frontend/app-client/node_modules/hosted-git-info/node_modules/lru-cache/README.html",
    "title": "lru-cache",
    "summary": "lru-cache A cache object that deletes the least-recently-used items. Specify a max number of the most recently used items that you want to keep, and this cache will keep that many of the most recently accessed items. This is not primarily a TTL cache, and does not make strong TTL guarantees. There is no preemptive pruning of expired items by default, but you may set a TTL on the cache or on a single set. If you do so, it will treat expired items as missing, and delete them when fetched. If you are more interested in TTL caching than LRU caching, check out @isaacs/ttlcache. As of version 7, this is one of the most performant LRU implementations available in JavaScript, and supports a wide diversity of use cases. However, note that using some of the features will necessarily impact performance, by causing the cache to have to do more work. See the \"Performance\" section below. Installation npm install lru-cache --save Usage // hybrid module, either works import LRUCache from 'lru-cache' // or: const LRUCache = require('lru-cache') // At least one of 'max', 'ttl', or 'maxSize' is required, to prevent // unsafe unbounded storage. // // In most cases, it's best to specify a max for performance, so all // the required memory allocation is done up-front. // // All the other options are optional, see the sections below for // documentation on what each one does. Most of them can be // overridden for specific items in get()/set() const options = { max: 500, // for use with tracking overall storage size maxSize: 5000, sizeCalculation: (value, key) => { return 1 }, // for use when you need to clean up something when objects // are evicted from the cache dispose: (value, key) => { freeFromMemoryOrWhatever(value) }, // how long to live in ms ttl: 1000 * 60 * 5, // return stale items before removing from cache? allowStale: false, updateAgeOnGet: false, updateAgeOnHas: false, // async method to use for cache.fetch(), for // stale-while-revalidate type of behavior fetchMethod: async (key, staleValue, { options, signal }) => {}, } const cache = new LRUCache(options) cache.set('key', 'value') cache.get('key') // \"value\" // non-string keys ARE fully supported // but note that it must be THE SAME object, not // just a JSON-equivalent object. var someObject = { a: 1 } cache.set(someObject, 'a value') // Object keys are not toString()-ed cache.set('[object Object]', 'a different value') assert.equal(cache.get(someObject), 'a value') // A similar object with same keys/values won't work, // because it's a different object identity assert.equal(cache.get({ a: 1 }), undefined) cache.clear() // empty the cache If you put more stuff in it, then items will fall out. Options max The maximum number of items that remain in the cache (assuming no TTL pruning or explicit deletions). Note that fewer items may be stored if size calculation is used, and maxSize is exceeded. This must be a positive finite intger. At least one of max, maxSize, or TTL is required. This must be a positive integer if set. It is strongly recommended to set a max to prevent unbounded growth of the cache. See \"Storage Bounds Safety\" below. maxSize Set to a positive integer to track the sizes of items added to the cache, and automatically evict items in order to stay below this size. Note that this may result in fewer than max items being stored. Attempting to add an item to the cache whose calculated size is greater that this amount will be a no-op. The item will not be cached, and no other items will be evicted. Optional, must be a positive integer if provided. Sets maxEntrySize to the same value, unless a different value is provided for maxEntrySize. At least one of max, maxSize, or TTL is required. This must be a positive integer if set. Even if size tracking is enabled, it is strongly recommended to set a max to prevent unbounded growth of the cache. See \"Storage Bounds Safety\" below. maxEntrySize Set to a positive integer to track the sizes of items added to the cache, and prevent caching any item over a given size. Attempting to add an item whose calculated size is greater than this amount will be a no-op. The item will not be cached, and no other items will be evicted. Optional, must be a positive integer if provided. Defaults to the value of maxSize if provided. sizeCalculation Function used to calculate the size of stored items. If you're storing strings or buffers, then you probably want to do something like n => n.length. The item is passed as the first argument, and the key is passed as the second argument. This may be overridden by passing an options object to cache.set(). Requires maxSize to be set. If the size (or return value of sizeCalculation) for a given entry is greater than maxEntrySize, then the item will not be added to the cache. Deprecated alias: length fetchMethod Function that is used to make background asynchronous fetches. Called with fetchMethod(key, staleValue, { signal, options, context }). May return a Promise. If fetchMethod is not provided, then cache.fetch(key) is equivalent to Promise.resolve(cache.get(key)). The signal object is an AbortSignal if that's available in the global object, otherwise it's a pretty close polyfill. If at any time, signal.aborted is set to true, or if the signal.onabort method is called, or if it emits an 'abort' event which you can listen to with addEventListener, then that means that the fetch should be abandoned. This may be passed along to async functions aware of AbortController/AbortSignal behavior. The fetchMethod should only return undefined or a Promise resolving to undefined if the AbortController signaled an abort event. In all other cases, it should return or resolve to a value suitable for adding to the cache. The options object is a union of the options that may be provided to set() and get(). If they are modified, then that will result in modifying the settings to cache.set() when the value is resolved, and in the case of noDeleteOnFetchRejection and allowStaleOnFetchRejection, the handling of fetchMethod failures. For example, a DNS cache may update the TTL based on the value returned from a remote DNS server by changing options.ttl in the fetchMethod. fetchContext Arbitrary data that can be passed to the fetchMethod as the context option. Note that this will only be relevant when the cache.fetch() call needs to call fetchMethod(). Thus, any data which will meaningfully vary the fetch response needs to be present in the key. This is primarily intended for including x-request-id headers and the like for debugging purposes, which do not affect the fetchMethod() response. noDeleteOnFetchRejection If a fetchMethod throws an error or returns a rejected promise, then by default, any existing stale value will be removed from the cache. If noDeleteOnFetchRejection is set to true, then this behavior is suppressed, and the stale value remains in the cache in the case of a rejected fetchMethod. This is important in cases where a fetchMethod is only called as a background update while the stale value is returned, when allowStale is used. This is implicitly in effect when allowStaleOnFetchRejection is set. This may be set in calls to fetch(), or defaulted on the constructor, or overridden by modifying the options object in the fetchMethod. allowStaleOnFetchRejection Set to true to return a stale value from the cache when a fetchMethod throws an error or returns a rejected Promise. If a fetchMethod fails, and there is no stale value available, the fetch() will resolve to undefined. Ie, all fetchMethod errors are suppressed. Implies noDeleteOnFetchRejection. This may be set in calls to fetch(), or defaulted on the constructor, or overridden by modifying the options object in the fetchMethod. allowStaleOnFetchAbort Set to true to return a stale value from the cache when the AbortSignal passed to the fetchMethod dispatches an 'abort' event, whether user-triggered, or due to internal cache behavior. Unless ignoreFetchAbort is also set, the underlying fetchMethod will still be considered canceled, and its return value will be ignored and not cached. ignoreFetchAbort Set to true to ignore the abort event emitted by the AbortSignal object passed to fetchMethod, and still cache the resulting resolution value, as long as it is not undefined. When used on its own, this means aborted fetch() calls are not immediately resolved or rejected when they are aborted, and instead take the full time to await. When used with allowStaleOnFetchAbort, aborted fetch() calls will resolve immediately to their stale cached value or undefined, and will continue to process and eventually update the cache when they resolve, as long as the resulting value is not undefined, thus supporting a \"return stale on timeout while refreshing\" mechanism by passing AbortSignal.timeout(n) as the signal. For example: const c = new LRUCache({ ttl: 100, ignoreFetchAbort: true, allowStaleOnFetchAbort: true, fetchMethod: async (key, oldValue, { signal }) => { // note: do NOT pass the signal to fetch()! // let's say this fetch can take a long time. const res = await fetch(`https://slow-backend-server/${key}`) return await res.json() }, }) // this will return the stale value after 100ms, while still // updating in the background for next time. const val = await c.fetch('key', { signal: AbortSignal.timeout(100) }) Note: regardless of this setting, an abort event is still emitted on the AbortSignal object, so may result in invalid results when passed to other underlying APIs that use AbortSignals. This may be overridden on the fetch() call or in the fetchMethod itself. dispose Function that is called on items when they are dropped from the cache, as this.dispose(value, key, reason). This can be handy if you want to close file descriptors or do other cleanup tasks when items are no longer stored in the cache. NOTE: It is called before the item has been fully removed from the cache, so if you want to put it right back in, you need to wait until the next tick. If you try to add it back in during the dispose() function call, it will break things in subtle and weird ways. Unlike several other options, this may not be overridden by passing an option to set(), for performance reasons. If disposal functions may vary between cache entries, then the entire list must be scanned on every cache swap, even if no disposal function is in use. The reason will be one of the following strings, corresponding to the reason for the item's deletion: evict Item was evicted to make space for a new addition set Item was overwritten by a new value delete Item was removed by explicit cache.delete(key) or by calling cache.clear(), which deletes everything. The dispose() method is not called for canceled calls to fetchMethod(). If you wish to handle evictions, overwrites, and deletes of in-flight asynchronous fetches, you must use the AbortSignal provided. Optional, must be a function. disposeAfter The same as dispose, but called after the entry is completely removed and the cache is once again in a clean state. It is safe to add an item right back into the cache at this point. However, note that it is very easy to inadvertently create infinite recursion in this way. The disposeAfter() method is not called for canceled calls to fetchMethod(). If you wish to handle evictions, overwrites, and deletes of in-flight asynchronous fetches, you must use the AbortSignal provided. noDisposeOnSet Set to true to suppress calling the dispose() function if the entry key is still accessible within the cache. This may be overridden by passing an options object to cache.set(). Boolean, default false. Only relevant if dispose or disposeAfter options are set. ttl Max time to live for items before they are considered stale. Note that stale items are NOT preemptively removed by default, and MAY live in the cache, contributing to its LRU max, long after they have expired. Also, as this cache is optimized for LRU/MRU operations, some of the staleness/TTL checks will reduce performance. This is not primarily a TTL cache, and does not make strong TTL guarantees. There is no pre-emptive pruning of expired items, but you may set a TTL on the cache, and it will treat expired items as missing when they are fetched, and delete them. Optional, but must be a positive integer in ms if specified. This may be overridden by passing an options object to cache.set(). At least one of max, maxSize, or TTL is required. This must be a positive integer if set. Even if ttl tracking is enabled, it is strongly recommended to set a max to prevent unbounded growth of the cache. See \"Storage Bounds Safety\" below. If ttl tracking is enabled, and max and maxSize are not set, and ttlAutopurge is not set, then a warning will be emitted cautioning about the potential for unbounded memory consumption. Deprecated alias: maxAge noUpdateTTL Boolean flag to tell the cache to not update the TTL when setting a new value for an existing key (ie, when updating a value rather than inserting a new value). Note that the TTL value is always set (if provided) when adding a new entry into the cache. This may be passed as an option to cache.set(). Boolean, default false. ttlResolution Minimum amount of time in ms in which to check for staleness. Defaults to 1, which means that the current time is checked at most once per millisecond. Set to 0 to check the current time every time staleness is tested. Note that setting this to a higher value will improve performance somewhat while using ttl tracking, albeit at the expense of keeping stale items around a bit longer than intended. ttlAutopurge Preemptively remove stale items from the cache. Note that this may significantly degrade performance, especially if the cache is storing a large number of items. It is almost always best to just leave the stale items in the cache, and let them fall out as new items are added. Note that this means that allowStale is a bit pointless, as stale items will be deleted almost as soon as they expire. Use with caution! Boolean, default false allowStale By default, if you set ttl, it'll only delete stale items from the cache when you get(key). That is, it's not preemptively pruning items. If you set allowStale:true, it'll return the stale value as well as deleting it. If you don't set this, then it'll return undefined when you try to get a stale entry. Note that when a stale entry is fetched, even if it is returned due to allowStale being set, it is removed from the cache immediately. You can immediately put it back in the cache if you wish, thus resetting the TTL. This may be overridden by passing an options object to cache.get(). The cache.has() method will always return false for stale items. Boolean, default false, only relevant if ttl is set. Deprecated alias: stale noDeleteOnStaleGet When using time-expiring entries with ttl, by default stale items will be removed from the cache when the key is accessed with cache.get(). Setting noDeleteOnStaleGet to true will cause stale items to remain in the cache, until they are explicitly deleted with cache.delete(key), or retrieved with noDeleteOnStaleGet set to false. This may be overridden by passing an options object to cache.get(). Boolean, default false, only relevant if ttl is set. updateAgeOnGet When using time-expiring entries with ttl, setting this to true will make each item's age reset to 0 whenever it is retrieved from cache with get(), causing it to not expire. (It can still fall out of cache based on recency of use, of course.) This may be overridden by passing an options object to cache.get(). Boolean, default false, only relevant if ttl is set. updateAgeOnHas When using time-expiring entries with ttl, setting this to true will make each item's age reset to 0 whenever its presence in the cache is checked with has(), causing it to not expire. (It can still fall out of cache based on recency of use, of course.) This may be overridden by passing an options object to cache.has(). Boolean, default false, only relevant if ttl is set. API new LRUCache(options) Create a new LRUCache. All options are documented above, and are on the cache as public members. cache.max, cache.maxSize, cache.allowStale, cache.noDisposeOnSet, cache.sizeCalculation, cache.dispose, cache.maxSize, cache.ttl, cache.updateAgeOnGet, cache.updateAgeOnHas All option names are exposed as public members on the cache object. These are intended for read access only. Changing them during program operation can cause undefined behavior. cache.size The total number of items held in the cache at the current moment. cache.calculatedSize The total size of items in cache when using size tracking. set(key, value, [{ size, sizeCalculation, ttl, noDisposeOnSet, start, status }]) Add a value to the cache. Optional options object may contain ttl and sizeCalculation as described above, which default to the settings on the cache object. If start is provided, then that will set the effective start time for the TTL calculation. Note that this must be a previous value of performance.now() if supported, or a previous value of Date.now() if not. Options object may also include size, which will prevent calling the sizeCalculation function and just use the specified number if it is a positive integer, and noDisposeOnSet which will prevent calling a dispose function in the case of overwrites. If the size (or return value of sizeCalculation) for a given entry is greater than maxEntrySize, then the item will not be added to the cache. Will update the recency of the entry. Returns the cache object. For the usage of the status option, see Status Tracking below. get(key, { updateAgeOnGet, allowStale, status } = {}) => value Return a value from the cache. Will update the recency of the cache entry found. If the key is not found, get() will return undefined. This can be confusing when setting values specifically to undefined, as in cache.set(key, undefined). Use cache.has() to determine whether a key is present in the cache at all. For the usage of the status option, see Status Tracking below. async fetch(key, options = {}) => Promise The following options are supported: updateAgeOnGet allowStale size sizeCalculation ttl noDisposeOnSet forceRefresh status - See Status Tracking below. signal - AbortSignal can be used to cancel the fetch(). Note that the signal option provided to the fetchMethod is a different object, because it must also respond to internal cache state changes, but aborting this signal will abort the one passed to fetchMethod as well. fetchContext - sets the context option passed to the underlying fetchMethod. If the value is in the cache and not stale, then the returned Promise resolves to the value. If not in the cache, or beyond its TTL staleness, then fetchMethod(key, staleValue, { options, signal, context }) is called, and the value returned will be added to the cache once resolved. If called with allowStale, and an asynchronous fetch is currently in progress to reload a stale value, then the former stale value will be returned. If called with forceRefresh, then the cached item will be re-fetched, even if it is not stale. However, if allowStale is set, then the old value will still be returned. This is useful in cases where you want to force a reload of a cached value. If a background fetch is already in progress, then forceRefresh has no effect. Multiple fetches for the same key will only call fetchMethod a single time, and all will be resolved when the value is resolved, even if different options are used. If fetchMethod is not specified, then this is effectively an alias for Promise.resolve(cache.get(key)). When the fetch method resolves to a value, if the fetch has not been aborted due to deletion, eviction, or being overwritten, then it is added to the cache using the options provided. If the key is evicted or deleted before the fetchMethod resolves, then the AbortSignal passed to the fetchMethod will receive an abort event, and the promise returned by fetch() will reject with the reason for the abort. If a signal is passed to the fetch() call, then aborting the signal will abort the fetch and cause the fetch() promise to reject with the reason provided. peek(key, { allowStale } = {}) => value Like get() but doesn't update recency or delete stale items. Returns undefined if the item is stale, unless allowStale is set either on the cache or in the options object. has(key, { updateAgeOnHas, status } = {}) => Boolean Check if a key is in the cache, without updating the recency of use. Age is updated if updateAgeOnHas is set to true in either the options or the constructor. Will return false if the item is stale, even though it is technically in the cache. The difference can be determined (if it matters) by using a status argument, and inspecting the has field. For the usage of the status option, see Status Tracking below. delete(key) Deletes a key out of the cache. Returns true if the key was deleted, false otherwise. clear() Clear the cache entirely, throwing away all values. Deprecated alias: reset() keys() Return a generator yielding the keys in the cache, in order from most recently used to least recently used. rkeys() Return a generator yielding the keys in the cache, in order from least recently used to most recently used. values() Return a generator yielding the values in the cache, in order from most recently used to least recently used. rvalues() Return a generator yielding the values in the cache, in order from least recently used to most recently used. entries() Return a generator yielding [key, value] pairs, in order from most recently used to least recently used. rentries() Return a generator yielding [key, value] pairs, in order from least recently used to most recently used. find(fn, [getOptions]) Find a value for which the supplied fn method returns a truthy value, similar to Array.find(). fn is called as fn(value, key, cache). The optional getOptions are applied to the resulting get() of the item found. dump() Return an array of [key, entry] objects which can be passed to cache.load() The start fields are calculated relative to a portable Date.now() timestamp, even if performance.now() is available. Stale entries are always included in the dump, even if allowStale is false. Note: this returns an actual array, not a generator, so it can be more easily passed around. load(entries) Reset the cache and load in the items in entries in the order listed. Note that the shape of the resulting cache may be different if the same options are not used in both caches. The start fields are assumed to be calculated relative to a portable Date.now() timestamp, even if performance.now() is available. purgeStale() Delete any stale entries. Returns true if anything was removed, false otherwise. Deprecated alias: prune getRemainingTTL(key) Return the number of ms left in the item's TTL. If item is not in cache, returns 0. Returns Infinity if item is in cache without a defined TTL. forEach(fn, [thisp]) Call the fn function with each set of fn(value, key, cache) in the LRU cache, from most recent to least recently used. Does not affect recency of use. If thisp is provided, function will be called in the this-context of the provided object. rforEach(fn, [thisp]) Same as cache.forEach(fn, thisp), but in order from least recently used to most recently used. pop() Evict the least recently used item, returning its value. Returns undefined if cache is empty. Internal Methods and Properties In order to optimize performance as much as possible, \"private\" members and methods are exposed on the object as normal properties, rather than being accessed via Symbols, private members, or closure variables. Do not use or rely on these. They will change or be removed without notice. They will cause undefined behavior if used inappropriately. There is no need or reason to ever call them directly. This documentation is here so that it is especially clear that this not \"undocumented\" because someone forgot; it is documented, and the documentation is telling you not to do it. Do not report bugs that stem from using these properties. They will be ignored. initializeTTLTracking() Set up the cache for tracking TTLs updateItemAge(index) Called when an item age is updated, by internal ID setItemTTL(index) Called when an item ttl is updated, by internal ID isStale(index) Called to check an item's staleness, by internal ID initializeSizeTracking() Set up the cache for tracking item size. Called automatically when a size is specified. removeItemSize(index) Updates the internal size calculation when an item is removed or modified, by internal ID addItemSize(index) Updates the internal size calculation when an item is added or modified, by internal ID indexes() An iterator over the non-stale internal IDs, from most recently to least recently used. rindexes() An iterator over the non-stale internal IDs, from least recently to most recently used. newIndex() Create a new internal ID, either reusing a deleted ID, evicting the least recently used ID, or walking to the end of the allotted space. evict() Evict the least recently used internal ID, returning its ID. Does not do any bounds checking. connect(p, n) Connect the p and n internal IDs in the linked list. moveToTail(index) Move the specified internal ID to the most recently used position. keyMap Map of keys to internal IDs keyList List of keys by internal ID valList List of values by internal ID sizes List of calculated sizes by internal ID ttls List of TTL values by internal ID starts List of start time values by internal ID next Array of \"next\" pointers by internal ID prev Array of \"previous\" pointers by internal ID head Internal ID of least recently used item tail Internal ID of most recently used item free Stack of deleted internal IDs Status Tracking Occasionally, it may be useful to track the internal behavior of the cache, particularly for logging, debugging, or for behavior within the fetchMethod. To do this, you can pass a status object to the get(), set(), has(), and fetch() methods. The status option should be a plain JavaScript object. The following fields will be set appropriately: interface Status<V> { /** * The status of a set() operation. * * - add: the item was not found in the cache, and was added * - update: the item was in the cache, with the same value provided * - replace: the item was in the cache, and replaced * - miss: the item was not added to the cache for some reason */ set?: 'add' | 'update' | 'replace' | 'miss' /** * the ttl stored for the item, or undefined if ttls are not used. */ ttl?: LRUMilliseconds /** * the start time for the item, or undefined if ttls are not used. */ start?: LRUMilliseconds /** * The timestamp used for TTL calculation */ now?: LRUMilliseconds /** * the remaining ttl for the item, or undefined if ttls are not used. */ remainingTTL?: LRUMilliseconds /** * The calculated size for the item, if sizes are used. */ size?: LRUSize /** * A flag indicating that the item was not stored, due to exceeding the * {@link maxEntrySize} */ maxEntrySizeExceeded?: true /** * The old value, specified in the case of `set:'update'` or * `set:'replace'` */ oldValue?: V /** * The results of a {@link has} operation * * - hit: the item was found in the cache * - stale: the item was found in the cache, but is stale * - miss: the item was not found in the cache */ has?: 'hit' | 'stale' | 'miss' /** * The status of a {@link fetch} operation. * Note that this can change as the underlying fetch() moves through * various states. * * - inflight: there is another fetch() for this key which is in process * - get: there is no fetchMethod, so {@link get} was called. * - miss: the item is not in cache, and will be fetched. * - hit: the item is in the cache, and was resolved immediately. * - stale: the item is in the cache, but stale. * - refresh: the item is in the cache, and not stale, but * {@link forceRefresh} was specified. */ fetch?: 'get' | 'inflight' | 'miss' | 'hit' | 'stale' | 'refresh' /** * The {@link fetchMethod} was called */ fetchDispatched?: true /** * The cached value was updated after a successful call to fetchMethod */ fetchUpdated?: true /** * The reason for a fetch() rejection. Either the error raised by the * {@link fetchMethod}, or the reason for an AbortSignal. */ fetchError?: Error /** * The fetch received an abort signal */ fetchAborted?: true /** * The abort signal received was ignored, and the fetch was allowed to * continue. */ fetchAbortIgnored?: true /** * The fetchMethod promise resolved successfully */ fetchResolved?: true /** * The results of the fetchMethod promise were stored in the cache */ fetchUpdated?: true /** * The fetchMethod promise was rejected */ fetchRejected?: true /** * The status of a {@link get} operation. * * - fetching: The item is currently being fetched. If a previous value is * present and allowed, that will be returned. * - stale: The item is in the cache, and is stale. * - hit: the item is in the cache * - miss: the item is not in the cache */ get?: 'stale' | 'hit' | 'miss' /** * A fetch or get operation returned a stale value. */ returnedStale?: true } Storage Bounds Safety This implementation aims to be as flexible as possible, within the limits of safe memory consumption and optimal performance. At initial object creation, storage is allocated for max items. If max is set to zero, then some performance is lost, and item count is unbounded. Either maxSize or ttl must be set if max is not specified. If maxSize is set, then this creates a safe limit on the maximum storage consumed, but without the performance benefits of pre-allocation. When maxSize is set, every item must provide a size, either via the sizeCalculation method provided to the constructor, or via a size or sizeCalculation option provided to cache.set(). The size of every item must be a positive integer. If neither max nor maxSize are set, then ttl tracking must be enabled. Note that, even when tracking item ttl, items are not preemptively deleted when they become stale, unless ttlAutopurge is enabled. Instead, they are only purged the next time the key is requested. Thus, if ttlAutopurge, max, and maxSize are all not set, then the cache will potentially grow unbounded. In this case, a warning is printed to standard error. Future versions may require the use of ttlAutopurge if max and maxSize are not specified. If you truly wish to use a cache that is bound only by TTL expiration, consider using a Map object, and calling setTimeout to delete entries when they expire. It will perform much better than an LRU cache. Here is an implementation you may use, under the same license as this package: // a storage-unbounded ttl cache that is not an lru-cache const cache = { data: new Map(), timers: new Map(), set: (k, v, ttl) => { if (cache.timers.has(k)) { clearTimeout(cache.timers.get(k)) } cache.timers.set( k, setTimeout(() => cache.delete(k), ttl) ) cache.data.set(k, v) }, get: k => cache.data.get(k), has: k => cache.data.has(k), delete: k => { if (cache.timers.has(k)) { clearTimeout(cache.timers.get(k)) } cache.timers.delete(k) return cache.data.delete(k) }, clear: () => { cache.data.clear() for (const v of cache.timers.values()) { clearTimeout(v) } cache.timers.clear() }, } If that isn't to your liking, check out @isaacs/ttlcache. Performance As of January 2022, version 7 of this library is one of the most performant LRU cache implementations in JavaScript. Benchmarks can be extremely difficult to get right. In particular, the performance of set/get/delete operations on objects will vary wildly depending on the type of key used. V8 is highly optimized for objects with keys that are short strings, especially integer numeric strings. Thus any benchmark which tests solely using numbers as keys will tend to find that an object-based approach performs the best. Note that coercing anything to strings to use as object keys is unsafe, unless you can be 100% certain that no other type of value will be used. For example: const myCache = {} const set = (k, v) => (myCache[k] = v) const get = k => myCache[k] set({}, 'please hang onto this for me') set('[object Object]', 'oopsie') Also beware of \"Just So\" stories regarding performance. Garbage collection of large (especially: deep) object graphs can be incredibly costly, with several \"tipping points\" where it increases exponentially. As a result, putting that off until later can make it much worse, and less predictable. If a library performs well, but only in a scenario where the object graph is kept shallow, then that won't help you if you are using large objects as keys. In general, when attempting to use a library to improve performance (such as a cache like this one), it's best to choose an option that will perform well in the sorts of scenarios where you'll actually use it. This library is optimized for repeated gets and minimizing eviction time, since that is the expected need of a LRU. Set operations are somewhat slower on average than a few other options, in part because of that optimization. It is assumed that you'll be caching some costly operation, ideally as rarely as possible, so optimizing set over get would be unwise. If performance matters to you: If it's at all possible to use small integer values as keys, and you can guarantee that no other types of values will be used as keys, then do that, and use a cache such as lru-fast, or mnemonist's LRUCache which uses an Object as its data store. Failing that, if at all possible, use short non-numeric strings (ie, less than 256 characters) as your keys, and use mnemonist's LRUCache. If the types of your keys will be long strings, strings that look like floats, null, objects, or some mix of types, or if you aren't sure, then this library will work well for you. Do not use a dispose function, size tracking, or especially ttl behavior, unless absolutely needed. These features are convenient, and necessary in some use cases, and every attempt has been made to make the performance impact minimal, but it isn't nothing. Breaking Changes in Version 7 This library changed to a different algorithm and internal data structure in version 7, yielding significantly better performance, albeit with some subtle changes as a result. If you were relying on the internals of LRUCache in version 6 or before, it probably will not work in version 7 and above. For more info, see the change log."
  },
  "src/frontend/app-client/node_modules/hosted-git-info/README.html": {
    "href": "src/frontend/app-client/node_modules/hosted-git-info/README.html",
    "title": "hosted-git-info",
    "summary": "hosted-git-info This will let you identify and transform various git hosts URLs between protocols. It also can tell you what the URL is for the raw path for particular file for direct access without git. Example const hostedGitInfo = require(\"hosted-git-info\") const info = hostedGitInfo.fromUrl(\"git@github.com:npm/hosted-git-info.git\", opts) /* info looks like: { type: \"github\", domain: \"github.com\", user: \"npm\", project: \"hosted-git-info\" } */ If the URL can't be matched with a git host, null will be returned. We can match git, ssh and https urls. Additionally, we can match ssh connect strings (git@github.com:npm/hosted-git-info) and shortcuts (eg, github:npm/hosted-git-info). GitHub specifically, is detected in the case of a third, unprefixed, form: npm/hosted-git-info. If it does match, the returned object has properties of: info.type -- The short name of the service info.domain -- The domain for git protocol use info.user -- The name of the user/org on the git host info.project -- The name of the project on the git host Version Contract The major version will be bumped any time… The constructor stops accepting URLs that it previously accepted. A method is removed. A method can no longer accept the number and type of arguments it previously accepted. A method can return a different type than it currently returns. Implications: I do not consider the specific format of the urls returned from, say .https() to be a part of the contract. The contract is that it will return a string that can be used to fetch the repo via HTTPS. But what that string looks like, specifically, can change. Dropping support for a hosted git provider would constitute a breaking change. Usage const info = hostedGitInfo.fromUrl(gitSpecifier[, options]) gitSpecifer is a URL of a git repository or a SCP-style specifier of one. options is an optional object. It can have the following properties: noCommittish — If true then committishes won't be included in generated URLs. noGitPlus — If true then git+ won't be prefixed on URLs. Methods All of the methods take the same options as the fromUrl factory. Options provided to a method override those provided to the constructor. info.file(path, opts) Given the path of a file relative to the repository, returns a URL for directly fetching it from the githost. If no committish was set then HEAD will be used as the default. For example hostedGitInfo.fromUrl(\"git@github.com:npm/hosted-git-info.git#v1.0.0\").file(\"package.json\") would return https://raw.githubusercontent.com/npm/hosted-git-info/v1.0.0/package.json info.shortcut(opts) eg, github:npm/hosted-git-info info.browse(path, fragment, opts) eg, https://github.com/npm/hosted-git-info/tree/v1.2.0, https://github.com/npm/hosted-git-info/tree/v1.2.0/package.json, https://github.com/npm/hosted-git-info/tree/v1.2.0/REAMDE.md#supported-hosts info.bugs(opts) eg, https://github.com/npm/hosted-git-info/issues info.docs(opts) eg, https://github.com/npm/hosted-git-info/tree/v1.2.0#readme info.https(opts) eg, git+https://github.com/npm/hosted-git-info.git info.sshurl(opts) eg, git+ssh://git@github.com/npm/hosted-git-info.git info.ssh(opts) eg, git@github.com:npm/hosted-git-info.git info.path(opts) eg, npm/hosted-git-info info.tarball(opts) eg, https://github.com/npm/hosted-git-info/archive/v1.2.0.tar.gz info.getDefaultRepresentation() Returns the default output type. The default output type is based on the string you passed in to be parsed info.toString(opts) Uses the getDefaultRepresentation to call one of the other methods to get a URL for this resource. As such hostedGitInfo.fromUrl(url).toString() will give you a normalized version of the URL that still uses the same protocol. Shortcuts will still be returned as shortcuts, but the special case github form of org/project will be normalized to github:org/project. SSH connect strings will be normalized into git+ssh URLs. Supported hosts Currently this supports GitHub (including Gists), Bitbucket, GitLab and Sourcehut. Pull requests for additional hosts welcome."
  },
  "src/frontend/app-client/node_modules/html/readme.html": {
    "href": "src/frontend/app-client/node_modules/html/readme.html",
    "title": "html prettyprinter",
    "summary": "html prettyprinter A node port of beautify-html.js by Nochum Sossonko which is based on jsbeautifier by Einar Lielmanis Installation from npm (node package manager) npm install html Usage (command line) echo \"<h2><strong><a href=\"http://awesome.com\">AwesomeCom</a></strong><span>is awesome</span></h2>\" | html returns: <h2> <strong> <a href=http://awesome.com>AwesomeCom</a> </strong> <span> is awesome </span> </h2> html foo.html will write the prettified version to stdout. html *.html will update in place all matching html files with their prettified versions. Advanced usage I find myself constantly using the 'Copy as HTML' feature of the Chrome Inspector: The downside is that that usually the HTML that gets copied is pretty ugly: On OS X you can use pbpaste and pbcopy to stream your clipboard in and out of unix pipes. With the ugly HTML still in your clipboard run this command: pbpaste | html | pbcopy Now when you paste your clipboard into an editor you will get nice, pretty printed HTML: Upgrading grab the newest beautify-html.js from js-beautifier and drop it into lib/ as html.js. then add the following code to the bottom of html.js: module.exports = { prettyPrint: style_html } BSD LICENSE"
  },
  "src/frontend/app-client/node_modules/http-errors/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/http-errors/HISTORY.html",
    "title": "2.0.0 / 2021-12-17",
    "summary": "2.0.0 / 2021-12-17 Drop support for Node.js 0.6 Remove I'mateapot export; use ImATeapot instead Remove support for status being non-first argument Rename UnorderedCollection constructor to TooEarly deps: depd@2.0.0 Replace internal eval usage with Function constructor Use instance methods on process to check for listeners deps: statuses@2.0.1 Fix messaging casing of 418 I'm a Teapot Remove code 306 Rename 425 Unordered Collection to standard 425 Too Early 2021-11-14 / 1.8.1 deps: toidentifier@1.0.1 2020-06-29 / 1.8.0 Add isHttpError export to determine if value is an HTTP error deps: setprototypeof@1.2.0 2019-06-24 / 1.7.3 deps: inherits@2.0.4 2019-02-18 / 1.7.2 deps: setprototypeof@1.1.1 2018-09-08 / 1.7.1 Fix error creating objects in some environments 2018-07-30 / 1.7.0 Set constructor name when possible Use toidentifier module to make class names deps: statuses@'>= 1.5.0 < 2' 2018-03-29 / 1.6.3 deps: depd@~1.1.2 perf: remove argument reassignment deps: setprototypeof@1.1.0 deps: statuses@'>= 1.4.0 < 2' 2017-08-04 / 1.6.2 deps: depd@1.1.1 Remove unnecessary Buffer loading 2017-02-20 / 1.6.1 deps: setprototypeof@1.0.3 Fix shim for old browsers 2017-02-14 / 1.6.0 Accept custom 4xx and 5xx status codes in factory Add deprecation message to \"I'mateapot\" export Deprecate passing status code as anything except first argument in factory Deprecate using non-error status codes Make message property enumerable for HttpErrors 2016-11-16 / 1.5.1 deps: inherits@2.0.3 Fix issue loading in browser deps: setprototypeof@1.0.2 deps: statuses@'>= 1.3.1 < 2' 2016-05-18 / 1.5.0 Support new code 421 Misdirected Request Use setprototypeof module to replace __proto__ setting deps: statuses@'>= 1.3.0 < 2' Add 421 Misdirected Request perf: enable strict mode perf: enable strict mode 2016-01-28 / 1.4.0 Add HttpError export, for err instanceof createError.HttpError deps: inherits@2.0.1 deps: statuses@'>= 1.2.1 < 2' Fix message for status 451 Remove incorrect nginx status code 2015-02-02 / 1.3.1 Fix regression where status can be overwritten in createError props 2015-02-01 / 1.3.0 Construct errors using defined constructors from createError Fix error names that are not identifiers createError[\"I'mateapot\"] is now createError.ImATeapot Set a meaningful name property on constructed errors 2014-12-09 / 1.2.8 Fix stack trace from exported function Remove arguments.callee usage 2014-10-14 / 1.2.7 Remove duplicate line 2014-10-02 / 1.2.6 Fix expose to be true for ClientError constructor 2014-09-28 / 1.2.5 deps: statuses@1 2014-09-21 / 1.2.4 Fix dependency version to work with old npms 2014-09-21 / 1.2.3 deps: statuses@~1.1.0 2014-09-21 / 1.2.2 Fix publish error 2014-09-21 / 1.2.1 Support Node.js 0.6 Use inherits instead of util 2014-09-09 / 1.2.0 Fix the way inheriting functions Support expose being provided in properties argument 2014-09-08 / 1.1.0 Default status to 500 Support provided error to extend 2014-09-08 / 1.0.1 Fix accepting string message 2014-09-08 / 1.0.0 Initial release"
  },
  "src/frontend/app-client/node_modules/http-errors/README.html": {
    "href": "src/frontend/app-client/node_modules/http-errors/README.html",
    "title": "http-errors",
    "summary": "http-errors Create HTTP errors for Express, Koa, Connect, etc. with ease. Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install http-errors Example var createError = require('http-errors') var express = require('express') var app = express() app.use(function (req, res, next) { if (!req.user) return next(createError(401, 'Please login to view this page.')) next() }) API This is the current API, currently extracted from Koa and subject to change. Error Properties expose - can be used to signal if message should be sent to the client, defaulting to false when status >= 500 headers - can be an object of header names to values to be sent to the client, defaulting to undefined. When defined, the key names should all be lower-cased message - the traditional error message, which should be kept short and all single line status - the status code of the error, mirroring statusCode for general compatibility statusCode - the status code of the error, defaulting to 500 createError([status], [message], [properties]) Create a new error object with the given message msg. The error object inherits from createError.HttpError. var err = createError(404, 'This video does not exist!') status: 500 - the status code as a number message - the message of the error, defaulting to node's text for that status code. properties - custom properties to attach to the object createError([status], [error], [properties]) Extend the given error object with createError.HttpError properties. This will not alter the inheritance of the given error object, and the modified error object is the return value. fs.readFile('foo.txt', function (err, buf) { if (err) { if (err.code === 'ENOENT') { var httpError = createError(404, err, { expose: false }) } else { var httpError = createError(500, err) } } }) status - the status code as a number error - the error object to extend properties - custom properties to attach to the object createError.isHttpError(val) Determine if the provided val is an HttpError. This will return true if the error inherits from the HttpError constructor of this module or matches the \"duck type\" for an error this module creates. All outputs from the createError factory will return true for this function, including if an non-HttpError was passed into the factory. new createError[code || name]([msg])) Create a new error object with the given message msg. The error object inherits from createError.HttpError. var err = new createError.NotFound() code - the status code as a number name - the name of the error as a \"bumpy case\", i.e. NotFound or InternalServerError. List of all constructors Status Code Constructor Name 400 BadRequest 401 Unauthorized 402 PaymentRequired 403 Forbidden 404 NotFound 405 MethodNotAllowed 406 NotAcceptable 407 ProxyAuthenticationRequired 408 RequestTimeout 409 Conflict 410 Gone 411 LengthRequired 412 PreconditionFailed 413 PayloadTooLarge 414 URITooLong 415 UnsupportedMediaType 416 RangeNotSatisfiable 417 ExpectationFailed 418 ImATeapot 421 MisdirectedRequest 422 UnprocessableEntity 423 Locked 424 FailedDependency 425 TooEarly 426 UpgradeRequired 428 PreconditionRequired 429 TooManyRequests 431 RequestHeaderFieldsTooLarge 451 UnavailableForLegalReasons 500 InternalServerError 501 NotImplemented 502 BadGateway 503 ServiceUnavailable 504 GatewayTimeout 505 HTTPVersionNotSupported 506 VariantAlsoNegotiates 507 InsufficientStorage 508 LoopDetected 509 BandwidthLimitExceeded 510 NotExtended 511 NetworkAuthenticationRequired License MIT"
  },
  "src/frontend/app-client/node_modules/iconv-lite/Changelog.html": {
    "href": "src/frontend/app-client/node_modules/iconv-lite/Changelog.html",
    "title": "0.4.24 / 2018-08-22",
    "summary": "0.4.24 / 2018-08-22 Added MIK encoding (#196, by @Ivan-Kalatchev) 0.4.23 / 2018-05-07 Fix deprecation warning in Node v10 due to the last usage of new Buffer (#185, by @felixbuenemann) Switched from NodeBuffer to Buffer in typings (#155 by @felixfbecker, #186 by @larssn) 0.4.22 / 2018-05-05 Use older semver style for dependencies to be compatible with Node version 0.10 (#182, by @dougwilson) Fix tests to accomodate fixes in Node v10 (#182, by @dougwilson) 0.4.21 / 2018-04-06 Fix encoding canonicalization (#156) Fix the paths in the \"browser\" field in package.json (#174 by @LMLB) Removed \"contributors\" section in package.json - see Git history instead. 0.4.20 / 2018-04-06 Updated new Buffer() usages with recommended replacements as it's being deprecated in Node v10 (#176, #178 by @ChALkeR) 0.4.19 / 2017-09-09 Fixed iso8859-1 codec regression in handling untranslatable characters (#162, caused by #147) Re-generated windows1255 codec, because it was updated in iconv project Fixed grammar in error message when iconv-lite is loaded with encoding other than utf8 0.4.18 / 2017-06-13 Fixed CESU-8 regression in Node v8. 0.4.17 / 2017-04-22 Updated typescript definition file to support Angular 2 AoT mode (#153 by @larssn) 0.4.16 / 2017-04-22 Added support for React Native (#150) Changed iso8859-1 encoding to usine internal 'binary' encoding, as it's the same thing (#147 by @mscdex) Fixed typo in Readme (#138 by @jiangzhuo) Fixed build for Node v6.10+ by making correct version comparison Added a warning if iconv-lite is loaded not as utf-8 (see #142) 0.4.15 / 2016-11-21 Fixed typescript type definition (#137) 0.4.14 / 2016-11-20 Preparation for v1.0 Added Node v6 and latest Node versions to Travis CI test rig Deprecated Node v0.8 support Typescript typings (@larssn) Fix encoding of Euro character in GB 18030 (inspired by @lygstate) Add ms prefix to dbcs windows encodings (@rokoroku) 0.4.13 / 2015-10-01 Fix silly mistake in deprecation notice. 0.4.12 / 2015-09-26 Node v4 support: Added CESU-8 decoding (#106) Added deprecation notice for extendNodeEncodings Added Travis tests for Node v4 and io.js latest (#105 by @Mithgol) 0.4.11 / 2015-07-03 Added CESU-8 encoding. 0.4.10 / 2015-05-26 Changed UTF-16 endianness heuristic to take into account any ASCII chars, not just spaces. This should minimize the importance of \"default\" endianness. 0.4.9 / 2015-05-24 Streamlined BOM handling: strip BOM by default, add BOM when encoding if addBOM: true. Added docs to Readme. UTF16 now uses UTF16-LE by default. Fixed minor issue with big5 encoding. Added io.js testing on Travis; updated node-iconv version to test against. Now we just skip testing SBCS encodings that node-iconv doesn't support. (internal refactoring) Updated codec interface to use classes. Use strict mode in all files. 0.4.8 / 2015-04-14 added alias UNICODE-1-1-UTF-7 for UTF-7 encoding (#94) 0.4.7 / 2015-02-05 stop official support of Node.js v0.8. Should still work, but no guarantees. reason: Packages needed for testing are hard to get on Travis CI. work in environment where Object.prototype is monkey patched with enumerable props (#89). 0.4.6 / 2015-01-12 fix rare aliases of single-byte encodings (thanks @mscdex) double the timeout for dbcs tests to make them less flaky on travis 0.4.5 / 2014-11-20 fix windows-31j and x-sjis encoding support (@nleush) minor fix: undefined variable reference when internal error happens 0.4.4 / 2014-07-16 added encodings UTF-7 (RFC2152) and UTF-7-IMAP (RFC3501 Section 5.1.3) fixed streaming base64 encoding 0.4.3 / 2014-06-14 added encodings UTF-16BE and UTF-16 with BOM 0.4.2 / 2014-06-12 don't throw exception if extendNodeEncodings() is called more than once 0.4.1 / 2014-06-11 codepage 808 added 0.4.0 / 2014-06-10 code is rewritten from scratch all widespread encodings are supported streaming interface added browserify compatibility added (optional) extend core primitive encodings to make usage even simpler moved from vows to mocha as the testing framework"
  },
  "src/frontend/app-client/node_modules/iconv-lite/README.html": {
    "href": "src/frontend/app-client/node_modules/iconv-lite/README.html",
    "title": "",
    "summary": "Pure JS character encoding conversion Doesn't need native code compilation. Works on Windows and in sandboxed environments like Cloud9. Used in popular projects like Express.js (body_parser), Grunt, Nodemailer, Yeoman and others. Faster than node-iconv (see below for performance comparison). Intuitive encode/decode API Streaming support for Node v0.10+ [Deprecated] Can extend Node.js primitives (buffers, streams) to support all iconv-lite encodings. In-browser usage via Browserify (~180k gzip compressed with Buffer shim included). Typescript type definition file included. React Native is supported (need to explicitly npm install two more modules: buffer and stream). License: MIT. Usage Basic API var iconv = require('iconv-lite'); // Convert from an encoded buffer to js string. str = iconv.decode(Buffer.from([0x68, 0x65, 0x6c, 0x6c, 0x6f]), 'win1251'); // Convert from js string to an encoded buffer. buf = iconv.encode(\"Sample input string\", 'win1251'); // Check if encoding is supported iconv.encodingExists(\"us-ascii\") Streaming API (Node v0.10+) // Decode stream (from binary stream to js strings) http.createServer(function(req, res) { var converterStream = iconv.decodeStream('win1251'); req.pipe(converterStream); converterStream.on('data', function(str) { console.log(str); // Do something with decoded strings, chunk-by-chunk. }); }); // Convert encoding streaming example fs.createReadStream('file-in-win1251.txt') .pipe(iconv.decodeStream('win1251')) .pipe(iconv.encodeStream('ucs2')) .pipe(fs.createWriteStream('file-in-ucs2.txt')); // Sugar: all encode/decode streams have .collect(cb) method to accumulate data. http.createServer(function(req, res) { req.pipe(iconv.decodeStream('win1251')).collect(function(err, body) { assert(typeof body == 'string'); console.log(body); // full request body string }); }); [Deprecated] Extend Node.js own encodings NOTE: This doesn't work on latest Node versions. See details. // After this call all Node basic primitives will understand iconv-lite encodings. iconv.extendNodeEncodings(); // Examples: buf = new Buffer(str, 'win1251'); buf.write(str, 'gbk'); str = buf.toString('latin1'); assert(Buffer.isEncoding('iso-8859-15')); Buffer.byteLength(str, 'us-ascii'); http.createServer(function(req, res) { req.setEncoding('big5'); req.collect(function(err, body) { console.log(body); }); }); fs.createReadStream(\"file.txt\", \"shift_jis\"); // External modules are also supported (if they use Node primitives, which they probably do). request = require('request'); request({ url: \"http://github.com/\", encoding: \"cp932\" }); // To remove extensions iconv.undoExtendNodeEncodings(); Supported encodings All node.js native encodings: utf8, ucs2 / utf16-le, ascii, binary, base64, hex. Additional unicode encodings: utf16, utf16-be, utf-7, utf-7-imap. All widespread singlebyte encodings: Windows 125x family, ISO-8859 family, IBM/DOS codepages, Macintosh family, KOI8 family, all others supported by iconv library. Aliases like 'latin1', 'us-ascii' also supported. All widespread multibyte encodings: CP932, CP936, CP949, CP950, GB2312, GBK, GB18030, Big5, Shift_JIS, EUC-JP. See all supported encodings on wiki. Most singlebyte encodings are generated automatically from node-iconv. Thank you Ben Noordhuis and libiconv authors! Multibyte encodings are generated from Unicode.org mappings and WHATWG Encoding Standard mappings. Thank you, respective authors! Encoding/decoding speed Comparison with node-iconv module (1000x256kb, on MacBook Pro, Core i5/2.6 GHz, Node v0.12.0). Note: your results may vary, so please always check on your hardware. operation iconv@2.1.4 iconv-lite@0.4.7 ---------------------------------------------------------- encode('win1251') ~96 Mb/s ~320 Mb/s decode('win1251') ~95 Mb/s ~246 Mb/s BOM handling Decoding: BOM is stripped by default, unless overridden by passing stripBOM: false in options (f.ex. iconv.decode(buf, enc, {stripBOM: false})). A callback might also be given as a stripBOM parameter - it'll be called if BOM character was actually found. If you want to detect UTF-8 BOM when decoding other encodings, use node-autodetect-decoder-stream module. Encoding: No BOM added, unless overridden by addBOM: true option. UTF-16 Encodings This library supports UTF-16LE, UTF-16BE and UTF-16 encodings. First two are straightforward, but UTF-16 is trying to be smart about endianness in the following ways: Decoding: uses BOM and 'spaces heuristic' to determine input endianness. Default is UTF-16LE, but can be overridden with defaultEncoding: 'utf-16be' option. Strips BOM unless stripBOM: false. Encoding: uses UTF-16LE and writes BOM by default. Use addBOM: false to override. Other notes When decoding, be sure to supply a Buffer to decode() method, otherwise bad things usually happen. Untranslatable characters are set to � or ?. No transliteration is currently supported. Node versions 0.10.31 and 0.11.13 are buggy, don't use them (see #65, #77). Testing $ git clone git@github.com:ashtuchkin/iconv-lite.git $ cd iconv-lite $ npm install $ npm test $ # To view performance: $ node test/performance.js $ # To view test coverage: $ npm run coverage $ open coverage/lcov-report/index.html"
  },
  "src/frontend/app-client/node_modules/import-fresh/readme.html": {
    "href": "src/frontend/app-client/node_modules/import-fresh/readme.html",
    "title": "import-fresh",
    "summary": "import-fresh Import a module while bypassing the cache Useful for testing purposes when you need to freshly import a module. ESM For ESM, you can use this snippet: const importFresh = moduleName => import(`${moduleName}?${Date.now()}`); const {default: foo} = await importFresh('foo'); This snippet causes a memory leak, so only use it for short-lived tests. Install npm install import-fresh Usage // foo.js let i = 0; module.exports = () => ++i; const importFresh = require('import-fresh'); require('./foo')(); //=> 1 require('./foo')(); //=> 2 importFresh('./foo')(); //=> 1 importFresh('./foo')(); //=> 1 Related clear-module - Clear a module from the import cache import-from - Import a module from a given path import-cwd - Import a module from the current working directory import-lazy - Import modules lazily"
  },
  "src/frontend/app-client/node_modules/inherits/README.html": {
    "href": "src/frontend/app-client/node_modules/inherits/README.html",
    "title": "",
    "summary": "Browser-friendly inheritance fully compatible with standard node.js inherits. This package exports standard inherits from node.js util module in node environment, but also provides alternative browser-friendly implementation through browser field. Alternative implementation is a literal copy of standard one located in standalone module to avoid requiring of util. It also has a shim for old browsers with no Object.create support. While keeping you sure you are using standard inherits implementation in node.js environment, it allows bundlers such as browserify to not include full util package to your client code if all you need is just inherits function. It worth, because browser shim for util package is large and inherits is often the single function you need from it. It's recommended to use this package instead of require('util').inherits for any code that has chances to be used not only in node.js but in browser too. usage var inherits = require('inherits'); // then use exactly as the standard one note on version ~1.0 Version ~1.0 had completely different motivation and is not compatible neither with 2.0 nor with standard node.js inherits. If you are using version ~1.0 and planning to switch to ~2.0, be careful: new version uses super_ instead of super for referencing superclass new version overwrites current prototype while old one preserves any existing fields on it"
  },
  "src/frontend/app-client/node_modules/ini/README.html": {
    "href": "src/frontend/app-client/node_modules/ini/README.html",
    "title": "",
    "summary": "An ini format parser and serializer for node. Sections are treated as nested objects. Items before the first heading are saved on the object directly. Usage Consider an ini-file config.ini that looks like this: ; this comment is being ignored scope = global [database] user = dbuser password = dbpassword database = use_this_database [paths.default] datadir = /var/lib/data array[] = first value array[] = second value array[] = third value You can read, manipulate and write the ini-file like so: var fs = require('fs') , ini = require('ini') var config = ini.parse(fs.readFileSync('./config.ini', 'utf-8')) config.scope = 'local' config.database.database = 'use_another_database' config.paths.default.tmpdir = '/tmp' delete config.paths.default.datadir config.paths.default.array.push('fourth value') fs.writeFileSync('./config_modified.ini', ini.stringify(config, { section: 'section' })) This will result in a file called config_modified.ini being written to the filesystem with the following content: [section] scope=local [section.database] user=dbuser password=dbpassword database=use_another_database [section.paths.default] tmpdir=/tmp array[]=first value array[]=second value array[]=third value array[]=fourth value API decode(inistring) Decode the ini-style formatted inistring into a nested object. parse(inistring) Alias for decode(inistring) encode(object, [options]) Encode the object object into an ini-style formatted string. If the optional parameter section is given, then all top-level properties of the object are put into this section and the section-string is prepended to all sub-sections, see the usage example above. The options object may contain the following: section A string which will be the first section in the encoded ini data. Defaults to none. whitespace Boolean to specify whether to put whitespace around the = character. By default, whitespace is omitted, to be friendly to some persnickety old parsers that don't tolerate it well. But some find that it's more human-readable and pretty with the whitespace. For backwards compatibility reasons, if a string options is passed in, then it is assumed to be the section value. stringify(object, [options]) Alias for encode(object, [options]) safe(val) Escapes the string val such that it is safe to be used as a key or value in an ini-file. Basically escapes quotes. For example ini.safe('\"unsafe string\"') would result in \"\\\"unsafe string\\\"\" unsafe(val) Unescapes the string val"
  },
  "src/frontend/app-client/node_modules/ipaddr.js/README.html": {
    "href": "src/frontend/app-client/node_modules/ipaddr.js/README.html",
    "title": "ipaddr.js — an IPv6 and IPv4 address manipulation library",
    "summary": "ipaddr.js — an IPv6 and IPv4 address manipulation library ipaddr.js is a small (1.9K minified and gzipped) library for manipulating IP addresses in JavaScript environments. It runs on both CommonJS runtimes (e.g. nodejs) and in a web browser. ipaddr.js allows you to verify and parse string representation of an IP address, match it against a CIDR range or range list, determine if it falls into some reserved ranges (examples include loopback and private ranges), and convert between IPv4 and IPv4-mapped IPv6 addresses. Installation npm install ipaddr.js or bower install ipaddr.js API ipaddr.js defines one object in the global scope: ipaddr. In CommonJS, it is exported from the module: var ipaddr = require('ipaddr.js'); The API consists of several global methods and two classes: ipaddr.IPv6 and ipaddr.IPv4. Global methods There are three global methods defined: ipaddr.isValid, ipaddr.parse and ipaddr.process. All of them receive a string as a single parameter. The ipaddr.isValid method returns true if the address is a valid IPv4 or IPv6 address, and false otherwise. It does not throw any exceptions. The ipaddr.parse method returns an object representing the IP address, or throws an Error if the passed string is not a valid representation of an IP address. The ipaddr.process method works just like the ipaddr.parse one, but it automatically converts IPv4-mapped IPv6 addresses to their IPv4 counterparts before returning. It is useful when you have a Node.js instance listening on an IPv6 socket, and the net.ivp6.bindv6only sysctl parameter (or its equivalent on non-Linux OS) is set to 0. In this case, you can accept IPv4 connections on your IPv6-only socket, but the remote address will be mangled. Use ipaddr.process method to automatically demangle it. Object representation Parsing methods return an object which descends from ipaddr.IPv6 or ipaddr.IPv4. These objects share some properties, but most of them differ. Shared properties One can determine the type of address by calling addr.kind(). It will return either \"ipv6\" or \"ipv4\". An address can be converted back to its string representation with addr.toString(). Note that this method: does not return the original string used to create the object (in fact, there is no way of getting that string) returns a compact representation (when it is applicable) A match(range, bits) method can be used to check if the address falls into a certain CIDR range. Note that an address can be (obviously) matched only against an address of the same type. For example: var addr = ipaddr.parse(\"2001:db8:1234::1\"); var range = ipaddr.parse(\"2001:db8::\"); addr.match(range, 32); // => true Alternatively, match can also be called as match([range, bits]). In this way, it can be used together with the parseCIDR(string) method, which parses an IP address together with a CIDR range. For example: var addr = ipaddr.parse(\"2001:db8:1234::1\"); addr.match(ipaddr.parseCIDR(\"2001:db8::/32\")); // => true A range() method returns one of predefined names for several special ranges defined by IP protocols. The exact names (and their respective CIDR ranges) can be looked up in the source: IPv6 ranges and IPv4 ranges. Some common ones include \"unicast\" (the default one) and \"reserved\". You can match against your own range list by using ipaddr.subnetMatch(address, rangeList, defaultName) method. It can work with a mix of IPv6 or IPv4 addresses, and accepts a name-to-subnet map as the range list. For example: var rangeList = { documentationOnly: [ ipaddr.parse('2001:db8::'), 32 ], tunnelProviders: [ [ ipaddr.parse('2001:470::'), 32 ], // he.net [ ipaddr.parse('2001:5c0::'), 32 ] // freenet6 ] }; ipaddr.subnetMatch(ipaddr.parse('2001:470:8:66::1'), rangeList, 'unknown'); // => \"tunnelProviders\" The addresses can be converted to their byte representation with toByteArray(). (Actually, JavaScript mostly does not know about byte buffers. They are emulated with arrays of numbers, each in range of 0..255.) var bytes = ipaddr.parse('2a00:1450:8007::68').toByteArray(); // ipv6.google.com bytes // => [42, 0x00, 0x14, 0x50, 0x80, 0x07, 0x00, <zeroes...>, 0x00, 0x68 ] The ipaddr.IPv4 and ipaddr.IPv6 objects have some methods defined, too. All of them have the same interface for both protocols, and are similar to global methods. ipaddr.IPvX.isValid(string) can be used to check if the string is a valid address for particular protocol, and ipaddr.IPvX.parse(string) is the error-throwing parser. ipaddr.IPvX.isValid(string) uses the same format for parsing as the POSIX inet_ntoa function, which accepts unusual formats like 0xc0.168.1.1 or 0x10000000. The function ipaddr.IPv4.isValidFourPartDecimal(string) validates the IPv4 address and also ensures that it is written in four-part decimal format. IPv6 properties Sometimes you will want to convert IPv6 not to a compact string representation (with the :: substitution); the toNormalizedString() method will return an address where all zeroes are explicit. For example: var addr = ipaddr.parse(\"2001:0db8::0001\"); addr.toString(); // => \"2001:db8::1\" addr.toNormalizedString(); // => \"2001:db8:0:0:0:0:0:1\" The isIPv4MappedAddress() method will return true if this address is an IPv4-mapped one, and toIPv4Address() will return an IPv4 object address. To access the underlying binary representation of the address, use addr.parts. var addr = ipaddr.parse(\"2001:db8:10::1234:DEAD\"); addr.parts // => [0x2001, 0xdb8, 0x10, 0, 0, 0, 0x1234, 0xdead] A IPv6 zone index can be accessed via addr.zoneId: var addr = ipaddr.parse(\"2001:db8::%eth0\"); addr.zoneId // => 'eth0' IPv4 properties toIPv4MappedAddress() will return a corresponding IPv4-mapped IPv6 address. To access the underlying representation of the address, use addr.octets. var addr = ipaddr.parse(\"192.168.1.1\"); addr.octets // => [192, 168, 1, 1] prefixLengthFromSubnetMask() will return a CIDR prefix length for a valid IPv4 netmask or null if the netmask is not valid. ipaddr.IPv4.parse('255.255.255.240').prefixLengthFromSubnetMask() == 28 ipaddr.IPv4.parse('255.192.164.0').prefixLengthFromSubnetMask() == null subnetMaskFromPrefixLength() will return an IPv4 netmask for a valid CIDR prefix length. ipaddr.IPv4.subnetMaskFromPrefixLength(24) == \"255.255.255.0\" ipaddr.IPv4.subnetMaskFromPrefixLength(29) == \"255.255.255.248\" broadcastAddressFromCIDR() will return the broadcast address for a given IPv4 interface and netmask in CIDR notation. ipaddr.IPv4.broadcastAddressFromCIDR(\"172.0.0.1/24\") == \"172.0.0.255\" networkAddressFromCIDR() will return the network address for a given IPv4 interface and netmask in CIDR notation. ipaddr.IPv4.networkAddressFromCIDR(\"172.0.0.1/24\") == \"172.0.0.0\" Conversion IPv4 and IPv6 can be converted bidirectionally to and from network byte order (MSB) byte arrays. The fromByteArray() method will take an array and create an appropriate IPv4 or IPv6 object if the input satisfies the requirements. For IPv4 it has to be an array of four 8-bit values, while for IPv6 it has to be an array of sixteen 8-bit values. For example: var addr = ipaddr.fromByteArray([0x7f, 0, 0, 1]); addr.toString(); // => \"127.0.0.1\" or var addr = ipaddr.fromByteArray([0x20, 1, 0xd, 0xb8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]) addr.toString(); // => \"2001:db8::1\" Both objects also offer a toByteArray() method, which returns an array in network byte order (MSB). For example: var addr = ipaddr.parse(\"127.0.0.1\"); addr.toByteArray(); // => [0x7f, 0, 0, 1] or var addr = ipaddr.parse(\"2001:db8::1\"); addr.toByteArray(); // => [0x20, 1, 0xd, 0xb8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]"
  },
  "src/frontend/app-client/node_modules/is-arrayish/README.html": {
    "href": "src/frontend/app-client/node_modules/is-arrayish/README.html",
    "title": "node-is-arrayish",
    "summary": "node-is-arrayish Determines if an object can be used like an Array Example var isArrayish = require('is-arrayish'); isArrayish([]); // true isArrayish({__proto__: []}); // true isArrayish({}); // false isArrayish({length:10}); // false License Licensed under the MIT License. You can find a copy of it in LICENSE."
  },
  "src/frontend/app-client/node_modules/is-core-module/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/is-core-module/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v2.16.1 - 2024-12-21 Fixed [Fix] node:sqlite is available in node ^22.13 #17 v2.16.0 - 2024-12-13 Commits [New] add node:sqlite 1ee94d2 [Dev Deps] update auto-changelog, tape aa84aa3 v2.15.1 - 2024-08-21 Commits [Tests] add process.getBuiltinModule tests 28c7791 [Fix] test/mock_loader is no longer exposed as of v22.7 68b08b0 [Tests] replace aud with npm audit 32f8060 [Dev Deps] update mock-property f7d3c8f [Dev Deps] add missing peer dep eaee885 v2.15.0 - 2024-07-17 Commits [New] add node:sea 2819fb3 v2.14.0 - 2024-06-20 Commits [Dev Deps] update @ljharb/eslint-config, aud, mock-property, npmignore, tape 0e43200 [meta] add missing engines.node 4ea3af8 [New] add test/mock_loader e9fbd29 [Deps] update hasown 57f1940 v2.13.1 - 2023-10-20 Commits [Refactor] use hasown instead of has 0e52096 [Dev Deps] update mock-property, tape 8736b35 v2.13.0 - 2023-08-05 Commits [Dev Deps] update @ljharb/eslint-config, aud, semver, tape c75b263 [New] node:test/reporters and wasi/node:wasi are in v18.17 d76cbf8 v2.12.1 - 2023-05-16 Commits [Fix] test/reporters now requires the node: prefix as of v20.2 12183d0 v2.12.0 - 2023-04-10 Commits [actions] update rebase action to use reusable workflow c0a7251 [Dev Deps] update @ljharb/eslint-config, aud, tape 9ae8b7f [New] test/reporters added in v19.9, wasi added in v20 9d5341a [Dev Deps] add missing in-publish dep 5980245 v2.11.0 - 2022-10-18 Commits [meta] use npmignore to autogenerate an npmignore file 3360011 [Dev Deps] update aud, tape 651c6b0 [New] inspector/promises and node:inspector/promises is now available in node 19 22d332f v2.10.0 - 2022-08-03 Commits [New] node:test is now available in node ^16.17 e8fd36e [Tests] improve skip message c014a4c v2.9.0 - 2022-04-19 Commits [New] add node:test, in node 18+ f853eca [Tests] use mock-property 03b3644 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 7c0e2d0 [meta] simplify \"exports\" d6ed201 v2.8.1 - 2022-01-05 Commits [actions] reuse common workflows cd2cf9b [Fix] update node 0.4 results 062195d [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape 0790b62 [Dev Deps] update eslint, @ljharb/eslint-config, tape 7d139a6 [Tests] run nyc in tests-only, not test 780e8a0 v2.8.0 - 2021-10-14 Commits [actions] update codecov uploader 0cfe94e [New] add readline/promises to node v17+ 4f78c30 [Tests] node ^14.18 supports node: prefixes for CJS 43e2f17 v2.7.0 - 2021-09-27 Commits [New] node v14.18 added node:-prefixed core modules to require 6d943ab [Tests] add coverage for Object.prototype pollution c6baf5f [Dev Deps] update @ljharb/eslint-config 6717f00 [eslint] fix linter warning 594c10b [meta] add sideEffects flag c32cfa5 v2.6.0 - 2021-08-17 Commits [Dev Deps] update eslint, tape 6cc928f [New] add stream/consumers to node &gt;= 16.7 a1a423e [Refactor] Remove duplicated && operand 86faea7 [Tests] include prereleases a4da7a6 v2.5.0 - 2021-07-12 Commits [Dev Deps] update auto-changelog, eslint 6334cc9 [New] add stream/web to node v16.5+ 17ac59b v2.4.0 - 2021-05-09 Commits [readme] add actions and codecov badges 82b7faa [Dev Deps] update @ljharb/eslint-config, aud 8096868 [Dev Deps] update eslint 6726824 [New] add diagnostics_channel to node ^14.17 86c6563 [meta] fix prepublish script 697a01e v2.3.0 - 2021-04-24 Commits [meta] do not publish github action workflow files 060d4bb [New] add support for node: prefix, in node 16+ 7341223 [actions] use node/install instead of node/run; use codecov action 016269a [patch] remove unneeded .0 in version ranges cb466a6 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape c9f9c39 [actions] update workflows 3ee4a89 [Dev Deps] update eslint, @ljharb/eslint-config dee4fed [Dev Deps] update eslint, @ljharb/eslint-config 7d046ba [meta] use prepublishOnly script for npm 7+ 149e677 [readme] remove travis badge 903b51d v2.2.0 - 2020-11-26 Commits [Tests] migrate tests to Github Actions c919f57 [patch] core.json: %s/ /\\t/g db3f685 [Tests] run nyc on all tests b2f925f [Dev Deps] update eslint, @ljharb/eslint-config, aud; add safe-publish-latest 89f02a2 [New] add path/posix, path/win32, util/types 77f94f1 v2.1.0 - 2020-11-04 Commits [Dev Deps] update eslint 5e0034e [New] Add diagnostics_channel c2d83d0 v2.0.0 - 2020-09-29 Commits v2 implementation 865aeb5 Only apps should have lockfiles 5a5e660 Initial commit for v2 5a51524 Tests 116eae4 [meta] add auto-changelog c24388b [actions] add \"Automatic Rebase\" and \"require allow edits\" actions 34292db [Tests] add npm run lint 4f9eeee [readme] fix travis badges, https all URLs e516a73 [meta] create FUNDING.yml 1aabebc [Fix] domain: domain landed sometime > v0.7.7 and <= v0.7.12 2df7d37 [Fix] sys: worked in 0.6, not 0.7, and 0.8+ a75c134 v1.0.2 - 2014-09-28 Commits simpler 66fe90f v1.0.1 - 2014-09-28 Commits remove stupid f21f906 update readme 1eff0ec v1.0.0 - 2014-09-28 Commits init 48e5e76"
  },
  "src/frontend/app-client/node_modules/is-core-module/README.html": {
    "href": "src/frontend/app-client/node_modules/is-core-module/README.html",
    "title": "is-core-module",
    "summary": "is-core-module Is this specifier a node.js core module? Optionally provide a node version to check; defaults to the current node version. Example var isCore = require('is-core-module'); var assert = require('assert'); assert(isCore('fs')); assert(!isCore('butts')); Tests Clone the repo, npm install, and run npm test"
  },
  "src/frontend/app-client/node_modules/is-fullwidth-code-point/readme.html": {
    "href": "src/frontend/app-client/node_modules/is-fullwidth-code-point/readme.html",
    "title": "is-fullwidth-code-point",
    "summary": "is-fullwidth-code-point Check if the character represented by a given Unicode code point is fullwidth Install $ npm install is-fullwidth-code-point Usage const isFullwidthCodePoint = require('is-fullwidth-code-point'); isFullwidthCodePoint('谢'.codePointAt(0)); //=> true isFullwidthCodePoint('a'.codePointAt(0)); //=> false API isFullwidthCodePoint(codePoint) codePoint Type: number The code point of a character. License MIT © Sindre Sorhus"
  },
  "src/frontend/app-client/node_modules/isarray/README.html": {
    "href": "src/frontend/app-client/node_modules/isarray/README.html",
    "title": "isarray",
    "summary": "isarray Array#isArray for older browsers. Usage var isArray = require('isarray'); console.log(isArray([])); // => true console.log(isArray({})); // => false Installation With npm do $ npm install isarray Then bundle for the browser with browserify. With component do $ component install juliangruber/isarray License (MIT) Copyright (c) 2013 Julian Gruber <julian@juliangruber.com&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/isbot/README.html": {
    "href": "src/frontend/app-client/node_modules/isbot/README.html",
    "title": "isbot \uD83E\uDD16/\uD83D\uDC68‍\uD83E\uDDB0",
    "summary": "isbot \uD83E\uDD16/\uD83D\uDC68‍\uD83E\uDDB0 Identify bots, crawlers, and spiders using the user agent string. Usage Install npm i isbot Straightforward usage import { isbot } from \"isbot\"; // Request isbot(request.headers.get(\"User-Agent\")); // Nodejs HTTP isbot(request.getHeader(\"User-Agent\")); // ExpressJS isbot(req.get(\"user-agent\")); // Browser isbot(navigator.userAgent); // User Agent string isbot( \"Mozilla/5.0 (iPhone; CPU iPhone OS 6_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/6.0 Mobile/10A5376e Safari/8536.25 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\", ); // true isbot( \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36\", ); // false Use JSDeliver CDN you can import to the browser directly See specific versions and instructions https://www.jsdelivr.com/package/npm/isbot ESM <script type=\"module\"> import { isbot } from \"https://cdn.jsdelivr.net/npm/isbot@5/+esm\"; isbot(navigator.userAgent); </script> UMD <script src=\"https://cdn.jsdelivr.net/npm/isbot@5\"></script> <script> // isbot is now global isbot(navigator.userAgent); </script> All named imports import Type Description isbot (string?): boolean Check if the user agent is a bot isbotNaive (string?): boolean Check if the user agent is a bot using a naive pattern (less accurate) getPattern (): RegExp The regular expression used to identify bots list string[] List of all individual pattern parts isbotMatch (string?): string | null The substring matched by the regular expression isbotMatches (string?): string[] All substrings matched by the regular expression isbotPattern (string?): string | null The regular expression used to identify bot substring in the user agent isbotPatterns (string?): string[] All regular expressions used to identify bot substrings in the user agent createIsbot (RegExp): (string?): boolean Create a custom isbot function createIsbotFromList (string[]): (string?): boolean Create a custom isbot function from a list of string representation patterns Example usages of helper functions Create a custom isbot that does not consider Chrome Lighthouse user agent as bots. import { createIsbotFromList, isbotMatches, list } from \"isbot\"; const ChromeLighthouseUserAgentStrings: string[] = [ \"mozilla/5.0 (macintosh; intel mac os x 10_15_7) applewebkit/537.36 (khtml, like gecko) chrome/94.0.4590.2 safari/537.36 chrome-lighthouse\", \"mozilla/5.0 (linux; android 7.0; moto g (4)) applewebkit/537.36 (khtml, like gecko) chrome/94.0.4590.2 mobile safari/537.36 chrome-lighthouse\", ]; const patternsToRemove = new Set<string>( ChromeLighthouseUserAgentStrings.map(isbotMatches).flat(), ); const isbot: (ua: string) => boolean = createIsbotFromList( list.filter( (record: string): boolean => patternsToRemove.has(record) === false, ), ); Create a custom isbot that considers another pattern as a bot, which is not included in the package originally. import { createIsbotFromList, list } from \"isbot\"; const isbot = createIsbotFromList(list.concat(\"shmulik\")); Definitions Bot. Autonomous program imitating or replacing some aspect of a human behaviour, performing repetitive tasks much faster than human users could. Good bot. Automated programs who visit websites in order to collect useful information. Web crawlers, site scrapers, stress testers, preview builders and other programs are welcomed on most websites because they serve purposes of mutual benefits. Bad bot. Programs which are designed to perform malicious actions, ultimately hurting businesses. Testing credential databases, DDoS attacks, spam bots. Clarifications What does \"isbot\" do? This package aims to identify \"Good bots\". Those who voluntarily identify themselves by setting a unique, preferably descriptive, user agent, usually by setting a dedicated request header. What doesn't \"isbot\" do? It does not try to recognise malicious bots or programs disguising themselves as real users. Why would I want to identify good bots? Recognising good bots such as web crawlers is useful for multiple purposes. Although it is not recommended to serve different content to web crawlers like Googlebot, you can still elect to Flag pageviews to consider with business analysis. Prefer to serve cached content and relieve service load. Omit third party solutions' code (tags, pixels) and reduce costs. It is not recommended to whitelist requests for any reason based on user agent header only. Instead, other methods of identification can be added such as reverse dns lookup. How isbot maintains accuracy isbot is an asset when it can most accurately identify bots by the user agent string. It uses expansive and regularly updated lists of user agent strings to create a regular expression that matches bots and only bots. And above everything else, it is maintained by a community of contributers who help keep the list up to date. Fallback The pattern uses lookbehind methods which are not supported in all environments. A fallback is provided for environments that do not support lookbehind. The fallback is less accurate. The test suite includes a percentage of false positives and false negatives which is deemed acceptable for the fallback: 1% false positive and 75% bot coverage. Data sources We use external data sources on top of our own lists to keep up to date Crawlers user agents user-agents.net monperrus/crawler-user-agents Kikobeats/top-crawler-agents myip.ms matomo.org A Manual list Non bot user agents user-agents npm package A Manual list Missing something? Please open an issue Major releases breaking changes (full changelog) Version 5 Remove named export \"pattern\" from the interface, instead use \"getPattern\" method Version 4 Remove isbot function default export in favour of a named export. import { isbot } from \"isbot\"; Version 3 Remove testing for node 6 and 8 Version 2 Change return value for isbot: true instead of matched string Version 1 No functional change"
  },
  "src/frontend/app-client/node_modules/isexe/README.html": {
    "href": "src/frontend/app-client/node_modules/isexe/README.html",
    "title": "isexe",
    "summary": "isexe Minimal module to check if a file is executable, and a normal file. Uses fs.stat and tests against the PATHEXT environment variable on Windows. USAGE var isexe = require('isexe') isexe('some-file-name', function (err, isExe) { if (err) { console.error('probably file does not exist or something', err) } else if (isExe) { console.error('this thing can be run') } else { console.error('cannot be run') } }) // same thing but synchronous, throws errors var isExe = isexe.sync('some-file-name') // treat errors as just \"not executable\" isexe('maybe-missing-file', { ignoreErrors: true }, callback) var isExe = isexe.sync('maybe-missing-file', { ignoreErrors: true }) API isexe(path, [options], [callback]) Check if the path is executable. If no callback provided, and a global Promise object is available, then a Promise will be returned. Will raise whatever errors may be raised by fs.stat, unless options.ignoreErrors is set to true. isexe.sync(path, [options]) Same as isexe but returns the value and throws any errors raised. Options ignoreErrors Treat all errors as \"no, this is not executable\", but don't raise them. uid Number to use as the user id gid Number to use as the group id pathExt List of path extensions to use instead of PATHEXT environment variable on Windows."
  },
  "src/frontend/app-client/node_modules/jackspeak/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/jackspeak/LICENSE.html",
    "title": "Blue Oak Model License",
    "summary": "Blue Oak Model License Version 1.0.0 Purpose This license gives everyone as much permission to work with this software as possible, while protecting contributors from liability. Acceptance In order to receive this license, you must agree to its rules. The rules of this license are both obligations under that agreement and conditions to your license. You must not do anything with this software that triggers a rule that you cannot or will not follow. Copyright Each contributor licenses you to do everything with this software that would otherwise infringe that contributor's copyright in it. Notices You must ensure that everyone who gets a copy of any part of this software from you, with or without changes, also gets the text of this license or a link to https://blueoakcouncil.org/license/1.0.0. Excuse If anyone notifies you in writing that you have not complied with Notices, you can keep your license by taking all practical steps to comply within 30 days after the notice. If you do not do so, your license ends immediately. Patent Each contributor licenses you to do everything with this software that would otherwise infringe any patent claims they can license or become able to license. Reliability No contributor can revoke this license. No Liability As far as the law allows, this software comes as is, without any warranty or condition, and no contributor will be liable to anyone for any damages related to this software or this license, under any kind of legal claim."
  },
  "src/frontend/app-client/node_modules/jackspeak/README.html": {
    "href": "src/frontend/app-client/node_modules/jackspeak/README.html",
    "title": "jackspeak",
    "summary": "jackspeak A very strict and proper argument parser. Validate string, boolean, and number options, from the command line and the environment. Call the jack method with a config object, and then chain methods off of it. At the end, call the .parse() method, and you'll get an object with positionals and values members. Any unrecognized configs or invalid values will throw an error. As long as you define configs using object literals, types will be properly inferred and TypeScript will know what kinds of things you got. If you give it a prefix for environment variables, then defaults will be read from the environment, and parsed values written back to it, so you can easily pass configs through to child processes. Automatically generates a usage/help banner by calling the .usage() method. Unless otherwise noted, all methods return the object itself. USAGE import { jack } from 'jackspeak' // this works too: // const { jack } = require('jackspeak') const { positionals, values } = jack({ envPrefix: 'FOO' }) .flag({ asdf: { description: 'sets the asfd flag', short: 'a', default: true }, 'no-asdf': { description: 'unsets the asdf flag', short: 'A' }, foo: { description: 'another boolean', short: 'f' }, }) .optList({ 'ip-addrs': { description: 'addresses to ip things', delim: ',', // defaults to '\\n' default: ['127.0.0.1'], }, }) .parse([ 'some', 'positional', '--ip-addrs', '192.168.0.1', '--ip-addrs', '1.1.1.1', 'args', '--foo', // sets the foo flag '-A', // short for --no-asdf, sets asdf flag to false ]) console.log(process.env.FOO_ASDF) // '0' console.log(process.env.FOO_FOO) // '1' console.log(values) // { // 'ip-addrs': ['192.168.0.1', '1.1.1.1'], // foo: true, // asdf: false, // } console.log(process.env.FOO_IP_ADDRS) // '192.168.0.1,1.1.1.1' console.log(positionals) // ['some', 'positional', 'args'] jack(options: JackOptions = {}) => Jack Returns a Jack object that can be used to chain and add field definitions. The other methods (apart from validate(), parse(), and usage() obviously) return the same Jack object, updated with the new types, so they can be chained together as shown in the code examples. Options: allowPositionals Defaults to true. Set to false to not allow any positional arguments. envPrefix Set to a string to write configs to and read configs from the environment. For example, if set to MY_APP then the foo-bar config will default based on the value of env.MY_APP_FOO_BAR and will write back to that when parsed. Boolean values are written as '1' and '0', and will be treated as true if they're '1' or false otherwise. Number values are written with their toString() representation. Strings are just strings. Any value with multiple: true will be represented in the environment split by a delimiter, which defaults to \\n. env The place to read/write environment variables. Defaults to process.env. usage A short usage string to print at the top of the help banner. stopAtPositional Boolean, default false. Stop parsing opts and flags at the first positional argument. This is useful if you want to pass certain options to subcommands, like some programs do, so you can stop parsing and pass the positionals to the subcommand to parse. stopAtPositionalTest Conditional stopAtPositional. Provide a function that takes a positional argument string and returns boolean. If it returns true, then parsing will stop. Useful when some subcommands should parse the rest of the command line options, and others should not. Jack.heading(text: string, level?: 1 | 2 | 3 | 4 | 5 | 6) Define a short string heading, used in the usage() output. Indentation of the heading and subsequent description/config usage entries (up until the next heading) is set by the heading level. If the first usage item defined is a heading, it is always treated as level 1, regardless of the argument provided. Headings level 1 and 2 will have a line of padding underneath them. Headings level 3 through 6 will not. Jack.description(text: string, { pre?: boolean } = {}) Define a long string description, used in the usage() output. If the pre option is set to true, then whitespace will not be normalized. However, if any line is too long for the width allotted, it will still be wrapped. Option Definitions Configs are defined by calling the appropriate field definition method with an object where the keys are the long option name, and the value defines the config. Options: type Only needed for the addFields method, as the others set it implicitly. Can be 'string', 'boolean', or 'number'. multiple Only needed for the addFields method, as the others set it implicitly. Set to true to define an array type. This means that it can be set on the CLI multiple times, set as an array in the values and it is represented in the environment as a delimited string. short A one-character shorthand for the option. description Some words to describe what this option is and why you'd set it. hint (Only relevant for non-boolean types) The thing to show in the usage output, like --option=<hint> validate A function that returns false (or throws) if an option value is invalid. validOptions An array of strings or numbers that define the valid values that can be set. This is not allowed on boolean (flag) options. May be used along with a validate() method. default A default value for the field. Note that this may be overridden by an environment variable, if present. Jack.flag({ [option: string]: definition, ... }) Define one or more boolean fields. Boolean options may be set to false by using a --no-${optionName} argument, which will be implicitly created if it's not defined to be something else. If a boolean option named no-${optionName} with the same multiple setting is in the configuration, then that will be treated as a negating flag. Jack.flagList({ [option: string]: definition, ... }) Define one or more boolean array fields. Jack.num({ [option: string]: definition, ... }) Define one or more number fields. These will be set in the environment as a stringified number, and included in the values object as a number. Jack.numList({ [option: string]: definition, ... }) Define one or more number list fields. These will be set in the environment as a delimited set of stringified numbers, and included in the values as a number array. Jack.opt({ [option: string]: definition, ... }) Define one or more string option fields. Jack.optList({ [option: string]: definition, ... }) Define one or more string list fields. Jack.addFields({ [option: string]: definition, ... }) Define one or more fields of any type. Note that type and multiple must be set explicitly on each definition when using this method. Actions Use these methods on a Jack object that's already had its config fields defined. Jack.parse(args: string[] = process.argv): { positionals: string[], values: OptionsResults } Parse the arguments list, write to the environment if envPrefix is set, and returned the parsed values and remaining positional arguments. Jack.validate(o: any): asserts o is OptionsResults Throws an error if the object provided is not a valid result set, for the configurations defined thusfar. Jack.usage(): string Returns the compiled usage string, with all option descriptions and heading/description text, wrapped to the appropriate width for the terminal. Jack.setConfigValues(options: OptionsResults, src?: string) Validate the options argument, and set the default value for each field that appears in the options. Values provided will be overridden by environment variables or command line arguments. Jack.usageMarkdown(): string Returns the compiled usage string, with all option descriptions and heading/description text, but as markdown instead of formatted for a terminal, for generating HTML documentation for your CLI. Some Example Code Also see the examples folder import { jack } from 'jackspeak' const j = jack({ // Optional // This will be auto-generated from the descriptions if not supplied // top level usage line, printed by -h // will be auto-generated if not specified usage: 'foo [options] <files>', }) .heading('The best Foo that ever Fooed') .description( ` Executes all the files and interprets their output as TAP formatted test result data. To parse TAP data from stdin, specify \"-\" as a filename. `, ) // flags don't take a value, they're boolean on or off, and can be // turned off by prefixing with `--no-` // so this adds support for -b to mean --bail, or -B to mean --no-bail .flag({ flag: { // specify a short value if you like. this must be a single char short: 'f', // description is optional as well. description: `Make the flags wave`, // default value for flags is 'false', unless you change it default: true, }, 'no-flag': { // you can can always negate a flag with `--no-flag` // specifying a negate option will let you define a short // single-char option for negation. short: 'F', description: `Do not wave the flags`, }, }) // Options that take a value are specified with `opt()` .opt({ reporter: { short: 'R', description: 'the style of report to display', }, }) // if you want a number, say so, and jackspeak will enforce it .num({ jobs: { short: 'j', description: 'how many jobs to run in parallel', default: 1, }, }) // A list is an option that can be specified multiple times, // to expand into an array of all the settings. Normal opts // will just give you the last value specified. .optList({ 'node-arg': {}, }) // a flagList is an array of booleans, so `-ddd` is [true, true, true] // count the `true` values to treat it as a counter. .flagList({ debug: { short: 'd' }, }) // opts take a value, and is set to the string in the results // you can combine multiple short-form flags together, but // an opt will end the combine chain, posix-style. So, // -bofilename would be like --bail --output-file=filename .opt({ 'output-file': { short: 'o', // optional: make it -o<file> in the help output insead of -o<value> hint: 'file', description: `Send the raw output to the specified file.`, }, }) // now we can parse argv like this: const { values, positionals } = j.parse(process.argv) // or decide to show the usage banner console.log(j.usage()) // or validate an object config we got from somewhere else try { j.validate(someConfig) } catch (er) { console.error('someConfig is not valid!', er) } Name The inspiration for this module is yargs, which is pirate talk themed. Yargs has all the features, and is infinitely flexible. \"Jackspeak\" is the slang of the royal navy. This module does not have all the features. It is declarative and rigid by design."
  },
  "src/frontend/app-client/node_modules/jiti/README.html": {
    "href": "src/frontend/app-client/node_modules/jiti/README.html",
    "title": "jiti",
    "summary": "jiti This is the active development branch. Check out jiti/v1 for legacy v1 docs and code. \uD83C\uDF1F Used in Docusaurus, ESLint, FormKit, Histoire, Knip, Nitro, Nuxt, PostCSS loader, Rsbuild, Size Limit, Slidev, Tailwindcss, Tokenami, UnoCSS, WXT, Winglang, Graphql code generator, Lingui, Scaffdog, Storybook, ...UnJS ecosystem, ...60M+ npm monthly downloads, ...6M+ public repositories. ✅ Features Seamless TypeScript and ESM syntax support for Node.js Seamless interoperability between ESM and CommonJS Asynchronous API to replace import() Synchronous API to replace require() (deprecated) Super slim and zero dependency Custom resolve aliases Smart syntax detection to avoid extra transforms Node.js native require.cache integration Filesystem transpile with hard disk caches ESM Loader support JSX support (opt-in) Important To enhance compatibility, jiti >=2.1 enabled interopdefault using a new Proxy method. If you migrated to 2.0.0 earlier, this might have caused behavior changes. In case of any issues during the upgrade, please report so we can investigate to solve them. \uD83D\uDE4F\uD83C\uDFFC \uD83D\uDCA1 Usage CLI You can use jiti CLI to quickly run any script with TypeScript and native ESM support! npx jiti ./index.ts Programmatic Initialize a jiti instance: // ESM import { createJiti } from \"jiti\"; const jiti = createJiti(import.meta.url); // CommonJS (deprecated) const { createJiti } = require(\"jiti\"); const jiti = createJiti(__filename); Import (async) and resolve with ESM compatibility: // jiti.import(id) is similar to import(id) const mod = await jiti.import(\"./path/to/file.ts\"); // jiti.esmResolve(id) is similar to import.meta.resolve(id) const resolvedPath = jiti.esmResolve(\"./src\"); If you need the default export of module, you can use jiti.import(id, { default: true }) as shortcut to mod?.default ?? mod. // shortcut to mod?.default ?? mod const modDefault = await jiti.import(\"./path/to/file.ts\", { default: true }); CommonJS (sync & deprecated): // jiti() is similar to require(id) const mod = jiti(\"./path/to/file.ts\"); // jiti.resolve() is similar to require.resolve(id) const resolvedPath = jiti.resolve(\"./src\"); You can also pass options as the second argument: const jiti = createJiti(import.meta.url, { debug: true }); Register global ESM loader You can globally register jiti using global hooks. (Important: Requires Node.js > 20) import \"jiti/register\"; Or: node --import jiti/register index.ts \uD83C\uDF88 jiti/native You can alias jiti to jiti/native to directly depend on runtime's import.meta.resolve and dynamic import() support. This allows easing up the ecosystem transition to runtime native support by giving the same API of jiti. ⚙️ Options debug Type: Boolean Default: false Environment variable: JITI_DEBUG Enable verbose logging. You can use JITI_DEBUG=1 <your command> to enable it. fsCache Type: Boolean | String Default: true Environment variable: JITI_FS_CACHE Filesystem source cache (enabled by default) By default (when is true), jiti uses node_modules/.cache/jiti (if exists) or {TMP_DIR}/jiti. Note: It is recommended that this option be enabled for better performance. moduleCache Type: String Default: true Environment variable: JITI_MODULE_CACHE Runtime module cache (enabled by default). Disabling allows editing code and importing the same module multiple times. When enabled, jiti integrates with Node.js native CommonJS cache-store. transform Type: Function Default: Babel (lazy loaded) Transform function. See src/babel for more details sourceMaps Type: Boolean Default false Environment variable: JITI_SOURCE_MAPS Add inline source map to transformed source for better debugging. interopDefault Type: Boolean Default: true Environment variable: JITI_INTEROP_DEFAULT Jiti combines module exports with the default export using an internal Proxy to improve compatibility with mixed CJS/ESM usage. You can check the current implementation here. alias Type: Object Default: - Environment variable: JITI_ALIAS You can also pass an object to the environment variable for inline config. Example: JITI_ALIAS='{\"~/*\": \"./src/*\"}' jiti .... Custom alias map used to resolve IDs. nativeModules Type: Array Default: ['typescript'] Environment variable: JITI_NATIVE_MODULES List of modules (within node_modules) to always use native require() for them. transformModules Type: Array Default: [] Environment variable: JITI_TRANSFORM_MODULES List of modules (within node_modules) to transform them regardless of syntax. importMeta Parent module's import.meta context to use for ESM resolution. (only used for jiti/native import). tryNative Type: Boolean Default: Enabled if bun is detected Environment variable: JITI_TRY_NATIVE Try to use native require and import without jiti transformations first. jsx Type: Boolean | {options} Default: false Environment Variable: JITI_JSX Enable JSX support using @babel/plugin-transform-react-jsx. See test/fixtures/jsx for framework integration examples. Development Clone this repository Enable Corepack using corepack enable Install dependencies using pnpm install Run pnpm dev Run pnpm jiti ./test/path/to/file.ts License Published under the MIT license. Made by @pi0 and community \uD83D\uDC9B"
  },
  "src/frontend/app-client/node_modules/js-beautify/README.html": {
    "href": "src/frontend/app-client/node_modules/js-beautify/README.html",
    "title": "Contributors Needed",
    "summary": "This little beautifier will reformat and re-indent bookmarklets, ugly JavaScript, unpack scripts packed by Dean Edward’s popular packer, as well as partly deobfuscate scripts processed by the npm package javascript-obfuscator. Open beautifier.io to try it out. Options are available via the UI. Contributors Needed I'm putting this front and center above because existing owners have very limited time to work on this project currently. This is a popular project and widely used but it desperately needs contributors who have time to commit to fixing both customer facing bugs and underlying problems with the internal design and implementation. If you are interested, please take a look at the CONTRIBUTING.md then fix an issue marked with the \"Good first issue\" label and submit a PR. Repeat as often as possible. Thanks! Installation You can install the beautifier for Node.js or Python. Node.js JavaScript You may install the NPM package js-beautify. When installed globally, it provides an executable js-beautify script. As with the Python script, the beautified result is sent to stdout unless otherwise configured. $ npm -g install js-beautify $ js-beautify foo.js You can also use js-beautify as a node library (install locally, the npm default): $ npm install js-beautify Node.js JavaScript (vNext) The above install the latest stable release. To install beta or RC versions: $ npm install js-beautify@next Web Library The beautifier can be added on your page as web library. JS Beautifier is hosted on two CDN services: cdnjs and rawgit. To pull the latest version from one of these services include one set of the script tags below in your document: <script src=\"https://cdnjs.cloudflare.com/ajax/libs/js-beautify/1.15.4/beautify.js\"></script> <script src=\"https://cdnjs.cloudflare.com/ajax/libs/js-beautify/1.15.4/beautify-css.js\"></script> <script src=\"https://cdnjs.cloudflare.com/ajax/libs/js-beautify/1.15.4/beautify-html.js\"></script> <script src=\"https://cdnjs.cloudflare.com/ajax/libs/js-beautify/1.15.4/beautify.min.js\"></script> <script src=\"https://cdnjs.cloudflare.com/ajax/libs/js-beautify/1.15.4/beautify-css.min.js\"></script> <script src=\"https://cdnjs.cloudflare.com/ajax/libs/js-beautify/1.15.4/beautify-html.min.js\"></script> Example usage of a JS tag in html: <!DOCTYPE html> <html lang=\"en\"> <body> . . . <script src=\"https://cdnjs.cloudflare.com/ajax/libs/js-beautify/1.15.4/beautify.min.js\"></script> <script src=\"script.js\"></script> </body> </html> Older versions are available by changing the version number. Disclaimer: These are free services, so there are no uptime or support guarantees. Python To install the Python version of the beautifier: $ pip install jsbeautifier Unlike the JavaScript version, the Python version can only reformat JavaScript. It does not work against HTML or CSS files, but you can install css-beautify for CSS: $ pip install cssbeautifier Usage You can beautify JavaScript using JS Beautifier in your web browser, or on the command-line using Node.js or Python. Web Browser Open beautifier.io. Options are available via the UI. Web Library After you embed the <script> tags in your html file, they expose three functions: js_beautify, css_beautify, and html_beautify Example usage of beautifying a json string: const options = { indent_size: 2, space_in_empty_paren: true } const dataObj = {completed: false,id: 1,title: \"delectus aut autem\",userId: 1,} const dataJson = JSON.stringify(dataObj) js_beautify(dataJson, options) /* OUTPUT { \"completed\": false, \"id\": 1, \"title\": \"delectus aut autem\", \"userId\": 1, } */ Node.js JavaScript When installed globally, the beautifier provides an executable js-beautify script. The beautified result is sent to stdout unless otherwise configured. $ js-beautify foo.js To use js-beautify as a node library (after install locally), import and call the appropriate beautifier method for JavaScript (JS), CSS, or HTML. All three method signatures are beautify(code, options). code is the string of code to be beautified. options is an object with the settings you would like used to beautify the code. The configuration option names are the same as the CLI names but with underscores instead of dashes. For example, --indent-size 2 --space-in-empty-paren would be { indent_size: 2, space_in_empty_paren: true }. var beautify = require('js-beautify/js').js, fs = require('fs'); fs.readFile('foo.js', 'utf8', function (err, data) { if (err) { throw err; } console.log(beautify(data, { indent_size: 2, space_in_empty_paren: true })); }); If you are using ESM Imports, you can import js-beautify like this: // 'beautify' can be any name here. import beautify from 'js-beautify'; beautify.js(data, options); beautify.html(data, options); beautify.css(data, options); Python After installing, to beautify using Python: $ js-beautify file.js Beautified output goes to stdout by default. To use jsbeautifier as a library is simple: import jsbeautifier res = jsbeautifier.beautify('your JavaScript string') res = jsbeautifier.beautify_file('some_file.js') ...or, to specify some options: opts = jsbeautifier.default_options() opts.indent_size = 2 opts.space_in_empty_paren = True res = jsbeautifier.beautify('some JavaScript', opts) The configuration option names are the same as the CLI names but with underscores instead of dashes. The example above would be set on the command-line as --indent-size 2 --space-in-empty-paren. Options These are the command-line flags for both Python and JS scripts: CLI Options: -f, --file Input file(s) (Pass '-' for stdin) -r, --replace Write output in-place, replacing input -o, --outfile Write output to file (default stdout) --config Path to config file --type [js|css|html] [\"js\"] Select beautifier type (NOTE: Does *not* filter files, only defines which beautifier type to run) -q, --quiet Suppress logging to stdout -h, --help Show this help -v, --version Show the version Beautifier Options: -s, --indent-size Indentation size [4] -c, --indent-char Indentation character [\" \"] -t, --indent-with-tabs Indent with tabs, overrides -s and -c -e, --eol Character(s) to use as line terminators. [first newline in file, otherwise \"\\n] -n, --end-with-newline End output with newline --editorconfig Use EditorConfig to set up the options -l, --indent-level Initial indentation level [0] -p, --preserve-newlines Preserve line-breaks (--no-preserve-newlines disables) -m, --max-preserve-newlines Number of line-breaks to be preserved in one chunk [10] -P, --space-in-paren Add padding spaces within paren, ie. f( a, b ) -E, --space-in-empty-paren Add a single space inside empty paren, ie. f( ) -j, --jslint-happy Enable jslint-stricter mode -a, --space-after-anon-function Add a space before an anonymous function's parens, ie. function () --space-after-named-function Add a space before a named function's parens, i.e. function example () -b, --brace-style [collapse|expand|end-expand|none][,preserve-inline] [collapse,preserve-inline] -u, --unindent-chained-methods Don't indent chained method calls -B, --break-chained-methods Break chained method calls across subsequent lines -k, --keep-array-indentation Preserve array indentation -x, --unescape-strings Decode printable characters encoded in xNN notation -w, --wrap-line-length Wrap lines that exceed N characters [0] -X, --e4x Pass E4X xml literals through untouched --good-stuff Warm the cockles of Crockford's heart -C, --comma-first Put commas at the beginning of new line instead of end -O, --operator-position Set operator position (before-newline|after-newline|preserve-newline) [before-newline] --indent-empty-lines Keep indentation on empty lines --templating List of templating languages (auto,django,erb,handlebars,php,smarty,angular) [\"auto\"] auto = none in JavaScript, all in HTML Which correspond to the underscored option keys for both library interfaces defaults per CLI options { \"indent_size\": 4, \"indent_char\": \" \", \"indent_with_tabs\": false, \"editorconfig\": false, \"eol\": \"\\n\", \"end_with_newline\": false, \"indent_level\": 0, \"preserve_newlines\": true, \"max_preserve_newlines\": 10, \"space_in_paren\": false, \"space_in_empty_paren\": false, \"jslint_happy\": false, \"space_after_anon_function\": false, \"space_after_named_function\": false, \"brace_style\": \"collapse\", \"unindent_chained_methods\": false, \"break_chained_methods\": false, \"keep_array_indentation\": false, \"unescape_strings\": false, \"wrap_line_length\": 0, \"e4x\": false, \"comma_first\": false, \"operator_position\": \"before-newline\", \"indent_empty_lines\": false, \"templating\": [\"auto\"] } defaults not exposed in the cli { \"eval_code\": false, \"space_before_conditional\": true } Notice not all defaults are exposed via the CLI. Historically, the Python and JS APIs have not been 100% identical. There are still a few other additional cases keeping us from 100% API-compatibility. Loading settings from environment or .jsbeautifyrc (JavaScript-Only) In addition to CLI arguments, you may pass config to the JS executable via: any jsbeautify_-prefixed environment variables a JSON-formatted file indicated by the --config parameter a .jsbeautifyrc file containing JSON data at any level of the filesystem above $PWD Configuration sources provided earlier in this stack will override later ones. Setting inheritance and Language-specific overrides The settings are a shallow tree whose values are inherited for all languages, but can be overridden. This works for settings passed directly to the API in either implementation. In the JavaScript implementation, settings loaded from a config file, such as .jsbeautifyrc, can also use inheritance/overriding. Below is an example configuration tree showing all the supported locations for language override nodes. We'll use indent_size to discuss how this configuration would behave, but any number of settings can be inherited or overridden: { \"indent_size\": 4, \"html\": { \"end_with_newline\": true, \"js\": { \"indent_size\": 2 }, \"css\": { \"indent_size\": 2 } }, \"css\": { \"indent_size\": 1 }, \"js\": { \"preserve-newlines\": true } } Using the above example would have the following result: HTML files Inherit indent_size of 4 spaces from the top-level setting. The files would also end with a newline. JavaScript and CSS inside HTML Inherit the HTML end_with_newline setting. Override their indentation to 2 spaces. CSS files Override the top-level setting to an indent_size of 1 space. JavaScript files Inherit indent_size of 4 spaces from the top-level setting. Set preserve-newlines to true. CSS & HTML In addition to the js-beautify executable, css-beautify and html-beautify are also provided as an easy interface into those scripts. Alternatively, js-beautify --css or js-beautify --html will accomplish the same thing, respectively. // Programmatic access var beautify_js = require('js-beautify'); // also available under \"js\" export var beautify_css = require('js-beautify').css; var beautify_html = require('js-beautify').html; // All methods accept two arguments, the string to be beautified, and an options object. The CSS & HTML beautifiers are much simpler in scope, and possess far fewer options. CSS Beautifier Options: -s, --indent-size Indentation size [4] -c, --indent-char Indentation character [\" \"] -t, --indent-with-tabs Indent with tabs, overrides -s and -c -e, --eol Character(s) to use as line terminators. (default newline - \"\\\\n\") -n, --end-with-newline End output with newline -b, --brace-style [collapse|expand] [\"collapse\"] -L, --selector-separator-newline Add a newline between multiple selectors -N, --newline-between-rules Add a newline between CSS rules --indent-empty-lines Keep indentation on empty lines HTML Beautifier Options: -s, --indent-size Indentation size [4] -c, --indent-char Indentation character [\" \"] -t, --indent-with-tabs Indent with tabs, overrides -s and -c -e, --eol Character(s) to use as line terminators. (default newline - \"\\\\n\") -n, --end-with-newline End output with newline -p, --preserve-newlines Preserve existing line-breaks (--no-preserve-newlines disables) -m, --max-preserve-newlines Maximum number of line-breaks to be preserved in one chunk [10] -I, --indent-inner-html Indent <head> and <body> sections. Default is false. -b, --brace-style [collapse-preserve-inline|collapse|expand|end-expand|none] [\"collapse\"] -S, --indent-scripts [keep|separate|normal] [\"normal\"] -w, --wrap-line-length Maximum characters per line (0 disables) [250] -A, --wrap-attributes Wrap attributes to new lines [auto|force|force-aligned|force-expand-multiline|aligned-multiple|preserve|preserve-aligned] [\"auto\"] -M, --wrap-attributes-min-attrs Minimum number of html tag attributes for force wrap attribute options [2] -i, --wrap-attributes-indent-size Indent wrapped attributes to after N characters [indent-size] (ignored if wrap-attributes is \"aligned\") -d, --inline List of tags to be considered inline tags --inline_custom_elements Inline custom elements [true] -U, --unformatted List of tags (defaults to inline) that should not be reformatted -T, --content_unformatted List of tags (defaults to pre) whose content should not be reformatted -E, --extra_liners List of tags (defaults to [head,body,/html] that should have an extra newline before them. --editorconfig Use EditorConfig to set up the options --indent_scripts Sets indent level inside script tags (\"normal\", \"keep\", \"separate\") --unformatted_content_delimiter Keep text content together between this string [\"\"] --indent-empty-lines Keep indentation on empty lines --templating List of templating languages (auto,none,django,erb,handlebars,php,smarty,angular) [\"auto\"] auto = none in JavaScript, all in html Directives Directives let you control the behavior of the Beautifier from within your source files. Directives are placed in comments inside the file. Directives are in the format /* beautify {name}:{value} */ in CSS and JavaScript. In HTML they are formatted as <!-- beautify {name}:{value} -->. Ignore directive The ignore directive makes the beautifier completely ignore part of a file, treating it as literal text that is not parsed. The input below will remain unchanged after beautification: // Use ignore when the content is not parsable in the current language, JavaScript in this case. var a = 1; /* beautify ignore:start */ {This is some strange{template language{using open-braces? /* beautify ignore:end */ Preserve directive NOTE: this directive only works in HTML and JavaScript, not CSS. The preserve directive makes the Beautifier parse and then keep the existing formatting of a section of code. The input below will remain unchanged after beautification: // Use preserve when the content is valid syntax in the current language, JavaScript in this case. // This will parse the code and preserve the existing formatting. /* beautify preserve:start */ { browserName: 'internet explorer', platform: 'Windows 7', version: '8' } /* beautify preserve:end */ License You are free to use this in any way you want, in case you find this useful or working for you but you must keep the copyright notice and license. (MIT) Credits Created by Einar Lielmanis, einar@beautifier.io Python version flourished by Stefano Sanfilippo a.little.coder@gmail.com Command-line for node.js by Daniel Stockman daniel.stockman@gmail.com Maintained and expanded by Liam Newman bitwiseman@beautifier.io Thanks also to Jason Diamond, Patrick Hof, Nochum Sossonko, Andreas Schneider, Dave Vasilevsky, Vital Batmanov, Ron Baldwin, Gabriel Harrison, Chris J. Shull, Mathias Bynens, Vittorio Gambaletta and others. (README.md: js-beautify@1.15.4)"
  },
  "src/frontend/app-client/node_modules/js-cookie/README.html": {
    "href": "src/frontend/app-client/node_modules/js-cookie/README.html",
    "title": "JavaScript Cookie",
    "summary": "JavaScript Cookie A simple, lightweight JavaScript API for handling cookies Works in all browsers Accepts any character Heavily tested No dependency Supports ES modules Supports AMD/CommonJS RFC 6265 compliant Useful Wiki Enable custom encoding/decoding < 800 bytes gzipped! \uD83D\uDC49\uD83D\uDC49 If you're viewing this at https://github.com/js-cookie/js-cookie, you're reading the documentation for the main branch. View documentation for the latest release. \uD83D\uDC48\uD83D\uDC48 Installation NPM JavaScript Cookie supports npm under the name js-cookie. npm i js-cookie The npm package has a module field pointing to an ES module variant of the library, mainly to provide support for ES module aware bundlers, whereas its browser field points to an UMD module for full backward compatibility. Not all browsers support ES modules natively yet. For this reason the npm package/release provides both the ES and UMD module variant and you may want to include the ES module along with the UMD fallback to account for this: CDN Alternatively, include js-cookie via jsDelivr CDN. Basic Usage Create a cookie, valid across the entire site: Cookies.set('name', 'value') Create a cookie that expires 7 days from now, valid across the entire site: Cookies.set('name', 'value', { expires: 7 }) Create an expiring cookie, valid to the path of the current page: Cookies.set('name', 'value', { expires: 7, path: '' }) Read cookie: Cookies.get('name') // => 'value' Cookies.get('nothing') // => undefined Read all visible cookies: Cookies.get() // => { name: 'value' } Note: It is not possible to read a particular cookie by passing one of the cookie attributes (which may or may not have been used when writing the cookie in question): Cookies.get('foo', { domain: 'sub.example.com' }) // `domain` won't have any effect...! The cookie with the name foo will only be available on .get() if it's visible from where the code is called; the domain and/or path attribute will not have an effect when reading. Delete cookie: Cookies.remove('name') Delete a cookie valid to the path of the current page: Cookies.set('name', 'value', { path: '' }) Cookies.remove('name') // fail! Cookies.remove('name', { path: '' }) // removed! IMPORTANT! When deleting a cookie and you're not relying on the default attributes, you must pass the exact same path and domain attributes that were used to set the cookie: Cookies.remove('name', { path: '', domain: '.yourdomain.com' }) Note: Removing a nonexistent cookie neither raises any exception nor returns any value. Namespace conflicts If there is any danger of a conflict with the namespace Cookies, the noConflict method will allow you to define a new namespace and preserve the original one. This is especially useful when running the script on third party sites e.g. as part of a widget or SDK. // Assign the js-cookie api to a different variable and restore the original \"window.Cookies\" var Cookies2 = Cookies.noConflict() Cookies2.set('name', 'value') Note: The .noConflict method is not necessary when using AMD or CommonJS, thus it is not exposed in those environments. Encoding This project is RFC 6265 compliant. All special characters that are not allowed in the cookie-name or cookie-value are encoded with each one's UTF-8 Hex equivalent using percent-encoding. The only character in cookie-name or cookie-value that is allowed and still encoded is the percent % character, it is escaped in order to interpret percent input as literal. Please note that the default encoding/decoding strategy is meant to be interoperable only between cookies that are read/written by js-cookie. To override the default encoding/decoding strategy you need to use a converter. Note: According to RFC 6265, your cookies may get deleted if they are too big or there are too many cookies in the same domain, more details here. Cookie Attributes Cookie attribute defaults can be set globally by creating an instance of the api via withAttributes(), or individually for each call to Cookies.set(...) by passing a plain object as the last argument. Per-call attributes override the default attributes. expires Define when the cookie will be removed. Value must be a Number which will be interpreted as days from time of creation or a Date instance. If omitted, the cookie becomes a session cookie. To create a cookie that expires in less than a day, you can check the FAQ on the Wiki. Default: Cookie is removed when the user closes the browser. Examples: Cookies.set('name', 'value', { expires: 365 }) Cookies.get('name') // => 'value' Cookies.remove('name') path A String indicating the path where the cookie is visible. Default: / Examples: Cookies.set('name', 'value', { path: '' }) Cookies.get('name') // => 'value' Cookies.remove('name', { path: '' }) Note regarding Internet Explorer: Due to an obscure bug in the underlying WinINET InternetGetCookie implementation, IE’s document.cookie will not return a cookie if it was set with a path attribute containing a filename. (From Internet Explorer Cookie Internals (FAQ)) This means one cannot set a path using window.location.pathname in case such pathname contains a filename like so: /check.html (or at least, such cookie cannot be read correctly). In fact, you should never allow untrusted input to set the cookie attributes or you might be exposed to a XSS attack. domain A String indicating a valid domain where the cookie should be visible. The cookie will also be visible to all subdomains. Default: Cookie is visible only to the domain or subdomain of the page where the cookie was created, except for Internet Explorer (see below). Examples: Assuming a cookie that is being created on site.com: Cookies.set('name', 'value', { domain: 'subdomain.site.com' }) Cookies.get('name') // => undefined (need to read at 'subdomain.site.com') Note regarding Internet Explorer default behavior: Q3: If I don’t specify a DOMAIN attribute (for) a cookie, IE sends it to all nested subdomains anyway? A: Yes, a cookie set on example.com will be sent to sub2.sub1.example.com. Internet Explorer differs from other browsers in this regard. (From Internet Explorer Cookie Internals (FAQ)) This means that if you omit the domain attribute, it will be visible for a subdomain in IE. secure Either true or false, indicating if the cookie transmission requires a secure protocol (https). Default: No secure protocol requirement. Examples: Cookies.set('name', 'value', { secure: true }) Cookies.get('name') // => 'value' Cookies.remove('name') sameSite A String, allowing to control whether the browser is sending a cookie along with cross-site requests. Default: not set. Note that more recent browsers are making \"Lax\" the default value even without specifiying anything here. Examples: Cookies.set('name', 'value', { sameSite: 'strict' }) Cookies.get('name') // => 'value' Cookies.remove('name') Setting up defaults const api = Cookies.withAttributes({ path: '/', domain: '.example.com' }) Converters Read Create a new instance of the api that overrides the default decoding implementation. All get methods that rely in a proper decoding to work, such as Cookies.get() and Cookies.get('name'), will run the given converter for each cookie. The returned value will be used as the cookie value. Example from reading one of the cookies that can only be decoded using the escape function: document.cookie = 'escaped=%u5317' document.cookie = 'default=%E5%8C%97' var cookies = Cookies.withConverter({ read: function (value, name) { if (name === 'escaped') { return unescape(value) } // Fall back to default for all other cookies return Cookies.converter.read(value, name) } }) cookies.get('escaped') // 北 cookies.get('default') // 北 cookies.get() // { escaped: '北', default: '北' } Write Create a new instance of the api that overrides the default encoding implementation: Cookies.withConverter({ write: function (value, name) { return value.toUpperCase() } }) TypeScript declarations npm i @types/js-cookie Server-side integration Check out the Servers Docs Contributing Check out the Contributing Guidelines Security For vulnerability reports, send an e-mail to js-cookie at googlegroups dot com Releasing Releasing should be done via the Release GitHub Actions workflow, so that published packages on npmjs.com have package provenance. GitHub releases are created as a draft and need to be published manually! (This is so we are able to craft suitable release notes before publishing.) Supporters Many thanks to BrowserStack for providing unlimited browser testing free of cost. Authors Klaus Hartl Fagner Brack And awesome contributors"
  },
  "src/frontend/app-client/node_modules/js-tokens/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/js-tokens/CHANGELOG.html",
    "title": "",
    "summary": "Version 4.0.0 (2018-01-28) Added: Support for ES2018. The only change needed was recognizing the s regex flag. Changed: All tokens returned by the matchToToken function now have a closed property. It is set to undefined for the tokens where “closed” doesn’t make sense. This means that all tokens objects have the same shape, which might improve performance. These are the breaking changes: '/a/s'.match(jsTokens) no longer returns ['/', 'a', '/', 's'], but ['/a/s']. (There are of course other variations of this.) Code that rely on some token objects not having the closed property could now behave differently. Version 3.0.2 (2017-06-28) No code changes. Just updates to the readme. Version 3.0.1 (2017-01-30) Fixed: ES2015 unicode escapes with more than 6 hex digits are now matched correctly. Version 3.0.0 (2017-01-11) This release contains one breaking change, that should improve performance in V8: So how can you, as a JavaScript developer, ensure that your RegExps are fast? If you are not interested in hooking into RegExp internals, make sure that neither the RegExp instance, nor its prototype is modified in order to get the best performance: var re = /./g; re.exec(''); // Fast path. re.new_property = 'slow'; This module used to export a single regex, with .matchToToken bolted on, just like in the above example. This release changes the exports of the module to avoid this issue. Before: import jsTokens from \"js-tokens\" // or: var jsTokens = require(\"js-tokens\") var matchToToken = jsTokens.matchToToken After: import jsTokens, {matchToToken} from \"js-tokens\" // or: var jsTokens = require(\"js-tokens\").default var matchToToken = require(\"js-tokens\").matchToToken Version 2.0.0 (2016-06-19) Added: Support for ES2016. In other words, support for the ** exponentiation operator. These are the breaking changes: '**'.match(jsTokens) no longer returns ['*', '*'], but ['**']. '**='.match(jsTokens) no longer returns ['*', '*='], but ['**=']. Version 1.0.3 (2016-03-27) Improved: Made the regex ever so slightly smaller. Updated: The readme. Version 1.0.2 (2015-10-18) Improved: Limited npm package contents for a smaller download. Thanks to @zertosh! Version 1.0.1 (2015-06-20) Fixed: Declared an undeclared variable. Version 1.0.0 (2015-02-26) Changed: Merged the 'operator' and 'punctuation' types into 'punctuator'. That type is now equivalent to the Punctuator token in the ECMAScript specification. (Backwards-incompatible change.) Fixed: A - followed by a number is now correctly matched as a punctuator followed by a number. It used to be matched as just a number, but there is no such thing as negative number literals. (Possibly backwards-incompatible change.) Version 0.4.1 (2015-02-21) Added: Support for the regex u flag. Version 0.4.0 (2015-02-21) Improved: jsTokens.matchToToken performance. Added: Support for octal and binary number literals. Added: Support for template strings. Version 0.3.1 (2015-01-06) Fixed: Support for unicode spaces. They used to be allowed in names (which is very confusing), and some unicode newlines were wrongly allowed in strings and regexes. Version 0.3.0 (2014-12-19) Changed: The jsTokens.names array has been replaced with the jsTokens.matchToToken function. The capturing groups of jsTokens are no longer part of the public API; instead use said function. See this gist for an example. (Backwards-incompatible change.) Changed: The empty string is now considered an “invalid” token, instead an “empty” token (its own group). (Backwards-incompatible change.) Removed: component support. (Backwards-incompatible change.) Version 0.2.0 (2014-06-19) Changed: Match ES6 function arrows (=>) as an operator, instead of its own category (“functionArrow”), for simplicity. (Backwards-incompatible change.) Added: ES6 splats (...) are now matched as an operator (instead of three punctuations). (Backwards-incompatible change.) Version 0.1.0 (2014-03-08) Initial release."
  },
  "src/frontend/app-client/node_modules/js-tokens/README.html": {
    "href": "src/frontend/app-client/node_modules/js-tokens/README.html",
    "title": "Overview",
    "summary": "Overview A regex that tokenizes JavaScript. var jsTokens = require(\"js-tokens\").default var jsString = \"var foo=opts.foo;\\n...\" jsString.match(jsTokens) // [\"var\", \" \", \"foo\", \"=\", \"opts\", \".\", \"foo\", \";\", \"\\n\", ...] Installation npm install js-tokens import jsTokens from \"js-tokens\" // or: var jsTokens = require(\"js-tokens\").default Usage jsTokens A regex with the g flag that matches JavaScript tokens. The regex always matches, even invalid JavaScript and the empty string. The next match is always directly after the previous. var token = matchToToken(match) import {matchToToken} from \"js-tokens\" // or: var matchToToken = require(\"js-tokens\").matchToToken Takes a match returned by jsTokens.exec(string), and returns a {type: String, value: String} object. The following types are available: string comment regex number name punctuator whitespace invalid Multi-line comments and strings also have a closed property indicating if the token was closed or not (see below). Comments and strings both come in several flavors. To distinguish them, check if the token starts with //, /*, ', \" or `. Names are ECMAScript IdentifierNames, that is, including both identifiers and keywords. You may use is-keyword-js to tell them apart. Whitespace includes both line terminators and other whitespace. ECMAScript support The intention is to always support the latest ECMAScript version whose feature set has been finalized. If adding support for a newer version requires changes, a new version with a major verion bump will be released. Currently, ECMAScript 2018 is supported. Invalid code handling Unterminated strings are still matched as strings. JavaScript strings cannot contain (unescaped) newlines, so unterminated strings simply end at the end of the line. Unterminated template strings can contain unescaped newlines, though, so they go on to the end of input. Unterminated multi-line comments are also still matched as comments. They simply go on to the end of the input. Unterminated regex literals are likely matched as division and whatever is inside the regex. Invalid ASCII characters have their own capturing group. Invalid non-ASCII characters are treated as names, to simplify the matching of names (except unicode spaces which are treated as whitespace). Note: See also the ES2018 section. Regex literals may contain invalid regex syntax. They are still matched as regex literals. They may also contain repeated regex flags, to keep the regex simple. Strings may contain invalid escape sequences. Limitations Tokenizing JavaScript using regexes—in fact, one single regex—won’t be perfect. But that’s not the point either. You may compare jsTokens with esprima by using esprima-compare.js. See npm run esprima-compare! Template string interpolation Template strings are matched as single tokens, from the starting ` to the ending `, including interpolations (whose tokens are not matched individually). Matching template string interpolations requires recursive balancing of { and }—something that JavaScript regexes cannot do. Only one level of nesting is supported. Division and regex literals collision Consider this example: var g = 9.82 var number = bar / 2/g var regex = / 2/g A human can easily understand that in the number line we’re dealing with division, and in the regex line we’re dealing with a regex literal. How come? Because humans can look at the whole code to put the / characters in context. A JavaScript regex cannot. It only sees forwards. (Well, ES2018 regexes can also look backwards. See the ES2018 section). When the jsTokens regex scans throught the above, it will see the following at the end of both the number and regex rows: / 2/g It is then impossible to know if that is a regex literal, or part of an expression dealing with division. Here is a similar case: foo /= 2/g foo(/= 2/g) The first line divides the foo variable with 2/g. The second line calls the foo function with the regex literal /= 2/g. Again, since jsTokens only sees forwards, it cannot tell the two cases apart. There are some cases where we can tell division and regex literals apart, though. First off, we have the simple cases where there’s only one slash in the line: var foo = 2/g foo /= 2 Regex literals cannot contain newlines, so the above cases are correctly identified as division. Things are only problematic when there are more than one non-comment slash in a single line. Secondly, not every character is a valid regex flag. var number = bar / 2/e The above example is also correctly identified as division, because e is not a valid regex flag. I initially wanted to future-proof by allowing [a-zA-Z]* (any letter) as flags, but it is not worth it since it increases the amount of ambigous cases. So only the standard g, m, i, y and u flags are allowed. This means that the above example will be identified as division as long as you don’t rename the e variable to some permutation of gmiyus 1 to 6 characters long. Lastly, we can look forward for information. If the token following what looks like a regex literal is not valid after a regex literal, but is valid in a division expression, then the regex literal is treated as division instead. For example, a flagless regex cannot be followed by a string, number or name, but all of those three can be the denominator of a division. Generally, if what looks like a regex literal is followed by an operator, the regex literal is treated as division instead. This is because regexes are seldomly used with operators (such as +, *, && and ==), but division could likely be part of such an expression. Please consult the regex source and the test cases for precise information on when regex or division is matched (should you need to know). In short, you could sum it up as: If the end of a statement looks like a regex literal (even if it isn’t), it will be treated as one. Otherwise it should work as expected (if you write sane code). ES2018 ES2018 added some nice regex improvements to the language. Unicode property escapes should allow telling names and invalid non-ASCII characters apart without blowing up the regex size. Lookbehind assertions should allow matching telling division and regex literals apart in more cases. Named capture groups might simplify some things. These things would be nice to do, but are not critical. They probably have to wait until the oldest maintained Node.js LTS release supports those features. License MIT."
  },
  "src/frontend/app-client/node_modules/jsesc/README.html": {
    "href": "src/frontend/app-client/node_modules/jsesc/README.html",
    "title": "jsesc",
    "summary": "jsesc Given some data, jsesc returns a stringified representation of that data. jsesc is similar to JSON.stringify() except: it outputs JavaScript instead of JSON by default, enabling support for data structures like ES6 maps and sets; it offers many options to customize the output; its output is ASCII-safe by default, thanks to its use of escape sequences where needed. For any input, jsesc generates the shortest possible valid printable-ASCII-only output. Here’s an online demo. jsesc’s output can be used instead of JSON.stringify’s to avoid mojibake and other encoding issues, or even to avoid errors when passing JSON-formatted data (which may contain U+2028 LINE SEPARATOR, U+2029 PARAGRAPH SEPARATOR, or lone surrogates) to a JavaScript parser or an UTF-8 encoder. Installation Via npm: npm install jsesc In Node.js: const jsesc = require('jsesc'); API jsesc(value, options) This function takes a value and returns an escaped version of the value where any characters that are not printable ASCII symbols are escaped using the shortest possible (but valid) escape sequences for use in JavaScript strings. The first supported value type is strings: jsesc('Ich ♥ Bücher'); // → 'Ich \\\\u2665 B\\\\xFCcher' jsesc('foo \uD834\uDF06 bar'); // → 'foo \\\\uD834\\\\uDF06 bar' Instead of a string, the value can also be an array, an object, a map, a set, or a buffer. In such cases, jsesc returns a stringified version of the value where any characters that are not printable ASCII symbols are escaped in the same way. // Escaping an array jsesc([ 'Ich ♥ Bücher', 'foo \uD834\uDF06 bar' ]); // → '[\\'Ich \\\\u2665 B\\\\xFCcher\\',\\'foo \\\\uD834\\\\uDF06 bar\\']' // Escaping an object jsesc({ 'Ich ♥ Bücher': 'foo \uD834\uDF06 bar' }); // → '{\\'Ich \\\\u2665 B\\\\xFCcher\\':\\'foo \\\\uD834\\\\uDF06 bar\\'}' The optional options argument accepts an object with the following options: quotes The default value for the quotes option is 'single'. This means that any occurrences of ' in the input string are escaped as \\', so that the output can be used in a string literal wrapped in single quotes. jsesc('`Lorem` ipsum \"dolor\" sit \\'amet\\' etc.'); // → 'Lorem ipsum \"dolor\" sit \\\\\\'amet\\\\\\' etc.' jsesc('`Lorem` ipsum \"dolor\" sit \\'amet\\' etc.', { 'quotes': 'single' }); // → '`Lorem` ipsum \"dolor\" sit \\\\\\'amet\\\\\\' etc.' // → \"`Lorem` ipsum \\\"dolor\\\" sit \\\\'amet\\\\' etc.\" If you want to use the output as part of a string literal wrapped in double quotes, set the quotes option to 'double'. jsesc('`Lorem` ipsum \"dolor\" sit \\'amet\\' etc.', { 'quotes': 'double' }); // → '`Lorem` ipsum \\\\\"dolor\\\\\" sit \\'amet\\' etc.' // → \"`Lorem` ipsum \\\\\\\"dolor\\\\\\\" sit 'amet' etc.\" If you want to use the output as part of a template literal (i.e. wrapped in backticks), set the quotes option to 'backtick'. jsesc('`Lorem` ipsum \"dolor\" sit \\'amet\\' etc.', { 'quotes': 'backtick' }); // → '\\\\`Lorem\\\\` ipsum \"dolor\" sit \\'amet\\' etc.' // → \"\\\\`Lorem\\\\` ipsum \\\"dolor\\\" sit 'amet' etc.\" // → `\\\\\\`Lorem\\\\\\` ipsum \"dolor\" sit 'amet' etc.` This setting also affects the output for arrays and objects: jsesc({ 'Ich ♥ Bücher': 'foo \uD834\uDF06 bar' }, { 'quotes': 'double' }); // → '{\"Ich \\\\u2665 B\\\\xFCcher\":\"foo \\\\uD834\\\\uDF06 bar\"}' jsesc([ 'Ich ♥ Bücher', 'foo \uD834\uDF06 bar' ], { 'quotes': 'double' }); // → '[\"Ich \\\\u2665 B\\\\xFCcher\",\"foo \\\\uD834\\\\uDF06 bar\"]' numbers The default value for the numbers option is 'decimal'. This means that any numeric values are represented using decimal integer literals. Other valid options are binary, octal, and hexadecimal, which result in binary integer literals, octal integer literals, and hexadecimal integer literals, respectively. jsesc(42, { 'numbers': 'binary' }); // → '0b101010' jsesc(42, { 'numbers': 'octal' }); // → '0o52' jsesc(42, { 'numbers': 'decimal' }); // → '42' jsesc(42, { 'numbers': 'hexadecimal' }); // → '0x2A' wrap The wrap option takes a boolean value (true or false), and defaults to false (disabled). When enabled, the output is a valid JavaScript string literal wrapped in quotes. The type of quotes can be specified through the quotes setting. jsesc('Lorem ipsum \"dolor\" sit \\'amet\\' etc.', { 'quotes': 'single', 'wrap': true }); // → '\\'Lorem ipsum \"dolor\" sit \\\\\\'amet\\\\\\' etc.\\'' // → \"\\'Lorem ipsum \\\"dolor\\\" sit \\\\\\'amet\\\\\\' etc.\\'\" jsesc('Lorem ipsum \"dolor\" sit \\'amet\\' etc.', { 'quotes': 'double', 'wrap': true }); // → '\"Lorem ipsum \\\\\"dolor\\\\\" sit \\'amet\\' etc.\"' // → \"\\\"Lorem ipsum \\\\\\\"dolor\\\\\\\" sit \\'amet\\' etc.\\\"\" es6 The es6 option takes a boolean value (true or false), and defaults to false (disabled). When enabled, any astral Unicode symbols in the input are escaped using ECMAScript 6 Unicode code point escape sequences instead of using separate escape sequences for each surrogate half. If backwards compatibility with ES5 environments is a concern, don’t enable this setting. If the json setting is enabled, the value for the es6 setting is ignored (as if it was false). // By default, the `es6` option is disabled: jsesc('foo \uD834\uDF06 bar \uD83D\uDCA9 baz'); // → 'foo \\\\uD834\\\\uDF06 bar \\\\uD83D\\\\uDCA9 baz' // To explicitly disable it: jsesc('foo \uD834\uDF06 bar \uD83D\uDCA9 baz', { 'es6': false }); // → 'foo \\\\uD834\\\\uDF06 bar \\\\uD83D\\\\uDCA9 baz' // To enable it: jsesc('foo \uD834\uDF06 bar \uD83D\uDCA9 baz', { 'es6': true }); // → 'foo \\\\u{1D306} bar \\\\u{1F4A9} baz' escapeEverything The escapeEverything option takes a boolean value (true or false), and defaults to false (disabled). When enabled, all the symbols in the output are escaped — even printable ASCII symbols. jsesc('lolwat\"foo\\'bar', { 'escapeEverything': true }); // → '\\\\x6C\\\\x6F\\\\x6C\\\\x77\\\\x61\\\\x74\\\\\"\\\\x66\\\\x6F\\\\x6F\\\\\\'\\\\x62\\\\x61\\\\x72' // → \"\\\\x6C\\\\x6F\\\\x6C\\\\x77\\\\x61\\\\x74\\\\\\\"\\\\x66\\\\x6F\\\\x6F\\\\'\\\\x62\\\\x61\\\\x72\" This setting also affects the output for string literals within arrays and objects. minimal The minimal option takes a boolean value (true or false), and defaults to false (disabled). When enabled, only a limited set of symbols in the output are escaped: U+0000 \\0 U+0008 \\b U+0009 \\t U+000A \\n U+000C \\f U+000D \\r U+005C \\\\ U+2028 \\u2028 U+2029 \\u2029 whatever symbol is being used for wrapping string literals (based on the quotes option) lone surrogates Note: with this option enabled, jsesc output is no longer guaranteed to be ASCII-safe. jsesc('foo\\u2029bar\\nbaz©qux\uD834\uDF06flops', { 'minimal': false }); // → 'foo\\\\u2029bar\\\\nbaz©qux\uD834\uDF06flops' isScriptContext The isScriptContext option takes a boolean value (true or false), and defaults to false (disabled). When enabled, occurrences of </script and </style in the output are escaped as <\\/script and <\\/style, and <!-- is escaped as \\x3C!-- (or \\u003C!-- when the json option is enabled). This setting is useful when jsesc’s output ends up as part of a <script> or <style> element in an HTML document. jsesc('foo</script>bar', { 'isScriptContext': true }); // → 'foo<\\\\/script>bar' compact The compact option takes a boolean value (true or false), and defaults to true (enabled). When enabled, the output for arrays and objects is as compact as possible; it’s not formatted nicely. jsesc({ 'Ich ♥ Bücher': 'foo \uD834\uDF06 bar' }, { 'compact': true // this is the default }); // → '{\\'Ich \\u2665 B\\xFCcher\\':\\'foo \\uD834\\uDF06 bar\\'}' jsesc({ 'Ich ♥ Bücher': 'foo \uD834\uDF06 bar' }, { 'compact': false }); // → '{\\n\\t\\'Ich \\u2665 B\\xFCcher\\': \\'foo \\uD834\\uDF06 bar\\'\\n}' jsesc([ 'Ich ♥ Bücher', 'foo \uD834\uDF06 bar' ], { 'compact': false }); // → '[\\n\\t\\'Ich \\u2665 B\\xFCcher\\',\\n\\t\\'foo \\uD834\\uDF06 bar\\'\\n]' This setting has no effect on the output for strings. indent The indent option takes a string value, and defaults to '\\t'. When the compact setting is disabled (false), the value of the indent option is used to format the output for arrays and objects. jsesc({ 'Ich ♥ Bücher': 'foo \uD834\uDF06 bar' }, { 'compact': false, 'indent': '\\t' // this is the default }); // → '{\\n\\t\\'Ich \\u2665 B\\xFCcher\\': \\'foo \\uD834\\uDF06 bar\\'\\n}' jsesc({ 'Ich ♥ Bücher': 'foo \uD834\uDF06 bar' }, { 'compact': false, 'indent': ' ' }); // → '{\\n \\'Ich \\u2665 B\\xFCcher\\': \\'foo \\uD834\\uDF06 bar\\'\\n}' jsesc([ 'Ich ♥ Bücher', 'foo \uD834\uDF06 bar' ], { 'compact': false, 'indent': ' ' }); // → '[\\n \\'Ich \\u2665 B\\xFCcher\\',\\n\\ t\\'foo \\uD834\\uDF06 bar\\'\\n]' This setting has no effect on the output for strings. indentLevel The indentLevel option takes a numeric value, and defaults to 0. It represents the current indentation level, i.e. the number of times the value of the indent option is repeated. jsesc(['a', 'b', 'c'], { 'compact': false, 'indentLevel': 1 }); // → '[\\n\\t\\t\\'a\\',\\n\\t\\t\\'b\\',\\n\\t\\t\\'c\\'\\n\\t]' jsesc(['a', 'b', 'c'], { 'compact': false, 'indentLevel': 2 }); // → '[\\n\\t\\t\\t\\'a\\',\\n\\t\\t\\t\\'b\\',\\n\\t\\t\\t\\'c\\'\\n\\t\\t]' json The json option takes a boolean value (true or false), and defaults to false (disabled). When enabled, the output is valid JSON. Hexadecimal character escape sequences and the \\v or \\0 escape sequences are not used. Setting json: true implies quotes: 'double', wrap: true, es6: false, although these values can still be overridden if needed — but in such cases, the output won’t be valid JSON anymore. jsesc('foo\\x00bar\\xFF\\uFFFDbaz', { 'json': true }); // → '\"foo\\\\u0000bar\\\\u00FF\\\\uFFFDbaz\"' jsesc({ 'foo\\x00bar\\xFF\\uFFFDbaz': 'foo\\x00bar\\xFF\\uFFFDbaz' }, { 'json': true }); // → '{\"foo\\\\u0000bar\\\\u00FF\\\\uFFFDbaz\":\"foo\\\\u0000bar\\\\u00FF\\\\uFFFDbaz\"}' jsesc([ 'foo\\x00bar\\xFF\\uFFFDbaz', 'foo\\x00bar\\xFF\\uFFFDbaz' ], { 'json': true }); // → '[\"foo\\\\u0000bar\\\\u00FF\\\\uFFFDbaz\",\"foo\\\\u0000bar\\\\u00FF\\\\uFFFDbaz\"]' // Values that are acceptable in JSON but aren’t strings, arrays, or object // literals can’t be escaped, so they’ll just be preserved: jsesc([ 'foo\\x00bar', [1, '©', { 'foo': true, 'qux': null }], 42 ], { 'json': true }); // → '[\"foo\\\\u0000bar\",[1,\"\\\\u00A9\",{\"foo\":true,\"qux\":null}],42]' // Values that aren’t allowed in JSON are run through `JSON.stringify()`: jsesc([ undefined, -Infinity ], { 'json': true }); // → '[null,null]' Note: Using this option on objects or arrays that contain non-string values relies on JSON.stringify(). For legacy environments like IE ≤ 7, use a JSON polyfill. lowercaseHex The lowercaseHex option takes a boolean value (true or false), and defaults to false (disabled). When enabled, any alphabetical hexadecimal digits in escape sequences as well as any hexadecimal integer literals (see the numbers option) in the output are in lowercase. jsesc('Ich ♥ Bücher', { 'lowercaseHex': true }); // → 'Ich \\\\u2665 B\\\\xfccher' // ^^ jsesc(42, { 'numbers': 'hexadecimal', 'lowercaseHex': true }); // → '0x2a' // ^^ jsesc.version A string representing the semantic version number. Using the jsesc binary To use the jsesc binary in your shell, simply install jsesc globally using npm: npm install -g jsesc After that you’re able to escape strings from the command line: $ jsesc 'föo ♥ bår \uD834\uDF06 baz' f\\xF6o \\u2665 b\\xE5r \\uD834\\uDF06 baz To escape arrays or objects containing string values, use the -o/--object option: $ jsesc --object '{ \"föo\": \"♥\", \"bår\": \"\uD834\uDF06 baz\" }' {'f\\xF6o':'\\u2665','b\\xE5r':'\\uD834\\uDF06 baz'} To prettify the output in such cases, use the -p/--pretty option: $ jsesc --pretty '{ \"föo\": \"♥\", \"bår\": \"\uD834\uDF06 baz\" }' { 'f\\xF6o': '\\u2665', 'b\\xE5r': '\\uD834\\uDF06 baz' } For valid JSON output, use the -j/--json option: $ jsesc --json --pretty '{ \"föo\": \"♥\", \"bår\": \"\uD834\uDF06 baz\" }' { \"f\\u00F6o\": \"\\u2665\", \"b\\u00E5r\": \"\\uD834\\uDF06 baz\" } Read a local JSON file, escape any non-ASCII symbols, and save the result to a new file: $ jsesc --json --object < data-raw.json > data-escaped.json Or do the same with an online JSON file: $ curl -sL \"http://git.io/aorKgQ\" | jsesc --json --object > data-escaped.json See jsesc --help for the full list of options. Support As of v3.0.0, jsesc supports Node.js v6+ only. Older versions (up to jsesc v1.3.0) support Chrome 27, Firefox 3, Safari 4, Opera 10, IE 6, Node.js v6.0.0, Narwhal 0.3.2, RingoJS 0.8-0.11, PhantomJS 1.9.0, and Rhino 1.7RC4. Note: Using the json option on objects or arrays that contain non-string values relies on JSON.parse(). For legacy environments like IE ≤ 7, use a JSON polyfill. Author Mathias Bynens License This library is available under the MIT license."
  },
  "src/frontend/app-client/node_modules/json-parse-even-better-errors/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/json-parse-even-better-errors/LICENSE.html",
    "title": "",
    "summary": "Copyright 2017 Kat Marchán Copyright npm, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. This library is a fork of 'better-json-errors' by Kat Marchán, extended and distributed under the terms of the MIT license above."
  },
  "src/frontend/app-client/node_modules/json-parse-even-better-errors/README.html": {
    "href": "src/frontend/app-client/node_modules/json-parse-even-better-errors/README.html",
    "title": "json-parse-even-better-errors",
    "summary": "json-parse-even-better-errors json-parse-even-better-errors is a Node.js library for getting nicer errors out of JSON.parse(), including context and position of the parse errors. It also preserves the newline and indentation styles of the JSON data, by putting them in the object or array in the Symbol.for('indent') and Symbol.for('newline') properties. Install $ npm install --save json-parse-even-better-errors Table of Contents Example Features Contributing API parse Example const parseJson = require('json-parse-even-better-errors') parseJson('\"foo\"') // returns the string 'foo' parseJson('garbage') // more useful error message parseJson.noExceptions('garbage') // returns undefined Features Like JSON.parse, but the errors are better. Strips a leading byte-order-mark that you sometimes get reading files. Has a noExceptions method that returns undefined rather than throwing. Attaches the newline character(s) used to the Symbol.for('newline') property on objects and arrays. Attaches the indentation character(s) used to the Symbol.for('indent') property on objects and arrays. Indentation To preserve indentation when the file is saved back to disk, use data[Symbol.for('indent')] as the third argument to JSON.stringify, and if you want to preserve windows \\r\\n newlines, replace the \\n chars in the string with data[Symbol.for('newline')]. For example: const txt = await readFile('./package.json', 'utf8') const data = parseJsonEvenBetterErrors(txt) const indent = Symbol.for('indent') const newline = Symbol.for('newline') // .. do some stuff to the data .. const string = JSON.stringify(data, null, data[indent]) + '\\n' const eolFixed = data[newline] === '\\n' ? string : string.replace(/\\n/g, data[newline]) await writeFile('./package.json', eolFixed) Indentation is determined by looking at the whitespace between the initial { and [ and the character that follows it. If you have lots of weird inconsistent indentation, then it won't track that or give you any way to preserve it. Whether this is a bug or a feature is debatable ;) API parse(txt, reviver = null, context = 20) Works just like JSON.parse, but will include a bit more information when an error happens, and attaches a Symbol.for('indent') and Symbol.for('newline') on objects and arrays. This throws a JSONParseError. parse.noExceptions(txt, reviver = null) Works just like JSON.parse, but will return undefined rather than throwing an error. class JSONParseError(er, text, context = 20, caller = null) Extends the JavaScript SyntaxError class to parse the message and provide better metadata. Pass in the error thrown by the built-in JSON.parse, and the text being parsed, and it'll parse out the bits needed to be helpful. context defaults to 20. Set a caller function to trim internal implementation details out of the stack trace. When calling parseJson, this is set to the parseJson function. If not set, then the constructor defaults to itself, so the stack trace will point to the spot where you call new JSONParseError."
  },
  "src/frontend/app-client/node_modules/json5/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/json5/LICENSE.html",
    "title": "",
    "summary": "MIT License Copyright (c) 2012-2018 Aseem Kishore, and others. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/json5/README.html": {
    "href": "src/frontend/app-client/node_modules/json5/README.html",
    "title": "JSON5 – JSON for Humans",
    "summary": "JSON5 – JSON for Humans JSON5 is an extension to the popular JSON file format that aims to be easier to write and maintain by hand (e.g. for config files). It is not intended to be used for machine-to-machine communication. (Keep using JSON or other file formats for that. \uD83D\uDE42) JSON5 was started in 2012, and as of 2022, now gets >65M downloads/week, ranks in the top 0.1% of the most depended-upon packages on npm, and has been adopted by major projects like Chromium, Next.js, Babel, Retool, WebStorm, and more. It's also natively supported on Apple platforms like MacOS and iOS. Formally, the JSON5 Data Interchange Format is a superset of JSON (so valid JSON files will always be valid JSON5 files) that expands its syntax to include some productions from ECMAScript 5.1 (ES5). It's also a strict subset of ES5, so valid JSON5 files will always be valid ES5. This JavaScript library is a reference implementation for JSON5 parsing and serialization, and is directly used in many of the popular projects mentioned above (where e.g. extreme performance isn't necessary), but others have created many other libraries across many other platforms. Summary of Features The following ECMAScript 5.1 features, which are not supported in JSON, have been extended to JSON5. Objects Object keys may be an ECMAScript 5.1 IdentifierName. Objects may have a single trailing comma. Arrays Arrays may have a single trailing comma. Strings Strings may be single quoted. Strings may span multiple lines by escaping new line characters. Strings may include character escapes. Numbers Numbers may be hexadecimal. Numbers may have a leading or trailing decimal point. Numbers may be IEEE 754 positive infinity, negative infinity, and NaN. Numbers may begin with an explicit plus sign. Comments Single and multi-line comments are allowed. White Space Additional white space characters are allowed. Example Kitchen-sink example: { // comments unquoted: 'and you can quote me on that', singleQuotes: 'I can use \"double quotes\" here', lineBreaks: \"Look, Mom! \\ No \\\\n's!\", hexadecimal: 0xdecaf, leadingDecimalPoint: .8675309, andTrailing: 8675309., positiveSign: +1, trailingComma: 'in objects', andIn: ['arrays',], \"backwardsCompatible\": \"with JSON\", } A more real-world example is this config file from the Chromium/Blink project. Specification For a detailed explanation of the JSON5 format, please read the official specification. Installation and Usage Node.js npm install json5 CommonJS const JSON5 = require('json5') Modules import JSON5 from 'json5' Browsers UMD <!-- This will create a global `JSON5` variable. --> <script src=\"https://unpkg.com/json5@2/dist/index.min.js\"></script> Modules <script type=\"module\"> import JSON5 from 'https://unpkg.com/json5@2/dist/index.min.mjs' </script> API The JSON5 API is compatible with the JSON API. JSON5.parse() Parses a JSON5 string, constructing the JavaScript value or object described by the string. An optional reviver function can be provided to perform a transformation on the resulting object before it is returned. Syntax JSON5.parse(text[, reviver]) Parameters text: The string to parse as JSON5. reviver: If a function, this prescribes how the value originally produced by parsing is transformed, before being returned. Return value The object corresponding to the given JSON5 text. JSON5.stringify() Converts a JavaScript value to a JSON5 string, optionally replacing values if a replacer function is specified, or optionally including only the specified properties if a replacer array is specified. Syntax JSON5.stringify(value[, replacer[, space]]) JSON5.stringify(value[, options]) Parameters value: The value to convert to a JSON5 string. replacer: A function that alters the behavior of the stringification process, or an array of String and Number objects that serve as a whitelist for selecting/filtering the properties of the value object to be included in the JSON5 string. If this value is null or not provided, all properties of the object are included in the resulting JSON5 string. space: A String or Number object that's used to insert white space into the output JSON5 string for readability purposes. If this is a Number, it indicates the number of space characters to use as white space; this number is capped at 10 (if it is greater, the value is just 10). Values less than 1 indicate that no space should be used. If this is a String, the string (or the first 10 characters of the string, if it's longer than that) is used as white space. If this parameter is not provided (or is null), no white space is used. If white space is used, trailing commas will be used in objects and arrays. options: An object with the following properties: replacer: Same as the replacer parameter. space: Same as the space parameter. quote: A String representing the quote character to use when serializing strings. Return value A JSON5 string representing the value. Node.js require() JSON5 files When using Node.js, you can require() JSON5 files by adding the following statement. require('json5/lib/register') Then you can load a JSON5 file with a Node.js require() statement. For example: const config = require('./config.json5') CLI Since JSON is more widely used than JSON5, this package includes a CLI for converting JSON5 to JSON and for validating the syntax of JSON5 documents. Installation npm install --global json5 Usage json5 [options] <file> If <file> is not provided, then STDIN is used. Options: -s, --space: The number of spaces to indent or t for tabs -o, --out-file [file]: Output to the specified file, otherwise STDOUT -v, --validate: Validate JSON5 but do not output JSON -V, --version: Output the version number -h, --help: Output usage information Contributing Development git clone https://github.com/json5/json5 cd json5 npm install When contributing code, please write relevant tests and run npm test and npm run lint before submitting pull requests. Please use an editor that supports EditorConfig. Issues To report bugs or request features regarding the JSON5 data format, please submit an issue to the official specification repository. Note that we will never add any features that make JSON5 incompatible with ES5; that compatibility is a fundamental premise of JSON5. To report bugs or request features regarding this JavaScript implementation of JSON5, please submit an issue to this repository. Security Vulnerabilities and Disclosures To report a security vulnerability, please follow the follow the guidelines described in our security policy. License MIT. See LICENSE.md for details. Credits Aseem Kishore founded this project. He wrote a blog post about the journey and lessons learned 10 years in. Michael Bolin independently arrived at and published some of these same ideas with awesome explanations and detail. Recommended reading: Suggested Improvements to JSON Douglas Crockford of course designed and built JSON, but his state machine diagrams on the JSON website, as cheesy as it may sound, gave us motivation and confidence that building a new parser to implement these ideas was within reach! The original implementation of JSON5 was also modeled directly off of Doug’s open-source json_parse.js parser. We’re grateful for that clean and well-documented code. Max Nanasy has been an early and prolific supporter, contributing multiple patches and ideas. Andrew Eisenberg contributed the original stringify method. Jordan Tucker has aligned JSON5 more closely with ES5, wrote the official JSON5 specification, completely rewrote the codebase from the ground up, and is actively maintaining this project."
  },
  "src/frontend/app-client/node_modules/jsonfile/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/jsonfile/CHANGELOG.html",
    "title": "",
    "summary": "6.1.0 / 2020-10-31 Add finalEOL option to disable writing final EOL (#115, #137) Update dependency (#138) 6.0.1 / 2020-03-07 Update dependency (#130) Fix code style (#129) 6.0.0 / 2020-02-24 BREAKING: Drop support for Node 6 & 8 (#128) BREAKING: Do not allow passing null as options to readFile() or writeFile() (#128) Refactor internals (#128) 5.0.0 / 2018-09-08 BREAKING: Drop Node 4 support BREAKING: If no callback is passed to an asynchronous method, a promise is now returned (#109) Cleanup docs 4.0.0 / 2017-07-12 BREAKING: Remove global spaces option. BREAKING: Drop support for Node 0.10, 0.12, and io.js. Remove undocumented passParsingErrors option. Added EOL override option to writeFile when using spaces. #89 3.0.1 / 2017-07-05 Fixed bug in writeFile when there was a serialization error & no callback was passed. In previous versions, an empty file would be written; now no file is written. 3.0.0 / 2017-04-25 Changed behavior of throws option for readFileSync; now does not throw filesystem errors when throws is false 2.4.0 / 2016-09-15 Changed added optional support for graceful-fs [#62] 2.3.1 / 2016-05-13 fix to support BOM. #45 2.3.0 / 2016-04-16 add throws to readFile(). See #39 add support for any arbitrary fs module. Useful with mock-fs 2.2.3 / 2015-10-14 include file name in parse error. See: https://github.com/jprichardson/node-jsonfile/pull/34 2.2.2 / 2015-09-16 split out tests into separate files fixed throws when set to true in readFileSync(). See: https://github.com/jprichardson/node-jsonfile/pull/33 2.2.1 / 2015-06-25 fixed regression when passing in string as encoding for options in writeFile() and writeFileSync(). See: https://github.com/jprichardson/node-jsonfile/issues/28 2.2.0 / 2015-06-25 added options.spaces to writeFile() and writeFileSync() 2.1.2 / 2015-06-22 fixed if passed readFileSync(file, 'utf8'). See: https://github.com/jprichardson/node-jsonfile/issues/25 2.1.1 / 2015-06-19 fixed regressions if null is passed for options. See: https://github.com/jprichardson/node-jsonfile/issues/24 2.1.0 / 2015-06-19 cleanup: JavaScript Standard Style, rename files, dropped terst for assert methods now support JSON revivers/replacers 2.0.1 / 2015-05-24 update license attribute https://github.com/jprichardson/node-jsonfile/pull/21 2.0.0 / 2014-07-28 added \\n to end of file on write. #14 added options.throws to readFileSync() dropped support for Node v0.8 1.2.0 / 2014-06-29 removed semicolons bugfix: passed options to fs.readFile and fs.readFileSync. This technically changes behavior, but changes it according to docs. #12 1.1.1 / 2013-11-11 fixed catching of callback bug (ffissore / #5) 1.1.0 / 2013-10-11 added options param to methods, (seanodell / #4) 1.0.1 / 2013-09-05 removed homepage field from package.json to remove NPM warning 1.0.0 / 2013-06-28 added .npmignore, #1 changed spacing default from 4 to 2 to follow Node conventions 0.0.1 / 2012-09-10 Initial release."
  },
  "src/frontend/app-client/node_modules/jsonfile/README.html": {
    "href": "src/frontend/app-client/node_modules/jsonfile/README.html",
    "title": "Node.js - jsonfile",
    "summary": "Node.js - jsonfile Easily read/write JSON files in Node.js. Note: this module cannot be used in the browser. Why? Writing JSON.stringify() and then fs.writeFile() and JSON.parse() with fs.readFile() enclosed in try/catch blocks became annoying. Installation npm install --save jsonfile API readFile(filename, [options], callback) readFileSync(filename, [options]) writeFile(filename, obj, [options], callback) writeFileSync(filename, obj, [options]) readFile(filename, [options], callback) options (object, default undefined): Pass in any fs.readFile options or set reviver for a JSON reviver. throws (boolean, default: true). If JSON.parse throws an error, pass this error to the callback. If false, returns null for the object. const jsonfile = require('jsonfile') const file = '/tmp/data.json' jsonfile.readFile(file, function (err, obj) { if (err) console.error(err) console.dir(obj) }) You can also use this method with promises. The readFile method will return a promise if you do not pass a callback function. const jsonfile = require('jsonfile') const file = '/tmp/data.json' jsonfile.readFile(file) .then(obj => console.dir(obj)) .catch(error => console.error(error)) readFileSync(filename, [options]) options (object, default undefined): Pass in any fs.readFileSync options or set reviver for a JSON reviver. throws (boolean, default: true). If an error is encountered reading or parsing the file, throw the error. If false, returns null for the object. const jsonfile = require('jsonfile') const file = '/tmp/data.json' console.dir(jsonfile.readFileSync(file)) writeFile(filename, obj, [options], callback) options: Pass in any fs.writeFile options or set replacer for a JSON replacer. Can also pass in spaces, or override EOL string or set finalEOL flag as false to not save the file with EOL at the end. const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFile(file, obj, function (err) { if (err) console.error(err) }) Or use with promises as follows: const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFile(file, obj) .then(res => { console.log('Write complete') }) .catch(error => console.error(error)) formatting with spaces: const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFile(file, obj, { spaces: 2 }, function (err) { if (err) console.error(err) }) overriding EOL: const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFile(file, obj, { spaces: 2, EOL: '\\r\\n' }, function (err) { if (err) console.error(err) }) disabling the EOL at the end of file: const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFile(file, obj, { spaces: 2, finalEOL: false }, function (err) { if (err) console.log(err) }) appending to an existing JSON file: You can use fs.writeFile option { flag: 'a' } to achieve this. const jsonfile = require('jsonfile') const file = '/tmp/mayAlreadyExistedData.json' const obj = { name: 'JP' } jsonfile.writeFile(file, obj, { flag: 'a' }, function (err) { if (err) console.error(err) }) writeFileSync(filename, obj, [options]) options: Pass in any fs.writeFileSync options or set replacer for a JSON replacer. Can also pass in spaces, or override EOL string or set finalEOL flag as false to not save the file with EOL at the end. const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFileSync(file, obj) formatting with spaces: const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFileSync(file, obj, { spaces: 2 }) overriding EOL: const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFileSync(file, obj, { spaces: 2, EOL: '\\r\\n' }) disabling the EOL at the end of file: const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFileSync(file, obj, { spaces: 2, finalEOL: false }) appending to an existing JSON file: You can use fs.writeFileSync option { flag: 'a' } to achieve this. const jsonfile = require('jsonfile') const file = '/tmp/mayAlreadyExistedData.json' const obj = { name: 'JP' } jsonfile.writeFileSync(file, obj, { flag: 'a' }) License (MIT License) Copyright 2012-2016, JP Richardson jprichardson@gmail.com"
  },
  "src/frontend/app-client/node_modules/lightningcss-win32-x64-msvc/README.html": {
    "href": "src/frontend/app-client/node_modules/lightningcss-win32-x64-msvc/README.html",
    "title": "",
    "summary": "This is the x86_64-pc-windows-msvc build of lightningcss. See https://github.com/parcel-bundler/lightningcss for details."
  },
  "src/frontend/app-client/node_modules/lightningcss/README.html": {
    "href": "src/frontend/app-client/node_modules/lightningcss/README.html",
    "title": "⚡️ Lightning CSS",
    "summary": "⚡️ Lightning CSS An extremely fast CSS parser, transformer, and minifier written in Rust. Use it with Parcel, as a standalone library or CLI, or via a plugin with any other tool. Features Extremely fast – Parsing and minifying large files is completed in milliseconds, often with significantly smaller output than other tools. See benchmarks below. Typed property values – many other CSS parsers treat property values as an untyped series of tokens. This means that each transformer that wants to do something with these values must interpret them itself, leading to duplicate work and inconsistencies. Lightning CSS parses all values using the grammar from the CSS specification, and exposes a specific value type for each property. Browser-grade parser – Lightning CSS is built on the cssparser and selectors crates created by Mozilla and used by Firefox and Servo. These provide a solid general purpose CSS-parsing foundation on top of which Lightning CSS implements support for all specific CSS rules and properties. Minification – One of the main purposes of Lightning CSS is to minify CSS to make it smaller. This includes many optimizations including: Combining longhand properties into shorthands where possible. Merging adjacent rules with the same selectors or declarations when it is safe to do so. Combining CSS transforms into a single matrix or vice versa when smaller. Removing vendor prefixes that are not needed, based on the provided browser targets. Reducing calc() expressions where possible. Converting colors to shorter hex notation where possible. Minifying gradients. Minifying CSS grid templates. Normalizing property value order. Removing default property sub-values which will be inferred by browsers. Many micro-optimizations, e.g. converting to shorter units, removing unnecessary quotation marks, etc. Vendor prefixing – Lightning CSS accepts a list of browser targets, and automatically adds (and removes) vendor prefixes. Browserslist configuration – Lightning CSS supports opt-in browserslist configuration discovery to resolve browser targets and integrate with your existing tools and config setup. Syntax lowering – Lightning CSS parses modern CSS syntax, and generates more compatible output where needed, based on browser targets. CSS Nesting Custom media queries (draft spec) Logical properties Color Level 5 color-mix() function Relative color syntax, e.g. lab(from purple calc(l * .8) a b) Color Level 4 lab(), lch(), oklab(), and oklch() colors color() function supporting predefined color spaces such as display-p3 and xyz Space separated components in rgb and hsl functions Hex with alpha syntax hwb() color syntax Percent syntax for opacity #rgba and #rrggbbaa hex colors Selectors :not with multiple arguments :lang with multiple arguments :dir :is Double position gradient stops (e.g. red 40% 80%) clamp(), round(), rem(), and mod() math functions Alignment shorthands (e.g. place-items) Two-value overflow shorthand Media query range syntax (e.g. @media (width <= 100px) or @media (100px < width < 500px)) Multi-value display property (e.g. inline flex) system-ui font family fallbacks CSS modules – Lightning CSS supports compiling a subset of CSS modules features. Locally scoped class and id selectors Locally scoped custom identifiers, e.g. @keyframes names, grid lines/areas, @counter-style names, etc. Opt-in support for locally scoped CSS variables and other dashed identifiers. :local() and :global() selectors The composes property Custom transforms – The Lightning CSS visitor API can be used to implement custom transform plugins. Documentation Lightning CSS can be used from Parcel, as a standalone library from JavaScript or Rust, using a standalone CLI, or wrapped as a plugin within any other tool. See the Lightning CSS website for documentation. Benchmarks $ node bench.js bootstrap-4.css cssnano: 544.809ms 159636 bytes esbuild: 17.199ms 160332 bytes lightningcss: 4.16ms 143091 bytes $ node bench.js animate.css cssnano: 283.105ms 71723 bytes esbuild: 11.858ms 72183 bytes lightningcss: 1.973ms 23666 bytes $ node bench.js tailwind.css cssnano: 2.198s 1925626 bytes esbuild: 107.668ms 1961642 bytes lightningcss: 43.368ms 1824130 bytes For more benchmarks comparing more tools and input, see here. Note that some of the tools shown perform unsafe optimizations that may change the behavior of the original CSS in favor of smaller file size. Lightning CSS does not do this – the output CSS should always behave identically to the input. Keep this in mind when comparing file sizes between tools."
  },
  "src/frontend/app-client/node_modules/lines-and-columns/README.html": {
    "href": "src/frontend/app-client/node_modules/lines-and-columns/README.html",
    "title": "lines-and-columns",
    "summary": "lines-and-columns Maps lines and columns to character offsets and back. This is useful for parsers and other text processors that deal in character ranges but process text with meaningful lines and columns. Install $ npm install [--save] lines-and-columns Usage import { LinesAndColumns } from 'lines-and-columns' const lines = new LinesAndColumns( `table { border: 0 }` ) lines.locationForIndex(9) // { line: 1, column: 1 } lines.indexForLocation({ line: 1, column: 2 }) // 10 License MIT"
  },
  "src/frontend/app-client/node_modules/lodash/README.html": {
    "href": "src/frontend/app-client/node_modules/lodash/README.html",
    "title": "lodash v4.17.21",
    "summary": "lodash v4.17.21 The Lodash library exported as Node.js modules. Installation Using npm: $ npm i -g npm $ npm i --save lodash In Node.js: // Load the full build. var _ = require('lodash'); // Load the core build. var _ = require('lodash/core'); // Load the FP build for immutable auto-curried iteratee-first data-last methods. var fp = require('lodash/fp'); // Load method categories. var array = require('lodash/array'); var object = require('lodash/fp/object'); // Cherry-pick methods for smaller browserify/rollup/webpack bundles. var at = require('lodash/at'); var curryN = require('lodash/fp/curryN'); See the package source for more details. Note: Install n_ for Lodash use in the Node.js < 6 REPL. Support Tested in Chrome 74-75, Firefox 66-67, IE 11, Edge 18, Safari 11-12, & Node.js 8-12. Automated browser & CI test runs are available."
  },
  "src/frontend/app-client/node_modules/lodash/release.html": {
    "href": "src/frontend/app-client/node_modules/lodash/release.html",
    "title": "",
    "summary": "npm run build npm run doc npm i git clone --depth=10 --branch=master git@github.com:lodash-archive/lodash-cli.git ./node_modules/lodash-cli mkdir -p ./node_modules/lodash-cli/node_modules/lodash; cd $_; cp ../../../../lodash.js ./lodash.js; cp ../../../../package.json ./package.json cd ../../; npm i --production; cd ../../ node ./node_modules/lodash-cli/bin/lodash core exports=node -o ./npm-package/core.js node ./node_modules/lodash-cli/bin/lodash modularize exports=node -o ./npm-package cp lodash.js npm-package/lodash.js cp dist/lodash.min.js npm-package/lodash.min.js cp LICENSE npm-package/LICENSE Clone two repos Bump lodash version in package.json, readme, package=locak, lodash.js npm run build npm run doc update mappings in ldoash-cli copy ldoash into lodash-cli node modules and package json. node ./node_modules/lodash-cli/bin/lodash core exports=node -o ./npm-package/core.js node ./node_modules/lodash-cli/bin/lodash modularize exports=node -o ./npm-package Clone the two repositories: $ git clone https://github.com/lodash/lodash.git $ git clone https://github.com/bnjmnt4n/lodash-cli.git Update lodash-cli to accomdate changes in lodash source. This can typically involve adding new function dependency mappings in lib/mappings.js. Sometimes, additional changes might be needed for more involved functions. In the lodash repository, update references to the lodash version in README.md, lodash.js, package.jsona nd package-lock.json Run: npm run build npm run doc node ../lodash-cli/bin/lodash core -o ./dist/lodash.core.js Add a commit and tag the release mkdir ../lodash-temp cp lodash.js dist/lodash.min.js dist/lodash.core.js dist/lodash.core.min.js ../lodash-temp/ node ../lodash-cli/bin/lodash modularize exports=node -o . cp ../lodash-temp/lodash.core.js core.js cp ../lodash-temp/lodash.core.min.js core.min.js cp ../lodash-temp/lodash.js lodash.js cp ../lodash-temp/lodash.min.js lodash.min.js ❯ node ../lodash-cli/bin/lodash modularize exports=es -o ."
  },
  "src/frontend/app-client/node_modules/loose-envify/README.html": {
    "href": "src/frontend/app-client/node_modules/loose-envify/README.html",
    "title": "loose-envify",
    "summary": "loose-envify Fast (and loose) selective process.env replacer using js-tokens instead of an AST. Works just like envify but much faster. Gotchas Doesn't handle broken syntax. Doesn't look inside embedded expressions in template strings. this won't work: console.log(`the current env is ${process.env.NODE_ENV}`); Doesn't replace oddly-spaced or oddly-commented expressions. this won't work: console.log(process./*won't*/env./*work*/NODE_ENV); Usage/Options loose-envify has the exact same interface as envify, including the CLI. Benchmark envify: $ for i in {1..5}; do node bench/bench.js 'envify'; done 708ms 727ms 791ms 719ms 720ms loose-envify: $ for i in {1..5}; do node bench/bench.js '../'; done 51ms 52ms 52ms 52ms 52ms"
  },
  "src/frontend/app-client/node_modules/lru-cache/README.html": {
    "href": "src/frontend/app-client/node_modules/lru-cache/README.html",
    "title": "lru cache",
    "summary": "lru cache A cache object that deletes the least-recently-used items. Installation: npm install lru-cache --save Usage: var LRU = require(\"lru-cache\") , options = { max: 500 , length: function (n, key) { return n * 2 + key.length } , dispose: function (key, n) { n.close() } , maxAge: 1000 * 60 * 60 } , cache = new LRU(options) , otherCache = new LRU(50) // sets just the max size cache.set(\"key\", \"value\") cache.get(\"key\") // \"value\" // non-string keys ARE fully supported // but note that it must be THE SAME object, not // just a JSON-equivalent object. var someObject = { a: 1 } cache.set(someObject, 'a value') // Object keys are not toString()-ed cache.set('[object Object]', 'a different value') assert.equal(cache.get(someObject), 'a value') // A similar object with same keys/values won't work, // because it's a different object identity assert.equal(cache.get({ a: 1 }), undefined) cache.reset() // empty the cache If you put more stuff in it, then items will fall out. If you try to put an oversized thing in it, then it'll fall out right away. Options max The maximum size of the cache, checked by applying the length function to all values in the cache. Not setting this is kind of silly, since that's the whole purpose of this lib, but it defaults to Infinity. Setting it to a non-number or negative number will throw a TypeError. Setting it to 0 makes it be Infinity. maxAge Maximum age in ms. Items are not pro-actively pruned out as they age, but if you try to get an item that is too old, it'll drop it and return undefined instead of giving it to you. Setting this to a negative value will make everything seem old! Setting it to a non-number will throw a TypeError. length Function that is used to calculate the length of stored items. If you're storing strings or buffers, then you probably want to do something like function(n, key){return n.length}. The default is function(){return 1}, which is fine if you want to store max like-sized things. The item is passed as the first argument, and the key is passed as the second argumnet. dispose Function that is called on items when they are dropped from the cache. This can be handy if you want to close file descriptors or do other cleanup tasks when items are no longer accessible. Called with key, value. It's called before actually removing the item from the internal cache, so if you want to immediately put it back in, you'll have to do that in a nextTick or setTimeout callback or it won't do anything. stale By default, if you set a maxAge, it'll only actually pull stale items out of the cache when you get(key). (That is, it's not pre-emptively doing a setTimeout or anything.) If you set stale:true, it'll return the stale value before deleting it. If you don't set this, then it'll return undefined when you try to get a stale entry, as if it had already been deleted. noDisposeOnSet By default, if you set a dispose() method, then it'll be called whenever a set() operation overwrites an existing key. If you set this option, dispose() will only be called when a key falls out of the cache, not when it is overwritten. updateAgeOnGet When using time-expiring entries with maxAge, setting this to true will make each item's effective time update to the current time whenever it is retrieved from cache, causing it to not expire. (It can still fall out of cache based on recency of use, of course.) API set(key, value, maxAge) get(key) => value Both of these will update the \"recently used\"-ness of the key. They do what you think. maxAge is optional and overrides the cache maxAge option if provided. If the key is not found, get() will return undefined. The key and val can be any value. peek(key) Returns the key value (or undefined if not found) without updating the \"recently used\"-ness of the key. (If you find yourself using this a lot, you might be using the wrong sort of data structure, but there are some use cases where it's handy.) del(key) Deletes a key out of the cache. reset() Clear the cache entirely, throwing away all values. has(key) Check if a key is in the cache, without updating the recent-ness or deleting it for being stale. forEach(function(value,key,cache), [thisp]) Just like Array.prototype.forEach. Iterates over all the keys in the cache, in order of recent-ness. (Ie, more recently used items are iterated over first.) rforEach(function(value,key,cache), [thisp]) The same as cache.forEach(...) but items are iterated over in reverse order. (ie, less recently used items are iterated over first.) keys() Return an array of the keys in the cache. values() Return an array of the values in the cache. length Return total length of objects in cache taking into account length options function. itemCount Return total quantity of objects currently in cache. Note, that stale (see options) items are returned as part of this item count. dump() Return an array of the cache entries ready for serialization and usage with 'destinationCache.load(arr)`. load(cacheEntriesArray) Loads another cache entries array, obtained with sourceCache.dump(), into the cache. The destination cache is reset before loading new entries prune() Manually iterates over the entire cache proactively pruning old entries"
  },
  "src/frontend/app-client/node_modules/lucide-react/README.html": {
    "href": "src/frontend/app-client/node_modules/lucide-react/README.html",
    "title": "Lucide React",
    "summary": "Lucide icon library for React applications. About · Icons · Documentation · License Lucide React Implementation of the lucide icon library for React applications. Installation pnpm add lucide-react npm install lucide-react yarn add lucide-react bun add lucide-react Documentation For full documentation, visit lucide.dev Community Join the Discord server to chat with the maintainers and other users. License Lucide is licensed under the ISC license. See LICENSE. Sponsors Awesome backers \uD83C\uDF7A"
  },
  "src/frontend/app-client/node_modules/math-intrinsics/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/math-intrinsics/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.1.0 - 2024-12-18 Commits [New] add round 7cfb044 [Tests] add attw e96be8f [Dev Deps] update @types/tape 30d0023 v1.0.0 - 2024-12-11 Commits Initial implementation, tests, readme, types b898caa Initial commit 02745b0 [New] add constants/maxArrayLength, mod b978178 npm init a39fc57 Only apps should have lockfiles 9451580"
  },
  "src/frontend/app-client/node_modules/math-intrinsics/README.html": {
    "href": "src/frontend/app-client/node_modules/math-intrinsics/README.html",
    "title": "math-intrinsics",
    "summary": "math-intrinsics ES Math-related intrinsics and helpers, robustly cached. abs floor isFinite isInteger isNaN isNegativeZero max min mod pow round sign constants/maxArrayLength constants/maxSafeInteger constants/maxValue Tests Simply clone the repo, npm install, and run npm test Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report."
  },
  "src/frontend/app-client/node_modules/media-typer/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/media-typer/HISTORY.html",
    "title": "0.3.0 / 2014-09-07",
    "summary": "0.3.0 / 2014-09-07 Support Node.js 0.6 Throw error when parameter format invalid on parse 0.2.0 / 2014-06-18 Add typer.format() to format media types 0.1.0 / 2014-06-17 Accept req as argument to parse Accept res as argument to parse Parse media type with extra LWS between type and first parameter 0.0.0 / 2014-06-13 Initial implementation"
  },
  "src/frontend/app-client/node_modules/media-typer/README.html": {
    "href": "src/frontend/app-client/node_modules/media-typer/README.html",
    "title": "media-typer",
    "summary": "media-typer Simple RFC 6838 media type parser Installation $ npm install media-typer API var typer = require('media-typer') typer.parse(string) var obj = typer.parse('image/svg+xml; charset=utf-8') Parse a media type string. This will return an object with the following properties (examples are shown for the string 'image/svg+xml; charset=utf-8'): type: The type of the media type (always lower case). Example: 'image' subtype: The subtype of the media type (always lower case). Example: 'svg' suffix: The suffix of the media type (always lower case). Example: 'xml' parameters: An object of the parameters in the media type (name of parameter always lower case). Example: {charset: 'utf-8'} typer.parse(req) var obj = typer.parse(req) Parse the content-type header from the given req. Short-cut for typer.parse(req.headers['content-type']). typer.parse(res) var obj = typer.parse(res) Parse the content-type header set on the given res. Short-cut for typer.parse(res.getHeader('content-type')). typer.format(obj) var obj = typer.format({type: 'image', subtype: 'svg', suffix: 'xml'}) Format an object into a media type string. This will return a string of the mime type for the given object. For the properties of the object, see the documentation for typer.parse(string). License MIT"
  },
  "src/frontend/app-client/node_modules/memoize-one/README.html": {
    "href": "src/frontend/app-client/node_modules/memoize-one/README.html",
    "title": "memoize-one",
    "summary": "memoize-one A memoization library that only caches the result of the most recent arguments. Rationale Unlike other memoization libraries, memoize-one only remembers the latest arguments and result. No need to worry about cache busting mechanisms such as maxAge, maxSize, exclusions and so on, which can be prone to memory leaks. A function memoized with memoize-one simply remembers the last arguments, and if the memoized function is next called with the same arguments then it returns the previous result. For working with promises, @Kikobeats has built async-memoize-one. Usage // memoize-one uses the default import import memoizeOne from 'memoize-one'; function add(a, b) { return a + b; } const memoizedAdd = memoizeOne(add); memoizedAdd(1, 2); // add function: is called // [new value returned: 3] memoizedAdd(1, 2); // add function: not called // [cached result is returned: 3] memoizedAdd(2, 3); // add function: is called // [new value returned: 5] memoizedAdd(2, 3); // add function: not called // [cached result is returned: 5] memoizedAdd(1, 2); // add function: is called // [new value returned: 3] // \uD83D\uDC47 // While the result of `add(1, 2)` was previously cached // `(1, 2)` was not the *latest* arguments (the last call was `(2, 3)`) // so the previous cached result of `(1, 3)` was lost Installation # yarn yarn add memoize-one # npm npm install memoize-one --save Function argument equality By default, we apply our own fast and relatively naive equality function to determine whether the arguments provided to your function are equal. You can see the full code here: are-inputs-equal.ts. (By default) function arguments are considered equal if: there is same amount of arguments each new argument has strict equality (===) with the previous argument [special case] if two arguments are not === and they are both NaN then the two arguments are treated as equal What this looks like in practice: import memoizeOne from 'memoize-one'; // add all numbers provided to the function const add = (...args = []) => args.reduce((current, value) => { return current + value; }, 0); const memoizedAdd = memoizeOne(add); there is same amount of arguments memoizedAdd(1, 2); // the amount of arguments has changed, so underlying add function is called memoizedAdd(1, 2, 3); new arguments have strict equality (===) with the previous argument memoizedAdd(1, 2); // each argument is `===` to the last argument, so cache is used memoizedAdd(1, 2); // second argument has changed, so add function is called again memoizedAdd(1, 3); // the first value is not `===` to the previous first value (1 !== 3) // so add function is called again memoizedAdd(3, 1); [special case] if the arguments are not === and they are both NaN then the argument is treated as equal memoizedAdd(NaN); // Even though NaN !== NaN these arguments are // treated as equal as they are both `NaN` memoizedAdd(NaN); Custom equality function You can also pass in a custom function for checking the equality of two sets of arguments const memoized = memoizeOne(fn, isEqual); An equality function should return true if the arguments are equal. If true is returned then the wrapped function will not be called. Tip: A custom equality function needs to compare Arrays. The newArgs array will be a new reference every time so a simple newArgs === lastArgs will always return false. Equality functions are not called if the this context of the function has changed (see below). Here is an example that uses a lodash.isEqual deep equal equality check lodash.isequal correctly handles deep comparing two arrays import memoizeOne from 'memoize-one'; import isDeepEqual from 'lodash.isequal'; const identity = (x) => x; const shallowMemoized = memoizeOne(identity); const deepMemoized = memoizeOne(identity, isDeepEqual); const result1 = shallowMemoized({ foo: 'bar' }); const result2 = shallowMemoized({ foo: 'bar' }); result1 === result2; // false - different object reference const result3 = deepMemoized({ foo: 'bar' }); const result4 = deepMemoized({ foo: 'bar' }); result3 === result4; // true - arguments are deep equal The equality function needs to conform to the EqualityFn type: // TFunc is the function being memoized type EqualityFn<TFunc extends (...args: any[]) => any> = ( newArgs: Parameters<TFunc>, lastArgs: Parameters<TFunc>, ) => boolean; // You can import this type import type { EqualityFn } from 'memoize-one'; The EqualityFn type allows you to create equality functions that are extremely typesafe. You are welcome to provide your own less type safe equality functions. Here are some examples of equality functions which are ordered by most type safe, to least type safe: Example equality function types // the function we are going to memoize function add(first: number, second: number): number { return first + second; } // Some options for our equality function // ↑ stronger types // ↓ weaker types // ✅ exact parameters of `add` { const isEqual = function (first: Parameters<typeof add>, second: Parameters<typeof add>) { return true; }; expectTypeOf<typeof isEqual>().toMatchTypeOf<EqualityFn<typeof add>>(); } // ✅ tuple of the correct types { const isEqual = function (first: [number, number], second: [number, number]) { return true; }; expectTypeOf<typeof isEqual>().toMatchTypeOf<EqualityFn<typeof add>>(); } // ❌ tuple of incorrect types { const isEqual = function (first: [number, string], second: [number, number]) { return true; }; expectTypeOf<typeof isEqual>().not.toMatchTypeOf<EqualityFn<typeof add>>(); } // ✅ array of the correct types { const isEqual = function (first: number[], second: number[]) { return true; }; expectTypeOf<typeof isEqual>().toMatchTypeOf<EqualityFn<typeof add>>(); } // ❌ array of incorrect types { const isEqual = function (first: string[], second: number[]) { return true; }; expectTypeOf<typeof isEqual>().not.toMatchTypeOf<EqualityFn<typeof add>>(); } // ✅ tuple of 'unknown' { const isEqual = function (first: [unknown, unknown], second: [unknown, unknown]) { return true; }; expectTypeOf<typeof isEqual>().toMatchTypeOf<EqualityFn<typeof add>>(); } // ❌ tuple of 'unknown' of incorrect length { const isEqual = function (first: [unknown, unknown, unknown], second: [unknown, unknown]) { return true; }; expectTypeOf<typeof isEqual>().not.toMatchTypeOf<EqualityFn<typeof add>>(); } // ✅ array of 'unknown' { const isEqual = function (first: unknown[], second: unknown[]) { return true; }; expectTypeOf<typeof isEqual>().toMatchTypeOf<EqualityFn<typeof add>>(); } // ✅ spread of 'unknown' { const isEqual = function (...first: unknown[]) { return !!first; }; expectTypeOf<typeof isEqual>().toMatchTypeOf<EqualityFn<typeof add>>(); } // ✅ tuple of 'any' { const isEqual = function (first: [any, any], second: [any, any]) { return true; }; expectTypeOf<typeof isEqual>().toMatchTypeOf<EqualityFn<typeof add>>(); } // ❌ tuple of 'any' or incorrect size { const isEqual = function (first: [any, any, any], second: [any, any]) { return true; }; expectTypeOf<typeof isEqual>().not.toMatchTypeOf<EqualityFn<typeof add>>(); } // ✅ array of 'any' { const isEqual = function (first: any[], second: any[]) { return true; }; expectTypeOf<typeof isEqual>().toMatchTypeOf<EqualityFn<typeof add>>(); } // ✅ two arguments of type any { const isEqual = function (first: any, second: any) { return true; }; expectTypeOf<typeof isEqual>().toMatchTypeOf<EqualityFn<typeof add>>(); } // ✅ a single argument of type any { const isEqual = function (first: any) { return true; }; expectTypeOf<typeof isEqual>().toMatchTypeOf<EqualityFn<typeof add>>(); } // ✅ spread of any type { const isEqual = function (...first: any[]) { return true; }; expectTypeOf<typeof isEqual>().toMatchTypeOf<EqualityFn<typeof add>>(); } this memoize-one correctly respects this control This library takes special care to maintain, and allow control over the the this context for both the original function being memoized as well as the returned memoized function. Both the original function and the memoized function's this context respect all the this controlling techniques: new bindings (new) explicit binding (call, apply, bind); implicit binding (call site: obj.foo()); default binding (window or undefined in strict mode); fat arrow binding (binding to lexical this) ignored this (pass null as this to explicit binding) Changes to this is considered an argument change Changes to the running context (this) of a function can result in the function returning a different value even though its arguments have stayed the same: function getA() { return this.a; } const temp1 = { a: 20, }; const temp2 = { a: 30, }; getA.call(temp1); // 20 getA.call(temp2); // 30 Therefore, in order to prevent against unexpected results, memoize-one takes into account the current execution context (this) of the memoized function. If this is different to the previous invocation then it is considered a change in argument. further discussion. Generally this will be of no impact if you are not explicity controlling the this context of functions you want to memoize with explicit binding or implicit binding. memoize-One will detect when you are manipulating this and will then consider the this context as an argument. If this changes, it will re-execute the original function even if the arguments have not changed. Clearing the memoization cache A .clear() property is added to memoized functions to allow you to clear it's memoization cache. This is helpful if you want to: Release memory Allow the underlying function to be called again without having to change arguments import memoizeOne from 'memoize-one'; function add(a: number, b: number): number { return a + b; } const memoizedAdd = memoizeOne(add); // first call - not memoized const first = memoizedAdd(1, 2); // second call - cache hit (underlying function not called) const second = memoizedAdd(1, 2); // \uD83D\uDC4B clearing memoization cache memoizedAdd.clear(); // third call - not memoized (cache was cleared) const third = memoizedAdd(1, 2); When your result function throws There is no caching when your result function throws If your result function throws then the memoized function will also throw. The throw will not break the memoized functions existing argument cache. It means the memoized function will pretend like it was never called with arguments that made it throw. const canThrow = (name: string) => { console.log('called'); if (name === 'throw') { throw new Error(name); } return { name }; }; const memoized = memoizeOne(canThrow); const value1 = memoized('Alex'); // console.log => 'called' const value2 = memoized('Alex'); // result function not called console.log(value1 === value2); // console.log => true try { memoized('throw'); // console.log => 'called' } catch (e) { firstError = e; } try { memoized('throw'); // console.log => 'called' // the result function was called again even though it was called twice // with the 'throw' string } catch (e) { secondError = e; } console.log(firstError !== secondError); const value3 = memoized('Alex'); // result function not called as the original memoization cache has not been busted console.log(value1 === value3); // console.log => true Function properties Functions memoized with memoize-one do not preserve any properties on the function object. This behaviour correctly reflected in the TypeScript types import memoizeOne from 'memoize-one'; function add(a, b) { return a + b; } add.hello = 'hi'; console.log(typeof add.hello); // string const memoized = memoizeOne(add); // hello property on the `add` was not preserved console.log(typeof memoized.hello); // undefined If you feel strongly that memoize-one should preserve function properties, please raise an issue. This decision was made in order to keep memoize-one as light as possible. For now, the .length property of a function is not preserved on the memoized function import memoizeOne from 'memoize-one'; function add(a, b) { return a + b; } console.log(add.length); // 2 const memoized = memoizeOne(add); console.log(memoized.length); // 0 There is no (great) way to correctly set the .length property of the memoized function while also supporting ie11. Once we remove ie11 support then we will set the .length property of the memoized function to match the original function → discussion. Memoized function type The resulting function you get back from memoize-one has almost the same type as the function that you are memoizing declare type MemoizedFn<TFunc extends (this: any, ...args: any[]) => any> = { clear: () => void; (this: ThisParameterType<TFunc>, ...args: Parameters<TFunc>): ReturnType<TFunc>; }; the same call signature as the function being memoized a .clear() function property added other function object properties on TFunc as not carried over You are welcome to use the MemoizedFn generic directly from memoize-one if you like: import memoize, { MemoizedFn } from 'memoize-one'; import isDeepEqual from 'lodash.isequal'; import { expectTypeOf } from 'expect-type'; // Takes any function: TFunc, and returns a Memoized<TFunc> function withDeepEqual<TFunc extends (...args: any[]) => any>(fn: TFunc): MemoizedFn<TFunc> { return memoize(fn, isDeepEqual); } function add(first: number, second: number): number { return first + second; } const memoized = withDeepEqual(add); expectTypeOf<typeof memoized>().toEqualTypeOf<MemoizedFn<typeof add>>(); In this specific example, this type would have been correctly inferred too import memoize, { MemoizedFn } from 'memoize-one'; import isDeepEqual from 'lodash.isequal'; import { expectTypeOf } from 'expect-type'; // return type of MemoizedFn<TFunc> is inferred function withDeepEqual<TFunc extends (...args: any[]) => any>(fn: TFunc) { return memoize(fn, isDeepEqual); } function add(first: number, second: number): number { return first + second; } const memoized = withDeepEqual(add); // type test still passes expectTypeOf<typeof memoized>().toEqualTypeOf<MemoizedFn<typeof add>>(); Performance \uD83D\uDE80 Tiny memoize-one is super lightweight at minified and gzipped. (1KB = 1,024 Bytes) Extremely fast memoize-one performs better or on par with than other popular memoization libraries for the purpose of remembering the latest invocation. The comparisons are not exhaustive and are primarily to show that memoize-one accomplishes remembering the latest invocation really fast. There is variability between runs. The benchmarks do not take into account the differences in feature sets, library sizes, parse time, and so on. Expand for results node version 16.11.1 You can run this test in the repo by: Add \"type\": \"module\" to the package.json (why is things so hard) Run yarn perf:library-comparison no arguments Position Library Operations per second 1 memoize-one 80,112,981 2 moize 72,885,631 3 memoizee 35,550,009 4 mem (JSON.stringify strategy) 4,610,532 5 lodash.memoize (JSON.stringify key resolver) 3,708,945 6 no memoization 505 7 fast-memoize 504 single primitive argument Position Library Operations per second 1 fast-memoize 45,482,711 2 moize 34,810,659 3 memoize-one 29,030,828 4 memoizee 23,467,065 5 mem (JSON.stringify strategy) 3,985,223 6 lodash.memoize (JSON.stringify key resolver) 3,369,297 7 no memoization 507 single complex argument Position Library Operations per second 1 moize 27,660,856 2 memoize-one 22,407,916 3 memoizee 19,546,835 4 mem (JSON.stringify strategy) 2,068,038 5 lodash.memoize (JSON.stringify key resolver) 1,911,335 6 fast-memoize 1,633,855 7 no memoization 504 multiple primitive arguments Position Library Operations per second 1 moize 22,366,497 2 memoize-one 17,241,995 3 memoizee 9,789,442 4 mem (JSON.stringify strategy) 3,065,328 5 lodash.memoize (JSON.stringify key resolver) 2,663,599 6 fast-memoize 1,219,548 7 no memoization 504 multiple complex arguments Position Library Operations per second 1 moize 21,788,081 2 memoize-one 17,321,248 3 memoizee 9,595,420 4 lodash.memoize (JSON.stringify key resolver) 873,283 5 mem (JSON.stringify strategy) 850,779 6 fast-memoize 687,863 7 no memoization 504 multiple complex arguments (spreading arguments) Position Library Operations per second 1 moize 21,701,537 2 memoizee 19,463,942 3 memoize-one 17,027,544 4 lodash.memoize (JSON.stringify key resolver) 887,816 5 mem (JSON.stringify strategy) 849,244 6 fast-memoize 691,512 7 no memoization 504 Code health \uD83D\uDC4D Tested with all built in JavaScript types Written in Typescript Correct typing for Typescript and flow type systems No dependencies"
  },
  "src/frontend/app-client/node_modules/merge-descriptors/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/merge-descriptors/HISTORY.html",
    "title": "1.0.1 / 2016-01-17",
    "summary": "1.0.1 / 2016-01-17 perf: enable strict mode 1.0.0 / 2015-03-01 Add option to only add new descriptors Add simple argument validation Add jsdoc to source file 0.0.2 / 2013-12-14 Move repository to component organization 0.0.1 / 2013-10-29 Initial release"
  },
  "src/frontend/app-client/node_modules/merge-descriptors/README.html": {
    "href": "src/frontend/app-client/node_modules/merge-descriptors/README.html",
    "title": "merge-descriptors",
    "summary": "merge-descriptors Merge objects using descriptors. var thing = { get name() { return 'jon' } } var animal = { } merge(animal, thing) animal.name === 'jon' API merge(destination, source) Redefines destination's descriptors with source's. The return value is the destination object. merge(destination, source, false) Defines source's descriptors on destination if destination does not have a descriptor by the same name. The return value is the destination object. License MIT"
  },
  "src/frontend/app-client/node_modules/methods/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/methods/HISTORY.html",
    "title": "1.1.2 / 2016-01-17",
    "summary": "1.1.2 / 2016-01-17 perf: enable strict mode 1.1.1 / 2014-12-30 Improve browserify support 1.1.0 / 2014-07-05 Add CONNECT method 1.0.1 / 2014-06-02 Fix module to work with harmony transform 1.0.0 / 2014-05-08 Add PURGE method 0.1.0 / 2013-10-28 Add http.METHODS support"
  },
  "src/frontend/app-client/node_modules/methods/README.html": {
    "href": "src/frontend/app-client/node_modules/methods/README.html",
    "title": "Methods",
    "summary": "Methods HTTP verbs that Node.js core's HTTP parser supports. This module provides an export that is just like http.METHODS from Node.js core, with the following differences: All method names are lower-cased. Contains a fallback list of methods for Node.js versions that do not have a http.METHODS export (0.10 and lower). Provides the fallback list when using tools like browserify without pulling in the http shim module. Install $ npm install methods API var methods = require('methods') methods This is an array of lower-cased method names that Node.js supports. If Node.js provides the http.METHODS export, then this is the same array lower-cased, otherwise it is a snapshot of the verbs from Node.js 0.10. License MIT"
  },
  "src/frontend/app-client/node_modules/mime-db/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/mime-db/HISTORY.html",
    "title": "1.54.0 / 2025-03-17",
    "summary": "1.54.0 / 2025-03-17 Update mime type for DCM format (#362) mark application/octet-stream as compressible (#163) Fix typo in application/x-zip-compressed mimetype (#359) Add mime-type for Jupyter notebooks (#282) Add Google Drive MIME types (#311) Add .blend file type (#338) Add support for the FBX file extension (#342) Add Adobe DNG file (#340) Add Procreate Brush and Brush Set file Types (#339) Add support for Procreate Dreams (#341) replace got with undici (#352) Added extensions list for model/step (#293) Add m4b as a type of audio/mp4 (#357) windows 11 application/x-zip-compressed (#346) add dotLottie mime type (#351) Add some MS-related extensions and types (#336) 1.53.0 / 2024-07-12 Add extension .sql to application/sql Add extensions .aac and .adts to audio/aac Add extensions .js and .mjs to text/javascript Add extensions for application/mp4 from IANA Add extensions from IANA for more MIME types Add Microsoft app installer types and extensions Add new upstream MIME types Fix extensions for text/markdown to match IANA Remove extension .mjs from application/javascript Remove obsolete MIME types from IANA data 1.52.0 / 2022-02-21 Add extensions from IANA for more image/* types Add extension .asc to application/pgp-keys Add extensions to various XML types Add new upstream MIME types 1.51.0 / 2021-11-08 Add new upstream MIME types Mark image/vnd.microsoft.icon as compressible Mark image/vnd.ms-dds as compressible 1.50.0 / 2021-09-15 Add deprecated iWorks mime types and extensions Add new upstream MIME types 1.49.0 / 2021-07-26 Add extension .trig to application/trig Add new upstream MIME types 1.48.0 / 2021-05-30 Add extension .mvt to application/vnd.mapbox-vector-tile Add new upstream MIME types Mark text/yaml as compressible 1.47.0 / 2021-04-01 Add new upstream MIME types Remove ambiguous extensions from IANA for application/*+xml types Update primary extension to .es for application/ecmascript 1.46.0 / 2021-02-13 Add extension .amr to audio/amr Add extension .m4s to video/iso.segment Add extension .opus to audio/ogg Add new upstream MIME types 1.45.0 / 2020-09-22 Add application/ubjson with extension .ubj Add image/avif with extension .avif Add image/ktx2 with extension .ktx2 Add extension .dbf to application/vnd.dbf Add extension .rar to application/vnd.rar Add extension .td to application/urc-targetdesc+xml Add new upstream MIME types Fix extension of application/vnd.apple.keynote to be .key 1.44.0 / 2020-04-22 Add charsets from IANA Add extension .cjs to application/node Add new upstream MIME types 1.43.0 / 2020-01-05 Add application/x-keepass2 with extension .kdbx Add extension .mxmf to audio/mobile-xmf Add extensions from IANA for application/*+xml types Add new upstream MIME types 1.42.0 / 2019-09-25 Add image/vnd.ms-dds with extension .dds Add new upstream MIME types Remove compressible from multipart/mixed 1.41.0 / 2019-08-30 Add new upstream MIME types Add application/toml with extension .toml Mark font/ttf as compressible 1.40.0 / 2019-04-20 Add extensions from IANA for model/* types Add text/mdx with extension .mdx 1.39.0 / 2019-04-04 Add extensions .siv and .sieve to application/sieve Add new upstream MIME types 1.38.0 / 2019-02-04 Add extension .nq to application/n-quads Add extension .nt to application/n-triples Add new upstream MIME types Mark text/less as compressible 1.37.0 / 2018-10-19 Add extensions to HEIC image types Add new upstream MIME types 1.36.0 / 2018-08-20 Add Apple file extensions from IANA Add extensions from IANA for image/* types Add new upstream MIME types 1.35.0 / 2018-07-15 Add extension .owl to application/rdf+xml Add new upstream MIME types Removes extension .woff from application/font-woff 1.34.0 / 2018-06-03 Add extension .csl to application/vnd.citationstyles.style+xml Add extension .es to application/ecmascript Add new upstream MIME types Add UTF-8 as default charset for text/turtle Mark all XML-derived types as compressible 1.33.0 / 2018-02-15 Add extensions from IANA for message/* types Add new upstream MIME types Fix some incorrect OOXML types Remove application/font-woff2 1.32.0 / 2017-11-29 Add new upstream MIME types Update text/hjson to registered application/hjson Add text/shex with extension .shex 1.31.0 / 2017-10-25 Add application/raml+yaml with extension .raml Add application/wasm with extension .wasm Add new font type from IANA Add new upstream font extensions Add new upstream MIME types Add extensions for JPEG-2000 images 1.30.0 / 2017-08-27 Add application/vnd.ms-outlook Add application/x-arj Add extension .mjs to application/javascript Add glTF types and extensions Add new upstream MIME types Add text/x-org Add VirtualBox MIME types Fix source records for video/* types that are IANA Update font/opentype to registered font/otf 1.29.0 / 2017-07-10 Add application/fido.trusted-apps+json Add extension .wadl to application/vnd.sun.wadl+xml Add new upstream MIME types Add UTF-8 as default charset for text/css 1.28.0 / 2017-05-14 Add new upstream MIME types Add extension .gz to application/gzip Update extensions .md and .markdown to be text/markdown 1.27.0 / 2017-03-16 Add new upstream MIME types Add image/apng with extension .apng 1.26.0 / 2017-01-14 Add new upstream MIME types Add extension .geojson to application/geo+json 1.25.0 / 2016-11-11 Add new upstream MIME types 1.24.0 / 2016-09-18 Add audio/mp3 Add new upstream MIME types 1.23.0 / 2016-05-01 Add new upstream MIME types Add extension .3gpp to audio/3gpp 1.22.0 / 2016-02-15 Add text/slim Add extension .rng to application/xml Add new upstream MIME types Fix extension of application/dash+xml to be .mpd Update primary extension to .m4a for audio/mp4 1.21.0 / 2016-01-06 Add Google document types Add new upstream MIME types 1.20.0 / 2015-11-10 Add text/x-suse-ymp Add new upstream MIME types 1.19.0 / 2015-09-17 Add application/vnd.apple.pkpass Add new upstream MIME types 1.18.0 / 2015-09-03 Add new upstream MIME types 1.17.0 / 2015-08-13 Add application/x-msdos-program Add audio/g711-0 Add image/vnd.mozilla.apng Add extension .exe to application/x-msdos-program 1.16.0 / 2015-07-29 Add application/vnd.uri-map 1.15.0 / 2015-07-13 Add application/x-httpd-php 1.14.0 / 2015-06-25 Add application/scim+json Add application/vnd.3gpp.ussd+xml Add application/vnd.biopax.rdf+xml Add text/x-processing 1.13.0 / 2015-06-07 Add nginx as a source Add application/x-cocoa Add application/x-java-archive-diff Add application/x-makeself Add application/x-perl Add application/x-pilot Add application/x-redhat-package-manager Add application/x-sea Add audio/x-m4a Add audio/x-realaudio Add image/x-jng Add text/mathml 1.12.0 / 2015-06-05 Add application/bdoc Add application/vnd.hyperdrive+json Add application/x-bdoc Add extension .rtf to text/rtf 1.11.0 / 2015-05-31 Add audio/wav Add audio/wave Add extension .litcoffee to text/coffeescript Add extension .sfd-hdstx to application/vnd.hydrostatix.sof-data Add extension .n-gage to application/vnd.nokia.n-gage.symbian.install 1.10.0 / 2015-05-19 Add application/vnd.balsamiq.bmpr Add application/vnd.microsoft.portable-executable Add application/x-ns-proxy-autoconfig 1.9.1 / 2015-04-19 Remove .json extension from application/manifest+json This is causing bugs downstream 1.9.0 / 2015-04-19 Add application/manifest+json Add application/vnd.micro+json Add image/vnd.zbrush.pcx Add image/x-ms-bmp 1.8.0 / 2015-03-13 Add application/vnd.citationstyles.style+xml Add application/vnd.fastcopy-disk-image Add application/vnd.gov.sk.xmldatacontainer+xml Add extension .jsonld to application/ld+json 1.7.0 / 2015-02-08 Add application/vnd.gerber Add application/vnd.msa-disk-image 1.6.1 / 2015-02-05 Community extensions ownership transferred from node-mime 1.6.0 / 2015-01-29 Add application/jose Add application/jose+json Add application/json-seq Add application/jwk+json Add application/jwk-set+json Add application/jwt Add application/rdap+json Add application/vnd.gov.sk.e-form+xml Add application/vnd.ims.imsccv1p3 1.5.0 / 2014-12-30 Add application/vnd.oracle.resource+json Fix various invalid MIME type entries application/mbox+xml application/oscp-response application/vwg-multiplexed audio/g721 1.4.0 / 2014-12-21 Add application/vnd.ims.imsccv1p2 Fix various invalid MIME type entries application/vnd-acucobol application/vnd-curl application/vnd-dart application/vnd-dxr application/vnd-fdf application/vnd-mif application/vnd-sema application/vnd-wap-wmlc application/vnd.adobe.flash-movie application/vnd.dece-zip application/vnd.dvb_service application/vnd.micrografx-igx application/vnd.sealed-doc application/vnd.sealed-eml application/vnd.sealed-mht application/vnd.sealed-ppt application/vnd.sealed-tiff application/vnd.sealed-xls application/vnd.sealedmedia.softseal-html application/vnd.sealedmedia.softseal-pdf application/vnd.wap-slc application/vnd.wap-wbxml audio/vnd.sealedmedia.softseal-mpeg image/vnd-djvu image/vnd-svf image/vnd-wap-wbmp image/vnd.sealed-png image/vnd.sealedmedia.softseal-gif image/vnd.sealedmedia.softseal-jpg model/vnd-dwf model/vnd.parasolid.transmit-binary model/vnd.parasolid.transmit-text text/vnd-a text/vnd-curl text/vnd.wap-wml Remove example template MIME types application/example audio/example image/example message/example model/example multipart/example text/example video/example 1.3.1 / 2014-12-16 Fix missing extensions application/json5 text/hjson 1.3.0 / 2014-12-07 Add application/a2l Add application/aml Add application/atfx Add application/atxml Add application/cdfx+xml Add application/dii Add application/json5 Add application/lxf Add application/mf4 Add application/vnd.apache.thrift.compact Add application/vnd.apache.thrift.json Add application/vnd.coffeescript Add application/vnd.enphase.envoy Add application/vnd.ims.imsccv1p1 Add text/csv-schema Add text/hjson Add text/markdown Add text/yaml 1.2.0 / 2014-11-09 Add application/cea Add application/dit Add application/vnd.gov.sk.e-form+zip Add application/vnd.tmd.mediaflex.api+xml Type application/epub+zip is now IANA-registered 1.1.2 / 2014-10-23 Rebuild database for application/x-www-form-urlencoded change 1.1.1 / 2014-10-20 Mark application/x-www-form-urlencoded as compressible. 1.1.0 / 2014-09-28 Add application/font-woff2 1.0.3 / 2014-09-25 Fix engine requirement in package 1.0.2 / 2014-09-25 Add application/coap-group+json Add application/dcd Add application/vnd.apache.thrift.binary Add image/vnd.tencent.tap Mark all JSON-derived types as compressible Update text/vtt data 1.0.1 / 2014-08-30 Fix extension ordering 1.0.0 / 2014-08-30 Add application/atf Add application/merge-patch+json Add multipart/x-mixed-replace Add source: 'apache' metadata Add source: 'iana' metadata Remove badly-assumed charset data"
  },
  "src/frontend/app-client/node_modules/mime-db/README.html": {
    "href": "src/frontend/app-client/node_modules/mime-db/README.html",
    "title": "mime-db",
    "summary": "mime-db This is a large database of mime types and information about them. It consists of a single, public JSON file and does not include any logic, allowing it to remain as un-opinionated as possible with an API. It aggregates data from the following sources: https://www.iana.org/assignments/media-types/media-types.xhtml https://svn.apache.org/repos/asf/httpd/httpd/trunk/docs/conf/mime.types https://hg.nginx.org/nginx/raw-file/default/conf/mime.types Installation npm install mime-db Database Download If you intend to use this in a web browser, you can conveniently access the JSON file via jsDelivr, a popular CDN (Content Delivery Network). To ensure stability and compatibility, it is advisable to specify a release tag instead of using the 'master' branch. This is because the JSON file's format might change in future updates, and relying on a specific release tag will prevent potential issues arising from these changes. https://cdn.jsdelivr.net/gh/jshttp/mime-db@master/db.json Usage var db = require('mime-db') // grab data on .js files var data = db['application/javascript'] Data Structure The JSON file is a map lookup for lowercased mime types. Each mime type has the following properties: .source - where the mime type is defined. If not set, it's probably a custom media type. apache - Apache common media types iana - IANA-defined media types nginx - nginx media types .extensions[] - known extensions associated with this mime type. .compressible - whether a file of this type can be gzipped. .charset - the default charset associated with this type, if any. If unknown, every property could be undefined. Note on MIME Type Data and Semver This package considers the programmatic api as the semver compatibility. This means the MIME type resolution is not considered in the semver bumps. This means that if you want to pin your mime-db data you will need to do it in your application. While this expectation was not set in docs until now, it is how the pacakge operated, so we do not feel this is a breaking change. Contributing The primary way to contribute to this database is by updating the data in one of the upstream sources. The database is updated from the upstreams periodically and will pull in any changes. Registering Media Types The best way to get new media types included in this library is to register them with the IANA. The community registration procedure is outlined in RFC 6838 section 5. Types registered with the IANA are automatically pulled into this library. Direct Inclusion If that is not possible / feasible, they can be added directly here as a \"custom\" type. To do this, it is required to have a primary source that definitively lists the media type. If an extension is going to be listed as associated with this media type, the source must definitively link the media type and extension as well. To edit the database, only make PRs against src/custom-types.json or src/custom-suffix.json. The src/custom-types.json file is a JSON object with the MIME type as the keys and the values being an object with the following keys: compressible - leave out if you don't know, otherwise true/false to indicate whether the data represented by the type is typically compressible. extensions - include an array of file extensions that are associated with the type. notes - human-readable notes about the type, typically what the type is. sources - include an array of URLs of where the MIME type and the associated extensions are sourced from. This needs to be a primary source; links to type aggregating sites and Wikipedia are not acceptable. To update the build, run npm run build."
  },
  "src/frontend/app-client/node_modules/mime-types/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/mime-types/HISTORY.html",
    "title": "2.1.35 / 2022-03-12",
    "summary": "2.1.35 / 2022-03-12 deps: mime-db@1.52.0 Add extensions from IANA for more image/* types Add extension .asc to application/pgp-keys Add extensions to various XML types Add new upstream MIME types 2.1.34 / 2021-11-08 deps: mime-db@1.51.0 Add new upstream MIME types 2.1.33 / 2021-10-01 deps: mime-db@1.50.0 Add deprecated iWorks mime types and extensions Add new upstream MIME types 2.1.32 / 2021-07-27 deps: mime-db@1.49.0 Add extension .trig to application/trig Add new upstream MIME types 2.1.31 / 2021-06-01 deps: mime-db@1.48.0 Add extension .mvt to application/vnd.mapbox-vector-tile Add new upstream MIME types 2.1.30 / 2021-04-02 deps: mime-db@1.47.0 Add extension .amr to audio/amr Remove ambigious extensions from IANA for application/*+xml types Update primary extension to .es for application/ecmascript 2.1.29 / 2021-02-17 deps: mime-db@1.46.0 Add extension .amr to audio/amr Add extension .m4s to video/iso.segment Add extension .opus to audio/ogg Add new upstream MIME types 2.1.28 / 2021-01-01 deps: mime-db@1.45.0 Add application/ubjson with extension .ubj Add image/avif with extension .avif Add image/ktx2 with extension .ktx2 Add extension .dbf to application/vnd.dbf Add extension .rar to application/vnd.rar Add extension .td to application/urc-targetdesc+xml Add new upstream MIME types Fix extension of application/vnd.apple.keynote to be .key 2.1.27 / 2020-04-23 deps: mime-db@1.44.0 Add charsets from IANA Add extension .cjs to application/node Add new upstream MIME types 2.1.26 / 2020-01-05 deps: mime-db@1.43.0 Add application/x-keepass2 with extension .kdbx Add extension .mxmf to audio/mobile-xmf Add extensions from IANA for application/*+xml types Add new upstream MIME types 2.1.25 / 2019-11-12 deps: mime-db@1.42.0 Add new upstream MIME types Add application/toml with extension .toml Add image/vnd.ms-dds with extension .dds 2.1.24 / 2019-04-20 deps: mime-db@1.40.0 Add extensions from IANA for model/* types Add text/mdx with extension .mdx 2.1.23 / 2019-04-17 deps: mime-db@~1.39.0 Add extensions .siv and .sieve to application/sieve Add new upstream MIME types 2.1.22 / 2019-02-14 deps: mime-db@~1.38.0 Add extension .nq to application/n-quads Add extension .nt to application/n-triples Add new upstream MIME types 2.1.21 / 2018-10-19 deps: mime-db@~1.37.0 Add extensions to HEIC image types Add new upstream MIME types 2.1.20 / 2018-08-26 deps: mime-db@~1.36.0 Add Apple file extensions from IANA Add extensions from IANA for image/* types Add new upstream MIME types 2.1.19 / 2018-07-17 deps: mime-db@~1.35.0 Add extension .csl to application/vnd.citationstyles.style+xml Add extension .es to application/ecmascript Add extension .owl to application/rdf+xml Add new upstream MIME types Add UTF-8 as default charset for text/turtle 2.1.18 / 2018-02-16 deps: mime-db@~1.33.0 Add application/raml+yaml with extension .raml Add application/wasm with extension .wasm Add text/shex with extension .shex Add extensions for JPEG-2000 images Add extensions from IANA for message/* types Add new upstream MIME types Update font MIME types Update text/hjson to registered application/hjson 2.1.17 / 2017-09-01 deps: mime-db@~1.30.0 Add application/vnd.ms-outlook Add application/x-arj Add extension .mjs to application/javascript Add glTF types and extensions Add new upstream MIME types Add text/x-org Add VirtualBox MIME types Fix source records for video/* types that are IANA Update font/opentype to registered font/otf 2.1.16 / 2017-07-24 deps: mime-db@~1.29.0 Add application/fido.trusted-apps+json Add extension .wadl to application/vnd.sun.wadl+xml Add extension .gz to application/gzip Add new upstream MIME types Update extensions .md and .markdown to be text/markdown 2.1.15 / 2017-03-23 deps: mime-db@~1.27.0 Add new mime types Add image/apng 2.1.14 / 2017-01-14 deps: mime-db@~1.26.0 Add new mime types 2.1.13 / 2016-11-18 deps: mime-db@~1.25.0 Add new mime types 2.1.12 / 2016-09-18 deps: mime-db@~1.24.0 Add new mime types Add audio/mp3 2.1.11 / 2016-05-01 deps: mime-db@~1.23.0 Add new mime types 2.1.10 / 2016-02-15 deps: mime-db@~1.22.0 Add new mime types Fix extension of application/dash+xml Update primary extension for audio/mp4 2.1.9 / 2016-01-06 deps: mime-db@~1.21.0 Add new mime types 2.1.8 / 2015-11-30 deps: mime-db@~1.20.0 Add new mime types 2.1.7 / 2015-09-20 deps: mime-db@~1.19.0 Add new mime types 2.1.6 / 2015-09-03 deps: mime-db@~1.18.0 Add new mime types 2.1.5 / 2015-08-20 deps: mime-db@~1.17.0 Add new mime types 2.1.4 / 2015-07-30 deps: mime-db@~1.16.0 Add new mime types 2.1.3 / 2015-07-13 deps: mime-db@~1.15.0 Add new mime types 2.1.2 / 2015-06-25 deps: mime-db@~1.14.0 Add new mime types 2.1.1 / 2015-06-08 perf: fix deopt during mapping 2.1.0 / 2015-06-07 Fix incorrectly treating extension-less file name as extension i.e. 'path/to/json' will no longer return application/json Fix .charset(type) to accept parameters Fix .charset(type) to match case-insensitive Improve generation of extension to MIME mapping Refactor internals for readability and no argument reassignment Prefer application/* MIME types from the same source Prefer any type over application/octet-stream deps: mime-db@~1.13.0 Add nginx as a source Add new mime types 2.0.14 / 2015-06-06 deps: mime-db@~1.12.0 Add new mime types 2.0.13 / 2015-05-31 deps: mime-db@~1.11.0 Add new mime types 2.0.12 / 2015-05-19 deps: mime-db@~1.10.0 Add new mime types 2.0.11 / 2015-05-05 deps: mime-db@~1.9.1 Add new mime types 2.0.10 / 2015-03-13 deps: mime-db@~1.8.0 Add new mime types 2.0.9 / 2015-02-09 deps: mime-db@~1.7.0 Add new mime types Community extensions ownership transferred from node-mime 2.0.8 / 2015-01-29 deps: mime-db@~1.6.0 Add new mime types 2.0.7 / 2014-12-30 deps: mime-db@~1.5.0 Add new mime types Fix various invalid MIME type entries 2.0.6 / 2014-12-30 deps: mime-db@~1.4.0 Add new mime types Fix various invalid MIME type entries Remove example template MIME types 2.0.5 / 2014-12-29 deps: mime-db@~1.3.1 Fix missing extensions 2.0.4 / 2014-12-10 deps: mime-db@~1.3.0 Add new mime types 2.0.3 / 2014-11-09 deps: mime-db@~1.2.0 Add new mime types 2.0.2 / 2014-09-28 deps: mime-db@~1.1.0 Add new mime types Update charsets 2.0.1 / 2014-09-07 Support Node.js 0.6 2.0.0 / 2014-09-02 Use mime-db Remove .define() 1.0.2 / 2014-08-04 Set charset=utf-8 for text/javascript 1.0.1 / 2014-06-24 Add text/jsx type 1.0.0 / 2014-05-12 Return false for unknown types Set charset=utf-8 for application/json 0.1.0 / 2014-05-02 Initial release"
  },
  "src/frontend/app-client/node_modules/mime-types/node_modules/mime-db/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/mime-types/node_modules/mime-db/HISTORY.html",
    "title": "1.52.0 / 2022-02-21",
    "summary": "1.52.0 / 2022-02-21 Add extensions from IANA for more image/* types Add extension .asc to application/pgp-keys Add extensions to various XML types Add new upstream MIME types 1.51.0 / 2021-11-08 Add new upstream MIME types Mark image/vnd.microsoft.icon as compressible Mark image/vnd.ms-dds as compressible 1.50.0 / 2021-09-15 Add deprecated iWorks mime types and extensions Add new upstream MIME types 1.49.0 / 2021-07-26 Add extension .trig to application/trig Add new upstream MIME types 1.48.0 / 2021-05-30 Add extension .mvt to application/vnd.mapbox-vector-tile Add new upstream MIME types Mark text/yaml as compressible 1.47.0 / 2021-04-01 Add new upstream MIME types Remove ambigious extensions from IANA for application/*+xml types Update primary extension to .es for application/ecmascript 1.46.0 / 2021-02-13 Add extension .amr to audio/amr Add extension .m4s to video/iso.segment Add extension .opus to audio/ogg Add new upstream MIME types 1.45.0 / 2020-09-22 Add application/ubjson with extension .ubj Add image/avif with extension .avif Add image/ktx2 with extension .ktx2 Add extension .dbf to application/vnd.dbf Add extension .rar to application/vnd.rar Add extension .td to application/urc-targetdesc+xml Add new upstream MIME types Fix extension of application/vnd.apple.keynote to be .key 1.44.0 / 2020-04-22 Add charsets from IANA Add extension .cjs to application/node Add new upstream MIME types 1.43.0 / 2020-01-05 Add application/x-keepass2 with extension .kdbx Add extension .mxmf to audio/mobile-xmf Add extensions from IANA for application/*+xml types Add new upstream MIME types 1.42.0 / 2019-09-25 Add image/vnd.ms-dds with extension .dds Add new upstream MIME types Remove compressible from multipart/mixed 1.41.0 / 2019-08-30 Add new upstream MIME types Add application/toml with extension .toml Mark font/ttf as compressible 1.40.0 / 2019-04-20 Add extensions from IANA for model/* types Add text/mdx with extension .mdx 1.39.0 / 2019-04-04 Add extensions .siv and .sieve to application/sieve Add new upstream MIME types 1.38.0 / 2019-02-04 Add extension .nq to application/n-quads Add extension .nt to application/n-triples Add new upstream MIME types Mark text/less as compressible 1.37.0 / 2018-10-19 Add extensions to HEIC image types Add new upstream MIME types 1.36.0 / 2018-08-20 Add Apple file extensions from IANA Add extensions from IANA for image/* types Add new upstream MIME types 1.35.0 / 2018-07-15 Add extension .owl to application/rdf+xml Add new upstream MIME types Removes extension .woff from application/font-woff 1.34.0 / 2018-06-03 Add extension .csl to application/vnd.citationstyles.style+xml Add extension .es to application/ecmascript Add new upstream MIME types Add UTF-8 as default charset for text/turtle Mark all XML-derived types as compressible 1.33.0 / 2018-02-15 Add extensions from IANA for message/* types Add new upstream MIME types Fix some incorrect OOXML types Remove application/font-woff2 1.32.0 / 2017-11-29 Add new upstream MIME types Update text/hjson to registered application/hjson Add text/shex with extension .shex 1.31.0 / 2017-10-25 Add application/raml+yaml with extension .raml Add application/wasm with extension .wasm Add new font type from IANA Add new upstream font extensions Add new upstream MIME types Add extensions for JPEG-2000 images 1.30.0 / 2017-08-27 Add application/vnd.ms-outlook Add application/x-arj Add extension .mjs to application/javascript Add glTF types and extensions Add new upstream MIME types Add text/x-org Add VirtualBox MIME types Fix source records for video/* types that are IANA Update font/opentype to registered font/otf 1.29.0 / 2017-07-10 Add application/fido.trusted-apps+json Add extension .wadl to application/vnd.sun.wadl+xml Add new upstream MIME types Add UTF-8 as default charset for text/css 1.28.0 / 2017-05-14 Add new upstream MIME types Add extension .gz to application/gzip Update extensions .md and .markdown to be text/markdown 1.27.0 / 2017-03-16 Add new upstream MIME types Add image/apng with extension .apng 1.26.0 / 2017-01-14 Add new upstream MIME types Add extension .geojson to application/geo+json 1.25.0 / 2016-11-11 Add new upstream MIME types 1.24.0 / 2016-09-18 Add audio/mp3 Add new upstream MIME types 1.23.0 / 2016-05-01 Add new upstream MIME types Add extension .3gpp to audio/3gpp 1.22.0 / 2016-02-15 Add text/slim Add extension .rng to application/xml Add new upstream MIME types Fix extension of application/dash+xml to be .mpd Update primary extension to .m4a for audio/mp4 1.21.0 / 2016-01-06 Add Google document types Add new upstream MIME types 1.20.0 / 2015-11-10 Add text/x-suse-ymp Add new upstream MIME types 1.19.0 / 2015-09-17 Add application/vnd.apple.pkpass Add new upstream MIME types 1.18.0 / 2015-09-03 Add new upstream MIME types 1.17.0 / 2015-08-13 Add application/x-msdos-program Add audio/g711-0 Add image/vnd.mozilla.apng Add extension .exe to application/x-msdos-program 1.16.0 / 2015-07-29 Add application/vnd.uri-map 1.15.0 / 2015-07-13 Add application/x-httpd-php 1.14.0 / 2015-06-25 Add application/scim+json Add application/vnd.3gpp.ussd+xml Add application/vnd.biopax.rdf+xml Add text/x-processing 1.13.0 / 2015-06-07 Add nginx as a source Add application/x-cocoa Add application/x-java-archive-diff Add application/x-makeself Add application/x-perl Add application/x-pilot Add application/x-redhat-package-manager Add application/x-sea Add audio/x-m4a Add audio/x-realaudio Add image/x-jng Add text/mathml 1.12.0 / 2015-06-05 Add application/bdoc Add application/vnd.hyperdrive+json Add application/x-bdoc Add extension .rtf to text/rtf 1.11.0 / 2015-05-31 Add audio/wav Add audio/wave Add extension .litcoffee to text/coffeescript Add extension .sfd-hdstx to application/vnd.hydrostatix.sof-data Add extension .n-gage to application/vnd.nokia.n-gage.symbian.install 1.10.0 / 2015-05-19 Add application/vnd.balsamiq.bmpr Add application/vnd.microsoft.portable-executable Add application/x-ns-proxy-autoconfig 1.9.1 / 2015-04-19 Remove .json extension from application/manifest+json This is causing bugs downstream 1.9.0 / 2015-04-19 Add application/manifest+json Add application/vnd.micro+json Add image/vnd.zbrush.pcx Add image/x-ms-bmp 1.8.0 / 2015-03-13 Add application/vnd.citationstyles.style+xml Add application/vnd.fastcopy-disk-image Add application/vnd.gov.sk.xmldatacontainer+xml Add extension .jsonld to application/ld+json 1.7.0 / 2015-02-08 Add application/vnd.gerber Add application/vnd.msa-disk-image 1.6.1 / 2015-02-05 Community extensions ownership transferred from node-mime 1.6.0 / 2015-01-29 Add application/jose Add application/jose+json Add application/json-seq Add application/jwk+json Add application/jwk-set+json Add application/jwt Add application/rdap+json Add application/vnd.gov.sk.e-form+xml Add application/vnd.ims.imsccv1p3 1.5.0 / 2014-12-30 Add application/vnd.oracle.resource+json Fix various invalid MIME type entries application/mbox+xml application/oscp-response application/vwg-multiplexed audio/g721 1.4.0 / 2014-12-21 Add application/vnd.ims.imsccv1p2 Fix various invalid MIME type entries application/vnd-acucobol application/vnd-curl application/vnd-dart application/vnd-dxr application/vnd-fdf application/vnd-mif application/vnd-sema application/vnd-wap-wmlc application/vnd.adobe.flash-movie application/vnd.dece-zip application/vnd.dvb_service application/vnd.micrografx-igx application/vnd.sealed-doc application/vnd.sealed-eml application/vnd.sealed-mht application/vnd.sealed-ppt application/vnd.sealed-tiff application/vnd.sealed-xls application/vnd.sealedmedia.softseal-html application/vnd.sealedmedia.softseal-pdf application/vnd.wap-slc application/vnd.wap-wbxml audio/vnd.sealedmedia.softseal-mpeg image/vnd-djvu image/vnd-svf image/vnd-wap-wbmp image/vnd.sealed-png image/vnd.sealedmedia.softseal-gif image/vnd.sealedmedia.softseal-jpg model/vnd-dwf model/vnd.parasolid.transmit-binary model/vnd.parasolid.transmit-text text/vnd-a text/vnd-curl text/vnd.wap-wml Remove example template MIME types application/example audio/example image/example message/example model/example multipart/example text/example video/example 1.3.1 / 2014-12-16 Fix missing extensions application/json5 text/hjson 1.3.0 / 2014-12-07 Add application/a2l Add application/aml Add application/atfx Add application/atxml Add application/cdfx+xml Add application/dii Add application/json5 Add application/lxf Add application/mf4 Add application/vnd.apache.thrift.compact Add application/vnd.apache.thrift.json Add application/vnd.coffeescript Add application/vnd.enphase.envoy Add application/vnd.ims.imsccv1p1 Add text/csv-schema Add text/hjson Add text/markdown Add text/yaml 1.2.0 / 2014-11-09 Add application/cea Add application/dit Add application/vnd.gov.sk.e-form+zip Add application/vnd.tmd.mediaflex.api+xml Type application/epub+zip is now IANA-registered 1.1.2 / 2014-10-23 Rebuild database for application/x-www-form-urlencoded change 1.1.1 / 2014-10-20 Mark application/x-www-form-urlencoded as compressible. 1.1.0 / 2014-09-28 Add application/font-woff2 1.0.3 / 2014-09-25 Fix engine requirement in package 1.0.2 / 2014-09-25 Add application/coap-group+json Add application/dcd Add application/vnd.apache.thrift.binary Add image/vnd.tencent.tap Mark all JSON-derived types as compressible Update text/vtt data 1.0.1 / 2014-08-30 Fix extension ordering 1.0.0 / 2014-08-30 Add application/atf Add application/merge-patch+json Add multipart/x-mixed-replace Add source: 'apache' metadata Add source: 'iana' metadata Remove badly-assumed charset data"
  },
  "src/frontend/app-client/node_modules/mime-types/node_modules/mime-db/README.html": {
    "href": "src/frontend/app-client/node_modules/mime-types/node_modules/mime-db/README.html",
    "title": "mime-db",
    "summary": "mime-db This is a large database of mime types and information about them. It consists of a single, public JSON file and does not include any logic, allowing it to remain as un-opinionated as possible with an API. It aggregates data from the following sources: http://www.iana.org/assignments/media-types/media-types.xhtml http://svn.apache.org/repos/asf/httpd/httpd/trunk/docs/conf/mime.types http://hg.nginx.org/nginx/raw-file/default/conf/mime.types Installation npm install mime-db Database Download If you're crazy enough to use this in the browser, you can just grab the JSON file using jsDelivr. It is recommended to replace master with a release tag as the JSON format may change in the future. https://cdn.jsdelivr.net/gh/jshttp/mime-db@master/db.json Usage var db = require('mime-db') // grab data on .js files var data = db['application/javascript'] Data Structure The JSON file is a map lookup for lowercased mime types. Each mime type has the following properties: .source - where the mime type is defined. If not set, it's probably a custom media type. apache - Apache common media types iana - IANA-defined media types nginx - nginx media types .extensions[] - known extensions associated with this mime type. .compressible - whether a file of this type can be gzipped. .charset - the default charset associated with this type, if any. If unknown, every property could be undefined. Contributing To edit the database, only make PRs against src/custom-types.json or src/custom-suffix.json. The src/custom-types.json file is a JSON object with the MIME type as the keys and the values being an object with the following keys: compressible - leave out if you don't know, otherwise true/false to indicate whether the data represented by the type is typically compressible. extensions - include an array of file extensions that are associated with the type. notes - human-readable notes about the type, typically what the type is. sources - include an array of URLs of where the MIME type and the associated extensions are sourced from. This needs to be a primary source; links to type aggregating sites and Wikipedia are not acceptable. To update the build, run npm run build. Adding Custom Media Types The best way to get new media types included in this library is to register them with the IANA. The community registration procedure is outlined in RFC 6838 section 5. Types registered with the IANA are automatically pulled into this library. If that is not possible / feasible, they can be added directly here as a \"custom\" type. To do this, it is required to have a primary source that definitively lists the media type. If an extension is going to be listed as associateed with this media type, the source must definitively link the media type and extension as well."
  },
  "src/frontend/app-client/node_modules/mime-types/README.html": {
    "href": "src/frontend/app-client/node_modules/mime-types/README.html",
    "title": "mime-types",
    "summary": "mime-types The ultimate javascript content-type utility. Similar to the mime@1.x module, except: No fallbacks. Instead of naively returning the first available type, mime-types simply returns false, so do var type = mime.lookup('unrecognized') || 'application/octet-stream'. No new Mime() business, so you could do var lookup = require('mime-types').lookup. No .define() functionality Bug fixes for .lookup(path) Otherwise, the API is compatible with mime 1.x. Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install mime-types Adding Types All mime types are based on mime-db, so open a PR there if you'd like to add mime types. API var mime = require('mime-types') All functions return false if input is invalid or not found. mime.lookup(path) Lookup the content-type associated with a file. mime.lookup('json') // 'application/json' mime.lookup('.md') // 'text/markdown' mime.lookup('file.html') // 'text/html' mime.lookup('folder/file.js') // 'application/javascript' mime.lookup('folder/.htaccess') // false mime.lookup('cats') // false mime.contentType(type) Create a full content-type header given a content-type or extension. When given an extension, mime.lookup is used to get the matching content-type, otherwise the given content-type is used. Then if the content-type does not already have a charset parameter, mime.charset is used to get the default charset and add to the returned content-type. mime.contentType('markdown') // 'text/x-markdown; charset=utf-8' mime.contentType('file.json') // 'application/json; charset=utf-8' mime.contentType('text/html') // 'text/html; charset=utf-8' mime.contentType('text/html; charset=iso-8859-1') // 'text/html; charset=iso-8859-1' // from a full path mime.contentType(path.extname('/path/to/file.json')) // 'application/json; charset=utf-8' mime.extension(type) Get the default extension for a content-type. mime.extension('application/octet-stream') // 'bin' mime.charset(type) Lookup the implied default charset of a content-type. mime.charset('text/markdown') // 'UTF-8' var type = mime.types[extension] A map of content-types by extension. [extensions...] = mime.extensions[type] A map of extensions by content-type. License MIT"
  },
  "src/frontend/app-client/node_modules/mime/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/mime/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog v1.6.0 (24/11/2017) No changelog for this release. v2.0.4 (24/11/2017) [closed] Switch to mime-score module for resolving extension contention issues. #182 [closed] Update mime-db to 1.31.0 in v1.x branch #181 v1.5.0 (22/11/2017) [closed] need ES5 version ready in npm package #179 [closed] mime-db no trace of iWork - pages / numbers / etc. #178 [closed] How it works in brownser ? #176 [closed] Missing ./Mime #175 [closed] Vulnerable Regular Expression #167 v2.0.3 (25/09/2017) No changelog for this release. v1.4.1 (25/09/2017) [closed] Issue when bundling with webpack #172 v2.0.2 (15/09/2017) [V2] fs.readFileSync is not a function #165 [closed] The extension for video/quicktime should map to .mov, not .qt #164 [V2] [v2 Feedback request] Mime class API #163 [V2] [v2 Feedback request] Resolving conflicts over extensions #162 [V2] Allow callers to load module with official, full, or no defined types. #161 [V2] Use \"facets\" to resolve extension conflicts #160 [V2] Remove fs and path dependencies #152 [V2] Default content-type should not be application/octet-stream #139 [V2] reset mime-types #124 [V2] Extensionless paths should return null or false #113 v2.0.1 (14/09/2017) [closed] Changelog for v2.0 does not mention breaking changes #171 [closed] MIME breaking with 'class' declaration as it is without 'use strict mode' #170 v2.0.0 (12/09/2017) [closed] woff and woff2 #168 v1.4.0 (28/08/2017) [closed] support for ac3 voc files #159 [closed] Help understanding change from application/xml to text/xml #158 [closed] no longer able to override mimetype #157 [closed] application/vnd.adobe.photoshop #147 [closed] Directories should appear as something other than application/octet-stream #135 [closed] requested features #131 [closed] Make types.json loading optional? #129 [closed] Cannot find module './types.json' #120 [V2] .wav files show up as \"audio/x-wav\" instead of \"audio/x-wave\" #118 [closed] Don't be a pain in the ass for node community #108 [closed] don't make default_type global #78 [closed] mime.extension() fails if the content-type is parameterized #74 v1.3.6 (11/05/2017) [closed] .md should be text/markdown as of March 2016 #154 [closed] Error while installing mime #153 [closed] application/manifest+json #149 [closed] Dynamic adaptive streaming over HTTP (DASH) file extension typo #141 [closed] charsets image/png undefined #140 [closed] Mime-db dependency out of date #130 [closed] how to support plist？ #126 [closed] how does .types file format look like? #123 [closed] Feature: support for expanding MIME patterns #121 [closed] DEBUG_MIME doesn't work #117 v1.3.4 (06/02/2015) No changelog for this release. v1.3.3 (06/02/2015) No changelog for this release. v1.3.1 (05/02/2015) [closed] Consider adding support for Handlebars .hbs file ending #111 [closed] Consider adding support for hjson. #110 [closed] Add mime type for Opus audio files #94 [closed] Consider making the Requesting New Types information more visible #77 v1.3.0 (05/02/2015) [closed] Add common name? #114 [closed] application/x-yaml #104 [closed] Add mime type for WOFF file format 2.0 #102 [closed] application/x-msi for .msi #99 [closed] Add mimetype for gettext translation files #98 [closed] collaborators #88 [closed] getting errot in installation of mime module...any1 can help? #87 [closed] should application/json's charset be utf8? #86 [closed] Add \"license\" and \"licenses\" to package.json #81 [closed] lookup with extension-less file on Windows returns wrong type #68 v1.2.11 (15/08/2013) [closed] Update mime.types #65 [closed] Publish a new version #63 [closed] README should state upfront that \"application/octet-stream\" is default for unknown extension #55 [closed] Suggested improvement to the charset API #52 v1.2.10 (25/07/2013) [closed] Mime type for woff files should be application/font-woff and not application/x-font-woff #62 [closed] node.types in conflict with mime.types #51 v1.2.9 (17/01/2013) [closed] Please update \"mime\" NPM #49 [closed] Please add semicolon #46 [closed] parse full mime types #43 v1.2.8 (10/01/2013) [closed] /js directory mime is application/javascript. Is it correct? #47 [closed] Add mime types for lua code. #45 v1.2.7 (19/10/2012) [closed] cannot install 1.2.7 via npm #41 [closed] Transfer ownership to @broofa #36 [closed] it's wrong to set charset to UTF-8 for text #30 [closed] Allow multiple instances of MIME types container #27 v1.2.5 (16/02/2012) [closed] When looking up a types, check hasOwnProperty #23 [closed] Bump version to 1.2.2 #18 [closed] No license #16 [closed] Some types missing that are used by html5/css3 #13 [closed] npm install fails for 1.2.1 #12 [closed] image/pjpeg + image/x-png #10 [closed] symlink #8 [closed] gzip #2 [closed] ALL CAPS filenames return incorrect mime type #1"
  },
  "src/frontend/app-client/node_modules/mime/README.html": {
    "href": "src/frontend/app-client/node_modules/mime/README.html",
    "title": "mime",
    "summary": "mime Comprehensive MIME type mapping API based on mime-db module. Install Install with npm: npm install mime Contributing / Testing npm run test Command Line mime [path_string] E.g. > mime scripts/jquery.js application/javascript API - Queries mime.lookup(path) Get the mime type associated with a file, if no mime type is found application/octet-stream is returned. Performs a case-insensitive lookup using the extension in path (the substring after the last '/' or '.'). E.g. var mime = require('mime'); mime.lookup('/path/to/file.txt'); // => 'text/plain' mime.lookup('file.txt'); // => 'text/plain' mime.lookup('.TXT'); // => 'text/plain' mime.lookup('htm'); // => 'text/html' mime.default_type Sets the mime type returned when mime.lookup fails to find the extension searched for. (Default is application/octet-stream.) mime.extension(type) Get the default extension for type mime.extension('text/html'); // => 'html' mime.extension('application/octet-stream'); // => 'bin' mime.charsets.lookup() Map mime-type to charset mime.charsets.lookup('text/plain'); // => 'UTF-8' (The logic for charset lookups is pretty rudimentary. Feel free to suggest improvements.) API - Defining Custom Types Custom type mappings can be added on a per-project basis via the following APIs. mime.define() Add custom mime/extension mappings mime.define({ 'text/x-some-format': ['x-sf', 'x-sft', 'x-sfml'], 'application/x-my-type': ['x-mt', 'x-mtt'], // etc ... }); mime.lookup('x-sft'); // => 'text/x-some-format' The first entry in the extensions array is returned by mime.extension(). E.g. mime.extension('text/x-some-format'); // => 'x-sf' mime.load(filepath) Load mappings from an Apache \".types\" format file mime.load('./my_project.types'); The .types file format is simple - See the types dir for examples."
  },
  "src/frontend/app-client/node_modules/minimatch/README.html": {
    "href": "src/frontend/app-client/node_modules/minimatch/README.html",
    "title": "minimatch",
    "summary": "minimatch A minimal matching utility. This is the matching library used internally by npm. It works by converting glob expressions into JavaScript RegExp objects. Usage // hybrid module, load with require() or import import { minimatch } from 'minimatch' // or: const { minimatch } = require('minimatch') minimatch('bar.foo', '*.foo') // true! minimatch('bar.foo', '*.bar') // false! minimatch('bar.foo', '*.+(bar|foo)', { debug: true }) // true, and noisy! Features Supports these glob features: Brace Expansion Extended glob matching \"Globstar\" ** matching Posix character classes, like [[:alpha:]], supporting the full range of Unicode characters. For example, [[:alpha:]] will match against 'é', though [a-zA-Z] will not. Collating symbol and set matching is not supported, so [[=e=]] will not match 'é' and [[.ch.]] will not match 'ch' in locales where ch is considered a single character. See: man sh man bash Pattern Matching man 3 fnmatch man 5 gitignore Windows Please only use forward-slashes in glob expressions. Though windows uses either / or \\ as its path separator, only / characters are used by this glob implementation. You must use forward-slashes only in glob expressions. Back-slashes in patterns will always be interpreted as escape characters, not path separators. Note that \\ or / will be interpreted as path separators in paths on Windows, and will match against / in glob expressions. So just always use / in patterns. UNC Paths On Windows, UNC paths like //?/c:/... or //ComputerName/Share/... are handled specially. Patterns starting with a double-slash followed by some non-slash characters will preserve their double-slash. As a result, a pattern like //* will match //x, but not /x. Patterns staring with //?/<drive letter>: will not treat the ? as a wildcard character. Instead, it will be treated as a normal string. Patterns starting with //?/<drive letter>:/... will match file paths starting with <drive letter>:/..., and vice versa, as if the //?/ was not present. This behavior only is present when the drive letters are a case-insensitive match to one another. The remaining portions of the path/pattern are compared case sensitively, unless nocase:true is set. Note that specifying a UNC path using \\ characters as path separators is always allowed in the file path argument, but only allowed in the pattern argument when windowsPathsNoEscape: true is set in the options. Minimatch Class Create a minimatch object by instantiating the minimatch.Minimatch class. var Minimatch = require('minimatch').Minimatch var mm = new Minimatch(pattern, options) Properties pattern The original pattern the minimatch object represents. options The options supplied to the constructor. set A 2-dimensional array of regexp or string expressions. Each row in the array corresponds to a brace-expanded pattern. Each item in the row corresponds to a single path-part. For example, the pattern {a,b/c}/d would expand to a set of patterns like: [ [ a, d ] , [ b, c, d ] ] If a portion of the pattern doesn't have any \"magic\" in it (that is, it's something like \"foo\" rather than fo*o?), then it will be left as a string rather than converted to a regular expression. regexp Created by the makeRe method. A single regular expression expressing the entire pattern. This is useful in cases where you wish to use the pattern somewhat like fnmatch(3) with FNM_PATH enabled. negate True if the pattern is negated. comment True if the pattern is a comment. empty True if the pattern is \"\". Methods makeRe() Generate the regexp member if necessary, and return it. Will return false if the pattern is invalid. match(fname) Return true if the filename matches the pattern, or false otherwise. matchOne(fileArray, patternArray, partial) Take a /-split filename, and match it against a single row in the regExpSet. This method is mainly for internal use, but is exposed so that it can be used by a glob-walker that needs to avoid excessive filesystem calls. hasMagic() Returns true if the parsed pattern contains any magic characters. Returns false if all comparator parts are string literals. If the magicalBraces option is set on the constructor, then it will consider brace expansions which are not otherwise magical to be magic. If not set, then a pattern like a{b,c}d will return false, because neither abd nor acd contain any special glob characters. This does not mean that the pattern string can be used as a literal filename, as it may contain magic glob characters that are escaped. For example, the pattern \\\\* or [*] would not be considered to have magic, as the matching portion parses to the literal string '*' and would match a path named '*', not '\\\\*' or '[*]'. The minimatch.unescape() method may be used to remove escape characters. All other methods are internal, and will be called as necessary. minimatch(path, pattern, options) Main export. Tests a path against the pattern using the options. var isJS = minimatch(file, '*.js', { matchBase: true }) minimatch.filter(pattern, options) Returns a function that tests its supplied argument, suitable for use with Array.filter. Example: var javascripts = fileList.filter(minimatch.filter('*.js', { matchBase: true })) minimatch.escape(pattern, options = {}) Escape all magic characters in a glob pattern, so that it will only ever match literal strings If the windowsPathsNoEscape option is used, then characters are escaped by wrapping in [], because a magic character wrapped in a character class can only be satisfied by that exact character. Slashes (and backslashes in windowsPathsNoEscape mode) cannot be escaped or unescaped. minimatch.unescape(pattern, options = {}) Un-escape a glob string that may contain some escaped characters. If the windowsPathsNoEscape option is used, then square-brace escapes are removed, but not backslash escapes. For example, it will turn the string '[*]' into *, but it will not turn '\\\\*' into '*', because \\ is a path separator in windowsPathsNoEscape mode. When windowsPathsNoEscape is not set, then both brace escapes and backslash escapes are removed. Slashes (and backslashes in windowsPathsNoEscape mode) cannot be escaped or unescaped. minimatch.match(list, pattern, options) Match against the list of files, in the style of fnmatch or glob. If nothing is matched, and options.nonull is set, then return a list containing the pattern itself. var javascripts = minimatch.match(fileList, '*.js', { matchBase: true }) minimatch.makeRe(pattern, options) Make a regular expression object from the pattern. Options All options are false by default. debug Dump a ton of stuff to stderr. nobrace Do not expand {a,b} and {1..3} brace sets. noglobstar Disable ** matching against multiple folder names. dot Allow patterns to match filenames starting with a period, even if the pattern does not explicitly have a period in that spot. Note that by default, a/**/b will not match a/.d/b, unless dot is set. noext Disable \"extglob\" style patterns like +(a|b). nocase Perform a case-insensitive match. nocaseMagicOnly When used with {nocase: true}, create regular expressions that are case-insensitive, but leave string match portions untouched. Has no effect when used without {nocase: true} Useful when some other form of case-insensitive matching is used, or if the original string representation is useful in some other way. nonull When a match is not found by minimatch.match, return a list containing the pattern itself if this option is set. When not set, an empty list is returned if there are no matches. magicalBraces This only affects the results of the Minimatch.hasMagic method. If the pattern contains brace expansions, such as a{b,c}d, but no other magic characters, then the Minimatch.hasMagic() method will return false by default. When this option set, it will return true for brace expansion as well as other magic glob characters. matchBase If set, then patterns without slashes will be matched against the basename of the path if it contains slashes. For example, a?b would match the path /xyz/123/acb, but not /xyz/acb/123. nocomment Suppress the behavior of treating # at the start of a pattern as a comment. nonegate Suppress the behavior of treating a leading ! character as negation. flipNegate Returns from negate expressions the same as if they were not negated. (Ie, true on a hit, false on a miss.) partial Compare a partial path to a pattern. As long as the parts of the path that are present are not contradicted by the pattern, it will be treated as a match. This is useful in applications where you're walking through a folder structure, and don't yet have the full path, but want to ensure that you do not walk down paths that can never be a match. For example, minimatch('/a/b', '/a/*/c/d', { partial: true }) // true, might be /a/b/c/d minimatch('/a/b', '/**/d', { partial: true }) // true, might be /a/b/.../d minimatch('/x/y/z', '/a/**/z', { partial: true }) // false, because x !== a windowsPathsNoEscape Use \\\\ as a path separator only, and never as an escape character. If set, all \\\\ characters are replaced with / in the pattern. Note that this makes it impossible to match against paths containing literal glob pattern characters, but allows matching with patterns constructed using path.join() and path.resolve() on Windows platforms, mimicking the (buggy!) behavior of earlier versions on Windows. Please use with caution, and be mindful of the caveat about Windows paths. For legacy reasons, this is also set if options.allowWindowsEscape is set to the exact value false. windowsNoMagicRoot When a pattern starts with a UNC path or drive letter, and in nocase:true mode, do not convert the root portions of the pattern into a case-insensitive regular expression, and instead leave them as strings. This is the default when the platform is win32 and nocase:true is set. preserveMultipleSlashes By default, multiple / characters (other than the leading // in a UNC path, see \"UNC Paths\" above) are treated as a single /. That is, a pattern like a///b will match the file path a/b. Set preserveMultipleSlashes: true to suppress this behavior. optimizationLevel A number indicating the level of optimization that should be done to the pattern prior to parsing and using it for matches. Globstar parts ** are always converted to * when noglobstar is set, and multiple adjacent ** parts are converted into a single ** (ie, a/**/**/b will be treated as a/**/b, as this is equivalent in all cases). 0 - Make no further changes. In this mode, . and .. are maintained in the pattern, meaning that they must also appear in the same position in the test path string. Eg, a pattern like a/*/../c will match the string a/b/../c but not the string a/c. 1 - (default) Remove cases where a double-dot .. follows a pattern portion that is not **, ., .., or empty ''. For example, the pattern ./a/b/../* is converted to ./a/*, and so it will match the path string ./a/c, but not the path string ./a/b/../c. Dots and empty path portions in the pattern are preserved. 2 (or higher) - Much more aggressive optimizations, suitable for use with file-walking cases: Remove cases where a double-dot .. follows a pattern portion that is not **, ., or empty ''. Remove empty and . portions of the pattern, where safe to do so (ie, anywhere other than the last position, the first position, or the second position in a pattern starting with /, as this may indicate a UNC path on Windows). Convert patterns containing <pre>/**/../<p>/<rest> into the equivalent <pre>/{..,**}/<p>/<rest>, where <p> is a a pattern portion other than ., .., **, or empty ''. Dedupe patterns where a ** portion is present in one and omitted in another, and it is not the final path portion, and they are otherwise equivalent. So {a/**/b,a/b} becomes a/**/b, because ** matches against an empty path portion. Dedupe patterns where a * portion is present in one, and a non-dot pattern other than **, ., .., or '' is in the same position in the other. So a/{*,x}/b becomes a/*/b, because * can match against x. While these optimizations improve the performance of file-walking use cases such as glob (ie, the reason this module exists), there are cases where it will fail to match a literal string that would have been matched in optimization level 1 or 0. Specifically, while the Minimatch.match() method will optimize the file path string in the same ways, resulting in the same matches, it will fail when tested with the regular expression provided by Minimatch.makeRe(), unless the path string is first processed with minimatch.levelTwoFileOptimize() or similar. platform When set to win32, this will trigger all windows-specific behaviors (special handling for UNC paths, and treating \\ as separators in file paths for comparison.) Defaults to the value of process.platform. Comparisons to other fnmatch/glob implementations While strict compliance with the existing standards is a worthwhile goal, some discrepancies exist between minimatch and other implementations. Some are intentional, and some are unavoidable. If the pattern starts with a ! character, then it is negated. Set the nonegate flag to suppress this behavior, and treat leading ! characters normally. This is perhaps relevant if you wish to start the pattern with a negative extglob pattern like !(a|B). Multiple ! characters at the start of a pattern will negate the pattern multiple times. If a pattern starts with #, then it is treated as a comment, and will not match anything. Use \\# to match a literal # at the start of a line, or set the nocomment flag to suppress this behavior. The double-star character ** is supported by default, unless the noglobstar flag is set. This is supported in the manner of bsdglob and bash 4.1, where ** only has special significance if it is the only thing in a path part. That is, a/**/b will match a/x/y/b, but a/**b will not. If an escaped pattern has no matches, and the nonull flag is set, then minimatch.match returns the pattern as-provided, rather than interpreting the character escapes. For example, minimatch.match([], \"\\\\*a\\\\?\") will return \"\\\\*a\\\\?\" rather than \"*a?\". This is akin to setting the nullglob option in bash, except that it does not resolve escaped pattern characters. If brace expansion is not disabled, then it is performed before any other interpretation of the glob pattern. Thus, a pattern like +(a|{b),c)}, which would not be valid in bash or zsh, is expanded first into the set of +(a|b) and +(a|c), and those patterns are checked for validity. Since those two are valid, matching proceeds. Negated extglob patterns are handled as closely as possible to Bash semantics, but there are some cases with negative extglobs which are exceedingly difficult to express in a JavaScript regular expression. In particular the negated pattern <start>!(<pattern>*|)* will in bash match anything that does not start with <start><pattern>. However, <start>!(<pattern>*)* will match paths starting with <start><pattern>, because the empty string can match against the negated portion. In this library, <start>!(<pattern>*|)* will not match any pattern starting with <start>, due to a difference in precisely which patterns are considered \"greedy\" in Regular Expressions vs bash path expansion. This may be fixable, but not without incurring some complexity and performance costs, and the trade-off seems to not be worth pursuing. Note that fnmatch(3) in libc is an extremely naive string comparison matcher, which does not do anything special for slashes. This library is designed to be used in glob searching and file walkers, and so it does do special things with /. Thus, foo* will not match foo/bar in this library, even though it would in fnmatch(3)."
  },
  "src/frontend/app-client/node_modules/minipass/README.html": {
    "href": "src/frontend/app-client/node_modules/minipass/README.html",
    "title": "minipass",
    "summary": "minipass A very minimal implementation of a PassThrough stream It's very fast for objects, strings, and buffers. Supports pipe()ing (including multi-pipe() and backpressure transmission), buffering data until either a data event handler or pipe() is added (so you don't lose the first chunk), and most other cases where PassThrough is a good idea. There is a read() method, but it's much more efficient to consume data from this stream via 'data' events or by calling pipe() into some other stream. Calling read() requires the buffer to be flattened in some cases, which requires copying memory. If you set objectMode: true in the options, then whatever is written will be emitted. Otherwise, it'll do a minimal amount of Buffer copying to ensure proper Streams semantics when read(n) is called. objectMode can only be set at instantiation. Attempting to write something other than a String or Buffer without having set objectMode in the options will throw an error. This is not a through or through2 stream. It doesn't transform the data, it just passes it right through. If you want to transform the data, extend the class, and override the write() method. Once you're done transforming the data however you want, call super.write() with the transform output. For some examples of streams that extend Minipass in various ways, check out: minizlib fs-minipass tar minipass-collect minipass-flush minipass-pipeline tap tap-parser treport minipass-fetch pacote make-fetch-happen cacache ssri npm-registry-fetch minipass-json-stream minipass-sized Usage in TypeScript The Minipass class takes three type template definitions: RType the type being read, which defaults to Buffer. If RType is string, then the constructor must get an options object specifying either an encoding or objectMode: true. If it's anything other than string or Buffer, then it must get an options object specifying objectMode: true. WType the type being written. If RType is Buffer or string, then this defaults to ContiguousData (Buffer, string, ArrayBuffer, or ArrayBufferView). Otherwise, it defaults to RType. Events type mapping event names to the arguments emitted with that event, which extends Minipass.Events. To declare types for custom events in subclasses, extend the third parameter with your own event signatures. For example: import { Minipass } from 'minipass' // a NDJSON stream that emits 'jsonError' when it can't stringify export interface Events extends Minipass.Events { jsonError: [e: Error] } export class NDJSONStream extends Minipass<string, any, Events> { constructor() { super({ objectMode: true }) } // data is type `any` because that's WType write(data, encoding, cb) { try { const json = JSON.stringify(data) return super.write(json + '\\n', encoding, cb) } catch (er) { if (!er instanceof Error) { er = Object.assign(new Error('json stringify failed'), { cause: er, }) } // trying to emit with something OTHER than an error will // fail, because we declared the event arguments type. this.emit('jsonError', er) } } } const s = new NDJSONStream() s.on('jsonError', e => { // here, TS knows that e is an Error }) Emitting/handling events that aren't declared in this way is fine, but the arguments will be typed as unknown. Differences from Node.js Streams There are several things that make Minipass streams different from (and in some ways superior to) Node.js core streams. Please read these caveats if you are familiar with node-core streams and intend to use Minipass streams in your programs. You can avoid most of these differences entirely (for a very small performance penalty) by setting {async: true} in the constructor options. Timing Minipass streams are designed to support synchronous use-cases. Thus, data is emitted as soon as it is available, always. It is buffered until read, but no longer. Another way to look at it is that Minipass streams are exactly as synchronous as the logic that writes into them. This can be surprising if your code relies on PassThrough.write() always providing data on the next tick rather than the current one, or being able to call resume() and not have the entire buffer disappear immediately. However, without this synchronicity guarantee, there would be no way for Minipass to achieve the speeds it does, or support the synchronous use cases that it does. Simply put, waiting takes time. This non-deferring approach makes Minipass streams much easier to reason about, especially in the context of Promises and other flow-control mechanisms. Example: // hybrid module, either works import { Minipass } from 'minipass' // or: const { Minipass } = require('minipass') const stream = new Minipass() stream.on('data', () => console.log('data event')) console.log('before write') stream.write('hello') console.log('after write') // output: // before write // data event // after write Exception: Async Opt-In If you wish to have a Minipass stream with behavior that more closely mimics Node.js core streams, you can set the stream in async mode either by setting async: true in the constructor options, or by setting stream.async = true later on. // hybrid module, either works import { Minipass } from 'minipass' // or: const { Minipass } = require('minipass') const asyncStream = new Minipass({ async: true }) asyncStream.on('data', () => console.log('data event')) console.log('before write') asyncStream.write('hello') console.log('after write') // output: // before write // after write // data event <-- this is deferred until the next tick Switching out of async mode is unsafe, as it could cause data corruption, and so is not enabled. Example: import { Minipass } from 'minipass' const stream = new Minipass({ encoding: 'utf8' }) stream.on('data', chunk => console.log(chunk)) stream.async = true console.log('before writes') stream.write('hello') setStreamSyncAgainSomehow(stream) // <-- this doesn't actually exist! stream.write('world') console.log('after writes') // hypothetical output would be: // before writes // world // after writes // hello // NOT GOOD! To avoid this problem, once set into async mode, any attempt to make the stream sync again will be ignored. const { Minipass } = require('minipass') const stream = new Minipass({ encoding: 'utf8' }) stream.on('data', chunk => console.log(chunk)) stream.async = true console.log('before writes') stream.write('hello') stream.async = false // <-- no-op, stream already async stream.write('world') console.log('after writes') // actual output: // before writes // after writes // hello // world No High/Low Water Marks Node.js core streams will optimistically fill up a buffer, returning true on all writes until the limit is hit, even if the data has nowhere to go. Then, they will not attempt to draw more data in until the buffer size dips below a minimum value. Minipass streams are much simpler. The write() method will return true if the data has somewhere to go (which is to say, given the timing guarantees, that the data is already there by the time write() returns). If the data has nowhere to go, then write() returns false, and the data sits in a buffer, to be drained out immediately as soon as anyone consumes it. Since nothing is ever buffered unnecessarily, there is much less copying data, and less bookkeeping about buffer capacity levels. Hazards of Buffering (or: Why Minipass Is So Fast) Since data written to a Minipass stream is immediately written all the way through the pipeline, and write() always returns true/false based on whether the data was fully flushed, backpressure is communicated immediately to the upstream caller. This minimizes buffering. Consider this case: const { PassThrough } = require('stream') const p1 = new PassThrough({ highWaterMark: 1024 }) const p2 = new PassThrough({ highWaterMark: 1024 }) const p3 = new PassThrough({ highWaterMark: 1024 }) const p4 = new PassThrough({ highWaterMark: 1024 }) p1.pipe(p2).pipe(p3).pipe(p4) p4.on('data', () => console.log('made it through')) // this returns false and buffers, then writes to p2 on next tick (1) // p2 returns false and buffers, pausing p1, then writes to p3 on next tick (2) // p3 returns false and buffers, pausing p2, then writes to p4 on next tick (3) // p4 returns false and buffers, pausing p3, then emits 'data' and 'drain' // on next tick (4) // p3 sees p4's 'drain' event, and calls resume(), emitting 'resume' and // 'drain' on next tick (5) // p2 sees p3's 'drain', calls resume(), emits 'resume' and 'drain' on next tick (6) // p1 sees p2's 'drain', calls resume(), emits 'resume' and 'drain' on next // tick (7) p1.write(Buffer.alloc(2048)) // returns false Along the way, the data was buffered and deferred at each stage, and multiple event deferrals happened, for an unblocked pipeline where it was perfectly safe to write all the way through! Furthermore, setting a highWaterMark of 1024 might lead someone reading the code to think an advisory maximum of 1KiB is being set for the pipeline. However, the actual advisory buffering level is the sum of highWaterMark values, since each one has its own bucket. Consider the Minipass case: const m1 = new Minipass() const m2 = new Minipass() const m3 = new Minipass() const m4 = new Minipass() m1.pipe(m2).pipe(m3).pipe(m4) m4.on('data', () => console.log('made it through')) // m1 is flowing, so it writes the data to m2 immediately // m2 is flowing, so it writes the data to m3 immediately // m3 is flowing, so it writes the data to m4 immediately // m4 is flowing, so it fires the 'data' event immediately, returns true // m4's write returned true, so m3 is still flowing, returns true // m3's write returned true, so m2 is still flowing, returns true // m2's write returned true, so m1 is still flowing, returns true // No event deferrals or buffering along the way! m1.write(Buffer.alloc(2048)) // returns true It is extremely unlikely that you don't want to buffer any data written, or ever buffer data that can be flushed all the way through. Neither node-core streams nor Minipass ever fail to buffer written data, but node-core streams do a lot of unnecessary buffering and pausing. As always, the faster implementation is the one that does less stuff and waits less time to do it. Immediately emit end for empty streams (when not paused) If a stream is not paused, and end() is called before writing any data into it, then it will emit end immediately. If you have logic that occurs on the end event which you don't want to potentially happen immediately (for example, closing file descriptors, moving on to the next entry in an archive parse stream, etc.) then be sure to call stream.pause() on creation, and then stream.resume() once you are ready to respond to the end event. However, this is usually not a problem because: Emit end When Asked One hazard of immediately emitting 'end' is that you may not yet have had a chance to add a listener. In order to avoid this hazard, Minipass streams safely re-emit the 'end' event if a new listener is added after 'end' has been emitted. Ie, if you do stream.on('end', someFunction), and the stream has already emitted end, then it will call the handler right away. (You can think of this somewhat like attaching a new .then(fn) to a previously-resolved Promise.) To prevent calling handlers multiple times who would not expect multiple ends to occur, all listeners are removed from the 'end' event whenever it is emitted. Emit error When Asked The most recent error object passed to the 'error' event is stored on the stream. If a new 'error' event handler is added, and an error was previously emitted, then the event handler will be called immediately (or on process.nextTick in the case of async streams). This makes it much more difficult to end up trying to interact with a broken stream, if the error handler is added after an error was previously emitted. Impact of \"immediate flow\" on Tee-streams A \"tee stream\" is a stream piping to multiple destinations: const tee = new Minipass() t.pipe(dest1) t.pipe(dest2) t.write('foo') // goes to both destinations Since Minipass streams immediately process any pending data through the pipeline when a new pipe destination is added, this can have surprising effects, especially when a stream comes in from some other function and may or may not have data in its buffer. // WARNING! WILL LOSE DATA! const src = new Minipass() src.write('foo') src.pipe(dest1) // 'foo' chunk flows to dest1 immediately, and is gone src.pipe(dest2) // gets nothing! One solution is to create a dedicated tee-stream junction that pipes to both locations, and then pipe to that instead. // Safe example: tee to both places const src = new Minipass() src.write('foo') const tee = new Minipass() tee.pipe(dest1) tee.pipe(dest2) src.pipe(tee) // tee gets 'foo', pipes to both locations The same caveat applies to on('data') event listeners. The first one added will immediately receive all of the data, leaving nothing for the second: // WARNING! WILL LOSE DATA! const src = new Minipass() src.write('foo') src.on('data', handler1) // receives 'foo' right away src.on('data', handler2) // nothing to see here! Using a dedicated tee-stream can be used in this case as well: // Safe example: tee to both data handlers const src = new Minipass() src.write('foo') const tee = new Minipass() tee.on('data', handler1) tee.on('data', handler2) src.pipe(tee) All of the hazards in this section are avoided by setting { async: true } in the Minipass constructor, or by setting stream.async = true afterwards. Note that this does add some overhead, so should only be done in cases where you are willing to lose a bit of performance in order to avoid having to refactor program logic. USAGE It's a stream! Use it like a stream and it'll most likely do what you want. import { Minipass } from 'minipass' const mp = new Minipass(options) // options is optional mp.write('foo') mp.pipe(someOtherStream) mp.end('bar') OPTIONS encoding How would you like the data coming out of the stream to be encoded? Accepts any values that can be passed to Buffer.toString(). objectMode Emit data exactly as it comes in. This will be flipped on by default if you write() something other than a string or Buffer at any point. Setting objectMode: true will prevent setting any encoding value. async Defaults to false. Set to true to defer data emission until next tick. This reduces performance slightly, but makes Minipass streams use timing behavior closer to Node core streams. See Timing for more details. signal An AbortSignal that will cause the stream to unhook itself from everything and become as inert as possible. Note that providing a signal parameter will make 'error' events no longer throw if they are unhandled, but they will still be emitted to handlers if any are attached. API Implements the user-facing portions of Node.js's Readable and Writable streams. Methods write(chunk, [encoding], [callback]) - Put data in. (Note that, in the base Minipass class, the same data will come out.) Returns false if the stream will buffer the next write, or true if it's still in \"flowing\" mode. end([chunk, [encoding]], [callback]) - Signal that you have no more data to write. This will queue an end event to be fired when all the data has been consumed. pause() - No more data for a while, please. This also prevents end from being emitted for empty streams until the stream is resumed. resume() - Resume the stream. If there's data in the buffer, it is all discarded. Any buffered events are immediately emitted. pipe(dest) - Send all output to the stream provided. When data is emitted, it is immediately written to any and all pipe destinations. (Or written on next tick in async mode.) unpipe(dest) - Stop piping to the destination stream. This is immediate, meaning that any asynchronously queued data will not make it to the destination when running in async mode. options.end - Boolean, end the destination stream when the source stream ends. Default true. options.proxyErrors - Boolean, proxy error events from the source stream to the destination stream. Note that errors are not proxied after the pipeline terminates, either due to the source emitting 'end' or manually unpiping with src.unpipe(dest). Default false. on(ev, fn), emit(ev, fn) - Minipass streams are EventEmitters. Some events are given special treatment, however. (See below under \"events\".) promise() - Returns a Promise that resolves when the stream emits end, or rejects if the stream emits error. collect() - Return a Promise that resolves on end with an array containing each chunk of data that was emitted, or rejects if the stream emits error. Note that this consumes the stream data. concat() - Same as collect(), but concatenates the data into a single Buffer object. Will reject the returned promise if the stream is in objectMode, or if it goes into objectMode by the end of the data. read(n) - Consume n bytes of data out of the buffer. If n is not provided, then consume all of it. If n bytes are not available, then it returns null. Note consuming streams in this way is less efficient, and can lead to unnecessary Buffer copying. destroy([er]) - Destroy the stream. If an error is provided, then an 'error' event is emitted. If the stream has a close() method, and has not emitted a 'close' event yet, then stream.close() will be called. Any Promises returned by .promise(), .collect() or .concat() will be rejected. After being destroyed, writing to the stream will emit an error. No more data will be emitted if the stream is destroyed, even if it was previously buffered. Properties bufferLength Read-only. Total number of bytes buffered, or in the case of objectMode, the total number of objects. encoding Read-only. The encoding that has been set. flowing Read-only. Boolean indicating whether a chunk written to the stream will be immediately emitted. emittedEnd Read-only. Boolean indicating whether the end-ish events (ie, end, prefinish, finish) have been emitted. Note that listening on any end-ish event will immediateyl re-emit it if it has already been emitted. writable Whether the stream is writable. Default true. Set to false when end() readable Whether the stream is readable. Default true. pipes An array of Pipe objects referencing streams that this stream is piping into. destroyed A getter that indicates whether the stream was destroyed. paused True if the stream has been explicitly paused, otherwise false. objectMode Indicates whether the stream is in objectMode. aborted Readonly property set when the AbortSignal dispatches an abort event. Events data Emitted when there's data to read. Argument is the data to read. This is never emitted while not flowing. If a listener is attached, that will resume the stream. end Emitted when there's no more data to read. This will be emitted immediately for empty streams when end() is called. If a listener is attached, and end was already emitted, then it will be emitted again. All listeners are removed when end is emitted. prefinish An end-ish event that follows the same logic as end and is emitted in the same conditions where end is emitted. Emitted after 'end'. finish An end-ish event that follows the same logic as end and is emitted in the same conditions where end is emitted. Emitted after 'prefinish'. close An indication that an underlying resource has been released. Minipass does not emit this event, but will defer it until after end has been emitted, since it throws off some stream libraries otherwise. drain Emitted when the internal buffer empties, and it is again suitable to write() into the stream. readable Emitted when data is buffered and ready to be read by a consumer. resume Emitted when stream changes state from buffering to flowing mode. (Ie, when resume is called, pipe is called, or a data event listener is added.) Static Methods Minipass.isStream(stream) Returns true if the argument is a stream, and false otherwise. To be considered a stream, the object must be either an instance of Minipass, or an EventEmitter that has either a pipe() method, or both write() and end() methods. (Pretty much any stream in node-land will return true for this.) EXAMPLES Here are some examples of things you can do with Minipass streams. simple \"are you done yet\" promise mp.promise().then( () => { // stream is finished }, er => { // stream emitted an error } ) collecting mp.collect().then(all => { // all is an array of all the data emitted // encoding is supported in this case, so // so the result will be a collection of strings if // an encoding is specified, or buffers/objects if not. // // In an async function, you may do // const data = await stream.collect() }) collecting into a single blob This is a bit slower because it concatenates the data into one chunk for you, but if you're going to do it yourself anyway, it's convenient this way: mp.concat().then(onebigchunk => { // onebigchunk is a string if the stream // had an encoding set, or a buffer otherwise. }) iteration You can iterate over streams synchronously or asynchronously in platforms that support it. Synchronous iteration will end when the currently available data is consumed, even if the end event has not been reached. In string and buffer mode, the data is concatenated, so unless multiple writes are occurring in the same tick as the read(), sync iteration loops will generally only have a single iteration. To consume chunks in this way exactly as they have been written, with no flattening, create the stream with the { objectMode: true } option. const mp = new Minipass({ objectMode: true }) mp.write('a') mp.write('b') for (let letter of mp) { console.log(letter) // a, b } mp.write('c') mp.write('d') for (let letter of mp) { console.log(letter) // c, d } mp.write('e') mp.end() for (let letter of mp) { console.log(letter) // e } for (let letter of mp) { console.log(letter) // nothing } Asynchronous iteration will continue until the end event is reached, consuming all of the data. const mp = new Minipass({ encoding: 'utf8' }) // some source of some data let i = 5 const inter = setInterval(() => { if (i-- > 0) mp.write(Buffer.from('foo\\n', 'utf8')) else { mp.end() clearInterval(inter) } }, 100) // consume the data with asynchronous iteration async function consume() { for await (let chunk of mp) { console.log(chunk) } return 'ok' } consume().then(res => console.log(res)) // logs `foo\\n` 5 times, and then `ok` subclass that console.log()s everything written into it class Logger extends Minipass { write(chunk, encoding, callback) { console.log('WRITE', chunk, encoding) return super.write(chunk, encoding, callback) } end(chunk, encoding, callback) { console.log('END', chunk, encoding) return super.end(chunk, encoding, callback) } } someSource.pipe(new Logger()).pipe(someDest) same thing, but using an inline anonymous class // js classes are fun someSource .pipe( new (class extends Minipass { emit(ev, ...data) { // let's also log events, because debugging some weird thing console.log('EMIT', ev) return super.emit(ev, ...data) } write(chunk, encoding, callback) { console.log('WRITE', chunk, encoding) return super.write(chunk, encoding, callback) } end(chunk, encoding, callback) { console.log('END', chunk, encoding) return super.end(chunk, encoding, callback) } })() ) .pipe(someDest) subclass that defers 'end' for some reason class SlowEnd extends Minipass { emit(ev, ...args) { if (ev === 'end') { console.log('going to end, hold on a sec') setTimeout(() => { console.log('ok, ready to end now') super.emit('end', ...args) }, 100) return true } else { return super.emit(ev, ...args) } } } transform that creates newline-delimited JSON class NDJSONEncode extends Minipass { write(obj, cb) { try { // JSON.stringify can throw, emit an error on that return super.write(JSON.stringify(obj) + '\\n', 'utf8', cb) } catch (er) { this.emit('error', er) } } end(obj, cb) { if (typeof obj === 'function') { cb = obj obj = undefined } if (obj !== undefined) { this.write(obj) } return super.end(cb) } } transform that parses newline-delimited JSON class NDJSONDecode extends Minipass { constructor(options) { // always be in object mode, as far as Minipass is concerned super({ objectMode: true }) this._jsonBuffer = '' } write(chunk, encoding, cb) { if ( typeof chunk === 'string' && typeof encoding === 'string' && encoding !== 'utf8' ) { chunk = Buffer.from(chunk, encoding).toString() } else if (Buffer.isBuffer(chunk)) { chunk = chunk.toString() } if (typeof encoding === 'function') { cb = encoding } const jsonData = (this._jsonBuffer + chunk).split('\\n') this._jsonBuffer = jsonData.pop() for (let i = 0; i < jsonData.length; i++) { try { // JSON.parse can throw, emit an error on that super.write(JSON.parse(jsonData[i])) } catch (er) { this.emit('error', er) continue } } if (cb) cb() } }"
  },
  "src/frontend/app-client/node_modules/morgan/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/morgan/HISTORY.html",
    "title": "1.10.0 / 2020-03-20",
    "summary": "1.10.0 / 2020-03-20 Add :total-time token Fix trailing space in colored status code for dev format deps: basic-auth@~2.0.1 deps: safe-buffer@5.1.2 deps: depd@~2.0.0 Replace internal eval usage with Function constructor Use instance methods on process to check for listeners deps: on-headers@~1.0.2 Fix res.writeHead patch missing return value 1.9.1 / 2018-09-10 Fix using special characters in format deps: depd@~1.1.2 perf: remove argument reassignment 1.9.0 / 2017-09-26 Use res.headersSent when available deps: basic-auth@~2.0.0 Use safe-buffer for improved Buffer API deps: debug@2.6.9 deps: depd@~1.1.1 Remove unnecessary Buffer loading 1.8.2 / 2017-05-23 deps: debug@2.6.8 Fix DEBUG_MAX_ARRAY_LENGTH deps: ms@2.0.0 1.8.1 / 2017-02-04 deps: debug@2.6.1 Fix deprecation messages in WebStorm and other editors Undeprecate DEBUG_FD set to 1 or 2 1.8.0 / 2017-02-04 Fix sending unnecessary undefined argument to token functions deps: basic-auth@~1.1.0 deps: debug@2.6.0 Allow colors in workers Deprecated DEBUG_FD environment variable Fix error when running under React Native Use same color for same namespace deps: ms@0.7.2 perf: enable strict mode in compiled functions 1.7.0 / 2016-02-18 Add digits argument to response-time token deps: depd@~1.1.0 Enable strict mode in more places Support web browser loading deps: on-headers@~1.0.1 perf: enable strict mode 1.6.1 / 2015-07-03 deps: basic-auth@~1.0.3 1.6.0 / 2015-06-12 Add morgan.compile(format) export Do not color 1xx status codes in dev format Fix response-time token to not include response latency Fix status token incorrectly displaying before response in dev format Fix token return values to be undefined or a string Improve representation of multiple headers in req and res tokens Use res.getHeader in res token deps: basic-auth@~1.0.2 perf: enable strict mode perf: hoist regular expression perf: parse with regular expressions perf: remove argument reassignment deps: on-finished@~2.3.0 Add defined behavior for HTTP CONNECT requests Add defined behavior for HTTP Upgrade requests deps: ee-first@1.1.1 pref: enable strict mode pref: reduce function closure scopes pref: remove dynamic compile on every request for dev format pref: remove an argument reassignment pref: skip function call without skip option 1.5.3 / 2015-05-10 deps: basic-auth@~1.0.1 deps: debug@~2.2.0 deps: ms@0.7.1 deps: depd@~1.0.1 deps: on-finished@~2.2.1 Fix isFinished(req) when data buffered 1.5.2 / 2015-03-15 deps: debug@~2.1.3 Fix high intensity foreground color for bold deps: ms@0.7.0 1.5.1 / 2014-12-31 deps: debug@~2.1.1 deps: on-finished@~2.2.0 1.5.0 / 2014-11-06 Add multiple date formats clf for the common log format iso for the common ISO 8601 date time format web for the common RFC 1123 date time format Deprecate buffer option Fix date format in common and combined formats Fix token arguments to accept values with \" 1.4.1 / 2014-10-22 deps: on-finished@~2.1.1 Fix handling of pipelined requests 1.4.0 / 2014-10-16 Add debug messages deps: depd@~1.0.0 1.3.2 / 2014-09-27 Fix req.ip integration when immediate: false 1.3.1 / 2014-09-14 Remove un-used bytes dependency deps: depd@0.4.5 1.3.0 / 2014-09-01 Assert if format is not a function or string 1.2.3 / 2014-08-16 deps: on-finished@2.1.0 1.2.2 / 2014-07-27 deps: depd@0.4.4 Work-around v8 generating empty stack traces 1.2.1 / 2014-07-26 deps: depd@0.4.3 Fix exception when global Error.stackTraceLimit is too low 1.2.0 / 2014-07-19 Add :remote-user token Add combined log format Add common log format Add morgan(format, options) function signature Deprecate default format -- use combined format instead Deprecate not providing a format Remove non-standard grey color from dev format 1.1.1 / 2014-05-20 simplify method to get remote address 1.1.0 / 2014-05-18 \"dev\" format will use same tokens as other formats :response-time token is now empty when immediate used :response-time token is now monotonic :response-time token has precision to 1 μs fix :status + immediate output in node.js 0.8 improve buffer option to prevent indefinite event loop holding deps: bytes@1.0.0 add negative support 1.0.1 / 2014-05-04 Make buffer unique per morgan instance deps: bytes@0.3.0 added terabyte support 1.0.0 / 2014-02-08 Initial release"
  },
  "src/frontend/app-client/node_modules/morgan/node_modules/debug/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/morgan/node_modules/debug/CHANGELOG.html",
    "title": "2.6.9 / 2017-09-22",
    "summary": "2.6.9 / 2017-09-22 remove ReDoS regexp in %o formatter (#504) 2.6.8 / 2017-05-18 Fix: Check for undefined on browser globals (#462, @marbemac) 2.6.7 / 2017-05-16 Fix: Update ms to 2.0.0 to fix regular expression denial of service vulnerability (#458, @hubdotcom) Fix: Inline extend function in node implementation (#452, @dougwilson) Docs: Fix typo (#455, @msasad) 2.6.5 / 2017-04-27 Fix: null reference check on window.documentElement.style.WebkitAppearance (#447, @thebigredgeek) Misc: clean up browser reference checks (#447, @thebigredgeek) Misc: add npm-debug.log to .gitignore (@thebigredgeek) 2.6.4 / 2017-04-20 Fix: bug that would occure if process.env.DEBUG is a non-string value. (#444, @LucianBuzzo) Chore: ignore bower.json in npm installations. (#437, @joaovieira) Misc: update \"ms\" to v0.7.3 (@tootallnate) 2.6.3 / 2017-03-13 Fix: Electron reference to process.env.DEBUG (#431, @paulcbetts) Docs: Changelog fix (@thebigredgeek) 2.6.2 / 2017-03-10 Fix: DEBUG_MAX_ARRAY_LENGTH (#420, @slavaGanzin) Docs: Add backers and sponsors from Open Collective (#422, @piamancini) Docs: Add Slackin invite badge (@tootallnate) 2.6.1 / 2017-02-10 Fix: Module's export default syntax fix for IE8 Expected identifier error Fix: Whitelist DEBUG_FD for values 1 and 2 only (#415, @pi0) Fix: IE8 \"Expected identifier\" error (#414, @vgoma) Fix: Namespaces would not disable once enabled (#409, @musikov) 2.6.0 / 2016-12-28 Fix: added better null pointer checks for browser useColors (@thebigredgeek) Improvement: removed explicit window.debug export (#404, @tootallnate) Improvement: deprecated DEBUG_FD environment variable (#405, @tootallnate) 2.5.2 / 2016-12-25 Fix: reference error on window within webworkers (#393, @KlausTrainer) Docs: fixed README typo (#391, @lurch) Docs: added notice about v3 api discussion (@thebigredgeek) 2.5.1 / 2016-12-20 Fix: babel-core compatibility 2.5.0 / 2016-12-20 Fix: wrong reference in bower file (@thebigredgeek) Fix: webworker compatibility (@thebigredgeek) Fix: output formatting issue (#388, @kribblo) Fix: babel-loader compatibility (#383, @escwald) Misc: removed built asset from repo and publications (@thebigredgeek) Misc: moved source files to /src (#378, @yamikuronue) Test: added karma integration and replaced babel with browserify for browser tests (#378, @yamikuronue) Test: coveralls integration (#378, @yamikuronue) Docs: simplified language in the opening paragraph (#373, @yamikuronue) 2.4.5 / 2016-12-17 Fix: navigator undefined in Rhino (#376, @jochenberger) Fix: custom log function (#379, @hsiliev) Improvement: bit of cleanup + linting fixes (@thebigredgeek) Improvement: rm non-maintainted dist/ dir (#375, @freewil) Docs: simplified language in the opening paragraph. (#373, @yamikuronue) 2.4.4 / 2016-12-14 Fix: work around debug being loaded in preload scripts for electron (#368, @paulcbetts) 2.4.3 / 2016-12-14 Fix: navigation.userAgent error for react native (#364, @escwald) 2.4.2 / 2016-12-14 Fix: browser colors (#367, @tootallnate) Misc: travis ci integration (@thebigredgeek) Misc: added linting and testing boilerplate with sanity check (@thebigredgeek) 2.4.1 / 2016-12-13 Fix: typo that broke the package (#356) 2.4.0 / 2016-12-13 Fix: bower.json references unbuilt src entry point (#342, @justmatt) Fix: revert \"handle regex special characters\" (@tootallnate) Feature: configurable util.inspect()`options for NodeJS (#327, @tootallnate) Feature: %O`(big O) pretty-prints objects (#322, @tootallnate) Improvement: allow colors in workers (#335, @botverse) Improvement: use same color for same namespace. (#338, @lchenay) 2.3.3 / 2016-11-09 Fix: Catch JSON.stringify() errors (#195, Jovan Alleyne) Fix: Returning localStorage saved values (#331, Levi Thomason) Improvement: Don't create an empty object when no process (Nathan Rajlich) 2.3.2 / 2016-11-09 Fix: be super-safe in index.js as well (@TooTallNate) Fix: should check whether process exists (Tom Newby) 2.3.1 / 2016-11-09 Fix: Added electron compatibility (#324, @paulcbetts) Improvement: Added performance optimizations (@tootallnate) Readme: Corrected PowerShell environment variable example (#252, @gimre) Misc: Removed yarn lock file from source control (#321, @fengmk2) 2.3.0 / 2016-11-07 Fix: Consistent placement of ms diff at end of output (#215, @gorangajic) Fix: Escaping of regex special characters in namespace strings (#250, @zacronos) Fix: Fixed bug causing crash on react-native (#282, @vkarpov15) Feature: Enabled ES6+ compatible import via default export (#212 @bucaran) Feature: Added %O formatter to reflect Chrome's console.log capability (#279, @oncletom) Package: Update \"ms\" to 0.7.2 (#315, @DevSide) Package: removed superfluous version property from bower.json (#207 @kkirsche) Readme: fix USE_COLORS to DEBUG_COLORS Readme: Doc fixes for format string sugar (#269, @mlucool) Readme: Updated docs for DEBUG_FD and DEBUG_COLORS environment variables (#232, @mattlyons0) Readme: doc fixes for PowerShell (#271 #243, @exoticknight @unreadable) Readme: better docs for browser support (#224, @matthewmueller) Tooling: Added yarn integration for development (#317, @thebigredgeek) Misc: Renamed History.md to CHANGELOG.md (@thebigredgeek) Misc: Added license file (#226 #274, @CantemoInternal @sdaitzman) Misc: Updated contributors (@thebigredgeek) 2.2.0 / 2015-05-09 package: update \"ms\" to v0.7.1 (#202, @dougwilson) README: add logging to file example (#193, @DanielOchoa) README: fixed a typo (#191, @amir-s) browser: expose storage (#190, @stephenmathieson) Makefile: add a distclean target (#189, @stephenmathieson) 2.1.3 / 2015-03-13 Updated stdout/stderr example (#186) Updated example/stdout.js to match debug current behaviour Renamed example/stderr.js to stdout.js Update Readme.md (#184) replace high intensity foreground color for bold (#182, #183) 2.1.2 / 2015-03-01 dist: recompile update \"ms\" to v0.7.0 package: update \"browserify\" to v9.0.3 component: fix \"ms.js\" repo location changed bower package name updated documentation about using debug in a browser fix: security error on safari (#167, #168, @yields) 2.1.1 / 2014-12-29 browser: use typeof to check for console existence browser: check for console.log truthiness (fix IE 8/9) browser: add support for Chrome apps Readme: added Windows usage remarks Add bower.json to properly support bower install 2.1.0 / 2014-10-15 node: implement DEBUG_FD env variable support package: update \"browserify\" to v6.1.0 package: add \"license\" field to package.json (#135, @panuhorsmalahti) 2.0.0 / 2014-09-01 package: update \"browserify\" to v5.11.0 node: use stderr rather than stdout for logging (#29, @stephenmathieson) 1.0.4 / 2014-07-15 dist: recompile example: remove console.info() log usage example: add \"Content-Type\" UTF-8 header to browser example browser: place %c marker after the space character browser: reset the \"content\" color via color: inherit browser: add colors support for Firefox >= v31 debug: prefer an instance log() function over the global one (#119) Readme: update documentation about styled console logs for FF v31 (#116, @wryk) 1.0.3 / 2014-07-09 Add support for multiple wildcards in namespaces (#122, @seegno) browser: fix lint 1.0.2 / 2014-06-10 browser: update color palette (#113, @gscottolson) common: make console logging function configurable (#108, @timoxley) node: fix %o colors on old node <= 0.8.x Makefile: find node path using shell/which (#109, @timoxley) 1.0.1 / 2014-06-06 browser: use removeItem() to clear localStorage browser, node: don't set DEBUG if namespaces is undefined (#107, @leedm777) package: add \"contributors\" section node: fix comment typo README: list authors 1.0.0 / 2014-06-04 make ms diff be global, not be scope debug: ignore empty strings in enable() node: make DEBUG_COLORS able to disable coloring *: export the colors array npmignore: don't publish the dist dir Makefile: refactor to use browserify package: add \"browserify\" as a dev dependency Readme: add Web Inspector Colors section node: reset terminal color for the debug content node: map \"%o\" to util.inspect() browser: map \"%j\" to JSON.stringify() debug: add custom \"formatters\" debug: use \"ms\" module for humanizing the diff Readme: add \"bash\" syntax highlighting browser: add Firebug color support browser: add colors for WebKit browsers node: apply log to console rewrite: abstract common logic for Node & browsers add .jshintrc file 0.8.1 / 2014-04-14 package: re-add the \"component\" section 0.8.0 / 2014-03-30 add enable() method for nodejs. Closes #27 change from stderr to stdout remove unnecessary index.js file 0.7.4 / 2013-11-13 remove \"browserify\" key from package.json (fixes something in browserify) 0.7.3 / 2013-10-30 fix: catch localStorage security error when cookies are blocked (Chrome) add debug(err) support. Closes #46 add .browser prop to package.json. Closes #42 0.7.2 / 2013-02-06 fix package.json fix: Mobile Safari (private mode) is broken with debug fix: Use unicode to send escape character to shell instead of octal to work with strict mode javascript 0.7.1 / 2013-02-05 add repository URL to package.json add DEBUG_COLORED to force colored output add browserify support fix component. Closes #24 0.7.0 / 2012-05-04 Added .component to package.json Added debug.component.js build 0.6.0 / 2012-03-16 Added support for \"-\" prefix in DEBUG [Vinay Pulim] Added .enabled flag to the node version [TooTallNate] 0.5.0 / 2012-02-02 Added: humanize diffs. Closes #8 Added debug.disable() to the CS variant Removed padding. Closes #10 Fixed: persist client-side variant again. Closes #9 0.4.0 / 2012-02-01 Added browser variant support for older browsers [TooTallNate] Added debug.enable('project:*') to browser variant [TooTallNate] Added padding to diff (moved it to the right) 0.3.0 / 2012-01-26 Added millisecond diff when isatty, otherwise UTC string 0.2.0 / 2012-01-22 Added wildcard support 0.1.0 / 2011-12-02 Added: remove colors unless stderr isatty [TooTallNate] 0.0.1 / 2010-01-03 Initial release"
  },
  "src/frontend/app-client/node_modules/morgan/node_modules/debug/README.html": {
    "href": "src/frontend/app-client/node_modules/morgan/node_modules/debug/README.html",
    "title": "debug",
    "summary": "debug A tiny node.js debugging utility modelled after node core's debugging technique. Discussion around the V3 API is under way here Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %s', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var debug = require('debug')('worker'); setInterval(function(){ debug('doing some work'); }, 1000); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows note On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Note that PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Then, run the program to be debugged as usual. Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toUTCString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); Web Inspector Colors Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Colored output looks something like: Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2016 TJ Holowaychuk <tj@vision-media.ca&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/morgan/node_modules/ms/license.html": {
    "href": "src/frontend/app-client/node_modules/morgan/node_modules/ms/license.html",
    "title": "",
    "summary": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/morgan/node_modules/ms/readme.html": {
    "href": "src/frontend/app-client/node_modules/morgan/node_modules/ms/readme.html",
    "title": "ms",
    "summary": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 Convert from milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(ms('10 hours')) // \"10h\" Time format written-out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in node and in the browser. If a number is supplied to ms, a string with a unit is returned. If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100'). If you pass a string with a number and a valid unit, the number of equivalent ms is returned. Caught a bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, node will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "src/frontend/app-client/node_modules/morgan/node_modules/on-finished/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/morgan/node_modules/on-finished/HISTORY.html",
    "title": "2.3.0 / 2015-05-26",
    "summary": "2.3.0 / 2015-05-26 Add defined behavior for HTTP CONNECT requests Add defined behavior for HTTP Upgrade requests deps: ee-first@1.1.1 2.2.1 / 2015-04-22 Fix isFinished(req) when data buffered 2.2.0 / 2014-12-22 Add message object to callback arguments 2.1.1 / 2014-10-22 Fix handling of pipelined requests 2.1.0 / 2014-08-16 Check if socket is detached Return undefined for isFinished if state unknown 2.0.0 / 2014-08-16 Add isFinished function Move to jshttp organization Remove support for plain socket argument Rename to on-finished Support both req and res as arguments deps: ee-first@1.0.5 1.2.2 / 2014-06-10 Reduce listeners added to emitters avoids \"event emitter leak\" warnings when used multiple times on same request 1.2.1 / 2014-06-08 Fix returned value when already finished 1.2.0 / 2014-06-05 Call callback when called on already-finished socket 1.1.4 / 2014-05-27 Support node.js 0.8 1.1.3 / 2014-04-30 Make sure errors passed as instanceof Error 1.1.2 / 2014-04-18 Default the socket to passed-in object 1.1.1 / 2014-01-16 Rename module to finished 1.1.0 / 2013-12-25 Call callback when called on already-errored socket 1.0.1 / 2013-12-20 Actually pass the error to the callback 1.0.0 / 2013-12-20 Initial release"
  },
  "src/frontend/app-client/node_modules/morgan/node_modules/on-finished/README.html": {
    "href": "src/frontend/app-client/node_modules/morgan/node_modules/on-finished/README.html",
    "title": "on-finished",
    "summary": "on-finished Execute a callback when a HTTP request closes, finishes, or errors. Install $ npm install on-finished API var onFinished = require('on-finished') onFinished(res, listener) Attach a listener to listen for the response to finish. The listener will be invoked only once when the response finished. If the response finished to an error, the first argument will contain the error. If the response has already finished, the listener will be invoked. Listening to the end of a response would be used to close things associated with the response, like open files. Listener is invoked as listener(err, res). onFinished(res, function (err, res) { // clean up open fds, etc. // err contains the error is request error'd }) onFinished(req, listener) Attach a listener to listen for the request to finish. The listener will be invoked only once when the request finished. If the request finished to an error, the first argument will contain the error. If the request has already finished, the listener will be invoked. Listening to the end of a request would be used to know when to continue after reading the data. Listener is invoked as listener(err, req). var data = '' req.setEncoding('utf8') res.on('data', function (str) { data += str }) onFinished(req, function (err, req) { // data is read unless there is err }) onFinished.isFinished(res) Determine if res is already finished. This would be useful to check and not even start certain operations if the response has already finished. onFinished.isFinished(req) Determine if req is already finished. This would be useful to check and not even start certain operations if the request has already finished. Special Node.js requests HTTP CONNECT method The meaning of the CONNECT method from RFC 7231, section 4.3.6: The CONNECT method requests that the recipient establish a tunnel to the destination origin server identified by the request-target and, if successful, thereafter restrict its behavior to blind forwarding of packets, in both directions, until the tunnel is closed. Tunnels are commonly used to create an end-to-end virtual connection, through one or more proxies, which can then be secured using TLS (Transport Layer Security, [RFC5246]). In Node.js, these request objects come from the 'connect' event on the HTTP server. When this module is used on a HTTP CONNECT request, the request is considered \"finished\" immediately, due to limitations in the Node.js interface. This means if the CONNECT request contains a request entity, the request will be considered \"finished\" even before it has been read. There is no such thing as a response object to a CONNECT request in Node.js, so there is no support for for one. HTTP Upgrade request The meaning of the Upgrade header from RFC 7230, section 6.1: The \"Upgrade\" header field is intended to provide a simple mechanism for transitioning from HTTP/1.1 to some other protocol on the same connection. In Node.js, these request objects come from the 'upgrade' event on the HTTP server. When this module is used on a HTTP request with an Upgrade header, the request is considered \"finished\" immediately, due to limitations in the Node.js interface. This means if the Upgrade request contains a request entity, the request will be considered \"finished\" even before it has been read. There is no such thing as a response object to a Upgrade request in Node.js, so there is no support for for one. Example The following code ensures that file descriptors are always closed once the response finishes. var destroy = require('destroy') var http = require('http') var onFinished = require('on-finished') http.createServer(function onRequest(req, res) { var stream = fs.createReadStream('package.json') stream.pipe(res) onFinished(res, function (err) { destroy(stream) }) }) License MIT"
  },
  "src/frontend/app-client/node_modules/morgan/README.html": {
    "href": "src/frontend/app-client/node_modules/morgan/README.html",
    "title": "morgan",
    "summary": "morgan HTTP request logger middleware for node.js Named after Dexter, a show you should not watch until completion. API var morgan = require('morgan') morgan(format, options) Create a new morgan logger middleware function using the given format and options. The format argument may be a string of a predefined name (see below for the names), a string of a format string, or a function that will produce a log entry. The format function will be called with three arguments tokens, req, and res, where tokens is an object with all defined tokens, req is the HTTP request and res is the HTTP response. The function is expected to return a string that will be the log line, or undefined / null to skip logging. Using a predefined format string morgan('tiny') Using format string of predefined tokens morgan(':method :url :status :res[content-length] - :response-time ms') Using a custom format function morgan(function (tokens, req, res) { return [ tokens.method(req, res), tokens.url(req, res), tokens.status(req, res), tokens.res(req, res, 'content-length'), '-', tokens['response-time'](req, res), 'ms' ].join(' ') }) Options Morgan accepts these properties in the options object. immediate Write log line on request instead of response. This means that a requests will be logged even if the server crashes, but data from the response (like the response code, content length, etc.) cannot be logged. skip Function to determine if logging is skipped, defaults to false. This function will be called as skip(req, res). // EXAMPLE: only log error responses morgan('combined', { skip: function (req, res) { return res.statusCode < 400 } }) stream Output stream for writing log lines, defaults to process.stdout. Predefined Formats There are various pre-defined formats provided: combined Standard Apache combined log output. :remote-addr - :remote-user [:date[clf]] \":method :url HTTP/:http-version\" :status :res[content-length] \":referrer\" \":user-agent\" common Standard Apache common log output. :remote-addr - :remote-user [:date[clf]] \":method :url HTTP/:http-version\" :status :res[content-length] dev Concise output colored by response status for development use. The :status token will be colored green for success codes, red for server error codes, yellow for client error codes, cyan for redirection codes, and uncolored for information codes. :method :url :status :response-time ms - :res[content-length] short Shorter than default, also including response time. :remote-addr :remote-user :method :url HTTP/:http-version :status :res[content-length] - :response-time ms tiny The minimal output. :method :url :status :res[content-length] - :response-time ms Tokens Creating new tokens To define a token, simply invoke morgan.token() with the name and a callback function. This callback function is expected to return a string value. The value returned is then available as \":type\" in this case: morgan.token('type', function (req, res) { return req.headers['content-type'] }) Calling morgan.token() using the same name as an existing token will overwrite that token definition. The token function is expected to be called with the arguments req and res, representing the HTTP request and HTTP response. Additionally, the token can accept further arguments of it's choosing to customize behavior. :date[format] The current date and time in UTC. The available formats are: clf for the common log format (\"10/Oct/2000:13:55:36 +0000\") iso for the common ISO 8601 date time format (2000-10-10T13:55:36.000Z) web for the common RFC 1123 date time format (Tue, 10 Oct 2000 13:55:36 GMT) If no format is given, then the default is web. :http-version The HTTP version of the request. :method The HTTP method of the request. :referrer The Referrer header of the request. This will use the standard mis-spelled Referer header if exists, otherwise Referrer. :remote-addr The remote address of the request. This will use req.ip, otherwise the standard req.connection.remoteAddress value (socket address). :remote-user The user authenticated as part of Basic auth for the request. :req[header] The given header of the request. If the header is not present, the value will be displayed as \"-\" in the log. :res[header] The given header of the response. If the header is not present, the value will be displayed as \"-\" in the log. :response-time[digits] The time between the request coming into morgan and when the response headers are written, in milliseconds. The digits argument is a number that specifies the number of digits to include on the number, defaulting to 3, which provides microsecond precision. :status The status code of the response. If the request/response cycle completes before a response was sent to the client (for example, the TCP socket closed prematurely by a client aborting the request), then the status will be empty (displayed as \"-\" in the log). :total-time[digits] The time between the request coming into morgan and when the response has finished being written out to the connection, in milliseconds. The digits argument is a number that specifies the number of digits to include on the number, defaulting to 3, which provides microsecond precision. :url The URL of the request. This will use req.originalUrl if exists, otherwise req.url. :user-agent The contents of the User-Agent header of the request. morgan.compile(format) Compile a format string into a format function for use by morgan. A format string is a string that represents a single log line and can utilize token syntax. Tokens are references by :token-name. If tokens accept arguments, they can be passed using [], for example: :token-name[pretty] would pass the string 'pretty' as an argument to the token token-name. The function returned from morgan.compile takes three arguments tokens, req, and res, where tokens is object with all defined tokens, req is the HTTP request and res is the HTTP response. The function will return a string that will be the log line, or undefined / null to skip logging. Normally formats are defined using morgan.format(name, format), but for certain advanced uses, this compile function is directly available. Examples express/connect Simple app that will log all request in the Apache combined format to STDOUT var express = require('express') var morgan = require('morgan') var app = express() app.use(morgan('combined')) app.get('/', function (req, res) { res.send('hello, world!') }) vanilla http server Simple app that will log all request in the Apache combined format to STDOUT var finalhandler = require('finalhandler') var http = require('http') var morgan = require('morgan') // create \"middleware\" var logger = morgan('combined') http.createServer(function (req, res) { var done = finalhandler(req, res) logger(req, res, function (err) { if (err) return done(err) // respond to request res.setHeader('content-type', 'text/plain') res.end('hello, world!') }) }) write logs to a file single file Simple app that will log all requests in the Apache combined format to the file access.log. var express = require('express') var fs = require('fs') var morgan = require('morgan') var path = require('path') var app = express() // create a write stream (in append mode) var accessLogStream = fs.createWriteStream(path.join(__dirname, 'access.log'), { flags: 'a' }) // setup the logger app.use(morgan('combined', { stream: accessLogStream })) app.get('/', function (req, res) { res.send('hello, world!') }) log file rotation Simple app that will log all requests in the Apache combined format to one log file per day in the log/ directory using the rotating-file-stream module. var express = require('express') var morgan = require('morgan') var path = require('path') var rfs = require('rotating-file-stream') // version 2.x var app = express() // create a rotating write stream var accessLogStream = rfs.createStream('access.log', { interval: '1d', // rotate daily path: path.join(__dirname, 'log') }) // setup the logger app.use(morgan('combined', { stream: accessLogStream })) app.get('/', function (req, res) { res.send('hello, world!') }) split / dual logging The morgan middleware can be used as many times as needed, enabling combinations like: Log entry on request and one on response Log all requests to file, but errors to console ... and more! Sample app that will log all requests to a file using Apache format, but error responses are logged to the console: var express = require('express') var fs = require('fs') var morgan = require('morgan') var path = require('path') var app = express() // log only 4xx and 5xx responses to console app.use(morgan('dev', { skip: function (req, res) { return res.statusCode < 400 } })) // log all requests to access.log app.use(morgan('common', { stream: fs.createWriteStream(path.join(__dirname, 'access.log'), { flags: 'a' }) })) app.get('/', function (req, res) { res.send('hello, world!') }) use custom token formats Sample app that will use custom token formats. This adds an ID to all requests and displays it using the :id token. var express = require('express') var morgan = require('morgan') var uuid = require('node-uuid') morgan.token('id', function getId (req) { return req.id }) var app = express() app.use(assignId) app.use(morgan(':id :method :url :response-time')) app.get('/', function (req, res) { res.send('hello, world!') }) function assignId (req, res, next) { req.id = uuid.v4() next() } License MIT"
  },
  "src/frontend/app-client/node_modules/motion-dom/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/motion-dom/LICENSE.html",
    "title": "",
    "summary": "The MIT License (MIT) Copyright (c) 2024 Motion B.V. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/motion-utils/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/motion-utils/LICENSE.html",
    "title": "",
    "summary": "The MIT License (MIT) Copyright (c) 2024 Motion B.V. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/ms/license.html": {
    "href": "src/frontend/app-client/node_modules/ms/license.html",
    "title": "",
    "summary": "The MIT License (MIT) Copyright (c) 2020 Vercel, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/ms/readme.html": {
    "href": "src/frontend/app-client/node_modules/ms/readme.html",
    "title": "ms",
    "summary": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 ms('-3 days') // -259200000 ms('-1h') // -3600000 ms('-200') // -200 Convert from Milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(-3 * 60000) // \"-3m\" ms(ms('10 hours')) // \"10h\" Time Format Written-Out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(-3 * 60000, { long: true }) // \"-3 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in Node.js and in the browser If a number is supplied to ms, a string with a unit is returned If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100') If you pass a string with a number and a valid unit, the number of equivalent milliseconds is returned Related Packages ms.macro - Run ms as a macro at build-time. Caught a Bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, Node.js will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "src/frontend/app-client/node_modules/nanoid/README.html": {
    "href": "src/frontend/app-client/node_modules/nanoid/README.html",
    "title": "Nano ID",
    "summary": "Nano ID English | Русский | 简体中文 | Bahasa Indonesia A tiny, secure, URL-friendly, unique string ID generator for JavaScript. “An amazing level of senseless perfectionism, which is simply impossible not to respect.” Small. 130 bytes (minified and gzipped). No dependencies. Size Limit controls the size. Fast. It is 2 times faster than UUID. Safe. It uses hardware random generator. Can be used in clusters. Short IDs. It uses a larger alphabet than UUID (A-Za-z0-9_-). So ID size was reduced from 36 to 21 symbols. Portable. Nano ID was ported to 20 programming languages. import { nanoid } from 'nanoid' model.id = nanoid() //=> \"V1StGXR8_Z5jdHi6B-myT\" Supports modern browsers, IE with Babel, Node.js and React Native. Docs Read full docs here."
  },
  "src/frontend/app-client/node_modules/negotiator/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/negotiator/HISTORY.html",
    "title": "unreleased",
    "summary": "unreleased Added an option preferred encodings array #59 0.6.3 / 2022-01-22 Revert \"Lazy-load modules from main entry point\" 0.6.2 / 2019-04-29 Fix sorting charset, encoding, and language with extra parameters 0.6.1 / 2016-05-02 perf: improve Accept parsing speed perf: improve Accept-Charset parsing speed perf: improve Accept-Encoding parsing speed perf: improve Accept-Language parsing speed 0.6.0 / 2015-09-29 Fix including type extensions in parameters in Accept parsing Fix parsing Accept parameters with quoted equals Fix parsing Accept parameters with quoted semicolons Lazy-load modules from main entry point perf: delay type concatenation until needed perf: enable strict mode perf: hoist regular expressions perf: remove closures getting spec properties perf: remove a closure from media type parsing perf: remove property delete from media type parsing 0.5.3 / 2015-05-10 Fix media type parameter matching to be case-insensitive 0.5.2 / 2015-05-06 Fix comparing media types with quoted values Fix splitting media types with quoted commas 0.5.1 / 2015-02-14 Fix preference sorting to be stable for long acceptable lists 0.5.0 / 2014-12-18 Fix list return order when large accepted list Fix missing identity encoding when q=0 exists Remove dynamic building of Negotiator class 0.4.9 / 2014-10-14 Fix error when media type has invalid parameter 0.4.8 / 2014-09-28 Fix all negotiations to be case-insensitive Stable sort preferences of same quality according to client order Support Node.js 0.6 0.4.7 / 2014-06-24 Handle invalid provided languages Handle invalid provided media types 0.4.6 / 2014-06-11 Order by specificity when quality is the same 0.4.5 / 2014-05-29 Fix regression in empty header handling 0.4.4 / 2014-05-29 Fix behaviors when headers are not present 0.4.3 / 2014-04-16 Handle slashes on media params correctly 0.4.2 / 2014-02-28 Fix media type sorting Handle media types params strictly 0.4.1 / 2014-01-16 Use most specific matches 0.4.0 / 2014-01-09 Remove preferred prefix from methods"
  },
  "src/frontend/app-client/node_modules/negotiator/README.html": {
    "href": "src/frontend/app-client/node_modules/negotiator/README.html",
    "title": "negotiator",
    "summary": "negotiator An HTTP content negotiator for Node.js Installation $ npm install negotiator API var Negotiator = require('negotiator') Accept Negotiation availableMediaTypes = ['text/html', 'text/plain', 'application/json'] // The negotiator constructor receives a request object negotiator = new Negotiator(request) // Let's say Accept header is 'text/html, application/*;q=0.2, image/jpeg;q=0.8' negotiator.mediaTypes() // -> ['text/html', 'image/jpeg', 'application/*'] negotiator.mediaTypes(availableMediaTypes) // -> ['text/html', 'application/json'] negotiator.mediaType(availableMediaTypes) // -> 'text/html' You can check a working example at examples/accept.js. Methods mediaType() Returns the most preferred media type from the client. mediaType(availableMediaType) Returns the most preferred media type from a list of available media types. mediaTypes() Returns an array of preferred media types ordered by the client preference. mediaTypes(availableMediaTypes) Returns an array of preferred media types ordered by priority from a list of available media types. Accept-Language Negotiation negotiator = new Negotiator(request) availableLanguages = ['en', 'es', 'fr'] // Let's say Accept-Language header is 'en;q=0.8, es, pt' negotiator.languages() // -> ['es', 'pt', 'en'] negotiator.languages(availableLanguages) // -> ['es', 'en'] language = negotiator.language(availableLanguages) // -> 'es' You can check a working example at examples/language.js. Methods language() Returns the most preferred language from the client. language(availableLanguages) Returns the most preferred language from a list of available languages. languages() Returns an array of preferred languages ordered by the client preference. languages(availableLanguages) Returns an array of preferred languages ordered by priority from a list of available languages. Accept-Charset Negotiation availableCharsets = ['utf-8', 'iso-8859-1', 'iso-8859-5'] negotiator = new Negotiator(request) // Let's say Accept-Charset header is 'utf-8, iso-8859-1;q=0.8, utf-7;q=0.2' negotiator.charsets() // -> ['utf-8', 'iso-8859-1', 'utf-7'] negotiator.charsets(availableCharsets) // -> ['utf-8', 'iso-8859-1'] negotiator.charset(availableCharsets) // -> 'utf-8' You can check a working example at examples/charset.js. Methods charset() Returns the most preferred charset from the client. charset(availableCharsets) Returns the most preferred charset from a list of available charsets. charsets() Returns an array of preferred charsets ordered by the client preference. charsets(availableCharsets) Returns an array of preferred charsets ordered by priority from a list of available charsets. Accept-Encoding Negotiation availableEncodings = ['identity', 'gzip'] negotiator = new Negotiator(request) // Let's say Accept-Encoding header is 'gzip, compress;q=0.2, identity;q=0.5' negotiator.encodings() // -> ['gzip', 'identity', 'compress'] negotiator.encodings(availableEncodings) // -> ['gzip', 'identity'] negotiator.encoding(availableEncodings) // -> 'gzip' You can check a working example at examples/encoding.js. Methods encoding() Returns the most preferred encoding from the client. encoding(availableEncodings) Returns the most preferred encoding from a list of available encodings. encoding(availableEncodings, preferred) Returns the most preferred encoding from a list of available encodings, while prioritizing based on preferred array between same-quality encodings. encodings() Returns an array of preferred encodings ordered by the client preference. encodings(availableEncodings) Returns an array of preferred encodings ordered by priority from a list of available encodings. encodings(availableEncodings, preferred) Returns an array of preferred encodings ordered by priority from a list of available encodings, while prioritizing based on preferred array between same-quality encodings. See Also The accepts module builds on this module and provides an alternative interface, mime type validation, and more. License MIT"
  },
  "src/frontend/app-client/node_modules/node-releases/README.html": {
    "href": "src/frontend/app-client/node_modules/node-releases/README.html",
    "title": "Node.js releases data",
    "summary": "Node.js releases data All data is located in data directory. data/processed contains envs.json with node.js releases data preprocessed to be used by Browserslist and other projects. Each version in this file contains only necessary info: version, release date, LTS flag/name, and security flag. data/release-schedule contains release-schedule.json with node.js releases date and end of life date. Installation npm install node-releases"
  },
  "src/frontend/app-client/node_modules/nopt/README.html": {
    "href": "src/frontend/app-client/node_modules/nopt/README.html",
    "title": "",
    "summary": "If you want to write an option parser, and have it be good, there are two ways to do it. The Right Way, and the Wrong Way. The Wrong Way is to sit down and write an option parser. We've all done that. The Right Way is to write some complex configurable program with so many options that you hit the limit of your frustration just trying to manage them all, and defer it with duct-tape solutions until you see exactly to the core of the problem, and finally snap and write an awesome option parser. If you want to write an option parser, don't write an option parser. Write a package manager, or a source control system, or a service restarter, or an operating system. You probably won't end up with a good one of those, but if you don't give up, and you are relentless and diligent enough in your procrastination, you may just end up with a very nice option parser. USAGE // my-program.js var nopt = require(\"nopt\") , Stream = require(\"stream\").Stream , path = require(\"path\") , knownOpts = { \"foo\" : [String, null] , \"bar\" : [Stream, Number] , \"baz\" : path , \"bloo\" : [ \"big\", \"medium\", \"small\" ] , \"flag\" : Boolean , \"pick\" : Boolean , \"many1\" : [String, Array] , \"many2\" : [path, Array] } , shortHands = { \"foofoo\" : [\"--foo\", \"Mr. Foo\"] , \"b7\" : [\"--bar\", \"7\"] , \"m\" : [\"--bloo\", \"medium\"] , \"p\" : [\"--pick\"] , \"f\" : [\"--flag\"] } // everything is optional. // knownOpts and shorthands default to {} // arg list defaults to process.argv // slice defaults to 2 , parsed = nopt(knownOpts, shortHands, process.argv, 2) console.log(parsed) This would give you support for any of the following: $ node my-program.js --foo \"blerp\" --no-flag { \"foo\" : \"blerp\", \"flag\" : false } $ node my-program.js ---bar 7 --foo \"Mr. Hand\" --flag { bar: 7, foo: \"Mr. Hand\", flag: true } $ node my-program.js --foo \"blerp\" -f -----p { foo: \"blerp\", flag: true, pick: true } $ node my-program.js -fp --foofoo { foo: \"Mr. Foo\", flag: true, pick: true } $ node my-program.js --foofoo -- -fp # -- stops the flag parsing. { foo: \"Mr. Foo\", argv: { remain: [\"-fp\"] } } $ node my-program.js --blatzk -fp # unknown opts are ok. { blatzk: true, flag: true, pick: true } $ node my-program.js --blatzk=1000 -fp # but you need to use = if they have a value { blatzk: 1000, flag: true, pick: true } $ node my-program.js --no-blatzk -fp # unless they start with \"no-\" { blatzk: false, flag: true, pick: true } $ node my-program.js --baz b/a/z # known paths are resolved. { baz: \"/Users/isaacs/b/a/z\" } # if Array is one of the types, then it can take many # values, and will always be an array. The other types provided # specify what types are allowed in the list. $ node my-program.js --many1 5 --many1 null --many1 foo { many1: [\"5\", \"null\", \"foo\"] } $ node my-program.js --many2 foo --many2 bar { many2: [\"/path/to/foo\", \"path/to/bar\"] } Read the tests at the bottom of lib/nopt.js for more examples of what this puppy can do. Types The following types are supported, and defined on nopt.typeDefs String: A normal string. No parsing is done. path: A file system path. Gets resolved against cwd if not absolute. url: A url. If it doesn't parse, it isn't accepted. Number: Must be numeric. Date: Must parse as a date. If it does, and Date is one of the options, then it will return a Date object, not a string. Boolean: Must be either true or false. If an option is a boolean, then it does not need a value, and its presence will imply true as the value. To negate boolean flags, do --no-whatever or --whatever false NaN: Means that the option is strictly not allowed. Any value will fail. Stream: An object matching the \"Stream\" class in node. Valuable for use when validating programmatically. (npm uses this to let you supply any WriteStream on the outfd and logfd config options.) Array: If Array is specified as one of the types, then the value will be parsed as a list of options. This means that multiple values can be specified, and that the value will always be an array. If a type is an array of values not on this list, then those are considered valid values. For instance, in the example above, the --bloo option can only be one of \"big\", \"medium\", or \"small\", and any other value will be rejected. When parsing unknown fields, \"true\", \"false\", and \"null\" will be interpreted as their JavaScript equivalents. You can also mix types and values, or multiple types, in a list. For instance { blah: [Number, null] } would allow a value to be set to either a Number or null. When types are ordered, this implies a preference, and the first type that can be used to properly interpret the value will be used. To define a new type, add it to nopt.typeDefs. Each item in that hash is an object with a type member and a validate method. The type member is an object that matches what goes in the type list. The validate method is a function that gets called with validate(data, key, val). Validate methods should assign data[key] to the valid value of val if it can be handled properly, or return boolean false if it cannot. You can also call nopt.clean(data, types, typeDefs) to clean up a config object and remove its invalid properties. Error Handling By default, nopt outputs a warning to standard error when invalid values for known options are found. You can change this behavior by assigning a method to nopt.invalidHandler. This method will be called with the offending nopt.invalidHandler(key, val, types). If no nopt.invalidHandler is assigned, then it will console.error its whining. If it is assigned to boolean false then the warning is suppressed. Abbreviations Yes, they are supported. If you define options like this: { \"foolhardyelephants\" : Boolean , \"pileofmonkeys\" : Boolean } Then this will work: node program.js --foolhar --pil node program.js --no-f --pileofmon # etc. Shorthands Shorthands are a hash of shorter option names to a snippet of args that they expand to. If multiple one-character shorthands are all combined, and the combination does not unambiguously match any other option or shorthand, then they will be broken up into their constituent parts. For example: { \"s\" : [\"--loglevel\", \"silent\"] , \"g\" : \"--global\" , \"f\" : \"--force\" , \"p\" : \"--parseable\" , \"l\" : \"--long\" } npm ls -sgflp # just like doing this: npm ls --loglevel silent --global --force --long --parseable The Rest of the args The config object returned by nopt is given a special member called argv, which is an object with the following fields: remain: The remaining args after all the parsing has occurred. original: The args as they originally appeared. cooked: The args after flags and shorthands are expanded. Slicing Node programs are called with more or less the exact argv as it appears in C land, after the v8 and node-specific options have been plucked off. As such, argv[0] is always node and argv[1] is always the JavaScript program being run. That's usually not very useful to you. So they're sliced off by default. If you want them, then you can pass in 0 as the last argument, or any other number that you'd like to slice off the start of the list."
  },
  "src/frontend/app-client/node_modules/normalize-package-data/README.html": {
    "href": "src/frontend/app-client/node_modules/normalize-package-data/README.html",
    "title": "normalize-package-data",
    "summary": "normalize-package-data normalize-package-data exports a function that normalizes package metadata. This data is typically found in a package.json file, but in principle could come from any source - for example the npm registry. normalize-package-data is used by read-package-json to normalize the data it reads from a package.json file. In turn, read-package-json is used by npm and various npm-related tools. Installation npm install normalize-package-data Usage Basic usage is really simple. You call the function that normalize-package-data exports. Let's call it normalizeData. normalizeData = require('normalize-package-data') packageData = require(\"./package.json\") normalizeData(packageData) // packageData is now normalized Strict mode You may activate strict validation by passing true as the second argument. normalizeData = require('normalize-package-data') packageData = require(\"./package.json\") normalizeData(packageData, true) // packageData is now normalized If strict mode is activated, only Semver 2.0 version strings are accepted. Otherwise, Semver 1.0 strings are accepted as well. Packages must have a name, and the name field must not have contain leading or trailing whitespace. Warnings Optionally, you may pass a \"warning\" function. It gets called whenever the normalizeData function encounters something that doesn't look right. It indicates less than perfect input data. normalizeData = require('normalize-package-data') packageData = require(\"./package.json\") warnFn = function(msg) { console.error(msg) } normalizeData(packageData, warnFn) // packageData is now normalized. Any number of warnings may have been logged. You may combine strict validation with warnings by passing true as the second argument, and warnFn as third. When private field is set to true, warnings will be suppressed. Potential exceptions If the supplied data has an invalid name or version field, normalizeData will throw an error. Depending on where you call normalizeData, you may want to catch these errors so can pass them to a callback. What normalization (currently) entails The value of name field gets trimmed (unless in strict mode). The value of the version field gets cleaned by semver.clean. See documentation for the semver module. If name and/or version fields are missing, they are set to empty strings. If files field is not an array, it will be removed. If bin field is a string, then bin field will become an object with name set to the value of the name field, and bin set to the original string value. If man field is a string, it will become an array with the original string as its sole member. If keywords field is string, it is considered to be a list of keywords separated by one or more white-space characters. It gets converted to an array by splitting on \\s+. All people fields (author, maintainers, contributors) get converted into objects with name, email and url properties. If bundledDependencies field (a typo) exists and bundleDependencies field does not, bundledDependencies will get renamed to bundleDependencies. If the value of any of the dependencies fields (dependencies, devDependencies, optionalDependencies) is a string, it gets converted into an object with familiar name=>value pairs. The values in optionalDependencies get added to dependencies. The optionalDependencies array is left untouched. As of v2: Dependencies that point at known hosted git providers (currently: github, bitbucket, gitlab) will have their URLs canonicalized, but protocols will be preserved. As of v2: Dependencies that use shortcuts for hosted git providers (org/proj, github:org/proj, bitbucket:org/proj, gitlab:org/proj, gist:docid) will have the shortcut left in place. (In the case of github, the org/proj form will be expanded to github:org/proj.) THIS MARKS A BREAKING CHANGE FROM V1, where the shortcut was previously expanded to a URL. If description field does not exist, but readme field does, then (more or less) the first paragraph of text that's found in the readme is taken as value for description. If repository field is a string, it will become an object with url set to the original string value, and type set to \"git\". If repository.url is not a valid url, but in the style of \"[owner-name]/[repo-name]\", repository.url will be set to git+https://github.com/[owner-name]/[repo-name].git If bugs field is a string, the value of bugs field is changed into an object with url set to the original string value. If bugs field does not exist, but repository field points to a repository hosted on GitHub, the value of the bugs field gets set to an url in the form of https://github.com/[owner-name]/[repo-name]/issues . If the repository field points to a GitHub Gist repo url, the associated http url is chosen. If bugs field is an object, the resulting value only has email and url properties. If email and url properties are not strings, they are ignored. If no valid values for either email or url is found, bugs field will be removed. If homepage field is not a string, it will be removed. If the url in the homepage field does not specify a protocol, then http is assumed. For example, myproject.org will be changed to http://myproject.org. If homepage field does not exist, but repository field points to a repository hosted on GitHub, the value of the homepage field gets set to an url in the form of https://github.com/[owner-name]/[repo-name]#readme . If the repository field points to a GitHub Gist repo url, the associated http url is chosen. Rules for name field If name field is given, the value of the name field must be a string. The string may not: start with a period. contain the following characters: /@\\s+% contain any characters that would need to be encoded for use in urls. resemble the word node_modules or favicon.ico (case doesn't matter). Rules for version field If version field is given, the value of the version field must be a valid semver string, as determined by the semver.valid method. See documentation for the semver module. Rules for license field The license/licence field should be a valid SPDX license expression or one of the special values allowed by validate-npm-package-license. See documentation for the license field in package.json. Credits This package contains code based on read-package-json written by Isaac Z. Schlueter. Used with permission. License normalize-package-data is released under the BSD 2-Clause License. Copyright (c) 2013 Meryn Stol"
  },
  "src/frontend/app-client/node_modules/npm-install-checks/README.html": {
    "href": "src/frontend/app-client/node_modules/npm-install-checks/README.html",
    "title": "npm-install-checks",
    "summary": "npm-install-checks Check the engines and platform fields in package.json API Both functions will throw an error if the check fails, or return undefined if everything is ok. Errors have a required and current fields. .checkEngine(pkg, npmVer, nodeVer, force = false) Check if a package's engines.node and engines.npm match the running system. force argument will override the node version check, but not the npm version check, as this typically would indicate that the current version of npm is unable to install the package properly for some reason. Error code: 'EBADENGINE' .checkPlatform(pkg, force, environment) Check if a package's os, cpu and libc match the running system. force argument skips all checks. environment overrides the execution environment which comes from process.platform process.arch and current libc environment by default. environment.os environment.cpu and environment.libc are available. Error code: 'EBADPLATFORM'"
  },
  "src/frontend/app-client/node_modules/npm-normalize-package-bin/README.html": {
    "href": "src/frontend/app-client/node_modules/npm-normalize-package-bin/README.html",
    "title": "npm-normalize-package-bin",
    "summary": "npm-normalize-package-bin Turn any flavor of allowable package.json bin into a normalized object. API const normalize = require('npm-normalize-package-bin') const pkg = {name: 'foo', bin: 'bar'} console.log(normalize(pkg)) // {name:'foo', bin:{foo: 'bar'}} Also strips out weird dots and slashes to prevent accidental and/or malicious bad behavior when the package is installed."
  },
  "src/frontend/app-client/node_modules/npm-package-arg/README.html": {
    "href": "src/frontend/app-client/node_modules/npm-package-arg/README.html",
    "title": "npm-package-arg",
    "summary": "npm-package-arg Parses package name and specifier passed to commands like npm install or npm cache add, or as found in package.json dependency sections. EXAMPLES var assert = require(\"assert\") var npa = require(\"npm-package-arg\") // Pass in the descriptor, and it'll return an object try { var parsed = npa(\"@bar/foo@1.2\") } catch (ex) { … } USING var npa = require('npm-package-arg') var result = npa(arg[, where]) arg - a string that you might pass to npm install, like: foo@1.2, @bar/foo@1.2, foo@user/foo, http://x.com/foo.tgz, git+https://github.com/user/foo, bitbucket:user/foo, foo.tar.gz, ../foo/bar/ or bar. If the arg you provide doesn't have a specifier part, eg foo then the specifier will default to latest. where - Optionally the path to resolve file paths relative to. Defaults to process.cwd() Throws if the package name is invalid, a dist-tag is invalid or a URL's protocol is not supported. var result = npa.resolve(name, spec[, where]) name - The name of the module you want to install. For example: foo or @bar/foo. spec - The specifier indicating where and how you can get this module. Something like: 1.2, ^1.7.17, http://x.com/foo.tgz, git+https://github.com/user/foo, bitbucket:user/foo, file:foo.tar.gz or file:../foo/bar/. If not included then the default is latest. where - Optionally the path to resolve file paths relative to. Defaults to process.cwd() Throws if the package name is invalid, a dist-tag is invalid or a URL's protocol is not supported. var purl = npa.toPurl(arg, reg) Returns the purl (package URL) form of the given pacakge name/spec. arg - A package/version string. For example: foo@1.0.0 or @bar/foo@2.0.0-alpha.1. reg - Optionally the URL to the package registry. If not specified, assumes the default https://registry.npmjs.org. Throws if the package name is invalid, or the supplied arg can't be resolved to a purl. RESULT OBJECT The objects that are returned by npm-package-arg contain the following keys: type - One of the following strings: git - A git repo tag - A tagged version, like \"foo@latest\" version - A specific version number, like \"foo@1.2.3\" range - A version range, like \"foo@2.x\" file - A local .tar.gz, .tar or .tgz file. directory - A local directory. remote - An http url (presumably to a tgz) alias - A specifier with an alias, like myalias@npm:foo@1.2.3 registry - If true this specifier refers to a resource hosted on a registry. This is true for tag, version and range types. name - If known, the name field expected in the resulting pkg. scope - If a name is something like @org/module then the scope field will be set to @org. If it doesn't have a scoped name, then scope is null. escapedName - A version of name escaped to match the npm scoped packages specification. Mostly used when making requests against a registry. When name is null, escapedName will also be null. rawSpec - The specifier part that was parsed out in calls to npa(arg), or the value of spec in calls to `npa.resolve(name, spec). saveSpec - The normalized specifier, for saving to package.json files. null for registry dependencies. fetchSpec - The version of the specifier to be used to fetch this resource. null for shortcuts to hosted git dependencies as there isn't just one URL to try with them. gitRange - If set, this is a semver specifier to match against git tags with gitCommittish - If set, this is the specific committish to use with a git dependency. hosted - If from === 'hosted' then this will be a hosted-git-info object. This property is not included when serializing the object as JSON. raw - The original un-modified string that was provided. If called as npa.resolve(name, spec) then this will be name + '@' + spec. subSpec - If type === 'alias', this is a Result Object for parsing the target specifier for the alias."
  },
  "src/frontend/app-client/node_modules/npm-pick-manifest/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/npm-pick-manifest/LICENSE.html",
    "title": "",
    "summary": "ISC License Copyright (c) npm, Inc. Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE COPYRIGHT HOLDER DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE."
  },
  "src/frontend/app-client/node_modules/npm-pick-manifest/README.html": {
    "href": "src/frontend/app-client/node_modules/npm-pick-manifest/README.html",
    "title": "npm-pick-manifest",
    "summary": "npm-pick-manifest npm-pick-manifest is a standalone implementation of npm's semver range resolution algorithm. Install $ npm install --save npm-pick-manifest Table of Contents Example Features API pickManifest() Example const pickManifest = require('npm-pick-manifest') fetch('https://registry.npmjs.org/npm-pick-manifest').then(res => { return res.json() }).then(packument => { return pickManifest(packument, '^1.0.0') }) // get same manifest as npm would get if you `npm i npm-pick-manifest@^1.0.0` Features Uses npm's exact semver resolution algorithm. Supports ranges, tags, and versions. Prefers non-deprecated versions to deprecated versions. Prefers versions whose engines requirements are satisfied over those that will raise a warning or error at install time. API > pickManifest(packument, selector, [opts]) -> manifest Returns the manifest that best matches selector, or throws an error. Packuments are anything returned by metadata URLs from the npm registry. That is, they're objects with the following shape (only fields used by npm-pick-manifest included): { name: 'some-package', 'dist-tags': { foo: '1.0.1' }, versions: { '1.0.0': { version: '1.0.0' }, '1.0.1': { version: '1.0.1' }, '1.0.2': { version: '1.0.2' }, '2.0.0': { version: '2.0.0' } } } The algorithm will follow npm's algorithm for semver resolution, and only tag, range, and version selectors are supported. The function will throw ETARGET if there was no matching manifest, and ENOVERSIONS if the packument object has no valid versions in versions. If the only matching manifest is included in a policyRestrictions section of the packument, then an E403 is raised. Options All options are optional. includeStaged - Boolean, default false. Include manifests in the stagedVersions.versions set, to support installing staged packages when appropriate. Note that staged packages are always treated as lower priority than actual publishes, even when includeStaged is set. defaultTag - String, default 'latest'. The default dist-tag to install when no specifier is provided. Note that the version indicated by this specifier will be given top priority if it matches a supplied semver range. before - String, Date, or Number, default null. This is passed to new Date(), so anything that works there will be valid. Do not consider any manifests that were published after the date indicated. Note that this is only relevant when the packument includes a time field listing the publish date of all the packages. nodeVersion - String, default process.version. The Node.js version to use when checking manifests for engines requirement satisfaction. npmVersion - String, default null. The npm version to use when checking manifest for engines requirement satisfaction. (If null, then this particular check is skipped.) avoid - String, default null. A SemVer range of versions that should be avoided. An avoided version MAY be selected if there is no other option, so when using this for version selection ensure that you check the result against the range to see if there was no alternative available. avoidStrict Boolean, default false. If set to true, then pickManifest will never return a version in the avoid range. If the only available version in the wanted range is a version that should be avoided, then it will return a version outside the wanted range, preferring to do so without making a SemVer-major jump, if possible. If there are no versions outside the avoid range, then throw an ETARGET error. It does this by calling pickManifest first with the wanted range, then with a ^ affixed to the version returned by the wanted range, and then with a * version range, and throwing if nothing could be found to satisfy the avoidance request. Return value is the manifest as it exists in the packument, possibly decorated with the following boolean flags: _shouldAvoid The version is in the avoid range. Watch out! _outsideDependencyRange The version is outside the wanted range, because avoidStrict: true was set. _isSemVerMajor The _outsideDependencyRange result is a SemVer-major step up from the version returned by the wanted range. Algorithm Create list of all versions in versions, policyRestrictions.versions, and (if includeStaged is set) stagedVersions.versions. If a dist-tag is requested, If the manifest is not after the specified before date, then select that from the set. If the manifest is after the specified before date, then re-start the selection looking for the highest SemVer range that is equal to or less than the dist-tag target. If a specific version is requested, If the manifest is not after the specified before date, then select the specified manifest. If the manifest is after the specified before date, then raise ETARGET error. (NB: this is a breaking change from v5, where a specified version would override the before setting.) (At this point we know a range is requested.) If the defaultTag refers to a dist-tag that satisfies the range (or if the range is '*' or ''), and the manifest is published before the before setting, then select that manifest. If nothing is yet selected, sort by the following heuristics in order, and select the top item: Prioritize versions that are not in the avoid range over those that are. Prioritize versions that are not in policyRestrictions over those that are. Prioritize published versions over staged versions. Prioritize versions that are not deprecated, and which have a satisfied engines requirement, over those that are either deprecated or have an engines mismatch. Prioritize versions that have a satisfied engines requirement over those that do not. Prioritize versions that are not are not deprecated (but have a mismatched engines requirement) over those that are deprecated. Prioritize higher SemVer precedence over lower SemVer precedence. If no manifest was selected, raise an ETARGET error. If the selected item is in the policyRestrictions.versions list, raise an E403 error. Return the selected manifest."
  },
  "src/frontend/app-client/node_modules/object-assign/readme.html": {
    "href": "src/frontend/app-client/node_modules/object-assign/readme.html",
    "title": "object-assign",
    "summary": "object-assign ES2015 Object.assign() ponyfill Use the built-in Node.js 4 and up, as well as every evergreen browser (Chrome, Edge, Firefox, Opera, Safari), support Object.assign() \uD83C\uDF89. If you target only those environments, then by all means, use Object.assign() instead of this package. Install $ npm install --save object-assign Usage const objectAssign = require('object-assign'); objectAssign({foo: 0}, {bar: 1}); //=> {foo: 0, bar: 1} // multiple sources objectAssign({foo: 0}, {bar: 1}, {baz: 2}); //=> {foo: 0, bar: 1, baz: 2} // overwrites equal keys objectAssign({foo: 0}, {foo: 1}, {foo: 2}); //=> {foo: 2} // ignores null and undefined sources objectAssign({foo: 0}, null, {bar: 1}, undefined); //=> {foo: 0, bar: 1} API objectAssign(target, [source, ...]) Assigns enumerable own properties of source objects to the target object and returns the target object. Additional source objects will overwrite previous ones. Resources ES2015 spec - Object.assign Related deep-assign - Recursive Object.assign() License MIT © Sindre Sorhus"
  },
  "src/frontend/app-client/node_modules/object-inspect/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/object-inspect/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.13.4 - 2025-02-04 Commits [Fix] avoid being fooled by a Symbol.toStringTag fa5870d [Tests] fix tests in node v6.0 - v6.4 2abfe1b [Dev Deps] update es-value-fixtures, for-each, has-symbols 3edfb01 v1.13.3 - 2024-11-09 Commits [actions] split out node 10-20, and 20+ 44395a8 [Fix] quoteStyle: properly escape only the containing quotes 5137f8f [Refactor] clean up quoteStyle code 450680c [Tests] add quoteStyle escaping tests e997c59 [Dev Deps] update auto-changelog, es-value-fixtures, tape d5a469c [Tests] replace aud with npm audit fb7815f [Dev Deps] update mock-property 11c817b v1.13.2 - 2024-06-21 Commits [readme] update badges 8a51e6b [Dev Deps] update @ljharb/eslint-config, tape ef05f58 [Dev Deps] update error-cause, has-tostringtag, tape c0c6c26 [Fix] Don't throw when global is not defined d4d0965 [meta] add missing engines.node 17a352a [Dev Deps] update globalthis 9c08884 [Dev Deps] update error-cause 6af352d [Dev Deps] update npmignore 94e617d [Dev Deps] update mock-property 2ac24d7 [Dev Deps] update tape 46125e5 v1.13.1 - 2023-10-19 Commits [Fix] in IE 8, global can !== window despite them being prototypes of each other 30d0859 v1.13.0 - 2023-10-14 Commits [New] add special handling for the global object 431bab2 [Dev Deps] update @ljharb/eslint-config, aud, tape fd4f619 [Dev Deps] update mock-property, tape b453f6c [Dev Deps] update error-cause e8ffc57 [Dev Deps] update tape 054b8b9 [Dev Deps] temporarily remove aud due to breaking change in transitive deps 2476845 [Dev Deps] pin glob, since v10.3.8+ requires a broken jackspeak 383fa5e [Dev Deps] pin jackspeak since 2.1.2+ depends on npm aliases, which kill the install process in npm < 6 68c244c v1.12.3 - 2023-01-12 Commits [Fix] in eg FF 24, collections lack forEach 75fc226 [actions] update rebase action to use reusable workflow 250a277 [Dev Deps] update aud, es-value-fixtures, tape 66a19b3 [Dev Deps] update @ljharb/eslint-config, aud, error-cause c43d332 [Tests] add @pkgjs/support to postlint e2618d2 v1.12.2 - 2022-05-26 Commits [Fix] use util.inspect for a custom inspection symbol method e243bf2 [meta] add support info ca20ba3 [Fix] ignore cause in node v16.9 and v16.10 where it has a bug 86aa553 v1.12.1 - 2022-05-21 Commits [Tests] use mock-property 4ec8893 [meta] use npmignore to autogenerate an npmignore file 07f868c [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape b05244b [Dev Deps] update @ljharb/eslint-config, error-cause, es-value-fixtures, functions-have-names, tape d037398 [Fix] properly handle callable regexes in older engines 848fe48 v1.12.0 - 2021-12-18 Commits [New] add numericSeparator boolean option 2d2d537 [Robustness] cache more prototype methods 191533d [New] ensure an Error’s cause is displayed 53bc2ce [Dev Deps] update eslint, @ljharb/eslint-config bc164b6 [Robustness] cache RegExp.prototype.test a314ab8 [meta] fix auto-changelog settings 5ed0983 v1.11.1 - 2021-12-05 Commits [meta] add auto-changelog 7dbdd22 [actions] reuse common workflows c8823bc [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape 7532b12 [Refactor] use has-tostringtag to behave correctly in the presence of symbol shams 94abb5d [actions] update codecov uploader 5ed5102 [Dev Deps] update eslint, tape 37b2ad2 [meta] add sideEffects flag d341f90 v1.11.0 - 2021-07-12 Commits [New] customInspect: add symbol option, to mimic modern util.inspect behavior e973a6e [Dev Deps] update eslint 05f1cb3 v1.10.3 - 2021-05-07 Commits [Fix] handle core-js Symbol shams 4acfc2c [readme] update badges 95c323a [Dev Deps] update eslint, @ljharb/eslint-config, aud cb38f48 v1.10.2 - 2021-04-17 Commits [Fix] use a robust check for a boxed Symbol 87f12d6 v1.10.1 - 2021-04-17 Commits [Fix] use a robust check for a boxed bigint d5ca829 v1.10.0 - 2021-04-17 Commits [Tests] increase coverage d8abb8a [actions] use node/install instead of node/run; use codecov action 4bfec2e [New] respect Symbol.toStringTag on objects 799b58f [Fix] do not allow Symbol.toStringTag to masquerade as builtins d6c5b37 [New] add WeakRef support b6d898e [meta] do not publish github action workflow files 918cdfc [meta] create FUNDING.yml 0bb5fc5 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 22c8dc0 [meta] use prepublishOnly script for npm 7+ e52ee09 [Dev Deps] update eslint 7c4e6fd v1.9.0 - 2020-11-30 Commits [Tests] migrate tests to Github Actions d262251 [New] add enumerable own Symbols to plain object output ee60c03 [Tests] add passing tests 01ac3e4 [actions] add \"Require Allow Edits\" action c2d7746 [Dev Deps] update eslint, @ljharb/eslint-config, aud, core-js 70058de [Fix] hex characters in strings should be uppercased, to match node assert 6ab8faa [Tests] run nyc on all tests 4c47372 [Tests] node 0.8 has an unpredictable property order; fix groups test by removing property f192069 [New] add enumerable properties to Function inspect result, per node’s assert fd38e1b [Tests] fix tests for node < 10, due to regex match groups 2ac6462 [Dev Deps] update eslint, @ljharb/eslint-config 44b59e2 [Robustness] cache Symbol.prototype.toString f3c2074 [Dev Deps] update eslint 9411294 [meta] require-allow-edits no longer requires an explicit github token 36c0220 [actions] update rebase checkout action to v2 55a39a6 [actions] switch Automatic Rebase workflow to pull_request_target event f59fd3c [Dev Deps] update eslint a492bec v1.8.0 - 2020-06-18 Fixed [New] add indent option #27 Commits [Tests] add codecov 4324cbb [New] add maxStringLength option b3995cb [New] add customInspect option, to disable custom inspect methods 28b9179 [Tests] add Date and RegExp tests 3b28eca [actions] add automatic rebasing / merge commit blocking 0d9c6c0 [Dev Deps] update eslint, @ljharb/eslint-config, core-js, tape; add aud 7c204f2 [readme] fix repo URLs, remove testling 34ca9a0 [Fix] when truncating a deep array, note it as [Array] instead of just [Object] f74c82d [Dev Deps] update eslint, @ljharb/eslint-config, tape 1a8a5ea [Fix] do not be fooled by a function’s own toString method 7cb5c65 [patch] indicate explicitly that anon functions are anonymous, to match node 81ebdd4 [Dev Deps] loosen the core-js dep e7472e8 [Dev Deps] update tape 699827e [meta] add safe-publish-latest c5d2868 [Dev Deps] update @ljharb/eslint-config 9199501 v1.7.0 - 2019-11-10 Commits [Tests] use shared travis-ci configs 19899ed [Tests] add linting a00f057 [Tests] lint last file 2698047 [Tests] up to node v12.7, v11.15, v10.16, v8.16, v6.17 589e87a [New] add support for WeakMap and WeakSet 3ddb3e4 [meta] clean up license so github can detect it properly 27527bb [Tests] cover util.inspect.custom 36d47b9 [Dev Deps] update eslint, @ljharb/eslint-config, core-js, tape b614eaa [Tests] fix coverage thresholds 7b7b176 [Tests] bigint tests now can run on unflagged node 063af31 [Refactor] add early bailout to isMap and isSet checks fc51047 [meta] add funding field 7f9953a [Tests] Fix invalid strict-mode syntax with hexadecimal a8b5425 [Dev Deps] update @ljharb/eslint-config 98df157 add copyright to LICENSE bb69fd0 [Tests] use npx aud in posttest 4838353 [Tests] move 0.6 to allowed failures, because it won‘t build on travis 1bff32a v1.6.0 - 2018-05-02 Commits [New] add support for boxed BigInt primitives 356c66a [Tests] up to node v10.0, v9.11, v8.11, v6.14, v4.9 c77b65b [New] Add support for upcoming BigInt 1ac548e [Tests] run bigint tests in CI with --harmony-bigint flag d31b738 [Dev Deps] update core-js, tape ff9eff6 [Docs] fix example to use safer-buffer 48cae12 v1.5.0 - 2017-12-25 Commits [New] add quoteStyle option f5a72d2 [Tests] add more test coverage 30ebe4e [Tests] require 0.6 to pass 99a008c v1.4.1 - 2017-12-19 Commits [Tests] up to node v9.3, v8.9, v6.12 6674476 [Fix] inspect(Object(-0)) should be “Object(-0)”, not “Object(0)” d0a031f v1.4.0 - 2017-10-24 Commits [Tests] add npm run coverage 3b48fb2 [Tests] remove commented-out osx builds 71e24db [New] add support for util.inspect.custom, in node only. 20cca77 [Tests] up to node v8.6; use nvm install-latest-npm to ensure new npm doesn’t break old node 252952d [Tests] up to node v8.8 4aa868d [Dev Deps] update core-js, tape 59483d1 v1.3.0 - 2017-07-31 Fixed [Fix] Map/Set: work around core-js bug < v2.5.0 #9 Commits [New] add support for arrays with additional object keys 0d19937 [Tests] up to node v8.2, v7.10, v6.11; fix new npm breaking on older nodes e24784a Only apps should have lockfiles c6faebc [Dev Deps] update tape 7345a0a v1.2.2 - 2017-03-24 Commits [Tests] up to node v7.7, v6.10, v4.8; improve test matrix a2ddc15 [Tests] up to node v7.0, v6.9, v5.12, v4.6, io.js v3.3; improve test matrix a48949f [Performance] check for primitive types as early as possible. 3b8092a [Refactor] remove unneeded elses. 7255034 [Refactor] avoid recreating lowbyte function every time. 81edd34 [Fix] differentiate -0 from 0 521d345 [Refactor] move object key gathering into separate function aca6265 [Refactor] consolidate wrapping logic for boxed primitives into a function. 4e440cd [Robustness] use typeof instead of comparing to literal undefined 5ca6f60 [Refactor] consolidate Map/Set notations. 4e576e5 [Tests] ensure that this function remains anonymous, despite ES6 name inference. 7540ae5 [Refactor] explicitly coerce Error objects to strings. 7f4ca84 [Refactor] split up var declarations for debuggability 6f2c11e [Robustness] cache Object.prototype.toString df44a20 [Dev Deps] update tape 3ec714e [Dev Deps] update tape beb72d9 v1.2.1 - 2016-04-09 Fixed [Fix] fix Boolean false object inspection. #7 v1.2.0 - 2016-04-09 Fixed [New] add support for inspecting String/Number/Boolean objects. #6 Commits [Dev Deps] update tape 742caa2 v1.1.0 - 2015-12-14 Merged [New] add ES6 Map/Set support. #4 Fixed [New] add ES6 Map/Set support. #3 Commits Update travis.yml to test on bunches of iojs and node versions. 4c1fd65 [Dev Deps] update tape 88a907e 1.0.2 - 2015-08-07 Commits [Fix] Cache Object.prototype.hasOwnProperty in case it's deleted later. 1d0075d [Dev Deps] Update tape ca8d5d7 gitignore node_modules since this is a reusable modules. ed41407 1.0.1 - 2015-07-19 Commits Make inspect work with symbol primitives and objects, including in node 0.11 and 0.12. ddf1b94 bump tape 103d674 use newer travis config d497276 1.0.0 - 2014-08-05 Commits error inspect works properly 260a22d seen coverage 57269e8 htmlelement instance coverage 397ffe1 more element coverage 6905cc2 failing test for type errors 385b615 fn name coverage edc906d server-side element test 362d1d3 custom inspect fn e89b0f6 fixed browser test b530882 depth test, matches node 1cfd9e0 exercise hasOwnProperty path 8d753fb more cases covered for errors c5c46a5 \\W obj key test case b0eceee coverage for explicit depth param e12b91c 0.4.0 - 2014-03-21 Commits passing lowbyte interpolation test b847511 lowbyte test 4a2b0e1 0.3.1 - 2014-03-04 Commits sort keys a07b19c 0.3.0 - 2014-03-04 Commits [] and {} instead of [ ] and { } 654c44b 0.2.0 - 2014-03-04 Commits failing holes test 99cdfad regex already work e324033 failing undef/null test 1f88a00 holes in the all example 7d345f3 check for .inspect(), fixes Buffer use-case c3f7546 fixes for holes ce25f73 weird null behavior 405c1ea tape is actually a devDependency, upgrade 703b0ce put date in the example a342219 passing the null test 4ab737e 0.1.3 - 2013-07-26 Commits special isElement() check 882768a oh right old IEs don't have indexOf either 36d1275 0.1.1 - 2013-07-26 Commits tests! 4422fd9 fix for ie<9, doesn't have hasOwnProperty 6b7d611 fix for all IEs: no f.name 4e0c2f6 badges 5ed0d88 0.1.0 - 2013-07-26 Commits [Function] for functions ad5c485 0.0.0 - 2013-07-26 Commits working browser example 34be6b6 package.json etc cad51f2 docs complete b80cce2 circular example 4b4a7b9 string rep 7afb479"
  },
  "src/frontend/app-client/node_modules/on-finished/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/on-finished/HISTORY.html",
    "title": "2.4.1 / 2022-02-22",
    "summary": "2.4.1 / 2022-02-22 Fix error on early async hooks implementations 2.4.0 / 2022-02-21 Prevent loss of async hooks context 2.3.0 / 2015-05-26 Add defined behavior for HTTP CONNECT requests Add defined behavior for HTTP Upgrade requests deps: ee-first@1.1.1 2.2.1 / 2015-04-22 Fix isFinished(req) when data buffered 2.2.0 / 2014-12-22 Add message object to callback arguments 2.1.1 / 2014-10-22 Fix handling of pipelined requests 2.1.0 / 2014-08-16 Check if socket is detached Return undefined for isFinished if state unknown 2.0.0 / 2014-08-16 Add isFinished function Move to jshttp organization Remove support for plain socket argument Rename to on-finished Support both req and res as arguments deps: ee-first@1.0.5 1.2.2 / 2014-06-10 Reduce listeners added to emitters avoids \"event emitter leak\" warnings when used multiple times on same request 1.2.1 / 2014-06-08 Fix returned value when already finished 1.2.0 / 2014-06-05 Call callback when called on already-finished socket 1.1.4 / 2014-05-27 Support node.js 0.8 1.1.3 / 2014-04-30 Make sure errors passed as instanceof Error 1.1.2 / 2014-04-18 Default the socket to passed-in object 1.1.1 / 2014-01-16 Rename module to finished 1.1.0 / 2013-12-25 Call callback when called on already-errored socket 1.0.1 / 2013-12-20 Actually pass the error to the callback 1.0.0 / 2013-12-20 Initial release"
  },
  "src/frontend/app-client/node_modules/on-finished/README.html": {
    "href": "src/frontend/app-client/node_modules/on-finished/README.html",
    "title": "on-finished",
    "summary": "on-finished Execute a callback when a HTTP request closes, finishes, or errors. Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install on-finished API var onFinished = require('on-finished') onFinished(res, listener) Attach a listener to listen for the response to finish. The listener will be invoked only once when the response finished. If the response finished to an error, the first argument will contain the error. If the response has already finished, the listener will be invoked. Listening to the end of a response would be used to close things associated with the response, like open files. Listener is invoked as listener(err, res). onFinished(res, function (err, res) { // clean up open fds, etc. // err contains the error if request error'd }) onFinished(req, listener) Attach a listener to listen for the request to finish. The listener will be invoked only once when the request finished. If the request finished to an error, the first argument will contain the error. If the request has already finished, the listener will be invoked. Listening to the end of a request would be used to know when to continue after reading the data. Listener is invoked as listener(err, req). var data = '' req.setEncoding('utf8') req.on('data', function (str) { data += str }) onFinished(req, function (err, req) { // data is read unless there is err }) onFinished.isFinished(res) Determine if res is already finished. This would be useful to check and not even start certain operations if the response has already finished. onFinished.isFinished(req) Determine if req is already finished. This would be useful to check and not even start certain operations if the request has already finished. Special Node.js requests HTTP CONNECT method The meaning of the CONNECT method from RFC 7231, section 4.3.6: The CONNECT method requests that the recipient establish a tunnel to the destination origin server identified by the request-target and, if successful, thereafter restrict its behavior to blind forwarding of packets, in both directions, until the tunnel is closed. Tunnels are commonly used to create an end-to-end virtual connection, through one or more proxies, which can then be secured using TLS (Transport Layer Security, [RFC5246]). In Node.js, these request objects come from the 'connect' event on the HTTP server. When this module is used on a HTTP CONNECT request, the request is considered \"finished\" immediately, due to limitations in the Node.js interface. This means if the CONNECT request contains a request entity, the request will be considered \"finished\" even before it has been read. There is no such thing as a response object to a CONNECT request in Node.js, so there is no support for one. HTTP Upgrade request The meaning of the Upgrade header from RFC 7230, section 6.1: The \"Upgrade\" header field is intended to provide a simple mechanism for transitioning from HTTP/1.1 to some other protocol on the same connection. In Node.js, these request objects come from the 'upgrade' event on the HTTP server. When this module is used on a HTTP request with an Upgrade header, the request is considered \"finished\" immediately, due to limitations in the Node.js interface. This means if the Upgrade request contains a request entity, the request will be considered \"finished\" even before it has been read. There is no such thing as a response object to a Upgrade request in Node.js, so there is no support for one. Example The following code ensures that file descriptors are always closed once the response finishes. var destroy = require('destroy') var fs = require('fs') var http = require('http') var onFinished = require('on-finished') http.createServer(function onRequest (req, res) { var stream = fs.createReadStream('package.json') stream.pipe(res) onFinished(res, function () { destroy(stream) }) }) License MIT"
  },
  "src/frontend/app-client/node_modules/on-headers/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/on-headers/HISTORY.html",
    "title": "1.0.2 / 2019-02-21",
    "summary": "1.0.2 / 2019-02-21 Fix res.writeHead patch missing return value 1.0.1 / 2015-09-29 perf: enable strict mode 1.0.0 / 2014-08-10 Honor res.statusCode change in listener Move to jshttp organization Prevent arguments-related de-opt 0.0.0 / 2014-05-13 Initial implementation"
  },
  "src/frontend/app-client/node_modules/on-headers/README.html": {
    "href": "src/frontend/app-client/node_modules/on-headers/README.html",
    "title": "on-headers",
    "summary": "on-headers Execute a listener when a response is about to write headers. Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install on-headers API var onHeaders = require('on-headers') onHeaders(res, listener) This will add the listener listener to fire when headers are emitted for res. The listener is passed the response object as it's context (this). Headers are considered to be emitted only once, right before they are sent to the client. When this is called multiple times on the same res, the listeners are fired in the reverse order they were added. Examples var http = require('http') var onHeaders = require('on-headers') http .createServer(onRequest) .listen(3000) function addPoweredBy () { // set if not set by end of request if (!this.getHeader('X-Powered-By')) { this.setHeader('X-Powered-By', 'Node.js') } } function onRequest (req, res) { onHeaders(res, addPoweredBy) res.setHeader('Content-Type', 'text/plain') res.end('hello!') } Testing $ npm test License MIT"
  },
  "src/frontend/app-client/node_modules/package-json-from-dist/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/package-json-from-dist/LICENSE.html",
    "title": "Blue Oak Model License",
    "summary": "All packages under src/ are licensed according to the terms in their respective LICENSE or LICENSE.md files. The remainder of this project is licensed under the Blue Oak Model License, as follows: Blue Oak Model License Version 1.0.0 Purpose This license gives everyone as much permission to work with this software as possible, while protecting contributors from liability. Acceptance In order to receive this license, you must agree to its rules. The rules of this license are both obligations under that agreement and conditions to your license. You must not do anything with this software that triggers a rule that you cannot or will not follow. Copyright Each contributor licenses you to do everything with this software that would otherwise infringe that contributor's copyright in it. Notices You must ensure that everyone who gets a copy of any part of this software from you, with or without changes, also gets the text of this license or a link to https://blueoakcouncil.org/license/1.0.0. Excuse If anyone notifies you in writing that you have not complied with Notices, you can keep your license by taking all practical steps to comply within 30 days after the notice. If you do not do so, your license ends immediately. Patent Each contributor licenses you to do everything with this software that would otherwise infringe any patent claims they can license or become able to license. Reliability No contributor can revoke this license. No Liability As far as the law allows, this software comes as is, without any warranty or condition, and no contributor will be liable to anyone for any damages related to this software or this license, under any kind of legal claim."
  },
  "src/frontend/app-client/node_modules/package-json-from-dist/README.html": {
    "href": "src/frontend/app-client/node_modules/package-json-from-dist/README.html",
    "title": "package-json-from-dist",
    "summary": "package-json-from-dist Sometimes you want to load the package.json into your TypeScript program, and it's tempting to just import '../package.json', since that seems to work. However, this requires tsc to make an entire copy of your package.json file into the dist folder, which is a problem if you're using something like tshy, which uses the package.json file in dist for another purpose. Even when that does work, it's asking the module system to do a bunch of extra fs system calls, just to load a version number or something. (See this issue.) This module helps by just finding the package.json file appropriately, and reading and parsing it in the most normal fashion. Caveats This only works if your code builds into a target folder called dist, which is in the root of the package. It also requires that you do not have a folder named node_modules anywhere within your dev environment, or else it'll get the wrong answers there. (But, at least, that'll be in dev, so you're pretty likely to notice.) If you build to some other location, then you'll need a different approach. (Feel free to fork this module and make it your own, or just put the code right inline, there's not much of it.) USAGE // src/index.ts import { findPackageJson, loadPackageJson, } from 'package-json-from-dist' const pj = findPackageJson(import.meta.url) console.log(`package.json found at ${pj}`) const pkg = loadPackageJson(import.meta.url) console.log(`Hello from ${pkg.name}@${pkg.version}`) If your module is not directly in the ./src folder, then you need to specify the path that you would expect to find the package.json when it's not built to the dist folder. // src/components/something.ts import { findPackageJson, loadPackageJson, } from 'package-json-from-dist' const pj = findPackageJson(import.meta.url, '../../package.json') console.log(`package.json found at ${pj}`) const pkg = loadPackageJson(import.meta.url, '../../package.json') console.log(`Hello from ${pkg.name}@${pkg.version}`) When running from CommmonJS, use __filename instead of import.meta.url. // src/index.cts import { findPackageJson, loadPackageJson, } from 'package-json-from-dist' const pj = findPackageJson(__filename) console.log(`package.json found at ${pj}`) const pkg = loadPackageJson(__filename) console.log(`Hello from ${pkg.name}@${pkg.version}`) Since tshy builds both CommonJS and ESM by default, you may find that you need a CommonJS override and some //@ts-ignore magic to make it work. src/pkg.ts: import { findPackageJson, loadPackageJson, } from 'package-json-from-dist' //@ts-ignore export const pkg = loadPackageJson(import.meta.url) //@ts-ignore export const pj = findPackageJson(import.meta.url) src/pkg-cjs.cts: import { findPackageJson, loadPackageJson, } from 'package-json-from-dist' export const pkg = loadPackageJson(__filename) export const pj = findPackageJson(__filename)"
  },
  "src/frontend/app-client/node_modules/parent-module/readme.html": {
    "href": "src/frontend/app-client/node_modules/parent-module/readme.html",
    "title": "parent-module",
    "summary": "parent-module Get the path of the parent module Node.js exposes module.parent, but it only gives you the first cached parent, which is not necessarily the actual parent. Install $ npm install parent-module Usage // bar.js const parentModule = require('parent-module'); module.exports = () => { console.log(parentModule()); //=> '/Users/sindresorhus/dev/unicorn/foo.js' }; // foo.js const bar = require('./bar'); bar(); API parentModule([filepath]) By default, it will return the path of the immediate parent. filepath Type: string Default: __filename Filepath of the module of which to get the parent path. Useful if you want it to work multiple module levels down. Tip Combine it with read-pkg-up to read the package.json of the parent module. const path = require('path'); const readPkgUp = require('read-pkg-up'); const parentModule = require('parent-module'); console.log(readPkgUp.sync({cwd: path.dirname(parentModule())}).pkg); //=> {name: 'chalk', version: '1.0.0', …} License MIT © Sindre Sorhus"
  },
  "src/frontend/app-client/node_modules/parse-json/node_modules/json-parse-even-better-errors/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/parse-json/node_modules/json-parse-even-better-errors/CHANGELOG.html",
    "title": "Change Log",
    "summary": "Change Log All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 2.0.0 Add custom error classes 1.0.2 (2018-03-30) Bug Fixes messages: More friendly messages for non-string (#1) (a476d42) 1.0.1 (2017-08-16) Bug Fixes license: oops. Forgot to update license.md (efe2958) 1.0.0 (2017-08-15) Features init: Initial Commit (562c977) BREAKING CHANGES init: This is the first commit! 0.1.0 (2017-08-15) Features init: Initial Commit (9dd1a19)"
  },
  "src/frontend/app-client/node_modules/parse-json/node_modules/json-parse-even-better-errors/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/parse-json/node_modules/json-parse-even-better-errors/LICENSE.html",
    "title": "",
    "summary": "Copyright 2017 Kat Marchán Copyright npm, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. This library is a fork of 'better-json-errors' by Kat Marchán, extended and distributed under the terms of the MIT license above."
  },
  "src/frontend/app-client/node_modules/parse-json/node_modules/json-parse-even-better-errors/README.html": {
    "href": "src/frontend/app-client/node_modules/parse-json/node_modules/json-parse-even-better-errors/README.html",
    "title": "json-parse-even-better-errors",
    "summary": "json-parse-even-better-errors json-parse-even-better-errors is a Node.js library for getting nicer errors out of JSON.parse(), including context and position of the parse errors. It also preserves the newline and indentation styles of the JSON data, by putting them in the object or array in the Symbol.for('indent') and Symbol.for('newline') properties. Install $ npm install --save json-parse-even-better-errors Table of Contents Example Features Contributing API parse Example const parseJson = require('json-parse-even-better-errors') parseJson('\"foo\"') // returns the string 'foo' parseJson('garbage') // more useful error message parseJson.noExceptions('garbage') // returns undefined Features Like JSON.parse, but the errors are better. Strips a leading byte-order-mark that you sometimes get reading files. Has a noExceptions method that returns undefined rather than throwing. Attaches the newline character(s) used to the Symbol.for('newline') property on objects and arrays. Attaches the indentation character(s) used to the Symbol.for('indent') property on objects and arrays. Indentation To preserve indentation when the file is saved back to disk, use data[Symbol.for('indent')] as the third argument to JSON.stringify, and if you want to preserve windows \\r\\n newlines, replace the \\n chars in the string with data[Symbol.for('newline')]. For example: const txt = await readFile('./package.json', 'utf8') const data = parseJsonEvenBetterErrors(txt) const indent = Symbol.for('indent') const newline = Symbol.for('newline') // .. do some stuff to the data .. const string = JSON.stringify(data, null, data[indent]) + '\\n' const eolFixed = data[newline] === '\\n' ? string : string.replace(/\\n/g, data[newline]) await writeFile('./package.json', eolFixed) Indentation is determined by looking at the whitespace between the initial { and [ and the character that follows it. If you have lots of weird inconsistent indentation, then it won't track that or give you any way to preserve it. Whether this is a bug or a feature is debatable ;) API parse(txt, reviver = null, context = 20) Works just like JSON.parse, but will include a bit more information when an error happens, and attaches a Symbol.for('indent') and Symbol.for('newline') on objects and arrays. This throws a JSONParseError. parse.noExceptions(txt, reviver = null) Works just like JSON.parse, but will return undefined rather than throwing an error. class JSONParseError(er, text, context = 20, caller = null) Extends the JavaScript SyntaxError class to parse the message and provide better metadata. Pass in the error thrown by the built-in JSON.parse, and the text being parsed, and it'll parse out the bits needed to be helpful. context defaults to 20. Set a caller function to trim internal implementation details out of the stack trace. When calling parseJson, this is set to the parseJson function. If not set, then the constructor defaults to itself, so the stack trace will point to the spot where you call new JSONParseError."
  },
  "src/frontend/app-client/node_modules/parse-json/readme.html": {
    "href": "src/frontend/app-client/node_modules/parse-json/readme.html",
    "title": "parse-json",
    "summary": "parse-json Parse JSON with more helpful errors Install $ npm install parse-json Usage const parseJson = require('parse-json'); const json = '{\\n\\t\"foo\": true,\\n}'; JSON.parse(json); /* undefined:3 } ^ SyntaxError: Unexpected token } */ parseJson(json); /* JSONError: Unexpected token } in JSON at position 16 while parsing near '{ \"foo\": true,}' 1 | { 2 | \"foo\": true, > 3 | } | ^ */ parseJson(json, 'foo.json'); /* JSONError: Unexpected token } in JSON at position 16 while parsing near '{ \"foo\": true,}' in foo.json 1 | { 2 | \"foo\": true, > 3 | } | ^ */ // You can also add the filename at a later point try { parseJson(json); } catch (error) { if (error instanceof parseJson.JSONError) { error.fileName = 'foo.json'; } throw error; } /* JSONError: Unexpected token } in JSON at position 16 while parsing near '{ \"foo\": true,}' in foo.json 1 | { 2 | \"foo\": true, > 3 | } | ^ */ API parseJson(string, reviver?, filename?) Throws a JSONError when there is a parsing error. string Type: string reviver Type: Function Prescribes how the value originally produced by parsing is transformed, before being returned. See JSON.parse docs for more. filename Type: string Filename displayed in the error message. parseJson.JSONError Exposed for instanceof checking. fileName Type: string The filename displayed in the error message. codeFrame Type: string The printable section of the JSON which produces the error. Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "src/frontend/app-client/node_modules/parseurl/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/parseurl/HISTORY.html",
    "title": "1.3.3 / 2019-04-15",
    "summary": "1.3.3 / 2019-04-15 Fix Node.js 0.8 return value inconsistencies 1.3.2 / 2017-09-09 perf: reduce overhead for full URLs perf: unroll the \"fast-path\" RegExp 1.3.1 / 2016-01-17 perf: enable strict mode 1.3.0 / 2014-08-09 Add parseurl.original for parsing req.originalUrl with fallback Return undefined if req.url is undefined 1.2.0 / 2014-07-21 Cache URLs based on original value Remove no-longer-needed URL mis-parse work-around Simplify the \"fast-path\" RegExp 1.1.3 / 2014-07-08 Fix typo 1.1.2 / 2014-07-08 Seriously fix Node.js 0.8 compatibility 1.1.1 / 2014-07-08 Fix Node.js 0.8 compatibility 1.1.0 / 2014-07-08 Incorporate URL href-only parse fast-path 1.0.1 / 2014-03-08 Add missing require 1.0.0 / 2014-03-08 Genesis from connect"
  },
  "src/frontend/app-client/node_modules/parseurl/README.html": {
    "href": "src/frontend/app-client/node_modules/parseurl/README.html",
    "title": "parseurl",
    "summary": "parseurl Parse a URL with memoization. Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install parseurl API var parseurl = require('parseurl') parseurl(req) Parse the URL of the given request object (looks at the req.url property) and return the result. The result is the same as url.parse in Node.js core. Calling this function multiple times on the same req where req.url does not change will return a cached parsed object, rather than parsing again. parseurl.original(req) Parse the original URL of the given request object and return the result. This works by trying to parse req.originalUrl if it is a string, otherwise parses req.url. The result is the same as url.parse in Node.js core. Calling this function multiple times on the same req where req.originalUrl does not change will return a cached parsed object, rather than parsing again. Benchmark $ npm run-script bench > parseurl@1.3.3 bench nodejs-parseurl > node benchmark/index.js http_parser@2.8.0 node@10.6.0 v8@6.7.288.46-node.13 uv@1.21.0 zlib@1.2.11 ares@1.14.0 modules@64 nghttp2@1.32.0 napi@3 openssl@1.1.0h icu@61.1 unicode@10.0 cldr@33.0 tz@2018c > node benchmark/fullurl.js Parsing URL \"http://localhost:8888/foo/bar?user=tj&pet=fluffy\" 4 tests completed. fasturl x 2,207,842 ops/sec ±3.76% (184 runs sampled) nativeurl - legacy x 507,180 ops/sec ±0.82% (191 runs sampled) nativeurl - whatwg x 290,044 ops/sec ±1.96% (189 runs sampled) parseurl x 488,907 ops/sec ±2.13% (192 runs sampled) > node benchmark/pathquery.js Parsing URL \"/foo/bar?user=tj&pet=fluffy\" 4 tests completed. fasturl x 3,812,564 ops/sec ±3.15% (188 runs sampled) nativeurl - legacy x 2,651,631 ops/sec ±1.68% (189 runs sampled) nativeurl - whatwg x 161,837 ops/sec ±2.26% (189 runs sampled) parseurl x 4,166,338 ops/sec ±2.23% (184 runs sampled) > node benchmark/samerequest.js Parsing URL \"/foo/bar?user=tj&pet=fluffy\" on same request object 4 tests completed. fasturl x 3,821,651 ops/sec ±2.42% (185 runs sampled) nativeurl - legacy x 2,651,162 ops/sec ±1.90% (187 runs sampled) nativeurl - whatwg x 175,166 ops/sec ±1.44% (188 runs sampled) parseurl x 14,912,606 ops/sec ±3.59% (183 runs sampled) > node benchmark/simplepath.js Parsing URL \"/foo/bar\" 4 tests completed. fasturl x 12,421,765 ops/sec ±2.04% (191 runs sampled) nativeurl - legacy x 7,546,036 ops/sec ±1.41% (188 runs sampled) nativeurl - whatwg x 198,843 ops/sec ±1.83% (189 runs sampled) parseurl x 24,244,006 ops/sec ±0.51% (194 runs sampled) > node benchmark/slash.js Parsing URL \"/\" 4 tests completed. fasturl x 17,159,456 ops/sec ±3.25% (188 runs sampled) nativeurl - legacy x 11,635,097 ops/sec ±3.79% (184 runs sampled) nativeurl - whatwg x 240,693 ops/sec ±0.83% (189 runs sampled) parseurl x 42,279,067 ops/sec ±0.55% (190 runs sampled) License MIT"
  },
  "src/frontend/app-client/node_modules/path-key/readme.html": {
    "href": "src/frontend/app-client/node_modules/path-key/readme.html",
    "title": "path-key",
    "summary": "path-key Get the PATH environment variable key cross-platform It's usually PATH, but on Windows it can be any casing like Path... Install $ npm install path-key Usage const pathKey = require('path-key'); const key = pathKey(); //=> 'PATH' const PATH = process.env[key]; //=> '/usr/local/bin:/usr/bin:/bin' API pathKey(options?) options Type: object env Type: object Default: process.env Use a custom environment variables object. platform Type: string Default: process.platform Get the PATH key for a specific platform. Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "src/frontend/app-client/node_modules/path-parse/README.html": {
    "href": "src/frontend/app-client/node_modules/path-parse/README.html",
    "title": "path-parse",
    "summary": "path-parse Node.js path.parse(pathString) ponyfill. Install $ npm install --save path-parse Usage var pathParse = require('path-parse'); pathParse('/home/user/dir/file.txt'); //=> { // root : \"/\", // dir : \"/home/user/dir\", // base : \"file.txt\", // ext : \".txt\", // name : \"file\" // } API See path.parse(pathString) docs. pathParse(path) pathParse.posix(path) The Posix specific version. pathParse.win32(path) The Windows specific version. License MIT © Javier Blanco"
  },
  "src/frontend/app-client/node_modules/path-scurry/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/path-scurry/LICENSE.html",
    "title": "Blue Oak Model License",
    "summary": "Blue Oak Model License Version 1.0.0 Purpose This license gives everyone as much permission to work with this software as possible, while protecting contributors from liability. Acceptance In order to receive this license, you must agree to its rules. The rules of this license are both obligations under that agreement and conditions to your license. You must not do anything with this software that triggers a rule that you cannot or will not follow. Copyright Each contributor licenses you to do everything with this software that would otherwise infringe that contributor's copyright in it. Notices You must ensure that everyone who gets a copy of any part of this software from you, with or without changes, also gets the text of this license or a link to https://blueoakcouncil.org/license/1.0.0. Excuse If anyone notifies you in writing that you have not complied with Notices, you can keep your license by taking all practical steps to comply within 30 days after the notice. If you do not do so, your license ends immediately. Patent Each contributor licenses you to do everything with this software that would otherwise infringe any patent claims they can license or become able to license. Reliability No contributor can revoke this license. No Liability As far as the law allows, this software comes as is, without any warranty or condition, and no contributor will be liable to anyone for any damages related to this software or this license, under any kind of legal claim."
  },
  "src/frontend/app-client/node_modules/path-scurry/node_modules/lru-cache/README.html": {
    "href": "src/frontend/app-client/node_modules/path-scurry/node_modules/lru-cache/README.html",
    "title": "lru-cache",
    "summary": "lru-cache A cache object that deletes the least-recently-used items. Specify a max number of the most recently used items that you want to keep, and this cache will keep that many of the most recently accessed items. This is not primarily a TTL cache, and does not make strong TTL guarantees. There is no preemptive pruning of expired items by default, but you may set a TTL on the cache or on a single set. If you do so, it will treat expired items as missing, and delete them when fetched. If you are more interested in TTL caching than LRU caching, check out @isaacs/ttlcache. As of version 7, this is one of the most performant LRU implementations available in JavaScript, and supports a wide diversity of use cases. However, note that using some of the features will necessarily impact performance, by causing the cache to have to do more work. See the \"Performance\" section below. Installation npm install lru-cache --save Usage // hybrid module, either works import { LRUCache } from 'lru-cache' // or: const { LRUCache } = require('lru-cache') // or in minified form for web browsers: import { LRUCache } from 'http://unpkg.com/lru-cache@9/dist/mjs/index.min.mjs' // At least one of 'max', 'ttl', or 'maxSize' is required, to prevent // unsafe unbounded storage. // // In most cases, it's best to specify a max for performance, so all // the required memory allocation is done up-front. // // All the other options are optional, see the sections below for // documentation on what each one does. Most of them can be // overridden for specific items in get()/set() const options = { max: 500, // for use with tracking overall storage size maxSize: 5000, sizeCalculation: (value, key) => { return 1 }, // for use when you need to clean up something when objects // are evicted from the cache dispose: (value, key) => { freeFromMemoryOrWhatever(value) }, // how long to live in ms ttl: 1000 * 60 * 5, // return stale items before removing from cache? allowStale: false, updateAgeOnGet: false, updateAgeOnHas: false, // async method to use for cache.fetch(), for // stale-while-revalidate type of behavior fetchMethod: async ( key, staleValue, { options, signal, context } ) => {}, } const cache = new LRUCache(options) cache.set('key', 'value') cache.get('key') // \"value\" // non-string keys ARE fully supported // but note that it must be THE SAME object, not // just a JSON-equivalent object. var someObject = { a: 1 } cache.set(someObject, 'a value') // Object keys are not toString()-ed cache.set('[object Object]', 'a different value') assert.equal(cache.get(someObject), 'a value') // A similar object with same keys/values won't work, // because it's a different object identity assert.equal(cache.get({ a: 1 }), undefined) cache.clear() // empty the cache If you put more stuff in the cache, then less recently used items will fall out. That's what an LRU cache is. For full description of the API and all options, please see the LRUCache typedocs Storage Bounds Safety This implementation aims to be as flexible as possible, within the limits of safe memory consumption and optimal performance. At initial object creation, storage is allocated for max items. If max is set to zero, then some performance is lost, and item count is unbounded. Either maxSize or ttl must be set if max is not specified. If maxSize is set, then this creates a safe limit on the maximum storage consumed, but without the performance benefits of pre-allocation. When maxSize is set, every item must provide a size, either via the sizeCalculation method provided to the constructor, or via a size or sizeCalculation option provided to cache.set(). The size of every item must be a positive integer. If neither max nor maxSize are set, then ttl tracking must be enabled. Note that, even when tracking item ttl, items are not preemptively deleted when they become stale, unless ttlAutopurge is enabled. Instead, they are only purged the next time the key is requested. Thus, if ttlAutopurge, max, and maxSize are all not set, then the cache will potentially grow unbounded. In this case, a warning is printed to standard error. Future versions may require the use of ttlAutopurge if max and maxSize are not specified. If you truly wish to use a cache that is bound only by TTL expiration, consider using a Map object, and calling setTimeout to delete entries when they expire. It will perform much better than an LRU cache. Here is an implementation you may use, under the same license as this package: // a storage-unbounded ttl cache that is not an lru-cache const cache = { data: new Map(), timers: new Map(), set: (k, v, ttl) => { if (cache.timers.has(k)) { clearTimeout(cache.timers.get(k)) } cache.timers.set( k, setTimeout(() => cache.delete(k), ttl) ) cache.data.set(k, v) }, get: k => cache.data.get(k), has: k => cache.data.has(k), delete: k => { if (cache.timers.has(k)) { clearTimeout(cache.timers.get(k)) } cache.timers.delete(k) return cache.data.delete(k) }, clear: () => { cache.data.clear() for (const v of cache.timers.values()) { clearTimeout(v) } cache.timers.clear() }, } If that isn't to your liking, check out @isaacs/ttlcache. Storing Undefined Values This cache never stores undefined values, as undefined is used internally in a few places to indicate that a key is not in the cache. You may call cache.set(key, undefined), but this is just an alias for cache.delete(key). Note that this has the effect that cache.has(key) will return false after setting it to undefined. cache.set(myKey, undefined) cache.has(myKey) // false! If you need to track undefined values, and still note that the key is in the cache, an easy workaround is to use a sigil object of your own. import { LRUCache } from 'lru-cache' const undefinedValue = Symbol('undefined') const cache = new LRUCache(...) const mySet = (key, value) => cache.set(key, value === undefined ? undefinedValue : value) const myGet = (key, value) => { const v = cache.get(key) return v === undefinedValue ? undefined : v } Performance As of January 2022, version 7 of this library is one of the most performant LRU cache implementations in JavaScript. Benchmarks can be extremely difficult to get right. In particular, the performance of set/get/delete operations on objects will vary wildly depending on the type of key used. V8 is highly optimized for objects with keys that are short strings, especially integer numeric strings. Thus any benchmark which tests solely using numbers as keys will tend to find that an object-based approach performs the best. Note that coercing anything to strings to use as object keys is unsafe, unless you can be 100% certain that no other type of value will be used. For example: const myCache = {} const set = (k, v) => (myCache[k] = v) const get = k => myCache[k] set({}, 'please hang onto this for me') set('[object Object]', 'oopsie') Also beware of \"Just So\" stories regarding performance. Garbage collection of large (especially: deep) object graphs can be incredibly costly, with several \"tipping points\" where it increases exponentially. As a result, putting that off until later can make it much worse, and less predictable. If a library performs well, but only in a scenario where the object graph is kept shallow, then that won't help you if you are using large objects as keys. In general, when attempting to use a library to improve performance (such as a cache like this one), it's best to choose an option that will perform well in the sorts of scenarios where you'll actually use it. This library is optimized for repeated gets and minimizing eviction time, since that is the expected need of a LRU. Set operations are somewhat slower on average than a few other options, in part because of that optimization. It is assumed that you'll be caching some costly operation, ideally as rarely as possible, so optimizing set over get would be unwise. If performance matters to you: If it's at all possible to use small integer values as keys, and you can guarantee that no other types of values will be used as keys, then do that, and use a cache such as lru-fast, or mnemonist's LRUCache which uses an Object as its data store. Failing that, if at all possible, use short non-numeric strings (ie, less than 256 characters) as your keys, and use mnemonist's LRUCache. If the types of your keys will be anything else, especially long strings, strings that look like floats, objects, or some mix of types, or if you aren't sure, then this library will work well for you. If you do not need the features that this library provides (like asynchronous fetching, a variety of TTL staleness options, and so on), then mnemonist's LRUMap is a very good option, and just slightly faster than this module (since it does considerably less). Do not use a dispose function, size tracking, or especially ttl behavior, unless absolutely needed. These features are convenient, and necessary in some use cases, and every attempt has been made to make the performance impact minimal, but it isn't nothing. Breaking Changes in Version 7 This library changed to a different algorithm and internal data structure in version 7, yielding significantly better performance, albeit with some subtle changes as a result. If you were relying on the internals of LRUCache in version 6 or before, it probably will not work in version 7 and above. Breaking Changes in Version 8 The fetchContext option was renamed to context, and may no longer be set on the cache instance itself. Rewritten in TypeScript, so pretty much all the types moved around a lot. The AbortController/AbortSignal polyfill was removed. For this reason, Node version 16.14.0 or higher is now required. Internal properties were moved to actual private class properties. Keys and values must not be null or undefined. Minified export available at 'lru-cache/min', for both CJS and MJS builds. Breaking Changes in Version 9 Named export only, no default export. AbortController polyfill returned, albeit with a warning when used. Breaking Changes in Version 10 cache.fetch() return type is now Promise<V | undefined> instead of Promise<V | void>. This is an irrelevant change practically speaking, but can require changes for TypeScript users. For more info, see the change log."
  },
  "src/frontend/app-client/node_modules/path-scurry/README.html": {
    "href": "src/frontend/app-client/node_modules/path-scurry/README.html",
    "title": "path-scurry",
    "summary": "path-scurry Extremely high performant utility for building tools that read the file system, minimizing filesystem and path string munging operations to the greatest degree possible. Ugh, yet another file traversal thing on npm? Yes. None of the existing ones gave me exactly what I wanted. Well what is it you wanted? While working on glob, I found that I needed a module to very efficiently manage the traversal over a folder tree, such that: No readdir() or stat() would ever be called on the same file or directory more than one time. No readdir() calls would be made if we can be reasonably sure that the path is not a directory. (Ie, a previous readdir() or stat() covered the path, and ent.isDirectory() is false.) path.resolve(), dirname(), basename(), and other string-parsing/munging operations are be minimized. This means it has to track \"provisional\" child nodes that may not exist (and if we find that they don't exist, store that information as well, so we don't have to ever check again). The API is not limited to use as a stream/iterator/etc. There are many cases where an API like node's fs is preferrable. It's more important to prevent excess syscalls than to be up to date, but it should be smart enough to know what it doesn't know, and go get it seamlessly when requested. Do not blow up the JS heap allocation if operating on a directory with a huge number of entries. Handle all the weird aspects of Windows paths, like UNC paths and drive letters and wrongway slashes, so that the consumer can return canonical platform-specific paths without having to parse or join or do any error-prone string munging. PERFORMANCE JavaScript people throw around the word \"blazing\" a lot. I hope that this module doesn't blaze anyone. But it does go very fast, in the cases it's optimized for, if used properly. PathScurry provides ample opportunities to get extremely good performance, as well as several options to trade performance for convenience. Benchmarks can be run by executing npm run bench. As is always the case, doing more means going slower, doing less means going faster, and there are trade offs between speed and memory usage. PathScurry makes heavy use of LRUCache to efficiently cache whatever it can, and Path objects remain in the graph for the lifetime of the walker, so repeated calls with a single PathScurry object will be extremely fast. However, adding items to a cold cache means \"doing more\", so in those cases, we pay a price. Nothing is free, but every effort has been made to reduce costs wherever possible. Also, note that a \"cache as long as possible\" approach means that changes to the filesystem may not be reflected in the results of repeated PathScurry operations. For resolving string paths, PathScurry ranges from 5-50 times faster than path.resolve on repeated resolutions, but around 100 to 1000 times slower on the first resolution. If your program is spending a lot of time resolving the same paths repeatedly (like, thousands or millions of times), then this can be beneficial. But both implementations are pretty fast, and speeding up an infrequent operation from 4µs to 400ns is not going to move the needle on your app's performance. For walking file system directory trees, a lot depends on how often a given PathScurry object will be used, and also on the walk method used. With default settings on a folder tree of 100,000 items, consisting of around a 10-to-1 ratio of normal files to directories, PathScurry performs comparably to @nodelib/fs.walk, which is the fastest and most reliable file system walker I could find. As far as I can tell, it's almost impossible to go much faster in a Node.js program, just based on how fast you can push syscalls out to the fs thread pool. On my machine, that is about 1000-1200 completed walks per second for async or stream walks, and around 500-600 walks per second synchronously. In the warm cache state, PathScurry's performance increases around 4x for async for await iteration, 10-15x faster for streams and synchronous for of iteration, and anywhere from 30x to 80x faster for the rest. # walk 100,000 fs entries, 10/1 file/dir ratio # operations / ms New PathScurry object | Reuse PathScurry object stream: 1112.589 | 13974.917 sync stream: 492.718 | 15028.343 async walk: 1095.648 | 32706.395 sync walk: 527.632 | 46129.772 async iter: 1288.821 | 5045.510 sync iter: 498.496 | 17920.746 A hand-rolled walk calling entry.readdir() and recursing through the entries can benefit even more from caching, with greater flexibility and without the overhead of streams or generators. The cold cache state is still limited by the costs of file system operations, but with a warm cache, the only bottleneck is CPU speed and VM optimizations. Of course, in that case, some care must be taken to ensure that you don't lose performance as a result of silly mistakes, like calling readdir() on entries that you know are not directories. # manual recursive iteration functions cold cache | warm cache async: 1164.901 | 17923.320 cb: 1101.127 | 40999.344 zalgo: 1082.240 | 66689.936 sync: 526.935 | 87097.591 In this case, the speed improves by around 10-20x in the async case, 40x in the case of using entry.readdirCB with protections against synchronous callbacks, and 50-100x with callback deferrals disabled, and several hundred times faster for synchronous iteration. If you can think of a case that is not covered in these benchmarks, or an implementation that performs significantly better than PathScurry, please let me know. USAGE // hybrid module, load with either method import { PathScurry, Path } from 'path-scurry' // or: const { PathScurry, Path } = require('path-scurry') // very simple example, say we want to find and // delete all the .DS_Store files in a given path // note that the API is very similar to just a // naive walk with fs.readdir() import { unlink } from 'fs/promises' // easy way, iterate over the directory and do the thing const pw = new PathScurry(process.cwd()) for await (const entry of pw) { if (entry.isFile() && entry.name === '.DS_Store') { unlink(entry.fullpath()) } } // here it is as a manual recursive method const walk = async (entry: Path) => { const promises: Promise<any> = [] // readdir doesn't throw on non-directories, it just doesn't // return any entries, to save stack trace costs. // Items are returned in arbitrary unsorted order for (const child of await pw.readdir(entry)) { // each child is a Path object if (child.name === '.DS_Store' && child.isFile()) { // could also do pw.resolve(entry, child.name), // just like fs.readdir walking, but .fullpath is // a *slightly* more efficient shorthand. promises.push(unlink(child.fullpath())) } else if (child.isDirectory()) { promises.push(walk(child)) } } return Promise.all(promises) } walk(pw.cwd).then(() => { console.log('all .DS_Store files removed') }) const pw2 = new PathScurry('/a/b/c') // pw2.cwd is the Path for /a/b/c const relativeDir = pw2.cwd.resolve('../x') // Path entry for '/a/b/x' const relative2 = pw2.cwd.resolve('/a/b/d/../x') // same path, same entry assert.equal(relativeDir, relative2) API Full TypeDoc API There are platform-specific classes exported, but for the most part, the default PathScurry and Path exports are what you most likely need, unless you are testing behavior for other platforms. Intended public API is documented here, but the full documentation does include internal types, which should not be accessed directly. Interface PathScurryOpts The type of the options argument passed to the PathScurry constructor. nocase: Boolean indicating that file names should be compared case-insensitively. Defaults to true on darwin and win32 implementations, false elsewhere. Warning Performing case-insensitive matching on a case-sensitive filesystem will result in occasionally very bizarre behavior. Performing case-sensitive matching on a case-insensitive filesystem may negatively impact performance. childrenCacheSize: Number of child entries to cache, in order to speed up resolve() and readdir() calls. Defaults to 16 * 1024 (ie, 16384). Setting it to a higher value will run the risk of JS heap allocation errors on large directory trees. Setting it to 256 or smaller will significantly reduce the construction time and data consumption overhead, but with the downside of operations being slower on large directory trees. Setting it to 0 will mean that effectively no operations are cached, and this module will be roughly the same speed as fs for file system operations, and much slower than path.resolve() for repeated path resolution. fs An object that will be used to override the default fs methods. Any methods that are not overridden will use Node's built-in implementations. lstatSync readdir (callback withFileTypes Dirent variant, used for readdirCB and most walks) readdirSync readlinkSync realpathSync promises: Object containing the following async methods: lstat readdir (Dirent variant only) readlink realpath Interface WalkOptions The options object that may be passed to all walk methods. withFileTypes: Boolean, default true. Indicates that Path objects should be returned. Set to false to get string paths instead. follow: Boolean, default false. Attempt to read directory entries from symbolic links. Otherwise, only actual directories are traversed. Regardless of this setting, a given target path will only ever be walked once, meaning that a symbolic link to a previously traversed directory will never be followed. Setting this imposes a slight performance penalty, because readlink must be called on all symbolic links encountered, in order to avoid infinite cycles. filter: Function (entry: Path) => boolean. If provided, will prevent the inclusion of any entry for which it returns a falsey value. This will not prevent directories from being traversed if they do not pass the filter, though it will prevent the directories themselves from being included in the results. By default, if no filter is provided, then all entries are included in the results. walkFilter: Function (entry: Path) => boolean. If provided, will prevent the traversal of any directory (or in the case of follow:true symbolic links to directories) for which the function returns false. This will not prevent the directories themselves from being included in the result set. Use filter for that. Note that TypeScript return types will only be inferred properly from static analysis if the withFileTypes option is omitted, or a constant true or false value. Class PathScurry The main interface. Defaults to an appropriate class based on the current platform. Use PathScurryWin32, PathScurryDarwin, or PathScurryPosix if implementation-specific behavior is desired. All walk methods may be called with a WalkOptions argument to walk over the object's current working directory with the supplied options. async pw.walk(entry?: string | Path | WalkOptions, opts?: WalkOptions) Walk the directory tree according to the options provided, resolving to an array of all entries found. pw.walkSync(entry?: string | Path | WalkOptions, opts?: WalkOptions) Walk the directory tree according to the options provided, returning an array of all entries found. pw.iterate(entry?: string | Path | WalkOptions, opts?: WalkOptions) Iterate over the directory asynchronously, for use with for await of. This is also the default async iterator method. pw.iterateSync(entry?: string | Path | WalkOptions, opts?: WalkOptions) Iterate over the directory synchronously, for use with for of. This is also the default sync iterator method. pw.stream(entry?: string | Path | WalkOptions, opts?: WalkOptions) Return a Minipass stream that emits each entry or path string in the walk. Results are made available asynchronously. pw.streamSync(entry?: string | Path | WalkOptions, opts?: WalkOptions) Return a Minipass stream that emits each entry or path string in the walk. Results are made available synchronously, meaning that the walk will complete in a single tick if the stream is fully consumed. pw.cwd Path object representing the current working directory for the PathScurry. pw.chdir(path: string) Set the new effective current working directory for the scurry object, so that path.relative() and path.relativePosix() return values relative to the new cwd path. pw.depth(path?: Path | string): number Return the depth of the specified path (or the PathScurry cwd) within the directory tree. Root entries have a depth of 0. pw.resolve(...paths: string[]) Caching path.resolve(). Significantly faster than path.resolve() if called repeatedly with the same paths. Significantly slower otherwise, as it builds out the cached Path entries. To get a Path object resolved from the PathScurry, use pw.cwd.resolve(path). Note that Path.resolve only takes a single string argument, not multiple. pw.resolvePosix(...paths: string[]) Caching path.resolve(), but always using posix style paths. This is identical to pw.resolve(...paths) on posix systems (ie, everywhere except Windows). On Windows, it returns the full absolute UNC path using / separators. Ie, instead of 'C:\\\\foo\\\\bar, it would return //?/C:/foo/bar. pw.relative(path: string | Path): string Return the relative path from the PathWalker cwd to the supplied path string or entry. If the nearest common ancestor is the root, then an absolute path is returned. pw.relativePosix(path: string | Path): string Return the relative path from the PathWalker cwd to the supplied path string or entry, using / path separators. If the nearest common ancestor is the root, then an absolute path is returned. On posix platforms (ie, all platforms except Windows), this is identical to pw.relative(path). On Windows systems, it returns the resulting string as a /-delimited path. If an absolute path is returned (because the target does not share a common ancestor with pw.cwd), then a full absolute UNC path will be returned. Ie, instead of 'C:\\\\foo\\\\bar, it would return //?/C:/foo/bar. pw.basename(path: string | Path): string Return the basename of the provided string or Path. pw.dirname(path: string | Path): string Return the parent directory of the supplied string or Path. async pw.readdir(dir = pw.cwd, opts = { withFileTypes: true }) Read the directory and resolve to an array of strings if withFileTypes is explicitly set to false or Path objects otherwise. Can be called as pw.readdir({ withFileTypes: boolean }) as well. Returns [] if no entries are found, or if any error occurs. Note that TypeScript return types will only be inferred properly from static analysis if the withFileTypes option is omitted, or a constant true or false value. pw.readdirSync(dir = pw.cwd, opts = { withFileTypes: true }) Synchronous pw.readdir() async pw.readlink(link = pw.cwd, opts = { withFileTypes: false }) Call fs.readlink on the supplied string or Path object, and return the result. Can be called as pw.readlink({ withFileTypes: boolean }) as well. Returns undefined if any error occurs (for example, if the argument is not a symbolic link), or a Path object if withFileTypes is explicitly set to true, or a string otherwise. Note that TypeScript return types will only be inferred properly from static analysis if the withFileTypes option is omitted, or a constant true or false value. pw.readlinkSync(link = pw.cwd, opts = { withFileTypes: false }) Synchronous pw.readlink() async pw.lstat(entry = pw.cwd) Call fs.lstat on the supplied string or Path object, and fill in as much information as possible, returning the updated Path object. Returns undefined if the entry does not exist, or if any error is encountered. Note that some Stats data (such as ino, dev, and mode) will not be supplied. For those things, you'll need to call fs.lstat yourself. pw.lstatSync(entry = pw.cwd) Synchronous pw.lstat() pw.realpath(entry = pw.cwd, opts = { withFileTypes: false }) Call fs.realpath on the supplied string or Path object, and return the realpath if available. Returns undefined if any error occurs. May be called as pw.realpath({ withFileTypes: boolean }) to run on pw.cwd. pw.realpathSync(entry = pw.cwd, opts = { withFileTypes: false }) Synchronous pw.realpath() Class Path implements fs.Dirent Object representing a given path on the filesystem, which may or may not exist. Note that the actual class in use will be either PathWin32 or PathPosix, depending on the implementation of PathScurry in use. They differ in the separators used to split and join path strings, and the handling of root paths. In PathPosix implementations, paths are split and joined using the '/' character, and '/' is the only root path ever in use. In PathWin32 implementations, paths are split using either '/' or '\\\\' and joined using '\\\\', and multiple roots may be in use based on the drives and UNC paths encountered. UNC paths such as //?/C:/ that identify a drive letter, will be treated as an alias for the same root entry as their associated drive letter (in this case 'C:\\\\'). path.name Name of this file system entry. Important: always test the path name against any test string using the isNamed method, and not by directly comparing this string. Otherwise, unicode path strings that the system sees as identical will not be properly treated as the same path, leading to incorrect behavior and possible security issues. path.isNamed(name: string): boolean Return true if the path is a match for the given path name. This handles case sensitivity and unicode normalization. Note: even on case-sensitive systems, it is not safe to test the equality of the .name property to determine whether a given pathname matches, due to unicode normalization mismatches. Always use this method instead of testing the path.name property directly. path.isCWD Set to true if this Path object is the current working directory of the PathScurry collection that contains it. path.getType() Returns the type of the Path object, 'File', 'Directory', etc. path.isType(t: type) Returns true if is{t}() returns true. For example, path.isType('Directory') is equivalent to path.isDirectory(). path.depth() Return the depth of the Path entry within the directory tree. Root paths have a depth of 0. path.fullpath() The fully resolved path to the entry. path.fullpathPosix() The fully resolved path to the entry, using / separators. On posix systems, this is identical to path.fullpath(). On windows, this will return a fully resolved absolute UNC path using / separators. Eg, instead of 'C:\\\\foo\\\\bar', it will return '//?/C:/foo/bar'. path.isFile(), path.isDirectory(), etc. Same as the identical fs.Dirent.isX() methods. path.isUnknown() Returns true if the path's type is unknown. Always returns true when the path is known to not exist. path.resolve(p: string) Return a Path object associated with the provided path string as resolved from the current Path object. path.relative(): string Return the relative path from the PathWalker cwd to the supplied path string or entry. If the nearest common ancestor is the root, then an absolute path is returned. path.relativePosix(): string Return the relative path from the PathWalker cwd to the supplied path string or entry, using / path separators. If the nearest common ancestor is the root, then an absolute path is returned. On posix platforms (ie, all platforms except Windows), this is identical to pw.relative(path). On Windows systems, it returns the resulting string as a /-delimited path. If an absolute path is returned (because the target does not share a common ancestor with pw.cwd), then a full absolute UNC path will be returned. Ie, instead of 'C:\\\\foo\\\\bar, it would return //?/C:/foo/bar. async path.readdir() Return an array of Path objects found by reading the associated path entry. If path is not a directory, or if any error occurs, returns [], and marks all children as provisional and non-existent. path.readdirSync() Synchronous path.readdir() async path.readlink() Return the Path object referenced by the path as a symbolic link. If the path is not a symbolic link, or any error occurs, returns undefined. path.readlinkSync() Synchronous path.readlink() async path.lstat() Call lstat on the path object, and fill it in with details determined. If path does not exist, or any other error occurs, returns undefined, and marks the path as \"unknown\" type. path.lstatSync() Synchronous path.lstat() async path.realpath() Call realpath on the path, and return a Path object corresponding to the result, or undefined if any error occurs. path.realpathSync() Synchornous path.realpath()"
  },
  "src/frontend/app-client/node_modules/path-to-regexp/Readme.html": {
    "href": "src/frontend/app-client/node_modules/path-to-regexp/Readme.html",
    "title": "Path-to-RegExp",
    "summary": "Path-to-RegExp Turn an Express-style path string such as /user/:name into a regular expression. Note: This is a legacy branch. You should upgrade to 1.x. Usage var pathToRegexp = require('path-to-regexp'); pathToRegexp(path, keys, options) path A string in the express format, an array of such strings, or a regular expression keys An array to be populated with the keys present in the url. Once the function completes, this will be an array of strings. options options.sensitive Defaults to false, set this to true to make routes case sensitive options.strict Defaults to false, set this to true to make the trailing slash matter. options.end Defaults to true, set this to false to only match the prefix of the URL. var keys = []; var exp = pathToRegexp('/foo/:bar', keys); //keys = ['bar'] //exp = /^\\/foo\\/(?:([^\\/]+?))\\/?$/i Live Demo You can see a live demo of this library in use at express-route-tester. License MIT"
  },
  "src/frontend/app-client/node_modules/path-type/readme.html": {
    "href": "src/frontend/app-client/node_modules/path-type/readme.html",
    "title": "path-type",
    "summary": "path-type Check if a path is a file, directory, or symlink Install $ npm install path-type Usage const {isFile} = require('path-type'); (async () => { console.log(await isFile('package.json')); //=> true })(); API isFile(path) Check whether the passed path is a file. Returns a Promise<boolean>. path Type: string The path to check. isDirectory(path) Check whether the passed path is a directory. Returns a Promise<boolean>. isSymlink(path) Check whether the passed path is a symlink. Returns a Promise<boolean>. isFileSync(path) Synchronously check whether the passed path is a file. Returns a boolean. isDirectorySync(path) Synchronously check whether the passed path is a directory. Returns a boolean. isSymlinkSync(path) Synchronously check whether the passed path is a symlink. Returns a boolean. License MIT © Sindre Sorhus"
  },
  "src/frontend/app-client/node_modules/pathe/README.html": {
    "href": "src/frontend/app-client/node_modules/pathe/README.html",
    "title": "\uD83D\uDEE3️ pathe",
    "summary": "\uD83D\uDEE3️ pathe Universal filesystem path utils ❓ Why For historical reasons, windows followed MS-DOS and using backslash for separating paths rather than slash used for macOS, Linux, and other Posix operating systems. Nowadays, Windows supports both Slash and Backslash for paths. Node.js's built in path module in the default operation of the path module varies based on the operating system on which a Node.js application is running. Specifically, when running on a Windows operating system, the path module will assume that Windows-style paths are being used. This makes inconsistent code behavior between Windows and POSIX. Compared to popular upath, pathe is providing identical exports of Node.js with normalization on all operations and written in modern ESM/Typescript and has no dependency on Node.js! This package is a drop-in replacement of the Node.js's path module module and ensures paths are normalized with slash / and work in environments including Node.js. \uD83D\uDCBF Usage Install using npm or yarn: # npm npm i pathe # yarn yarn add pathe # pnpm pnpm i pathe Import: // ESM / Typescript import { resolve } from 'pathe' // CommonJS const { resolve } = require('pathe') Read more about path utils from Node.js documentation and rest assured behavior is ALWAYS like POSIX regardless of your input paths format and running platform! Extra utilties Pathe exports some extra utilities that do not exist in standard Node.js path module. In order to use them, you can import from pathe/utils subpath: import { filename, normalizeAliases, resolveAlias } from 'pathe/utils' License MIT. Made with \uD83D\uDC96 Some code used from Node.js project. See LICENSE."
  },
  "src/frontend/app-client/node_modules/picocolors/README.html": {
    "href": "src/frontend/app-client/node_modules/picocolors/README.html",
    "title": "picocolors",
    "summary": "picocolors The tiniest and the fastest library for terminal output formatting with ANSI colors. import pc from \"picocolors\" console.log( pc.green(`How are ${pc.italic(`you`)} doing?`) ) No dependencies. 14 times smaller and 2 times faster than chalk. Used by popular tools like PostCSS, SVGO, Stylelint, and Browserslist. Node.js v6+ & browsers support. Support for both CJS and ESM projects. TypeScript type declarations included. NO_COLOR friendly. Docs Read full docs on GitHub."
  },
  "src/frontend/app-client/node_modules/postcss/README.html": {
    "href": "src/frontend/app-client/node_modules/postcss/README.html",
    "title": "PostCSS",
    "summary": "PostCSS PostCSS is a tool for transforming styles with JS plugins. These plugins can lint your CSS, support variables and mixins, transpile future CSS syntax, inline images, and more. PostCSS is used by industry leaders including Wikipedia, Twitter, Alibaba, and JetBrains. The Autoprefixer and Stylelint PostCSS plugins is one of the most popular CSS tools. Made at Evil Martians, product consulting for developer tools. Docs Read full docs here."
  },
  "src/frontend/app-client/node_modules/prettier/README.html": {
    "href": "src/frontend/app-client/node_modules/prettier/README.html",
    "title": "",
    "summary": "Opinionated Code Formatter JavaScript · TypeScript · Flow · JSX · JSON CSS · SCSS · Less HTML · Vue · Angular GraphQL · Markdown · YAML Your favorite language? Intro Prettier is an opinionated code formatter. It enforces a consistent style by parsing your code and re-printing it with its own rules that take the maximum line length into account, wrapping code when necessary. Input foo(reallyLongArg(), omgSoManyParameters(), IShouldRefactorThis(), isThereSeriouslyAnotherOne()); Output foo( reallyLongArg(), omgSoManyParameters(), IShouldRefactorThis(), isThereSeriouslyAnotherOne() ); Prettier can be run in your editor on-save, in a pre-commit hook, or in CI environments to ensure your codebase has a consistent style without devs ever having to post a nit-picky comment on a code review ever again! Documentation Install · Options · CLI · API Playground Badge Show the world you're using Prettier → [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier) Contributing See CONTRIBUTING.md."
  },
  "src/frontend/app-client/node_modules/proc-log/README.html": {
    "href": "src/frontend/app-client/node_modules/proc-log/README.html",
    "title": "proc-log",
    "summary": "proc-log Emits 'log' events on the process object which a log output listener can consume and print to the terminal. This is used by various modules within the npm CLI stack in order to send log events that can be consumed by a listener on the process object. API log.error(...args) calls process.emit('log', 'error', ...args) The highest log level. For printing extremely serious errors that indicate something went wrong. log.warn(...args) calls process.emit('log', 'warn', ...args) A fairly high log level. Things that the user needs to be aware of, but which won't necessarily cause improper functioning of the system. log.notice(...args) calls process.emit('log', 'notice', ...args) Notices which are important, but not necessarily dangerous or a cause for excess concern. log.info(...args) calls process.emit('log', 'info', ...args) Informative messages that may benefit the user, but aren't particularly important. log.verbose(...args) calls process.emit('log', 'verbose', ...args) Noisy output that is more detail that most users will care about. log.silly(...args) calls process.emit('log', 'silly', ...args) Extremely noisy excessive logging messages that are typically only useful for debugging. log.http(...args) calls process.emit('log', 'http', ...args) Information about HTTP requests made and/or completed. log.pause() calls process.emit('log', 'pause') Used to tell the consumer to stop printing messages. log.resume() calls process.emit('log', 'resume') Used to tell the consumer that it is ok to print messages again. log.LEVELS an array of strings of all log method names Examples Every method calls process.emit('log', level, ...otherArgs) internally. So in order to consume those events you need to do process.on('log', fn). Colorize based on level Here's an example of how to consume proc-log events and colorize them based on level: const chalk = require('chalk') process.on('log', (level, ...args) => { if (level === 'error') { console.log(chalk.red(level), ...args) } else { console.log(chalk.blue(level), ...args) } }) Pause and resume pause and resume are included so you have the ability to tell your consumer that you want to pause or resume your display of logs. In the npm CLI we use this to buffer all logs on init until we know the correct loglevel to display. But we also setup a second handler that writes everything to a file even if paused. let paused = true const buffer = [] // this handler will buffer and replay logs only // after `procLog.resume()` is called process.on('log', (level, ...args) => { if (level === 'resume') { buffer.forEach((item) => console.log(...item)) paused = false return } if (paused) { buffer.push([level, ...args]) } else { console.log(level, ...args) } }) // this handler will write everything to a file process.on('log', (...args) => { fs.appendFileSync('debug.log', args.join(' ')) })"
  },
  "src/frontend/app-client/node_modules/process-nextick-args/license.html": {
    "href": "src/frontend/app-client/node_modules/process-nextick-args/license.html",
    "title": "Copyright (c) 2015 Calvin Metcalf",
    "summary": "Copyright (c) 2015 Calvin Metcalf Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/process-nextick-args/readme.html": {
    "href": "src/frontend/app-client/node_modules/process-nextick-args/readme.html",
    "title": "process-nextick-args",
    "summary": "process-nextick-args npm install --save process-nextick-args Always be able to pass arguments to process.nextTick, no matter the platform var pna = require('process-nextick-args'); pna.nextTick(function (a, b, c) { console.log(a, b, c); }, 'step', 3, 'profit');"
  },
  "src/frontend/app-client/node_modules/promise-inflight/README.html": {
    "href": "src/frontend/app-client/node_modules/promise-inflight/README.html",
    "title": "promise-inflight",
    "summary": "promise-inflight One promise for multiple requests in flight to avoid async duplication USAGE const inflight = require('promise-inflight') // some request that does some stuff function req(key) { // key is any random string. like a url or filename or whatever. return inflight(key, () => { // this is where you'd fetch the url or whatever return Promise.delay(100) }) } // only assigns a single setTimeout // when it dings, all thens get called with the same result. (There's only // one underlying promise.) req('foo').then(…) req('foo').then(…) req('foo').then(…) req('foo').then(…) SEE ALSO inflight - For the callback based function on which this is based. STILL NEEDS Tests!"
  },
  "src/frontend/app-client/node_modules/promise-retry/README.html": {
    "href": "src/frontend/app-client/node_modules/promise-retry/README.html",
    "title": "node-promise-retry",
    "summary": "node-promise-retry Retries a function that returns a promise, leveraging the power of the retry module to the promises world. There's already some modules that are able to retry functions that return promises but they were rather difficult to use or do not offer an easy way to do conditional retries. Installation $ npm install promise-retry Usage promiseRetry(fn, [options]) Calls fn until the returned promise ends up fulfilled or rejected with an error different than a retry error. The options argument is an object which maps to the retry module options: retries: The maximum amount of times to retry the operation. Default is 10. factor: The exponential factor to use. Default is 2. minTimeout: The number of milliseconds before starting the first retry. Default is 1000. maxTimeout: The maximum number of milliseconds between two retries. Default is Infinity. randomize: Randomizes the timeouts by multiplying with a factor between 1 to 2. Default is false. The fn function will receive a retry function as its first argument that should be called with an error whenever you want to retry fn. The retry function will always throw an error. If there are retries left, it will throw a special retry error that will be handled internally to call fn again. If there are no retries left, it will throw the actual error passed to it. If you prefer, you can pass the options first using the alternative function signature promiseRetry([options], fn). Example var promiseRetry = require('promise-retry'); // Simple example promiseRetry(function (retry, number) { console.log('attempt number', number); return doSomething() .catch(retry); }) .then(function (value) { // .. }, function (err) { // .. }); // Conditional example promiseRetry(function (retry, number) { console.log('attempt number', number); return doSomething() .catch(function (err) { if (err.code === 'ETIMEDOUT') { retry(err); } throw err; }); }) .then(function (value) { // .. }, function (err) { // .. }); Tests $ npm test License Released under the MIT License."
  },
  "src/frontend/app-client/node_modules/prop-types/README.html": {
    "href": "src/frontend/app-client/node_modules/prop-types/README.html",
    "title": "prop-types",
    "summary": "prop-types Runtime type checking for React props and similar objects. You can use prop-types to document the intended types of properties passed to components. React (and potentially other libraries—see the checkPropTypes() reference below) will check props passed to your components against those definitions, and warn in development if they don’t match. Installation npm install --save prop-types Importing import PropTypes from 'prop-types'; // ES6 var PropTypes = require('prop-types'); // ES5 with npm CDN If you prefer to exclude prop-types from your application and use it globally via window.PropTypes, the prop-types package provides single-file distributions, which are hosted on the following CDNs: unpkg <!-- development version --> <script src=\"https://unpkg.com/prop-types@15.6/prop-types.js\"></script> <!-- production version --> <script src=\"https://unpkg.com/prop-types@15.6/prop-types.min.js\"></script> cdnjs <!-- development version --> <script src=\"https://cdnjs.cloudflare.com/ajax/libs/prop-types/15.6.0/prop-types.js\"></script> <!-- production version --> <script src=\"https://cdnjs.cloudflare.com/ajax/libs/prop-types/15.6.0/prop-types.min.js\"></script> To load a specific version of prop-types replace 15.6.0 with the version number. Usage PropTypes was originally exposed as part of the React core module, and is commonly used with React components. Here is an example of using PropTypes with a React component, which also documents the different validators provided: import React from 'react'; import PropTypes from 'prop-types'; class MyComponent extends React.Component { render() { // ... do things with the props } } MyComponent.propTypes = { // You can declare that a prop is a specific JS primitive. By default, these // are all optional. optionalArray: PropTypes.array, optionalBigInt: PropTypes.bigint, optionalBool: PropTypes.bool, optionalFunc: PropTypes.func, optionalNumber: PropTypes.number, optionalObject: PropTypes.object, optionalString: PropTypes.string, optionalSymbol: PropTypes.symbol, // Anything that can be rendered: numbers, strings, elements or an array // (or fragment) containing these types. // see https://reactjs.org/docs/rendering-elements.html for more info optionalNode: PropTypes.node, // A React element (ie. <MyComponent />). optionalElement: PropTypes.element, // A React element type (eg. MyComponent). // a function, string, or \"element-like\" object (eg. React.Fragment, Suspense, etc.) // see https://github.com/facebook/react/blob/HEAD/packages/shared/isValidElementType.js optionalElementType: PropTypes.elementType, // You can also declare that a prop is an instance of a class. This uses // JS's instanceof operator. optionalMessage: PropTypes.instanceOf(Message), // You can ensure that your prop is limited to specific values by treating // it as an enum. optionalEnum: PropTypes.oneOf(['News', 'Photos']), // An object that could be one of many types optionalUnion: PropTypes.oneOfType([ PropTypes.string, PropTypes.number, PropTypes.instanceOf(Message) ]), // An array of a certain type optionalArrayOf: PropTypes.arrayOf(PropTypes.number), // An object with property values of a certain type optionalObjectOf: PropTypes.objectOf(PropTypes.number), // You can chain any of the above with `isRequired` to make sure a warning // is shown if the prop isn't provided. // An object taking on a particular shape optionalObjectWithShape: PropTypes.shape({ optionalProperty: PropTypes.string, requiredProperty: PropTypes.number.isRequired }), // An object with warnings on extra properties optionalObjectWithStrictShape: PropTypes.exact({ optionalProperty: PropTypes.string, requiredProperty: PropTypes.number.isRequired }), requiredFunc: PropTypes.func.isRequired, // A value of any data type requiredAny: PropTypes.any.isRequired, // You can also specify a custom validator. It should return an Error // object if the validation fails. Don't `console.warn` or throw, as this // won't work inside `oneOfType`. customProp: function(props, propName, componentName) { if (!/matchme/.test(props[propName])) { return new Error( 'Invalid prop `' + propName + '` supplied to' + ' `' + componentName + '`. Validation failed.' ); } }, // You can also supply a custom validator to `arrayOf` and `objectOf`. // It should return an Error object if the validation fails. The validator // will be called for each key in the array or object. The first two // arguments of the validator are the array or object itself, and the // current item's key. customArrayProp: PropTypes.arrayOf(function(propValue, key, componentName, location, propFullName) { if (!/matchme/.test(propValue[key])) { return new Error( 'Invalid prop `' + propFullName + '` supplied to' + ' `' + componentName + '`. Validation failed.' ); } }) }; Refer to the React documentation for more information. Migrating from React.PropTypes Check out Migrating from React.PropTypes for details on how to migrate to prop-types from React.PropTypes. Note that this blog posts mentions a codemod script that performs the conversion automatically. There are also important notes below. How to Depend on This Package? For apps, we recommend putting it in dependencies with a caret range. For example: \"dependencies\": { \"prop-types\": \"^15.5.7\" } For libraries, we also recommend leaving it in dependencies: \"dependencies\": { \"prop-types\": \"^15.5.7\" }, \"peerDependencies\": { \"react\": \"^15.5.0\" } Note: there are known issues in versions before 15.5.7 so we recommend using it as the minimal version. Make sure that the version range uses a caret (^) and thus is broad enough for npm to efficiently deduplicate packages. For UMD bundles of your components, make sure you don’t include PropTypes in the build. Usually this is done by marking it as an external (the specifics depend on your bundler), just like you do with React. Compatibility React 0.14 This package is compatible with React 0.14.9. Compared to 0.14.8 (which was released in March of 2016), there are no other changes in 0.14.9, so it should be a painless upgrade. # ATTENTION: Only run this if you still use React 0.14! npm install --save react@^0.14.9 react-dom@^0.14.9 React 15+ This package is compatible with React 15.3.0 and higher. npm install --save react@^15.3.0 react-dom@^15.3.0 What happens on other React versions? It outputs warnings with the message below even though the developer doesn’t do anything wrong. Unfortunately there is no solution for this other than updating React to either 15.3.0 or higher, or 0.14.9 if you’re using React 0.14. Difference from React.PropTypes: Don’t Call Validator Functions First of all, which version of React are you using? You might be seeing this message because a component library has updated to use prop-types package, but your version of React is incompatible with it. See the above section for more details. Are you using either React 0.14.9 or a version higher than React 15.3.0? Read on. When you migrate components to use the standalone prop-types, all validator functions will start throwing an error if you call them directly. This makes sure that nobody relies on them in production code, and it is safe to strip their implementations to optimize the bundle size. Code like this is still fine: MyComponent.propTypes = { myProp: PropTypes.bool }; However, code like this will not work with the prop-types package: // Will not work with `prop-types` package! var errorOrNull = PropTypes.bool(42, 'myProp', 'MyComponent', 'prop'); It will throw an error: Calling PropTypes validators directly is not supported by the `prop-types` package. Use PropTypes.checkPropTypes() to call them. (If you see a warning rather than an error with this message, please check the above section about compatibility.) This is new behavior, and you will only encounter it when you migrate from React.PropTypes to the prop-types package. For the vast majority of components, this doesn’t matter, and if you didn’t see this warning in your components, your code is safe to migrate. This is not a breaking change in React because you are only opting into this change for a component by explicitly changing your imports to use prop-types. If you temporarily need the old behavior, you can keep using React.PropTypes until React 16. If you absolutely need to trigger the validation manually, call PropTypes.checkPropTypes(). Unlike the validators themselves, this function is safe to call in production, as it will be replaced by an empty function: // Works with standalone PropTypes PropTypes.checkPropTypes(MyComponent.propTypes, props, 'prop', 'MyComponent'); See below for more info. If you DO want to use validation in production, you can choose to use the development version by importing/requiring prop-types/prop-types instead of prop-types. You might also see this error if you’re calling a PropTypes validator from your own custom PropTypes validator. In this case, the fix is to make sure that you are passing all of the arguments to the inner function. There is a more in-depth explanation of how to fix it on this page. Alternatively, you can temporarily keep using React.PropTypes until React 16, as it would still only warn in this case. If you use a bundler like Browserify or Webpack, don’t forget to follow these instructions to correctly bundle your application in development or production mode. Otherwise you’ll ship unnecessary code to your users. PropTypes.checkPropTypes React will automatically check the propTypes you set on the component, but if you are using PropTypes without React then you may want to manually call PropTypes.checkPropTypes, like so: const myPropTypes = { name: PropTypes.string, age: PropTypes.number, // ... define your prop validations }; const props = { name: 'hello', // is valid age: 'world', // not valid }; // Let's say your component is called 'MyComponent' // Works with standalone PropTypes PropTypes.checkPropTypes(myPropTypes, props, 'prop', 'MyComponent'); // This will warn as follows: // Warning: Failed prop type: Invalid prop `age` of type `string` supplied to // `MyComponent`, expected `number`. PropTypes.resetWarningCache() PropTypes.checkPropTypes(...) only console.errors a given message once. To reset the error warning cache in tests, call PropTypes.resetWarningCache() License prop-types is MIT licensed."
  },
  "src/frontend/app-client/node_modules/proto-list/README.html": {
    "href": "src/frontend/app-client/node_modules/proto-list/README.html",
    "title": "",
    "summary": "A list of objects, bound by their prototype chain. Used in npm's config stuff."
  },
  "src/frontend/app-client/node_modules/proxy-addr/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/proxy-addr/HISTORY.html",
    "title": "2.0.7 / 2021-05-31",
    "summary": "2.0.7 / 2021-05-31 deps: forwarded@0.2.0 Use req.socket over deprecated req.connection 2.0.6 / 2020-02-24 deps: ipaddr.js@1.9.1 2.0.5 / 2019-04-16 deps: ipaddr.js@1.9.0 2.0.4 / 2018-07-26 deps: ipaddr.js@1.8.0 2.0.3 / 2018-02-19 deps: ipaddr.js@1.6.0 2.0.2 / 2017-09-24 deps: forwarded@~0.1.2 perf: improve header parsing perf: reduce overhead when no X-Forwarded-For header 2.0.1 / 2017-09-10 deps: forwarded@~0.1.1 Fix trimming leading / trailing OWS perf: hoist regular expression deps: ipaddr.js@1.5.2 2.0.0 / 2017-08-08 Drop support for Node.js below 0.10 1.1.5 / 2017-07-25 Fix array argument being altered deps: ipaddr.js@1.4.0 1.1.4 / 2017-03-24 deps: ipaddr.js@1.3.0 1.1.3 / 2017-01-14 deps: ipaddr.js@1.2.0 1.1.2 / 2016-05-29 deps: ipaddr.js@1.1.1 Fix IPv6-mapped IPv4 validation edge cases 1.1.1 / 2016-05-03 Fix regression matching mixed versions against multiple subnets 1.1.0 / 2016-05-01 Fix accepting various invalid netmasks IPv4 netmasks must be contingous IPv6 addresses cannot be used as a netmask deps: ipaddr.js@1.1.0 1.0.10 / 2015-12-09 deps: ipaddr.js@1.0.5 Fix regression in isValid with non-string arguments 1.0.9 / 2015-12-01 deps: ipaddr.js@1.0.4 Fix accepting some invalid IPv6 addresses Reject CIDRs with negative or overlong masks perf: enable strict mode 1.0.8 / 2015-05-10 deps: ipaddr.js@1.0.1 1.0.7 / 2015-03-16 deps: ipaddr.js@0.1.9 Fix OOM on certain inputs to isValid 1.0.6 / 2015-02-01 deps: ipaddr.js@0.1.8 1.0.5 / 2015-01-08 deps: ipaddr.js@0.1.6 1.0.4 / 2014-11-23 deps: ipaddr.js@0.1.5 Fix edge cases with isValid 1.0.3 / 2014-09-21 Use forwarded npm module 1.0.2 / 2014-09-18 Fix a global leak when multiple subnets are trusted Support Node.js 0.6 deps: ipaddr.js@0.1.3 1.0.1 / 2014-06-03 Fix links in npm package 1.0.0 / 2014-05-08 Add trust argument to determine proxy trust on Accepts custom function Accepts IPv4/IPv6 address(es) Accepts subnets Accepts pre-defined names Add optional trust argument to proxyaddr.all to stop at first untrusted Add proxyaddr.compile to pre-compile trust function to make subsequent calls faster 0.0.1 / 2014-05-04 Fix bad npm publish 0.0.0 / 2014-05-04 Initial release"
  },
  "src/frontend/app-client/node_modules/proxy-addr/README.html": {
    "href": "src/frontend/app-client/node_modules/proxy-addr/README.html",
    "title": "proxy-addr",
    "summary": "proxy-addr Determine address of proxied request Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install proxy-addr API var proxyaddr = require('proxy-addr') proxyaddr(req, trust) Return the address of the request, using the given trust parameter. The trust argument is a function that returns true if you trust the address, false if you don't. The closest untrusted address is returned. proxyaddr(req, function (addr) { return addr === '127.0.0.1' }) proxyaddr(req, function (addr, i) { return i < 1 }) The trust arugment may also be a single IP address string or an array of trusted addresses, as plain IP addresses, CIDR-formatted strings, or IP/netmask strings. proxyaddr(req, '127.0.0.1') proxyaddr(req, ['127.0.0.0/8', '10.0.0.0/8']) proxyaddr(req, ['127.0.0.0/255.0.0.0', '192.168.0.0/255.255.0.0']) This module also supports IPv6. Your IPv6 addresses will be normalized automatically (i.e. fe80::00ed:1 equals fe80:0:0:0:0:0:ed:1). proxyaddr(req, '::1') proxyaddr(req, ['::1/128', 'fe80::/10']) This module will automatically work with IPv4-mapped IPv6 addresses as well to support node.js in IPv6-only mode. This means that you do not have to specify both ::ffff:a00:1 and 10.0.0.1. As a convenience, this module also takes certain pre-defined names in addition to IP addresses, which expand into IP addresses: proxyaddr(req, 'loopback') proxyaddr(req, ['loopback', 'fc00:ac:1ab5:fff::1/64']) loopback: IPv4 and IPv6 loopback addresses (like ::1 and 127.0.0.1). linklocal: IPv4 and IPv6 link-local addresses (like fe80::1:1:1:1 and 169.254.0.1). uniquelocal: IPv4 private addresses and IPv6 unique-local addresses (like fc00:ac:1ab5:fff::1 and 192.168.0.1). When trust is specified as a function, it will be called for each address to determine if it is a trusted address. The function is given two arguments: addr and i, where addr is a string of the address to check and i is a number that represents the distance from the socket address. proxyaddr.all(req, [trust]) Return all the addresses of the request, optionally stopping at the first untrusted. This array is ordered from closest to furthest (i.e. arr[0] === req.connection.remoteAddress). proxyaddr.all(req) The optional trust argument takes the same arguments as trust does in proxyaddr(req, trust). proxyaddr.all(req, 'loopback') proxyaddr.compile(val) Compiles argument val into a trust function. This function takes the same arguments as trust does in proxyaddr(req, trust) and returns a function suitable for proxyaddr(req, trust). var trust = proxyaddr.compile('loopback') var addr = proxyaddr(req, trust) This function is meant to be optimized for use against every request. It is recommend to compile a trust function up-front for the trusted configuration and pass that to proxyaddr(req, trust) for each request. Testing $ npm test Benchmarks $ npm run-script bench License MIT"
  },
  "src/frontend/app-client/node_modules/qs/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/qs/CHANGELOG.html",
    "title": "",
    "summary": "6.13.0 [New] parse: add strictDepth option (#511) [Tests] use npm audit instead of aud 6.12.3 [Fix] parse: properly account for strictNullHandling when allowEmptyArrays [meta] fix changelog indentation 6.12.2 [Fix] parse: parse encoded square brackets (#506) [readme] add CII best practices badge 6.12.1 [Fix] parse: Disable decodeDotInKeys by default to restore previous behavior (#501) [Performance] utils: Optimize performance under large data volumes, reduce memory usage, and speed up processing (#502) [Refactor] utils: use += [Tests] increase coverage 6.12.0 [New] parse/stringify: add decodeDotInKeys/encodeDotKeys options (#488) [New] parse: add duplicates option [New] parse/stringify: add allowEmptyArrays option to allow [] in object values (#487) [Refactor] parse/stringify: move allowDots config logic to its own variable [Refactor] stringify: move option-handling code into normalizeStringifyOptions [readme] update readme, add logos (#484) [readme] stringify: clarify default arrayFormat behavior [readme] fix line wrapping [readme] remove dead badges [Deps] update side-channel [meta] make the dist build 50% smaller [meta] add sideEffects flag [meta] run build in prepack, not prepublish [Tests] parse: remove useless tests; add coverage [Tests] stringify: increase coverage [Tests] use mock-property [Tests] stringify: improve coverage [Dev Deps] update @ljharb/eslint-config , aud, has-override-mistake, has-property-descriptors, mock-property, npmignore, object-inspect, tape [Dev Deps] pin glob, since v10.3.8+ requires a broken jackspeak [Dev Deps] pin jackspeak since 2.1.2+ depends on npm aliases, which kill the install process in npm < 6 6.11.2 [Fix] parse: Fix parsing when the global Object prototype is frozen (#473) [Tests] add passing test cases with empty keys (#473) 6.11.1 [Fix] stringify: encode comma values more consistently (#463) [readme] add usage of filter option for injecting custom serialization, i.e. of custom types (#447) [meta] remove extraneous code backticks (#457) [meta] fix changelog markdown [actions] update checkout action [actions] restrict action permissions [Dev Deps] update @ljharb/eslint-config, aud, object-inspect, tape 6.11.0 [New] [Fix] stringify: revert 0e903c0; add commaRoundTrip option (#442) [readme] fix version badge 6.10.5 [Fix] stringify: with arrayFormat: comma, properly include an explicit [] on a single-item array (#434) 6.10.4 [Fix] stringify: with arrayFormat: comma, include an explicit [] on a single-item array (#441) [meta] use npmignore to autogenerate an npmignore file [Dev Deps] update eslint, @ljharb/eslint-config, aud, has-symbol, object-inspect, tape 6.10.3 [Fix] parse: ignore __proto__ keys (#428) [Robustness] stringify: avoid relying on a global undefined (#427) [actions] reuse common workflows [Dev Deps] update eslint, @ljharb/eslint-config, object-inspect, tape 6.10.2 [Fix] stringify: actually fix cyclic references (#426) [Fix] stringify: avoid encoding arrayformat comma when encodeValuesOnly = true (#424) [readme] remove travis badge; add github actions/codecov badges; update URLs [Docs] add note and links for coercing primitive values (#408) [actions] update codecov uploader [actions] update workflows [Tests] clean up stringify tests slightly [Dev Deps] update eslint, @ljharb/eslint-config, aud, object-inspect, safe-publish-latest, tape 6.10.1 [Fix] stringify: avoid exception on repeated object values (#402) 6.10.0 [New] stringify: throw on cycles, instead of an infinite loop (#395, #394, #393) [New] parse: add allowSparse option for collapsing arrays with missing indices (#312) [meta] fix README.md (#399) [meta] only run npm run dist in publish, not install [Dev Deps] update eslint, @ljharb/eslint-config, aud, has-symbols, tape [Tests] fix tests on node v0.6 [Tests] use ljharb/actions/node/install instead of ljharb/actions/node/run [Tests] Revert \"[meta] ignore eclint transitive audit warning\" 6.9.7 [Fix] parse: ignore __proto__ keys (#428) [Fix] stringify: avoid encoding arrayformat comma when encodeValuesOnly = true (#424) [Robustness] stringify: avoid relying on a global undefined (#427) [readme] remove travis badge; add github actions/codecov badges; update URLs [Docs] add note and links for coercing primitive values (#408) [Tests] clean up stringify tests slightly [meta] fix README.md (#399) Revert \"[meta] ignore eclint transitive audit warning\" [actions] backport actions from main [Dev Deps] backport updates from main 6.9.6 [Fix] restore dist dir; mistakenly removed in d4f6c32 6.9.5 [Fix] stringify: do not encode parens for RFC1738 [Fix] stringify: fix arrayFormat comma with empty array/objects (#350) [Refactor] format: remove util.assign call [meta] add \"Allow Edits\" workflow; update rebase workflow [actions] switch Automatic Rebase workflow to pull_request_target event [Tests] stringify: add tests for #378 [Tests] migrate tests to Github Actions [Tests] run nyc on all tests; use tape runner [Dev Deps] update eslint, @ljharb/eslint-config, browserify, mkdirp, object-inspect, tape; add aud 6.9.4 [Fix] stringify: when arrayFormat is comma, respect serializeDate (#364) [Refactor] stringify: reduce branching (part of #350) [Refactor] move maybeMap to utils [Dev Deps] update browserify, tape 6.9.3 [Fix] proper comma parsing of URL-encoded commas (#361) [Fix] parses comma delimited array while having percent-encoded comma treated as normal text (#336) 6.9.2 [Fix] parse: Fix parsing array from object with comma true (#359) [Fix] parse: throw a TypeError instead of an Error for bad charset (#349) [meta] ignore eclint transitive audit warning [meta] fix indentation in package.json [meta] add tidelift marketing copy [Dev Deps] update eslint, @ljharb/eslint-config, object-inspect, has-symbols, tape, mkdirp, iconv-lite [actions] add automatic rebasing / merge commit blocking 6.9.1 [Fix] parse: with comma true, handle field that holds an array of arrays (#335) [Fix] parse: with comma true, do not split non-string values (#334) [meta] add funding field [Dev Deps] update eslint, @ljharb/eslint-config [Tests] use shared travis-ci config 6.9.0 [New] parse/stringify: Pass extra key/value argument to decoder (#333) [Dev Deps] update eslint, @ljharb/eslint-config, evalmd [Tests] parse: add passing arrayFormat tests [Tests] add posttest using npx aud to run npm audit without a lockfile [Tests] up to node v12.10, v11.15, v10.16, v8.16 [Tests] Buffer.from in node v5.0-v5.9 and v4.0-v4.4 requires a TypedArray 6.8.3 [Fix] parse: ignore __proto__ keys (#428) [Robustness] stringify: avoid relying on a global undefined (#427) [Fix] stringify: avoid encoding arrayformat comma when encodeValuesOnly = true (#424) [readme] remove travis badge; add github actions/codecov badges; update URLs [Tests] clean up stringify tests slightly [Docs] add note and links for coercing primitive values (#408) [meta] fix README.md (#399) [actions] backport actions from main [Dev Deps] backport updates from main [Refactor] stringify: reduce branching [meta] do not publish workflow files 6.8.2 [Fix] proper comma parsing of URL-encoded commas (#361) [Fix] parses comma delimited array while having percent-encoded comma treated as normal text (#336) 6.8.1 [Fix] parse: Fix parsing array from object with comma true (#359) [Fix] parse: throw a TypeError instead of an Error for bad charset (#349) [Fix] parse: with comma true, handle field that holds an array of arrays (#335) [fix] parse: with comma true, do not split non-string values (#334) [meta] add tidelift marketing copy [meta] add funding field [Dev Deps] update eslint, @ljharb/eslint-config, tape, safe-publish-latest, evalmd, has-symbols, iconv-lite, mkdirp, object-inspect [Tests] parse: add passing arrayFormat tests [Tests] use shared travis-ci configs [Tests] Buffer.from in node v5.0-v5.9 and v4.0-v4.4 requires a TypedArray [actions] add automatic rebasing / merge commit blocking 6.8.0 [New] add depth=false to preserve the original key; [Fix] depth=0 should preserve the original key (#326) [New] [Fix] stringify symbols and bigints [Fix] ensure node 0.12 can stringify Symbols [Fix] fix for an impossible situation: when the formatter is called with a non-string value [Refactor] formats: tiny bit of cleanup. [Dev Deps] update eslint, @ljharb/eslint-config, browserify, safe-publish-latest, iconv-lite, tape [Tests] add tests for depth=0 and depth=false behavior, both current and intuitive/intended (#326) [Tests] use eclint instead of editorconfig-tools [docs] readme: add security note [meta] add github sponsorship [meta] add FUNDING.yml [meta] Clean up license text so it’s properly detected as BSD-3-Clause 6.7.3 [Fix] parse: ignore __proto__ keys (#428) [Fix] stringify: avoid encoding arrayformat comma when encodeValuesOnly = true (#424) [Robustness] stringify: avoid relying on a global undefined (#427) [readme] remove travis badge; add github actions/codecov badges; update URLs [Docs] add note and links for coercing primitive values (#408) [meta] fix README.md (#399) [meta] do not publish workflow files [actions] backport actions from main [Dev Deps] backport updates from main [Tests] use nyc for coverage [Tests] clean up stringify tests slightly 6.7.2 [Fix] proper comma parsing of URL-encoded commas (#361) [Fix] parses comma delimited array while having percent-encoded comma treated as normal text (#336) 6.7.1 [Fix] parse: Fix parsing array from object with comma true (#359) [Fix] parse: with comma true, handle field that holds an array of arrays (#335) [fix] parse: with comma true, do not split non-string values (#334) [Fix] parse: throw a TypeError instead of an Error for bad charset (#349) [Fix] fix for an impossible situation: when the formatter is called with a non-string value [Refactor] formats: tiny bit of cleanup. readme: add security note [meta] add tidelift marketing copy [meta] add funding field [meta] add FUNDING.yml [meta] Clean up license text so it’s properly detected as BSD-3-Clause [Dev Deps] update eslint, @ljharb/eslint-config, tape, safe-publish-latest, evalmd, iconv-lite, mkdirp, object-inspect, browserify [Tests] parse: add passing arrayFormat tests [Tests] use shared travis-ci configs [Tests] Buffer.from in node v5.0-v5.9 and v4.0-v4.4 requires a TypedArray [Tests] add tests for depth=0 and depth=false behavior, both current and intuitive/intended [Tests] use eclint instead of editorconfig-tools [actions] add automatic rebasing / merge commit blocking 6.7.0 [New] stringify/parse: add comma as an arrayFormat option (#276, #219) [Fix] correctly parse nested arrays (#212) [Fix] utils.merge: avoid a crash with a null target and a truthy non-array source, also with an array source [Robustness] stringify: cache Object.prototype.hasOwnProperty [Refactor] utils: isBuffer: small tweak; add tests [Refactor] use cached Array.isArray [Refactor] parse/stringify: make a function to normalize the options [Refactor] utils: reduce observable [[Get]]s [Refactor] stringify/utils: cache Array.isArray [Tests] always use String(x) over x.toString() [Tests] fix Buffer tests to work in node < 4.5 and node < 5.10 [Tests] temporarily allow coverage to fail 6.6.1 [Fix] parse: ignore __proto__ keys (#428) [Fix] fix for an impossible situation: when the formatter is called with a non-string value [Fix] utils.merge: avoid a crash with a null target and an array source [Fix] utils.merge: avoid a crash with a null target and a truthy non-array source [Fix] correctly parse nested arrays [Robustness] stringify: avoid relying on a global undefined (#427) [Robustness] stringify: cache Object.prototype.hasOwnProperty [Refactor] formats: tiny bit of cleanup. [Refactor] utils: isBuffer: small tweak; add tests [Refactor]: stringify/utils: cache Array.isArray [Refactor] utils: reduce observable [[Get]]s [Refactor] use cached Array.isArray [Refactor] parse/stringify: make a function to normalize the options [readme] remove travis badge; add github actions/codecov badges; update URLs [Docs] Clarify the need for \"arrayLimit\" option [meta] fix README.md (#399) [meta] do not publish workflow files [meta] Clean up license text so it’s properly detected as BSD-3-Clause [meta] add FUNDING.yml [meta] Fixes typo in CHANGELOG.md [actions] backport actions from main [Tests] fix Buffer tests to work in node < 4.5 and node < 5.10 [Tests] always use String(x) over x.toString() [Dev Deps] backport from main 6.6.0 [New] Add support for iso-8859-1, utf8 \"sentinel\" and numeric entities (#268) [New] move two-value combine to a utils function (#189) [Fix] stringify: fix a crash with strictNullHandling and a custom filter/serializeDate (#279) [Fix] when parseArrays is false, properly handle keys ending in [] (#260) [Fix] stringify: do not crash in an obscure combo of interpretNumericEntities, a bad custom decoder, & iso-8859-1 [Fix] utils: merge: fix crash when source is a truthy primitive & no options are provided [refactor] stringify: Avoid arr = arr.concat(...), push to the existing instance (#269) [Refactor] parse: only need to reassign the var once [Refactor] parse/stringify: clean up charset options checking; fix defaults [Refactor] add missing defaults [Refactor] parse: one less concat call [Refactor] utils: compactQueue: make it explicitly side-effecting [Dev Deps] update browserify, eslint, @ljharb/eslint-config, iconv-lite, safe-publish-latest, tape [Tests] up to node v10.10, v9.11, v8.12, v6.14, v4.9; pin included builds to LTS 6.5.3 [Fix] parse: ignore __proto__ keys (#428) [Fix] utils.merge: avoid a crash with a null target and a truthy non-array source [Fix] correctly parse nested arrays [Fix] stringify: fix a crash with strictNullHandling and a custom filter/serializeDate (#279) [Fix] utils: merge: fix crash when source is a truthy primitive & no options are provided [Fix] when parseArrays is false, properly handle keys ending in [] [Fix] fix for an impossible situation: when the formatter is called with a non-string value [Fix] utils.merge: avoid a crash with a null target and an array source [Refactor] utils: reduce observable [[Get]]s [Refactor] use cached Array.isArray [Refactor] stringify: Avoid arr = arr.concat(...), push to the existing instance (#269) [Refactor] parse: only need to reassign the var once [Robustness] stringify: avoid relying on a global undefined (#427) [readme] remove travis badge; add github actions/codecov badges; update URLs [Docs] Clean up license text so it’s properly detected as BSD-3-Clause [Docs] Clarify the need for \"arrayLimit\" option [meta] fix README.md (#399) [meta] add FUNDING.yml [actions] backport actions from main [Tests] always use String(x) over x.toString() [Tests] remove nonexistent tape option [Dev Deps] backport from main 6.5.2 [Fix] use safer-buffer instead of Buffer constructor [Refactor] utils: module.exports one thing, instead of mutating exports (#230) [Dev Deps] update browserify, eslint, iconv-lite, safer-buffer, tape, browserify 6.5.1 [Fix] Fix parsing & compacting very deep objects (#224) [Refactor] name utils functions [Dev Deps] update eslint, @ljharb/eslint-config, tape [Tests] up to node v8.4; use nvm install-latest-npm so newer npm doesn’t break older node [Tests] Use precise dist for Node.js 0.6 runtime (#225) [Tests] make 0.6 required, now that it’s passing [Tests] on node v8.2; fix npm on node 0.6 6.5.0 [New] add utils.assign [New] pass default encoder/decoder to custom encoder/decoder functions (#206) [New] parse/stringify: add ignoreQueryPrefix/addQueryPrefix options, respectively (#213) [Fix] Handle stringifying empty objects with addQueryPrefix (#217) [Fix] do not mutate options argument (#207) [Refactor] parse: cache index to reuse in else statement (#182) [Docs] add various badges to readme (#208) [Dev Deps] update eslint, browserify, iconv-lite, tape [Tests] up to node v8.1, v7.10, v6.11; npm v4.6 breaks on node < v1; npm v5+ breaks on node < v4 [Tests] add editorconfig-tools 6.4.1 [Fix] parse: ignore __proto__ keys (#428) [Fix] fix for an impossible situation: when the formatter is called with a non-string value [Fix] use safer-buffer instead of Buffer constructor [Fix] utils.merge: avoid a crash with a null target and an array source [Fix] utils.merge: avoid a crash with a null target and a truthy non-array source [Fix] stringify: fix a crash with strictNullHandling and a custom filter/serializeDate (#279) [Fix] utils: merge: fix crash when source is a truthy primitive & no options are provided [Fix] when parseArrays is false, properly handle keys ending in [] [Robustness] stringify: avoid relying on a global undefined (#427) [Refactor] use cached Array.isArray [Refactor] stringify: Avoid arr = arr.concat(...), push to the existing instance (#269) [readme] remove travis badge; add github actions/codecov badges; update URLs [Docs] Clarify the need for \"arrayLimit\" option [meta] fix README.md (#399) [meta] Clean up license text so it’s properly detected as BSD-3-Clause [meta] add FUNDING.yml [actions] backport actions from main [Tests] remove nonexistent tape option [Dev Deps] backport from main 6.4.0 [New] qs.stringify: add encodeValuesOnly option [Fix] follow allowPrototypes option during merge (#201, #201) [Fix] support keys starting with brackets (#202, #200) [Fix] chmod a-x [Dev Deps] update eslint [Tests] up to node v7.7, v6.10, v4.8; disable osx builds since they block linux builds [eslint] reduce warnings 6.3.3 [Fix] parse: ignore __proto__ keys (#428) [Fix] fix for an impossible situation: when the formatter is called with a non-string value [Fix] utils.merge: avoid a crash with a null target and an array source [Fix] utils.merge: avoid a crash with a null target and a truthy non-array source [Fix] stringify: fix a crash with strictNullHandling and a custom filter/serializeDate (#279) [Fix] utils: merge: fix crash when source is a truthy primitive & no options are provided [Fix] when parseArrays is false, properly handle keys ending in [] [Robustness] stringify: avoid relying on a global undefined (#427) [Refactor] use cached Array.isArray [Refactor] stringify: Avoid arr = arr.concat(...), push to the existing instance (#269) [Docs] Clarify the need for \"arrayLimit\" option [meta] fix README.md (#399) [meta] Clean up license text so it’s properly detected as BSD-3-Clause [meta] add FUNDING.yml [actions] backport actions from main [Tests] use safer-buffer instead of Buffer constructor [Tests] remove nonexistent tape option [Dev Deps] backport from main 6.3.2 [Fix] follow allowPrototypes option during merge (#201, #200) [Dev Deps] update eslint [Fix] chmod a-x [Fix] support keys starting with brackets (#202, #200) [Tests] up to node v7.7, v6.10, v4.8; disable osx builds since they block linux builds 6.3.1 [Fix] ensure that allowPrototypes: false does not ever shadow Object.prototype properties (thanks, @snyk!) [Dev Deps] update eslint, @ljharb/eslint-config, browserify, iconv-lite, qs-iconv, tape [Tests] on all node minors; improve test matrix [Docs] document stringify option allowDots (#195) [Docs] add empty object and array values example (#195) [Docs] Fix minor inconsistency/typo (#192) [Docs] document stringify option sort (#191) [Refactor] stringify: throw faster with an invalid encoder [Refactor] remove unnecessary escapes (#184) Remove contributing.md, since qs is no longer part of hapi (#183) 6.3.0 [New] Add support for RFC 1738 (#174, #173) [New] stringify: Add serializeDate option to customize Date serialization (#159) [Fix] ensure utils.merge handles merging two arrays [Refactor] only constructors should be capitalized [Refactor] capitalized var names are for constructors only [Refactor] avoid using a sparse array [Robustness] formats: cache String#replace [Dev Deps] update browserify, eslint, @ljharb/eslint-config; add safe-publish-latest [Tests] up to node v6.8, v4.6; improve test matrix [Tests] flesh out arrayLimit/arrayFormat tests (#107) [Tests] skip Object.create tests when null objects are not available [Tests] Turn on eslint for test files (#175) 6.2.4 [Fix] parse: ignore __proto__ keys (#428) [Fix] utils.merge: avoid a crash with a null target and an array source [Fix] utils.merge: avoid a crash with a null target and a truthy non-array source [Fix] utils: merge: fix crash when source is a truthy primitive & no options are provided [Fix] when parseArrays is false, properly handle keys ending in [] [Robustness] stringify: avoid relying on a global undefined (#427) [Refactor] use cached Array.isArray [Docs] Clarify the need for \"arrayLimit\" option [meta] fix README.md (#399) [meta] Clean up license text so it’s properly detected as BSD-3-Clause [meta] add FUNDING.yml [actions] backport actions from main [Tests] use safer-buffer instead of Buffer constructor [Tests] remove nonexistent tape option [Dev Deps] backport from main 6.2.3 [Fix] follow allowPrototypes option during merge (#201, #200) [Fix] chmod a-x [Fix] support keys starting with brackets (#202, #200) [Tests] up to node v7.7, v6.10, v4.8; disable osx builds since they block linux builds 6.2.2 [Fix] ensure that allowPrototypes: false does not ever shadow Object.prototype properties 6.2.1 [Fix] ensure key[]=x&key[]&key[]=y results in 3, not 2, values [Refactor] Be explicit and use Object.prototype.hasOwnProperty.call [Tests] remove parallelshell since it does not reliably report failures [Tests] up to node v6.3, v5.12 [Dev Deps] update tape, eslint, @ljharb/eslint-config, qs-iconv 6.2.0 [New] pass Buffers to the encoder/decoder directly (#161) [New] add \"encoder\" and \"decoder\" options, for custom param encoding/decoding (#160) [Fix] fix compacting of nested sparse arrays (#150) 6.1.2 [Fix] follow allowPrototypes option during merge (#201, #200) [Fix] chmod a-x [Fix] support keys starting with brackets (#202, #200) [Tests] up to node v7.7, v6.10, v4.8; disable osx builds since they block linux builds 6.1.1 [Fix] ensure that allowPrototypes: false does not ever shadow Object.prototype properties 6.1.0 [New] allowDots option for stringify (#151) [Fix] \"sort\" option should work at a depth of 3 or more (#151) [Fix] Restore dist directory; will be removed in v7 (#148) 6.0.4 [Fix] follow allowPrototypes option during merge (#201, #200) [Fix] chmod a-x [Fix] support keys starting with brackets (#202, #200) [Tests] up to node v7.7, v6.10, v4.8; disable osx builds since they block linux builds 6.0.3 [Fix] ensure that allowPrototypes: false does not ever shadow Object.prototype properties [Fix] Restore dist directory; will be removed in v7 (#148) 6.0.2 Revert ES6 requirement and restore support for node down to v0.8. 6.0.1 #127 Fix engines definition in package.json 6.0.0 #124 Use ES6 and drop support for node < v4 5.2.1 [Fix] ensure key[]=x&key[]&key[]=y results in 3, not 2, values 5.2.0 #64 Add option to sort object keys in the query string 5.1.0 #117 make URI encoding stringified results optional #106 Add flag skipNulls to optionally skip null values in stringify 5.0.0 #114 default allowDots to false #100 include dist to npm 4.0.0 #98 make returning plain objects and allowing prototype overwriting properties optional 3.1.0 #89 Add option to disable \"Transform dot notation to bracket notation\" 3.0.0 #80 qs.parse silently drops properties #77 Perf boost #60 Add explicit option to disable array parsing #74 Bad parse when turning array into object #81 Add a filter option #68 Fixed issue with recursion and passing strings into objects. #66 Add mixed array and object dot notation support Closes: #47 #76 RFC 3986 #85 No equal sign #84 update license attribute 2.4.1 #73 Property 'hasOwnProperty' of object # is not a function 2.4.0 #70 Add arrayFormat option 2.3.3 #59 make sure array indexes are >= 0, closes #57 #58 make qs usable for browser loader 2.3.2 #55 allow merging a string into an object 2.3.1 #52 Return \"undefined\" and \"false\" instead of throwing \"TypeError\". 2.3.0 #50 add option to omit array indices, closes #46 2.2.5 #39 Is there an alternative to Buffer.isBuffer? #49 refactor utils.merge, fixes #45 #41 avoid browserifying Buffer, for #39 2.2.4 #38 how to handle object keys beginning with a number 2.2.3 #37 parser discards first empty value in array #36 Update to lab 4.x 2.2.2 #33 Error when plain object in a value #34 use Object.prototype.hasOwnProperty.call instead of obj.hasOwnProperty #24 Changelog? Semver? 2.2.1 #32 account for circular references properly, closes #31 #31 qs.parse stackoverflow on circular objects 2.2.0 #26 Don't use Buffer global if it's not present #30 Bug when merging non-object values into arrays #29 Don't call Utils.clone at the top of Utils.merge #23 Ability to not limit parameters? 2.1.0 #22 Enable using a RegExp as delimiter 2.0.0 #18 Why is there arrayLimit? #20 Configurable parametersLimit #21 make all limits optional, for #18, for #20 1.2.2 #19 Don't overwrite null values 1.2.1 #16 ignore non-string delimiters #15 Close code block 1.2.0 #12 Add optional delim argument #13 fix #11: flattened keys in array are now correctly parsed 1.1.0 #7 Empty values of a POST array disappear after being submitted #9 Should not omit equals signs (=) when value is null #6 Minor grammar fix in README 1.0.2 #5 array holes incorrectly copied into object on large index"
  },
  "src/frontend/app-client/node_modules/qs/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/qs/LICENSE.html",
    "title": "",
    "summary": "BSD 3-Clause License Copyright (c) 2014, Nathan LaFreniere and other contributors All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  "src/frontend/app-client/node_modules/qs/README.html": {
    "href": "src/frontend/app-client/node_modules/qs/README.html",
    "title": "qs",
    "summary": "qs A querystring parsing and stringifying library with some added security. Lead Maintainer: Jordan Harband The qs module was originally created and maintained by TJ Holowaychuk. Usage var qs = require('qs'); var assert = require('assert'); var obj = qs.parse('a=c'); assert.deepEqual(obj, { a: 'c' }); var str = qs.stringify(obj); assert.equal(str, 'a=c'); Parsing Objects qs.parse(string, [options]); qs allows you to create nested objects within your query strings, by surrounding the name of sub-keys with square brackets []. For example, the string 'foo[bar]=baz' converts to: assert.deepEqual(qs.parse('foo[bar]=baz'), { foo: { bar: 'baz' } }); When using the plainObjects option the parsed value is returned as a null object, created via Object.create(null) and as such you should be aware that prototype methods will not exist on it and a user may set those names to whatever value they like: var nullObject = qs.parse('a[hasOwnProperty]=b', { plainObjects: true }); assert.deepEqual(nullObject, { a: { hasOwnProperty: 'b' } }); By default parameters that would overwrite properties on the object prototype are ignored, if you wish to keep the data from those fields either use plainObjects as mentioned above, or set allowPrototypes to true which will allow user input to overwrite those properties. WARNING It is generally a bad idea to enable this option as it can cause problems when attempting to use the properties that have been overwritten. Always be careful with this option. var protoObject = qs.parse('a[hasOwnProperty]=b', { allowPrototypes: true }); assert.deepEqual(protoObject, { a: { hasOwnProperty: 'b' } }); URI encoded strings work too: assert.deepEqual(qs.parse('a%5Bb%5D=c'), { a: { b: 'c' } }); You can also nest your objects, like 'foo[bar][baz]=foobarbaz': assert.deepEqual(qs.parse('foo[bar][baz]=foobarbaz'), { foo: { bar: { baz: 'foobarbaz' } } }); By default, when nesting objects qs will only parse up to 5 children deep. This means if you attempt to parse a string like 'a[b][c][d][e][f][g][h][i]=j' your resulting object will be: var expected = { a: { b: { c: { d: { e: { f: { '[g][h][i]': 'j' } } } } } } }; var string = 'a[b][c][d][e][f][g][h][i]=j'; assert.deepEqual(qs.parse(string), expected); This depth can be overridden by passing a depth option to qs.parse(string, [options]): var deep = qs.parse('a[b][c][d][e][f][g][h][i]=j', { depth: 1 }); assert.deepEqual(deep, { a: { b: { '[c][d][e][f][g][h][i]': 'j' } } }); You can configure qs to throw an error when parsing nested input beyond this depth using the strictDepth option (defaulted to false): try { qs.parse('a[b][c][d][e][f][g][h][i]=j', { depth: 1, strictDepth: true }); } catch (err) { assert(err instanceof RangeError); assert.strictEqual(err.message, 'Input depth exceeded depth option of 1 and strictDepth is true'); } The depth limit helps mitigate abuse when qs is used to parse user input, and it is recommended to keep it a reasonably small number. The strictDepth option adds a layer of protection by throwing an error when the limit is exceeded, allowing you to catch and handle such cases. For similar reasons, by default qs will only parse up to 1000 parameters. This can be overridden by passing a parameterLimit option: var limited = qs.parse('a=b&c=d', { parameterLimit: 1 }); assert.deepEqual(limited, { a: 'b' }); To bypass the leading question mark, use ignoreQueryPrefix: var prefixed = qs.parse('?a=b&c=d', { ignoreQueryPrefix: true }); assert.deepEqual(prefixed, { a: 'b', c: 'd' }); An optional delimiter can also be passed: var delimited = qs.parse('a=b;c=d', { delimiter: ';' }); assert.deepEqual(delimited, { a: 'b', c: 'd' }); Delimiters can be a regular expression too: var regexed = qs.parse('a=b;c=d,e=f', { delimiter: /[;,]/ }); assert.deepEqual(regexed, { a: 'b', c: 'd', e: 'f' }); Option allowDots can be used to enable dot notation: var withDots = qs.parse('a.b=c', { allowDots: true }); assert.deepEqual(withDots, { a: { b: 'c' } }); Option decodeDotInKeys can be used to decode dots in keys Note: it implies allowDots, so parse will error if you set decodeDotInKeys to true, and allowDots to false. var withDots = qs.parse('name%252Eobj.first=John&name%252Eobj.last=Doe', { decodeDotInKeys: true }); assert.deepEqual(withDots, { 'name.obj': { first: 'John', last: 'Doe' }}); Option allowEmptyArrays can be used to allowing empty array values in object var withEmptyArrays = qs.parse('foo[]&bar=baz', { allowEmptyArrays: true }); assert.deepEqual(withEmptyArrays, { foo: [], bar: 'baz' }); Option duplicates can be used to change the behavior when duplicate keys are encountered assert.deepEqual(qs.parse('foo=bar&foo=baz'), { foo: ['bar', 'baz'] }); assert.deepEqual(qs.parse('foo=bar&foo=baz', { duplicates: 'combine' }), { foo: ['bar', 'baz'] }); assert.deepEqual(qs.parse('foo=bar&foo=baz', { duplicates: 'first' }), { foo: 'bar' }); assert.deepEqual(qs.parse('foo=bar&foo=baz', { duplicates: 'last' }), { foo: 'baz' }); If you have to deal with legacy browsers or services, there's also support for decoding percent-encoded octets as iso-8859-1: var oldCharset = qs.parse('a=%A7', { charset: 'iso-8859-1' }); assert.deepEqual(oldCharset, { a: '§' }); Some services add an initial utf8=✓ value to forms so that old Internet Explorer versions are more likely to submit the form as utf-8. Additionally, the server can check the value against wrong encodings of the checkmark character and detect that a query string or application/x-www-form-urlencoded body was not sent as utf-8, eg. if the form had an accept-charset parameter or the containing page had a different character set. qs supports this mechanism via the charsetSentinel option. If specified, the utf8 parameter will be omitted from the returned object. It will be used to switch to iso-8859-1/utf-8 mode depending on how the checkmark is encoded. Important: When you specify both the charset option and the charsetSentinel option, the charset will be overridden when the request contains a utf8 parameter from which the actual charset can be deduced. In that sense the charset will behave as the default charset rather than the authoritative charset. var detectedAsUtf8 = qs.parse('utf8=%E2%9C%93&a=%C3%B8', { charset: 'iso-8859-1', charsetSentinel: true }); assert.deepEqual(detectedAsUtf8, { a: 'ø' }); // Browsers encode the checkmark as &#10003; when submitting as iso-8859-1: var detectedAsIso8859_1 = qs.parse('utf8=%26%2310003%3B&a=%F8', { charset: 'utf-8', charsetSentinel: true }); assert.deepEqual(detectedAsIso8859_1, { a: 'ø' }); If you want to decode the &#...; syntax to the actual character, you can specify the interpretNumericEntities option as well: var detectedAsIso8859_1 = qs.parse('a=%26%239786%3B', { charset: 'iso-8859-1', interpretNumericEntities: true }); assert.deepEqual(detectedAsIso8859_1, { a: '☺' }); It also works when the charset has been detected in charsetSentinel mode. Parsing Arrays qs can also parse arrays using a similar [] notation: var withArray = qs.parse('a[]=b&a[]=c'); assert.deepEqual(withArray, { a: ['b', 'c'] }); You may specify an index as well: var withIndexes = qs.parse('a[1]=c&a[0]=b'); assert.deepEqual(withIndexes, { a: ['b', 'c'] }); Note that the only difference between an index in an array and a key in an object is that the value between the brackets must be a number to create an array. When creating arrays with specific indices, qs will compact a sparse array to only the existing values preserving their order: var noSparse = qs.parse('a[1]=b&a[15]=c'); assert.deepEqual(noSparse, { a: ['b', 'c'] }); You may also use allowSparse option to parse sparse arrays: var sparseArray = qs.parse('a[1]=2&a[3]=5', { allowSparse: true }); assert.deepEqual(sparseArray, { a: [, '2', , '5'] }); Note that an empty string is also a value, and will be preserved: var withEmptyString = qs.parse('a[]=&a[]=b'); assert.deepEqual(withEmptyString, { a: ['', 'b'] }); var withIndexedEmptyString = qs.parse('a[0]=b&a[1]=&a[2]=c'); assert.deepEqual(withIndexedEmptyString, { a: ['b', '', 'c'] }); qs will also limit specifying indices in an array to a maximum index of 20. Any array members with an index of greater than 20 will instead be converted to an object with the index as the key. This is needed to handle cases when someone sent, for example, a[999999999] and it will take significant time to iterate over this huge array. var withMaxIndex = qs.parse('a[100]=b'); assert.deepEqual(withMaxIndex, { a: { '100': 'b' } }); This limit can be overridden by passing an arrayLimit option: var withArrayLimit = qs.parse('a[1]=b', { arrayLimit: 0 }); assert.deepEqual(withArrayLimit, { a: { '1': 'b' } }); To disable array parsing entirely, set parseArrays to false. var noParsingArrays = qs.parse('a[]=b', { parseArrays: false }); assert.deepEqual(noParsingArrays, { a: { '0': 'b' } }); If you mix notations, qs will merge the two items into an object: var mixedNotation = qs.parse('a[0]=b&a[b]=c'); assert.deepEqual(mixedNotation, { a: { '0': 'b', b: 'c' } }); You can also create arrays of objects: var arraysOfObjects = qs.parse('a[][b]=c'); assert.deepEqual(arraysOfObjects, { a: [{ b: 'c' }] }); Some people use comma to join array, qs can parse it: var arraysOfObjects = qs.parse('a=b,c', { comma: true }) assert.deepEqual(arraysOfObjects, { a: ['b', 'c'] }) (this cannot convert nested objects, such as a={b:1},{c:d}) Parsing primitive/scalar values (numbers, booleans, null, etc) By default, all values are parsed as strings. This behavior will not change and is explained in issue #91. var primitiveValues = qs.parse('a=15&b=true&c=null'); assert.deepEqual(primitiveValues, { a: '15', b: 'true', c: 'null' }); If you wish to auto-convert values which look like numbers, booleans, and other values into their primitive counterparts, you can use the query-types Express JS middleware which will auto-convert all request query parameters. Stringifying qs.stringify(object, [options]); When stringifying, qs by default URI encodes output. Objects are stringified as you would expect: assert.equal(qs.stringify({ a: 'b' }), 'a=b'); assert.equal(qs.stringify({ a: { b: 'c' } }), 'a%5Bb%5D=c'); This encoding can be disabled by setting the encode option to false: var unencoded = qs.stringify({ a: { b: 'c' } }, { encode: false }); assert.equal(unencoded, 'a[b]=c'); Encoding can be disabled for keys by setting the encodeValuesOnly option to true: var encodedValues = qs.stringify( { a: 'b', c: ['d', 'e=f'], f: [['g'], ['h']] }, { encodeValuesOnly: true } ); assert.equal(encodedValues,'a=b&c[0]=d&c[1]=e%3Df&f[0][0]=g&f[1][0]=h'); This encoding can also be replaced by a custom encoding method set as encoder option: var encoded = qs.stringify({ a: { b: 'c' } }, { encoder: function (str) { // Passed in values `a`, `b`, `c` return // Return encoded string }}) (Note: the encoder option does not apply if encode is false) Analogue to the encoder there is a decoder option for parse to override decoding of properties and values: var decoded = qs.parse('x=z', { decoder: function (str) { // Passed in values `x`, `z` return // Return decoded string }}) You can encode keys and values using different logic by using the type argument provided to the encoder: var encoded = qs.stringify({ a: { b: 'c' } }, { encoder: function (str, defaultEncoder, charset, type) { if (type === 'key') { return // Encoded key } else if (type === 'value') { return // Encoded value } }}) The type argument is also provided to the decoder: var decoded = qs.parse('x=z', { decoder: function (str, defaultDecoder, charset, type) { if (type === 'key') { return // Decoded key } else if (type === 'value') { return // Decoded value } }}) Examples beyond this point will be shown as though the output is not URI encoded for clarity. Please note that the return values in these cases will be URI encoded during real usage. When arrays are stringified, they follow the arrayFormat option, which defaults to indices: qs.stringify({ a: ['b', 'c', 'd'] }); // 'a[0]=b&a[1]=c&a[2]=d' You may override this by setting the indices option to false, or to be more explicit, the arrayFormat option to repeat: qs.stringify({ a: ['b', 'c', 'd'] }, { indices: false }); // 'a=b&a=c&a=d' You may use the arrayFormat option to specify the format of the output array: qs.stringify({ a: ['b', 'c'] }, { arrayFormat: 'indices' }) // 'a[0]=b&a[1]=c' qs.stringify({ a: ['b', 'c'] }, { arrayFormat: 'brackets' }) // 'a[]=b&a[]=c' qs.stringify({ a: ['b', 'c'] }, { arrayFormat: 'repeat' }) // 'a=b&a=c' qs.stringify({ a: ['b', 'c'] }, { arrayFormat: 'comma' }) // 'a=b,c' Note: when using arrayFormat set to 'comma', you can also pass the commaRoundTrip option set to true or false, to append [] on single-item arrays, so that they can round trip through a parse. When objects are stringified, by default they use bracket notation: qs.stringify({ a: { b: { c: 'd', e: 'f' } } }); // 'a[b][c]=d&a[b][e]=f' You may override this to use dot notation by setting the allowDots option to true: qs.stringify({ a: { b: { c: 'd', e: 'f' } } }, { allowDots: true }); // 'a.b.c=d&a.b.e=f' You may encode the dot notation in the keys of object with option encodeDotInKeys by setting it to true: Note: it implies allowDots, so stringify will error if you set decodeDotInKeys to true, and allowDots to false. Caveat: when encodeValuesOnly is true as well as encodeDotInKeys, only dots in keys and nothing else will be encoded. qs.stringify({ \"name.obj\": { \"first\": \"John\", \"last\": \"Doe\" } }, { allowDots: true, encodeDotInKeys: true }) // 'name%252Eobj.first=John&name%252Eobj.last=Doe' You may allow empty array values by setting the allowEmptyArrays option to true: qs.stringify({ foo: [], bar: 'baz' }, { allowEmptyArrays: true }); // 'foo[]&bar=baz' Empty strings and null values will omit the value, but the equals sign (=) remains in place: assert.equal(qs.stringify({ a: '' }), 'a='); Key with no values (such as an empty object or array) will return nothing: assert.equal(qs.stringify({ a: [] }), ''); assert.equal(qs.stringify({ a: {} }), ''); assert.equal(qs.stringify({ a: [{}] }), ''); assert.equal(qs.stringify({ a: { b: []} }), ''); assert.equal(qs.stringify({ a: { b: {}} }), ''); Properties that are set to undefined will be omitted entirely: assert.equal(qs.stringify({ a: null, b: undefined }), 'a='); The query string may optionally be prepended with a question mark: assert.equal(qs.stringify({ a: 'b', c: 'd' }, { addQueryPrefix: true }), '?a=b&c=d'); The delimiter may be overridden with stringify as well: assert.equal(qs.stringify({ a: 'b', c: 'd' }, { delimiter: ';' }), 'a=b;c=d'); If you only want to override the serialization of Date objects, you can provide a serializeDate option: var date = new Date(7); assert.equal(qs.stringify({ a: date }), 'a=1970-01-01T00:00:00.007Z'.replace(/:/g, '%3A')); assert.equal( qs.stringify({ a: date }, { serializeDate: function (d) { return d.getTime(); } }), 'a=7' ); You may use the sort option to affect the order of parameter keys: function alphabeticalSort(a, b) { return a.localeCompare(b); } assert.equal(qs.stringify({ a: 'c', z: 'y', b : 'f' }, { sort: alphabeticalSort }), 'a=c&b=f&z=y'); Finally, you can use the filter option to restrict which keys will be included in the stringified output. If you pass a function, it will be called for each key to obtain the replacement value. Otherwise, if you pass an array, it will be used to select properties and array indices for stringification: function filterFunc(prefix, value) { if (prefix == 'b') { // Return an `undefined` value to omit a property. return; } if (prefix == 'e[f]') { return value.getTime(); } if (prefix == 'e[g][0]') { return value * 2; } return value; } qs.stringify({ a: 'b', c: 'd', e: { f: new Date(123), g: [2] } }, { filter: filterFunc }); // 'a=b&c=d&e[f]=123&e[g][0]=4' qs.stringify({ a: 'b', c: 'd', e: 'f' }, { filter: ['a', 'e'] }); // 'a=b&e=f' qs.stringify({ a: ['b', 'c', 'd'], e: 'f' }, { filter: ['a', 0, 2] }); // 'a[0]=b&a[2]=d' You could also use filter to inject custom serialization for user defined types. Consider you're working with some api that expects query strings of the format for ranges: https://domain.com/endpoint?range=30...70 For which you model as: class Range { constructor(from, to) { this.from = from; this.to = to; } } You could inject a custom serializer to handle values of this type: qs.stringify( { range: new Range(30, 70), }, { filter: (prefix, value) => { if (value instanceof Range) { return `${value.from}...${value.to}`; } // serialize the usual way return value; }, } ); // range=30...70 Handling of null values By default, null values are treated like empty strings: var withNull = qs.stringify({ a: null, b: '' }); assert.equal(withNull, 'a=&b='); Parsing does not distinguish between parameters with and without equal signs. Both are converted to empty strings. var equalsInsensitive = qs.parse('a&b='); assert.deepEqual(equalsInsensitive, { a: '', b: '' }); To distinguish between null values and empty strings use the strictNullHandling flag. In the result string the null values have no = sign: var strictNull = qs.stringify({ a: null, b: '' }, { strictNullHandling: true }); assert.equal(strictNull, 'a&b='); To parse values without = back to null use the strictNullHandling flag: var parsedStrictNull = qs.parse('a&b=', { strictNullHandling: true }); assert.deepEqual(parsedStrictNull, { a: null, b: '' }); To completely skip rendering keys with null values, use the skipNulls flag: var nullsSkipped = qs.stringify({ a: 'b', c: null}, { skipNulls: true }); assert.equal(nullsSkipped, 'a=b'); If you're communicating with legacy systems, you can switch to iso-8859-1 using the charset option: var iso = qs.stringify({ æ: 'æ' }, { charset: 'iso-8859-1' }); assert.equal(iso, '%E6=%E6'); Characters that don't exist in iso-8859-1 will be converted to numeric entities, similar to what browsers do: var numeric = qs.stringify({ a: '☺' }, { charset: 'iso-8859-1' }); assert.equal(numeric, 'a=%26%239786%3B'); You can use the charsetSentinel option to announce the character by including an utf8=✓ parameter with the proper encoding if the checkmark, similar to what Ruby on Rails and others do when submitting forms. var sentinel = qs.stringify({ a: '☺' }, { charsetSentinel: true }); assert.equal(sentinel, 'utf8=%E2%9C%93&a=%E2%98%BA'); var isoSentinel = qs.stringify({ a: 'æ' }, { charsetSentinel: true, charset: 'iso-8859-1' }); assert.equal(isoSentinel, 'utf8=%26%2310003%3B&a=%E6'); Dealing with special character sets By default the encoding and decoding of characters is done in utf-8, and iso-8859-1 support is also built in via the charset parameter. If you wish to encode querystrings to a different character set (i.e. Shift JIS) you can use the qs-iconv library: var encoder = require('qs-iconv/encoder')('shift_jis'); var shiftJISEncoded = qs.stringify({ a: 'こんにちは！' }, { encoder: encoder }); assert.equal(shiftJISEncoded, 'a=%82%B1%82%F1%82%C9%82%BF%82%CD%81I'); This also works for decoding of query strings: var decoder = require('qs-iconv/decoder')('shift_jis'); var obj = qs.parse('a=%82%B1%82%F1%82%C9%82%BF%82%CD%81I', { decoder: decoder }); assert.deepEqual(obj, { a: 'こんにちは！' }); RFC 3986 and RFC 1738 space encoding RFC3986 used as default option and encodes ' ' to %20 which is backward compatible. In the same time, output can be stringified as per RFC1738 with ' ' equal to '+'. assert.equal(qs.stringify({ a: 'b c' }), 'a=b%20c'); assert.equal(qs.stringify({ a: 'b c' }, { format : 'RFC3986' }), 'a=b%20c'); assert.equal(qs.stringify({ a: 'b c' }, { format : 'RFC1738' }), 'a=b+c'); Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report. qs for enterprise Available as part of the Tidelift Subscription The maintainers of qs and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more. Acknowledgements qs logo by NUMI:"
  },
  "src/frontend/app-client/node_modules/range-parser/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/range-parser/HISTORY.html",
    "title": "1.2.1 / 2019-05-10",
    "summary": "1.2.1 / 2019-05-10 Improve error when str is not a string 1.2.0 / 2016-06-01 Add combine option to combine overlapping ranges 1.1.0 / 2016-05-13 Fix incorrectly returning -1 when there is at least one valid range perf: remove internal function 1.0.3 / 2015-10-29 perf: enable strict mode 1.0.2 / 2014-09-08 Support Node.js 0.6 1.0.1 / 2014-09-07 Move repository to jshttp 1.0.0 / 2013-12-11 Add repository to package.json Add MIT license 0.0.4 / 2012-06-17 Change ret -1 for unsatisfiable and -2 when invalid 0.0.3 / 2012-06-17 Fix last-byte-pos default to len - 1 0.0.2 / 2012-06-14 Add .type 0.0.1 / 2012-06-11 Initial release"
  },
  "src/frontend/app-client/node_modules/range-parser/README.html": {
    "href": "src/frontend/app-client/node_modules/range-parser/README.html",
    "title": "range-parser",
    "summary": "range-parser Range header field parser. Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install range-parser API var parseRange = require('range-parser') parseRange(size, header, options) Parse the given header string where size is the maximum size of the resource. An array of ranges will be returned or negative numbers indicating an error parsing. -2 signals a malformed header string -1 signals an unsatisfiable range // parse header from request var range = parseRange(size, req.headers.range) // the type of the range if (range.type === 'bytes') { // the ranges range.forEach(function (r) { // do something with r.start and r.end }) } Options These properties are accepted in the options object. combine Specifies if overlapping & adjacent ranges should be combined, defaults to false. When true, ranges will be combined and returned as if they were specified that way in the header. parseRange(100, 'bytes=50-55,0-10,5-10,56-60', { combine: true }) // => [ // { start: 0, end: 10 }, // { start: 50, end: 60 } // ] License MIT"
  },
  "src/frontend/app-client/node_modules/raw-body/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/raw-body/HISTORY.html",
    "title": "2.5.2 / 2023-02-21",
    "summary": "2.5.2 / 2023-02-21 Fix error message for non-stream argument 2.5.1 / 2022-02-28 Fix error on early async hooks implementations 2.5.0 / 2022-02-21 Prevent loss of async hooks context Prevent hanging when stream is not readable deps: http-errors@2.0.0 deps: depd@2.0.0 deps: statuses@2.0.1 2.4.3 / 2022-02-14 deps: bytes@3.1.2 2.4.2 / 2021-11-16 deps: bytes@3.1.1 deps: http-errors@1.8.1 deps: setprototypeof@1.2.0 deps: toidentifier@1.0.1 2.4.1 / 2019-06-25 deps: http-errors@1.7.3 deps: inherits@2.0.4 2.4.0 / 2019-04-17 deps: bytes@3.1.0 Add petabyte (pb) support deps: http-errors@1.7.2 Set constructor name when possible deps: setprototypeof@1.1.1 deps: statuses@'>= 1.5.0 < 2' deps: iconv-lite@0.4.24 Added encoding MIK 2.3.3 / 2018-05-08 deps: http-errors@1.6.3 deps: depd@~1.1.2 deps: setprototypeof@1.1.0 deps: statuses@'>= 1.3.1 < 2' deps: iconv-lite@0.4.23 Fix loading encoding with year appended Fix deprecation warnings on Node.js 10+ 2.3.2 / 2017-09-09 deps: iconv-lite@0.4.19 Fix ISO-8859-1 regression Update Windows-1255 2.3.1 / 2017-09-07 deps: bytes@3.0.0 deps: http-errors@1.6.2 deps: depd@1.1.1 perf: skip buffer decoding on overage chunk 2.3.0 / 2017-08-04 Add TypeScript definitions Use http-errors for standard emitted errors deps: bytes@2.5.0 deps: iconv-lite@0.4.18 Add support for React Native Add a warning if not loaded as utf-8 Fix CESU-8 decoding in Node.js 8 Improve speed of ISO-8859-1 encoding 2.2.0 / 2017-01-02 deps: iconv-lite@0.4.15 Added encoding MS-31J Added encoding MS-932 Added encoding MS-936 Added encoding MS-949 Added encoding MS-950 Fix GBK/GB18030 handling of Euro character 2.1.7 / 2016-06-19 deps: bytes@2.4.0 perf: remove double-cleanup on happy path 2.1.6 / 2016-03-07 deps: bytes@2.3.0 Drop partial bytes on all parsed units Fix parsing byte string that looks like hex 2.1.5 / 2015-11-30 deps: bytes@2.2.0 deps: iconv-lite@0.4.13 2.1.4 / 2015-09-27 Fix masking critical errors from iconv-lite deps: iconv-lite@0.4.12 Fix CESU-8 decoding in Node.js 4.x 2.1.3 / 2015-09-12 Fix sync callback when attaching data listener causes sync read Node.js 0.10 compatibility issue 2.1.2 / 2015-07-05 Fix error stack traces to skip makeError deps: iconv-lite@0.4.11 Add encoding CESU-8 2.1.1 / 2015-06-14 Use unpipe module for unpiping requests 2.1.0 / 2015-05-28 deps: iconv-lite@0.4.10 Improved UTF-16 endianness detection Leading BOM is now removed when decoding The encoding UTF-16 without BOM now defaults to UTF-16LE when detection fails 2.0.2 / 2015-05-21 deps: bytes@2.1.0 Slight optimizations 2.0.1 / 2015-05-10 Fix a false-positive when unpiping in Node.js 0.8 2.0.0 / 2015-05-08 Return a promise without callback instead of thunk deps: bytes@2.0.1 units no longer case sensitive when parsing 1.3.4 / 2015-04-15 Fix hanging callback if request aborts during read deps: iconv-lite@0.4.8 Add encoding alias UNICODE-1-1-UTF-7 1.3.3 / 2015-02-08 deps: iconv-lite@0.4.7 Gracefully support enumerables on Object.prototype 1.3.2 / 2015-01-20 deps: iconv-lite@0.4.6 Fix rare aliases of single-byte encodings 1.3.1 / 2014-11-21 deps: iconv-lite@0.4.5 Fix Windows-31J and X-SJIS encoding support 1.3.0 / 2014-07-20 Fully unpipe the stream on error Fixes Cannot switch to old mode now error on Node.js 0.10+ 1.2.3 / 2014-07-20 deps: iconv-lite@0.4.4 Added encoding UTF-7 1.2.2 / 2014-06-19 Send invalid encoding error to callback 1.2.1 / 2014-06-15 deps: iconv-lite@0.4.3 Added encodings UTF-16BE and UTF-16 with BOM 1.2.0 / 2014-06-13 Passing string as options interpreted as encoding Support all encodings from iconv-lite 1.1.7 / 2014-06-12 use string_decoder module from npm 1.1.6 / 2014-05-27 check encoding for old streams1 support node.js < 0.10.6 1.1.5 / 2014-05-14 bump bytes 1.1.4 / 2014-04-19 allow true as an option bump bytes 1.1.3 / 2014-03-02 fix case when length=null 1.1.2 / 2013-12-01 be less strict on state.encoding check 1.1.1 / 2013-11-27 add engines 1.1.0 / 2013-11-27 add err.statusCode and err.type allow for encoding option to be true pause the stream instead of dumping on error throw if the stream's encoding is set 1.0.1 / 2013-11-19 dont support streams1, throw if dev set encoding 1.0.0 / 2013-11-17 rename expected option to length 0.2.0 / 2013-11-15 republish 0.1.1 / 2013-11-15 use bytes 0.1.0 / 2013-11-11 generator support 0.0.3 / 2013-10-10 update repo 0.0.2 / 2013-09-14 dump stream on bad headers listen to events after defining received and buffers 0.0.1 / 2013-09-14 Initial release"
  },
  "src/frontend/app-client/node_modules/raw-body/README.html": {
    "href": "src/frontend/app-client/node_modules/raw-body/README.html",
    "title": "raw-body",
    "summary": "raw-body Gets the entire buffer of a stream either as a Buffer or a string. Validates the stream's length against an expected length and maximum limit. Ideal for parsing request bodies. Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install raw-body TypeScript This module includes a TypeScript declaration file to enable auto complete in compatible editors and type information for TypeScript projects. This module depends on the Node.js types, so install @types/node: $ npm install @types/node API var getRawBody = require('raw-body') getRawBody(stream, [options], [callback]) Returns a promise if no callback specified and global Promise exists. Options: length - The length of the stream. If the contents of the stream do not add up to this length, an 400 error code is returned. limit - The byte limit of the body. This is the number of bytes or any string format supported by bytes, for example 1000, '500kb' or '3mb'. If the body ends up being larger than this limit, a 413 error code is returned. encoding - The encoding to use to decode the body into a string. By default, a Buffer instance will be returned when no encoding is specified. Most likely, you want utf-8, so setting encoding to true will decode as utf-8. You can use any type of encoding supported by iconv-lite. You can also pass a string in place of options to just specify the encoding. If an error occurs, the stream will be paused, everything unpiped, and you are responsible for correctly disposing the stream. For HTTP requests, you may need to finish consuming the stream if you want to keep the socket open for future requests. For streams that use file descriptors, you should stream.destroy() or stream.close() to prevent leaks. Errors This module creates errors depending on the error condition during reading. The error may be an error from the underlying Node.js implementation, but is otherwise an error created by this module, which has the following attributes: limit - the limit in bytes length and expected - the expected length of the stream received - the received bytes encoding - the invalid encoding status and statusCode - the corresponding status code for the error type - the error type Types The errors from this module have a type property which allows for the programmatic determination of the type of error returned. encoding.unsupported This error will occur when the encoding option is specified, but the value does not map to an encoding supported by the iconv-lite module. entity.too.large This error will occur when the limit option is specified, but the stream has an entity that is larger. request.aborted This error will occur when the request stream is aborted by the client before reading the body has finished. request.size.invalid This error will occur when the length option is specified, but the stream has emitted more bytes. stream.encoding.set This error will occur when the given stream has an encoding set on it, making it a decoded stream. The stream should not have an encoding set and is expected to emit Buffer objects. stream.not.readable This error will occur when the given stream is not readable. Examples Simple Express example var contentType = require('content-type') var express = require('express') var getRawBody = require('raw-body') var app = express() app.use(function (req, res, next) { getRawBody(req, { length: req.headers['content-length'], limit: '1mb', encoding: contentType.parse(req).parameters.charset }, function (err, string) { if (err) return next(err) req.text = string next() }) }) // now access req.text Simple Koa example var contentType = require('content-type') var getRawBody = require('raw-body') var koa = require('koa') var app = koa() app.use(function * (next) { this.text = yield getRawBody(this.req, { length: this.req.headers['content-length'], limit: '1mb', encoding: contentType.parse(this.req).parameters.charset }) yield next }) // now access this.text Using as a promise To use this library as a promise, simply omit the callback and a promise is returned, provided that a global Promise is defined. var getRawBody = require('raw-body') var http = require('http') var server = http.createServer(function (req, res) { getRawBody(req) .then(function (buf) { res.statusCode = 200 res.end(buf.length + ' bytes submitted') }) .catch(function (err) { res.statusCode = 500 res.end(err.message) }) }) server.listen(3000) Using with TypeScript import * as getRawBody from 'raw-body'; import * as http from 'http'; const server = http.createServer((req, res) => { getRawBody(req) .then((buf) => { res.statusCode = 200; res.end(buf.length + ' bytes submitted'); }) .catch((err) => { res.statusCode = err.statusCode; res.end(err.message); }); }); server.listen(3000); License MIT"
  },
  "src/frontend/app-client/node_modules/raw-body/SECURITY.html": {
    "href": "src/frontend/app-client/node_modules/raw-body/SECURITY.html",
    "title": "Security Policies and Procedures",
    "summary": "Security Policies and Procedures Reporting a Bug The raw-body team and community take all security bugs seriously. Thank you for improving the security of Express. We appreciate your efforts and responsible disclosure and will make every effort to acknowledge your contributions. Report security bugs by emailing the current owners of raw-body. This information can be found in the npm registry using the command npm owner ls raw-body. If unsure or unable to get the information from the above, open an issue in the project issue tracker asking for the current contact information. To ensure the timely response to your report, please ensure that the entirety of the report is contained within the email body and not solely behind a web link or an attachment. At least one owner will acknowledge your email within 48 hours, and will send a more detailed response within 48 hours indicating the next steps in handling your report. After the initial reply to your report, the owners will endeavor to keep you informed of the progress towards a fix and full announcement, and may ask for additional information or guidance."
  },
  "src/frontend/app-client/node_modules/react-d3-tree/README.html": {
    "href": "src/frontend/app-client/node_modules/react-d3-tree/README.html",
    "title": "React D3 Tree",
    "summary": "React D3 Tree \uD83D\uDC7E Playground \uD83D\uDCD6 API Documentation (v3) React D3 Tree is a React component that lets you represent hierarchical data (e.g. family trees, org charts, file directories) as an interactive tree graph with minimal setup, by leveraging D3's tree layout. Upgrading from v1? Check out the v2 release notes. Legacy v1 docs Contents Installation Usage Props Working with the default Tree Providing data Styling Nodes Styling Links Event Handlers Customizing the Tree renderCustomNodeElement pathFunc Providing your own pathFunc Development Setup Hot reloading Contributors Installation npm i --save react-d3-tree Usage import React from 'react'; import Tree from 'react-d3-tree'; // This is a simplified example of an org chart with a depth of 2. // Note how deeper levels are defined recursively via the `children` property. const orgChart = { name: 'CEO', children: [ { name: 'Manager', attributes: { department: 'Production', }, children: [ { name: 'Foreman', attributes: { department: 'Fabrication', }, children: [ { name: 'Worker', }, ], }, { name: 'Foreman', attributes: { department: 'Assembly', }, children: [ { name: 'Worker', }, ], }, ], }, ], }; export default function OrgChartTree() { return ( // `<Tree />` will fill width/height of its container; in this case `#treeWrapper`. <div id=\"treeWrapper\" style={{ width: '50em', height: '20em' }}> <Tree data={orgChart} /> </div> ); } Props For details on all props accepted by Tree, check out the TreeProps reference docs. The only required prop is data, all other props on Tree are optional/pre-defined (see \"Default value\" on each prop definition). Working with the default Tree react-d3-tree provides default implementations for Tree's nodes & links, which are intended to get you up & running with a working tree quickly. This section is focused on explaining how to provide data, styles and event handlers for the default Tree implementation. Need more fine-grained control over how nodes & links appear/behave? Check out the Customizing the Tree section below. Providing data By default, Tree expects each node object in data to implement the RawNodeDatum interface: interface RawNodeDatum { name: string; attributes?: Record<string, string | number | boolean>; children?: RawNodeDatum[]; } The orgChart example in the Usage section above is an example of this: Every node has at least a name. This is rendered as the node's primary label. Some nodes have attributes defined (the CEO node does not). The key-value pairs in attributes are rendered as a list of secondary labels. Nodes can have further RawNodeDatum objects nested inside them via the children key, creating a hierarchy from which the tree graph can be generated. Styling Nodes Tree provides the following props to style different types of nodes, all of which use an SVG circle by default: rootNodeClassName - applied to the root node. branchNodeClassName - applied to any node with 1+ children. leafNodeClassName - applied to any node without children. To visually distinguish these three types of nodes from each other by color, we could provide each with their own class: /* custom-tree.css */ .node__root > circle { fill: red; } .node__branch > circle { fill: yellow; } .node__leaf > circle { fill: green; /* Let's also make the radius of leaf nodes larger */ r: 40; } import React from 'react'; import Tree from 'react-d3-tree'; import './custom-tree.css'; // ... export default function StyledNodesTree() { return ( <div id=\"treeWrapper\" style={{ width: '50em', height: '20em' }}> <Tree data={data} rootNodeClassName=\"node__root\" branchNodeClassName=\"node__branch\" leafNodeClassName=\"node__leaf\" /> </div> ); } For more details on the className props for nodes, see the TreeProps reference docs. Styling Links Tree provides the pathClassFunc property to pass additional classNames to every link to be rendered. Each link calls pathClassFunc with its own TreeLinkDatum and the tree's current orientation. Tree expects pathClassFunc to return a className string. function StyledLinksTree() { const getDynamicPathClass = ({ source, target }, orientation) => { if (!target.children) { // Target node has no children -> this link leads to a leaf node. return 'link__to-leaf'; } // Style it as a link connecting two branch nodes by default. return 'link__to-branch'; }; return ( <Tree data={data} // Statically apply same className(s) to all links pathClassFunc={() => 'custom-link'} // Want to apply multiple static classes? `Array.join` is your friend :) pathClassFunc={() => ['custom-link', 'extra-custom-link'].join(' ')} // Dynamically determine which `className` to pass based on the link's properties. pathClassFunc={getDynamicPathClass} /> ); } For more details, see the PathClassFunction reference docs. Event Handlers Tree exposes the following event handler callbacks by default: onLinkClick onLinkMouseOut onLinkMouseOver onNodeClick onNodeMouseOut onNodeMouseOver Note: Nodes are expanded/collapsed whenever onNodeClick fires. To prevent this, set the collapsible prop to false. onNodeClick will still fire, but it will not change the target node's expanded/collapsed state. Customizing the Tree renderCustomNodeElement The renderCustomNodeElement prop accepts a custom render function that will be used for every node in the tree. Cases where you may find rendering your own Node element useful include: Using a different SVG tag for your nodes (instead of the default <circle>) - Example (codesandbox.io) Gaining fine-grained control over event handling (e.g. to implement events not covered by the default API) - Example (codesandbox.io) Building richer & more complex nodes/labels by leveraging the foreignObject tag to render HTML inside the SVG namespace - Example (codesandbox.io) pathFunc The pathFunc prop accepts a predefined PathFunctionOption enum or a user-defined PathFunction. By changing or providing your own pathFunc, you are able to change how links between nodes of the tree (which are SVG path tags under the hood) are drawn. The currently available enums are: diagonal (default) elbow straight step Want to see how each option looks? Try them out on the playground. Providing your own pathFunc If none of the available path functions suit your needs, you're also able to provide a custom PathFunction: function CustomPathFuncTree() { const straightPathFunc = (linkDatum, orientation) => { const { source, target } = linkDatum; return orientation === 'horizontal' ? `M${source.y},${source.x}L${target.y},${target.x}` : `M${source.x},${source.y}L${target.x},${target.y}`; }; return ( <Tree data={data} // Passing `straight` function as a custom `PathFunction`. pathFunc={straightPathFunc} /> ); } For more details, see the PathFunction reference docs. Development Setup To set up react-d3-tree for local development, clone the repo and follow the steps below: # 1. Set up the library, create a reference to it for symlinking. cd react-d3-tree npm i npm link # 2. Set up the demo/playground, symlink to the local copy of `react-d3-tree`. cd demo npm i npm link react-d3-tree Tip: If you'd prefer to use your own app for development instead of the demo, simply run npm link react-d3-tree in your app's root folder instead of the demo's :) Hot reloading npm run build:watch If you're using react-d3-tree/demo for development, open up another terminal window in the demo directory and call: npm start Contributors A huge thank you to all the contributors, as well as users who have opened issues with thoughtful suggestions and feedback."
  },
  "src/frontend/app-client/node_modules/react-diff-viewer-continued/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/react-diff-viewer-continued/CHANGELOG.html",
    "title": "4.0.0 (2023-10-19)",
    "summary": "4.0.5 (2025-01-31) Bug Fixes modify imports for proper esm resolution (7fda63a) 4.0.4 (2025-01-28) Bug Fixes added line number for inline view onLineNumberClick (0e92dfe) fix several type issues and update packages (23aa832) line break anywhere (17c51e6) 4.0.3 (2024-05-23) Reverts Revert \"refactoring attempt\" (6a9789b) 4.0.2 (2024-02-14) Bug Fixes revert back to table based layout, add example image (fixes #35, #15, #21) (a1571ab) 4.0.1 (2023-11-01) Bug Fixes publish files on 4.x (650c249) 4.0.0 (2023-10-19) Bug Fixes do not trim trailing newlines (fixes #27) (ee4d53f) use semantic elements for diff elements (fixes #23) (a6222c7) feat!: diff/flexbox based layout, text selectable per side (fixes #15) (9f6c4d5), closes #15 Features add summary element and fold expansion/folding (fixes #22, #21) (e47cbe1) BREAKING CHANGES This completely modifies the way react-diff-viewer-continued is rendered. The overall layout should be more or less the same, but with the new layout probably come new bugs. 3.3.0 (2023-10-17) Bug Fixes update dependencies and correct zero width extraLines (fixes #29) (c4b317a) Features add ability to always show certain lines (896eb32) 3.2.6 (2023-03-02) Bug Fixes release for chore fix (9775afa) 3.2.5 (2023-01-23) Bug Fixes correctly break strings for long values so size remains within bounds (cfa5de1) 3.2.4 (2022-12-23) Bug Fixes to deploy previous fixes (06d8361) 3.2.3 (2022-11-11) Bug Fixes update example with JSON (f61c977) 3.2.2 (2022-10-10) Bug Fixes move the dependencies for development only to devDependencies (206394c) 3.2.1 (2022-07-07) Bug Fixes correct diff line numbering (bab9977) 3.2.0 (2022-07-07) Features update library for react 17, and add custom gutters (7193350)"
  },
  "src/frontend/app-client/node_modules/react-diff-viewer-continued/README.html": {
    "href": "src/frontend/app-client/node_modules/react-diff-viewer-continued/README.html",
    "title": "",
    "summary": "A simple and beautiful text diff viewer component made with Diff and React. Inspired by the Github diff viewer, it includes features like split view, inline view, word diff, line highlight and more. It is highly customizable and it supports almost all languages. Most credit goes to Pranesh Ravi who created the original diff viewer. I've just made a few modifications and updated the dependencies so they work with modern stacks. Install yarn add react-diff-viewer-continued # or npm i react-diff-viewer-continued # or pnpm add react-diff-viewer-continued Usage import React, { PureComponent } from 'react'; import ReactDiffViewer from 'react-diff-viewer-continued'; const oldCode = ` const a = 10 const b = 10 const c = () => console.log('foo') if(a > 10) { console.log('bar') } console.log('done') `; const newCode = ` const a = 10 const boo = 10 if(a === 10) { console.log('bar') } `; class Diff extends PureComponent { render = () => { return ( <ReactDiffViewer oldValue={oldCode} newValue={newCode} splitView={true} /> ); }; } Props Prop Type Default Description oldValue string \\| Object '' Old value as string (or Object if using diffJson). newValue string \\| Object '' New value as string (or Object if using diffJson). splitView boolean true Switch between unified and split view. disableWordDiff boolean false Show and hide word diff in a diff line. compareMethod DiffMethod \\| (string, string) => diff.Change[] DiffMethod.CHARS Uses an existing diff method when a DiffMethod enum is passed. If a function is passed, that function is used as the diff method. JsDiff text diff method used for diffing strings. Check out the guide to use different methods. renderGutter (diffData) => ReactNode undefined Function that can be used to render an extra gutter with various information next to the line number. hideLineNumbers boolean false Show and hide line numbers. alwaysShowLines string[] [] List of lines to always be shown, regardless of diff status. Line number are prefixed with L and R for the left and right section of the diff viewer, respectively. For example, L-20 means 20th line in the left pane. extraLinesSurroundingDiff applies to these lines as well. renderContent function undefined Render Prop API to render code in the diff viewer. Helpful for syntax highlighting onLineNumberClick function undefined Event handler for line number click. (lineId: string) => void highlightLines string[] [] List of lines to be highlighted. Works together with onLineNumberClick. Line number are prefixed with L and R for the left and right section of the diff viewer, respectively. For example, L-20 means 20th line in the left pane. To highlight a range of line numbers, pass the prefixed line number as an array. For example, [L-2, L-3, L-4, L-5] will highlight the lines 2-5 in the left pane. showDiffOnly boolean true Shows only the diffed lines and folds the unchanged lines extraLinesSurroundingDiff number 3 Number of extra unchanged lines surrounding the diff. Works along with showDiffOnly. codeFoldMessageRenderer function Expand {number} of lines ... Render Prop API to render code fold message. styles object {} To override style variables and styles. Learn more about overriding styles useDarkTheme boolean true To enable/disable dark theme. leftTitle string undefined Column title for left section of the diff in split view. This will be used as the only title in inline view. rightTitle string undefined Column title for right section of the diff in split view. This will be ignored in inline view. linesOffset number 0 Number to start count code lines from. Instance Methods resetCodeBlocks() - Resets the expanded code blocks to it's initial state. Return true on successful reset and false during unsuccessful reset. Syntax Highlighting Syntax highlighting is a bit tricky when combined with diff. Here, React Diff Viewer provides a simple render prop API to handle syntax highlighting. Use renderContent(content: string) => JSX.Element and your favorite syntax highlighting library to achieve this. An example using Prism JS // Load Prism CSS <link href=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/prism.min.css\" /> // Load Prism JS <script src=\"https://cdnjs.cloudflare.com/ajax/libs/prism/1.15.0/prism.min.js\"></script> import React, { PureComponent } from 'react'; import ReactDiffViewer from 'react-diff-viewer'; const oldCode = ` const a = 10 const b = 10 const c = () => console.log('foo') if(a > 10) { console.log('bar') } console.log('done') `; const newCode = ` const a = 10 const boo = 10 if(a === 10) { console.log('bar') } `; class Diff extends PureComponent { highlightSyntax = (str) => ( <pre style={{ display: 'inline' }} dangerouslySetInnerHTML={{ __html: Prism.highlight(str, Prism.languages.javascript), }} /> ); render = () => { return ( <ReactDiffViewer oldValue={oldCode} newValue={newCode} splitView={true} renderContent={this.highlightSyntax} /> ); }; } Text block diff comparison Different styles of text block diffing are possible by using the enums corresponding to variou JsDiff methods (learn more). The supported methods are as follows. enum DiffMethod { CHARS = 'diffChars', WORDS = 'diffWords', WORDS_WITH_SPACE = 'diffWordsWithSpace', LINES = 'diffLines', TRIMMED_LINES = 'diffTrimmedLines', SENTENCES = 'diffSentences', CSS = 'diffCss', } import React, { PureComponent } from 'react'; import ReactDiffViewer, { DiffMethod } from 'react-diff-viewer'; const oldCode = ` { \"name\": \"Original name\", \"description\": null } `; const newCode = ` { \"name\": \"My updated name\", \"description\": \"Brand new description\", \"status\": \"running\" } `; class Diff extends PureComponent { render = () => { return ( <ReactDiffViewer oldValue={oldCode} newValue={newCode} compareMethod={DiffMethod.WORDS} splitView={true} /> ); }; } Overriding Styles React Diff Viewer uses emotion for styling. It also offers a simple way to override styles and style variables. You can supply different variables for both light and dark themes. Styles will be common for both themes. Below are the default style variables and style object keys. // Default variables and style keys const defaultStyles = { variables: { light: { diffViewerBackground: '#fff', diffViewerColor: '#212529', addedBackground: '#e6ffed', addedColor: '#24292e', removedBackground: '#ffeef0', removedColor: '#24292e', wordAddedBackground: '#acf2bd', wordRemovedBackground: '#fdb8c0', addedGutterBackground: '#cdffd8', removedGutterBackground: '#ffdce0', gutterBackground: '#f7f7f7', gutterBackgroundDark: '#f3f1f1', highlightBackground: '#fffbdd', highlightGutterBackground: '#fff5b1', codeFoldGutterBackground: '#dbedff', codeFoldBackground: '#f1f8ff', emptyLineBackground: '#fafbfc', gutterColor: '#212529', addedGutterColor: '#212529', removedGutterColor: '#212529', codeFoldContentColor: '#212529', diffViewerTitleBackground: '#fafbfc', diffViewerTitleColor: '#212529', diffViewerTitleBorderColor: '#eee', }, dark: { diffViewerBackground: '#2e303c', diffViewerColor: '#FFF', addedBackground: '#044B53', addedColor: 'white', removedBackground: '#632F34', removedColor: 'white', wordAddedBackground: '#055d67', wordRemovedBackground: '#7d383f', addedGutterBackground: '#034148', removedGutterBackground: '#632b30', gutterBackground: '#2c2f3a', gutterBackgroundDark: '#262933', highlightBackground: '#2a3967', highlightGutterBackground: '#2d4077', codeFoldGutterBackground: '#21232b', codeFoldBackground: '#262831', emptyLineBackground: '#363946', gutterColor: '#464c67', addedGutterColor: '#8c8c8c', removedGutterColor: '#8c8c8c', codeFoldContentColor: '#555a7b', diffViewerTitleBackground: '#2f323e', diffViewerTitleColor: '#555a7b', diffViewerTitleBorderColor: '#353846', } }, diffContainer?: {}, // style object diffRemoved?: {}, // style object diffAdded?: {}, // style object marker?: {}, // style object emptyGutter?: {}, // style object highlightedLine?: {}, // style object lineNumber?: {}, // style object highlightedGutter?: {}, // style object contentText?: {}, // style object gutter?: {}, // style object line?: {}, // style object wordDiff?: {}, // style object wordAdded?: {}, // style object wordRemoved?: {}, // style object codeFoldGutter?: {}, // style object codeFold?: {}, // style object emptyLine?: {}, // style object content?: {}, // style object titleBlock?: {}, // style object splitView?: {}, // style object } To override any style, just pass the new style object to the styles prop. New style will be computed using Object.assign(default, override). For keys other than variables, the value can either be an object or string interpolation. import React, { PureComponent } from 'react'; import ReactDiffViewer from 'react-diff-viewer'; const oldCode = ` const a = 10 const b = 10 const c = () => console.log('foo') if(a > 10) { console.log('bar') } console.log('done') `; const newCode = ` const a = 10 const boo = 10 if(a === 10) { console.log('bar') } `; class Diff extends PureComponent { highlightSyntax = (str) => ( <span style={{ display: 'inline' }} dangerouslySetInnerHTML={{ __html: Prism.highlight(str, Prism.languages.javascript), }} /> ); render = () => { const newStyles = { variables: { dark: { highlightBackground: '#fefed5', highlightGutterBackground: '#ffcd3c', }, }, line: { padding: '10px 2px', '&:hover': { background: '#a26ea1', }, }, }; return ( <ReactDiffViewer styles={newStyles} oldValue={oldCode} newValue={newCode} splitView={true} renderContent={this.highlightSyntax} /> ); }; } Local Development pnpm install pnpm build # or use yarn build:watch pnpm start:examples Check package.json for more build scripts. Contributors Eric M. \uD83D\uDCBB Andrei Kovalevsky \uD83D\uDCBB Chang Hyun Kim \uD83D\uDCBB License MIT"
  },
  "src/frontend/app-client/node_modules/react-dom/README.html": {
    "href": "src/frontend/app-client/node_modules/react-dom/README.html",
    "title": "react-dom",
    "summary": "react-dom This package serves as the entry point to the DOM and server renderers for React. It is intended to be paired with the generic React package, which is shipped as react to npm. Installation npm install react react-dom Usage In the browser import { createRoot } from 'react-dom/client'; function App() { return <div>Hello World</div>; } const root = createRoot(document.getElementById('root')); root.render(<App />); On the server import { renderToPipeableStream } from 'react-dom/server'; function App() { return <div>Hello World</div>; } function handleRequest(res) { // ... in your server handler ... const stream = renderToPipeableStream(<App />, { onShellReady() { res.statusCode = 200; res.setHeader('Content-type', 'text/html'); stream.pipe(res); }, // ... }); } API react-dom See https://react.dev/reference/react-dom react-dom/client See https://react.dev/reference/react-dom/client react-dom/server See https://react.dev/reference/react-dom/server"
  },
  "src/frontend/app-client/node_modules/react-hotkeys-hook/README.html": {
    "href": "src/frontend/app-client/node_modules/react-hotkeys-hook/README.html",
    "title": "useHotkeys(keys, callback)",
    "summary": "useHotkeys(keys, callback) npm i react-hotkeys-hook A React hook for using keyboard shortcuts in components in a declarative way. Quick Start The easiest way to use the hook. import { useHotkeys } from 'react-hotkeys-hook' export const ExampleComponent = () => { const [count, setCount] = useState(0) useHotkeys('ctrl+k', () => setCount(count + 1), [count]) return ( <p> Pressed {count} times. </p> ) } Scopes Scopes allow you to group hotkeys together. You can use scopes to prevent hotkeys from colliding with each other. const App = () => { return ( <HotkeysProvider initiallyActiveScopes={['settings']}> <ExampleComponent /> </HotkeysProvider> ) } export const ExampleComponent = () => { const [count, setCount] = useState(0) useHotkeys('ctrl+k', () => setCount(prevCount => prevCount + 1), { scopes: ['settings'] }) return ( <p> Pressed {count} times. </p> ) } Changing a scope's active state You can change the active state of a scope using the disableScope, enableScope and toggleScope functions returned by the useHotkeysContext() hook. Note that you have to have your app wrapped in a <HotkeysProvider> component. const App = () => { return ( <HotkeysProvider initiallyActiveScopes={['settings']}> <ExampleComponent /> </HotkeysProvider> ) } export const ExampleComponent = () => { const { toggleScope } = useHotkeysContext() return ( <button onClick={() => toggleScope('settings')}> Change scope active state </button> ) } Focus trap This will only trigger the hotkey if the component is focused. export const ExampleComponent = () => { const [count, setCount] = useState(0) const ref = useHotkeys<HTMLParagraphElement>('ctrl+k', () => setCount(prevCount => prevCount + 1)) return ( <p tabIndex={-1} ref={ref}> Pressed {count} times. </p> ) } Documentation & Live Examples Quick Start Documentation API API useHotkeys(keys, callback) useHotkeys(keys: string | string[], callback: (event: KeyboardEvent, handler: HotkeysEvent) => void, options: Options = {}, deps: DependencyList = []) Parameter Type Required? Default value Description keys string or string[] required - set the hotkeys you want the hook to listen to. You can use single or multiple keys, modifier combinations, etc. This will either be a string or an array of strings. To separate multiple keys, use a comma. This split key value can be overridden with the splitKey option. callback (event: KeyboardEvent, handler: HotkeysEvent) => void required - This is the callback function that will be called when the hotkey is pressed. The callback will receive the browsers native KeyboardEvent and the libraries HotkeysEvent. options Options optional {} Object to modify the behavior of the hook. Default options are given below. dependencies DependencyList optional [] The given callback will always be memoised inside the hook. So if you reference any outside variables, you need to set them here for the callback to get updated (Much like useCallback works in React). Options All options are optional and have a default value which you can override to change the behavior of the hook. Option Type Default value Description enabled boolean or (keyboardEvent: KeyboardEvent, hotkeysEvent: HotkeysEvent) => boolean true This option determines whether the hotkey is active or not. It can take a boolean (for example a flag from a state outside) or a function which gets executed once the hotkey is pressed. If the function returns false the hotkey won't get executed and all browser events are prevented. enableOnFormTags boolean or FormTags[] false By default hotkeys are not registered if a focus focuses on an input field. This will prevent accidental triggering of hotkeys when the user is typing. If you want to enable hotkeys, use this option. Setting it to true will enable on all form tags, otherwise you can give an array of form tags to enable the hotkey on (possible options are: ['input', 'textarea', 'select']) enableOnContentEditable boolean false Set this option to enable hotkeys on tags that have set the contentEditable prop to true combinationKey string + Character to indicate keystrokes like shift+c. You might want to change this if you want to listen to the + character like ctrl-+. splitKey string , Character to separate different keystrokes like ctrl+a, ctrl+b. scopes string or string[] * With scopes you can group hotkeys together. The default scope is the wildcard * which matches all hotkeys. Use the <HotkeysProvider> component to change active scopes. keyup boolean false Determines whether to listen to the browsers keyup event for triggering the callback. keydown boolean true Determines whether to listen to the browsers keydown event for triggering the callback. If you set both keyupand keydown to true, the callback will trigger on both events. preventDefault boolean or (keyboardEvent: KeyboardEvent, hotkeysEvent: HotkeysEvent) => boolean false Set this to a true if you want the hook to prevent the browsers default behavior on certain keystrokes like meta+s to save a page. NOTE: Certain keystrokes are not preventable, like meta+w to close a tab in chrome. description string undefined Use this option to describe what the hotkey does. this is helpful if you want to display a list of active hotkeys to the user. Overloads The hooks call signature is very flexible. For example if you don't need to set any special options you can use the dependency array as your third parameter: useHotkeys('ctrl+k', () => console.log(counter + 1), [counter]) isHotkeyPressed(keys: string | string[], splitKey?: string = ',') This function allows us to check if the user is currently pressing down a key. import { isHotkeyPressed } from 'react-hotkeys-hook' isHotkeyPressed('esc') // Returns true if Escape key is pressed down. You can also check for multiple keys at the same time: isHotkeyPressed(['esc', 'ctrl+s']) // Returns true if Escape or Ctrl+S are pressed down. Support Ask your question in the Github Discussions Ask your question on StackOverflow Found an issue or have a feature request? Open up an issue or pull request and participate. Local Development Checkout this repo, run yarn or npm i and then run the test script to test the behavior of the hook. Contributing Contributions are what make the open source community such an amazing place to learn, inspire, and create. Any contributions you make are greatly appreciated. Fork the Project Create your Feature Branch (git checkout -b feature/AmazingFeature) Commit your Changes (git commit -m 'Add some AmazingFeature') Push to the Branch (git push origin feature/AmazingFeature) Open a Pull Request License Distributed under the MIT License. See LICENSE for more information. Contact Johannes Klauss - @JohannesKlauss - klauss.johannes@gmail.com Project Link: https://github.com/JohannesKlauss/react-hotkeys-hook Contributors"
  },
  "src/frontend/app-client/node_modules/react-is/README.html": {
    "href": "src/frontend/app-client/node_modules/react-is/README.html",
    "title": "react-is",
    "summary": "react-is This package allows you to test arbitrary values and see if they're a particular React element type. Installation # Yarn yarn add react-is # NPM npm install react-is Usage Determining if a Component is Valid import React from \"react\"; import * as ReactIs from \"react-is\"; class ClassComponent extends React.Component { render() { return React.createElement(\"div\"); } } const FunctionComponent = () => React.createElement(\"div\"); const ForwardRefComponent = React.forwardRef((props, ref) => React.createElement(Component, { forwardedRef: ref, ...props }) ); const Context = React.createContext(false); ReactIs.isValidElementType(\"div\"); // true ReactIs.isValidElementType(ClassComponent); // true ReactIs.isValidElementType(FunctionComponent); // true ReactIs.isValidElementType(ForwardRefComponent); // true ReactIs.isValidElementType(Context.Provider); // true ReactIs.isValidElementType(Context.Consumer); // true ReactIs.isValidElementType(React.createFactory(\"div\")); // true Determining an Element's Type Context import React from \"react\"; import * as ReactIs from 'react-is'; const ThemeContext = React.createContext(\"blue\"); ReactIs.isContextConsumer(<ThemeContext.Consumer />); // true ReactIs.isContextProvider(<ThemeContext.Provider />); // true ReactIs.typeOf(<ThemeContext.Provider />) === ReactIs.ContextProvider; // true ReactIs.typeOf(<ThemeContext.Consumer />) === ReactIs.ContextConsumer; // true Element import React from \"react\"; import * as ReactIs from 'react-is'; ReactIs.isElement(<div />); // true ReactIs.typeOf(<div />) === ReactIs.Element; // true Fragment import React from \"react\"; import * as ReactIs from 'react-is'; ReactIs.isFragment(<></>); // true ReactIs.typeOf(<></>) === ReactIs.Fragment; // true Portal import React from \"react\"; import ReactDOM from \"react-dom\"; import * as ReactIs from 'react-is'; const div = document.createElement(\"div\"); const portal = ReactDOM.createPortal(<div />, div); ReactIs.isPortal(portal); // true ReactIs.typeOf(portal) === ReactIs.Portal; // true StrictMode import React from \"react\"; import * as ReactIs from 'react-is'; ReactIs.isStrictMode(<React.StrictMode />); // true ReactIs.typeOf(<React.StrictMode />) === ReactIs.StrictMode; // true"
  },
  "src/frontend/app-client/node_modules/react-lifecycles-compat/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/react-lifecycles-compat/CHANGELOG.html",
    "title": "",
    "summary": "[Unreleased] Changes that have landed in master but are not yet released. Click to see more. 3.0.4 (May 11, 2018) Fixed shallow renderer regression (introduced in 3.0.3) that caused setState updater to fail due to incorrect this. (#26) 3.0.3 (May 9, 2018) Fixed an edge case bug where a batched update containing both a setState updater and a parent re-render could result in dropped state updates. (#24) 3.0.2 (April 11, 2018) Replaced an unintentional template literal to ensure broader browser compatibility. (ce42fe4) 3.0.1 (April 10, 2018) Replaced a few unintentional let keywords with var to ensure broader browser compatibility. (#17) 3.0.0 (April 9, 2018) Throw an error for any polyfilled component that mixes old lifecycles (componentWillMount, componentWillReceiveProps, or componentWillUpdate) and new lifecycles (getDerivedStateFromProps or getSnapshotBeforeUpdate) as React 16.3+ does not support this case and will not invoke the old lifecycles. This error ensures consistent behavior between React 16.3+ and older versions. (#14) 2.0.1 (April 9, 2018) Add a DEV mode warning for any polyfilled component that mixes old lifecycles (componentWillMount, componentWillReceiveProps, or componentWillUpdate) and new lifecycles (getDerivedStateFromProps or getSnapshotBeforeUpdate) as React 16.3+ does not support this case and will not invoke the old lifecycles. This warning ensures consistent behavior between React 16.3+ and older versions. (#15) 2.0.0 (April 4, 2018) Package uses a named export and includes an ES6 module build. (#11) // 1.x (before) import polyfill from 'react-lifecycles-compat'; // 2.x (after) import {polyfill} from 'react-lifecycles-compat'; 1.1.4 (April 3, 2018) Improved handling of falsy return values from polyfilled getSnapshotBeforeUpdate() lifecycle. #12"
  },
  "src/frontend/app-client/node_modules/react-lifecycles-compat/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/react-lifecycles-compat/LICENSE.html",
    "title": "",
    "summary": "MIT License Copyright (c) 2013-present, Facebook, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/react-lifecycles-compat/README.html": {
    "href": "src/frontend/app-client/node_modules/react-lifecycles-compat/README.html",
    "title": "react-lifecycles-compat",
    "summary": "react-lifecycles-compat What is this project? React version 17 will deprecate several of the class component API lifecycles: componentWillMount, componentWillReceiveProps, and componentWillUpdate. (Read the Update on Async rendering blog post to learn more about why.) A couple of new lifecycles are also being added to better support async rendering mode. Typically, this type of change would require third party libraries to release a new major version in order to adhere to semver. However, the react-lifecycles-compat polyfill offers a way to use the new lifecycles with older versions of React as well (0.14.9+) so no breaking release is required. This enables shared libraries to support both older and newer versions of React simultaneously. How can I use the polyfill First, install the polyfill from NPM: # Yarn yarn add react-lifecycles-compat # NPM npm install react-lifecycles-compat --save Next, update your component and replace any of the deprecated lifecycles with new ones introduced with React 16.3. (Refer to the React docs for examples of how to use the new lifecycles.) Lastly, use the polyfill to make the new lifecycles work with older versions of React: import React from 'react'; import {polyfill} from 'react-lifecycles-compat'; class ExampleComponent extends React.Component { static getDerivedStateFromProps(nextProps, prevState) { // Normally this method would only work for React 16.3 and newer, // But the polyfill will make it work for older versions also! } getSnapshotBeforeUpdate(prevProps, prevState) { // Normally this method would only work for React 16.3 and newer, // But the polyfill will make it work for older versions also! } // render() and other methods ... } // Polyfill your component so the new lifecycles will work with older versions of React: polyfill(ExampleComponent); export default ExampleComponent; Which lifecycles are supported? Currently, this polyfill supports static getDerivedStateFromProps and getSnapshotBeforeUpdate- both introduced in version 16.3. Validation Note that in order for the polyfill to work, none of the following lifecycles can be defined by your component: componentWillMount, componentWillReceiveProps, or componentWillUpdate. Note also that if your component contains getSnapshotBeforeUpdate, componentDidUpdate must be defined as well. An error will be thrown if any of the above conditions are not met."
  },
  "src/frontend/app-client/node_modules/react-refresh/README.html": {
    "href": "src/frontend/app-client/node_modules/react-refresh/README.html",
    "title": "react-refresh",
    "summary": "react-refresh This package implements the wiring necessary to integrate Fast Refresh into bundlers. Fast Refresh is a feature that lets you edit React components in a running application without losing their state. It is similar to an old feature known as \"hot reloading\", but Fast Refresh is more reliable and officially supported by React. This package is primarily aimed at developers of bundler plugins. If you’re working on one, here is a rough guide for Fast Refresh integration using this package."
  },
  "src/frontend/app-client/node_modules/react-remove-scroll-bar/README.html": {
    "href": "src/frontend/app-client/node_modules/react-remove-scroll-bar/README.html",
    "title": "react-remove-scroll-bar",
    "summary": "react-remove-scroll-bar v1+ for React 15, v2+ requires React 16.8+ Removes scroll bar (by setting overflow: hidden on body), and preserves the scroll bar \"gap\". Read - it just makes scroll bar invisible. Does nothing if scroll bar does not consume any space. Usage import {RemoveScrollBar} from 'react-remove-scroll-bar'; <RemoveScrollBar /> -> no scroll bar The Right Border To prevent content jumps position:fixed elements with right:0 should have additional classname applied. It will just provide a non-zero right, when it needed, to maintain the right \"gap\". import {zeroRightClassName,fullWidthClassName, noScrollbarsClassName} from 'react-remove-scroll-bar'; // to set `right:0` on an element <div className={zeroRightClassName} /> // to set `width:100%` on an element <div className={fullWidthClassName} /> // to remove scrollbar from an element <div className={noScrollbarsClassName} /> Size 500b after compression (excluding tslib). Scroll-Locky All code is a result of a react-scroll-locky refactoring. Article There is a medium article about preventing the body scroll - How to fight the scroll License MIT"
  },
  "src/frontend/app-client/node_modules/react-remove-scroll/README.html": {
    "href": "src/frontend/app-client/node_modules/react-remove-scroll/README.html",
    "title": "React-remove-\uD83D\uDCDC",
    "summary": "React-remove-\uD83D\uDCDC dont even scroll react-remove-scroll Disables scroll outside of children node. \uD83D\uDDB1 mouse and touch devices friendly \uD83D\uDCC8 vertical and horizontal \uD83D\uDCDC removes document scroll bar maintaining it space ✅ support nested scrollable elements \uD83D\uDD73 supports react-portals (uses React Event system) ☠️ it could block literally any scroll anywhere Usage Just wrap content, which should be scrollable, and everything else would not. import {RemoveScroll} from 'react-remove-scroll'; <RemoveScroll> Only this content would be scrollable </RemoveScroll> RemoveScroll accept following props children [enabled] - activate or deactivate component behaviour without removing it. [allowPinchZoom=false] - enabled \"pinch-n-zoom\" behavior. By default it might be prevented. However - pinch and zoom might break \"scroll isolation\", and disabled by default. [noIsolation=false] - disables outer event capturing. Event capturing is React friendly and unlikely be a problem. But if you are using shadowbox of some sort - you dont need it. [inert=false] - ☠️(be careful) disables events the rest of page completely using pointer-events except the Lock(+shards). React portals not friendly, might lead to production issues. Enable only for rare cases, when you have to disable scrollbars somewhere on the page(except body, Lock and shards). [forwardProps] - will forward all props to the children [className] - className for an internal div [removeScrollBar] - to control scroll bar removal. Set to false, if you prefer to keep it (wheel and touch scroll is still disabled). Size (\uD83E\uDDE9 full) 1.7kb after compression (excluding tslib). (\uD83D\uDC41 UI) 400b, visual elements only (\uD83D\uDE97 sidecar) 1.5kb, side effects import {sidecar} from \"react-remove-scroll\"; import {RemoveScroll} from 'react-remove-scroll/UI'; const sidecar = sidecar(() => import('react-remove-scroll/sidecar')); <RemoveScroll sideCar={sidecar}> Will load logic from a sidecar when needed </RemoveScroll> Consider setting -webkit-overflow-scrolling: touch; on a document level for a proper mobile experience. Internal div By default RemoveScroll will create a div to handle and capture events. You may specify className for it, if you need, or remove it. The following code samples will produce the same output <RemoveScroll className=\"scroll\"> Only this content would be scrollable </RemoveScroll> <RemoveScroll forwardProps> <div className=\"scroll\"> //RemoveScroll will inject props to this div Only this content would be scrollable </div> </RemoveScroll> Pick the first one if you don't need a second. Position:fixed elements To properly size these elements please add a special className to them. import {RemoveScroll} from 'react-remove-scroll'; // to make \"width: 100%\" <div className={cx(classWithPositionFixed, RemoveScroll.classNames.fullWidth)} /> // to make \"right:0\" <div className={cx(classWithPositionFixed, RemoveScroll.classNames.zeroRight)} /> See react-remove-scroll-bar documentation for details. More than one lock When stacked more is active (default) only one (last) component would be active. Over isolation That could happen - you disable scroll on the body, you are suppressing all scroll and wheel events, and you are ghosting the rest of the page by the inert prop. Only something inside Lock does exists for the browser, and that might be less than you expected. Dont forget about shard, dont forget - inert is not portals friendly, dont forget - you dont need over isolation in most of the cases. just be careful! Performance To do the job this library setup non passive event listener. Chrome dev tools would complain about it, as a performance no-op. We have to use synchronous scroll/touch handler, and it may affect scrolling performance. Consider using noIsolation mode, if you have large scrollable areas. Supported React versions v1 supports React 15/16 v2 requires 16.8.0+ (hooks) Scroll-Locky This is a refactoring of another library - react-scroll-locky - to make package smaller and more react-portals friendly. See also react-focus-on - Finite Modal creator (uses Scroll-Locky) underneath. react-locky - React event canceler react-scrolllock - React scroll lock scroll-lock - DOM scroll lock body-scroll-lock - DOM scroll lock This package is relative smaller(1), more react friendly(2), works with non zero body margins(3), and has a better \"overscroll\" management. License MIT"
  },
  "src/frontend/app-client/node_modules/react-router-devtools/README.html": {
    "href": "src/frontend/app-client/node_modules/react-router-devtools/README.html",
    "title": "react-router-devtools",
    "summary": "react-router-devtools react-router-devtools is an open-source package designed to enhance your development workflow when working with React Router v7+, a full-stack JavaScript framework for building web applications. This package provides a user-friendly interface consisting of three tabs, Active Page, Terminal, Settings, Errors, Network and Routes, along with a side tab called Timeline. With react-router-devtools, you can efficiently monitor and manage various aspects of your React Router v7+ projects, including page information, URL parameters, server responses, loader data, routes, and more. You can also track down hydration issues with the Errors tab and view your routes in a tree/list view with the Routes tab. Network tab is a powerful tool for tracing all your network requests and see what's happening under the hood. You can see all the requests in real-time, with the ability to see if they are aborted, if they are cached, and if they are successful or not. Remix Development Tools This repository used to be called remix-development-tools, but we decided to rename it to react-router-devtools to better reflect the fact that it's a package for React Router v7+ and not just for Remix. If you're looking for the old version of this package, you can find it here. And the detailed documentation can be found here. Documentation Detailed documentation can be found here: https://remix-development-tools.fly.dev/ Getting Started Install the package via npm: npm install react-router-devtools -D import { reactRouterDevTools } from \"react-router-devtools\"; // Add it to your plugins array in vite.config.js export default defineConfig({ plugins: [reactRouterDevTools(), reactRouter(), tsconfigPaths()], }); That's it, you're done! CloudFlare If you're trying to spin it up on CF, try adding this to your optimizeDeps in your vite.config.js file: optimizeDeps: { include: [ // other optimized deps \"beautify\", \"react-diff-viewer-continued\", \"classnames\", \"@bkrem/react-transition-group\", ], }, Support If you like react-router-devtools consider starring the repository or donating via Github sponsors. If you have any questions, comments, or suggestions, please feel free to reach out! License react-router-devtools is open-source software released under the MIT License. Acknowledgments React Router Devtools was inspired by the React Router v7 and aims to enhance the development experience for React Router v7+ users. Feel free to explore React Router Devtools, and we hope it significantly improves your React Router development process. If you encounter any issues or have suggestions for enhancements, please don't hesitate to open an issue on our GitHub repository. Happy Remixing! Thanks Thanks to all the contributors on this project and the support to the community. You guys are awesome! Devoted to my loving wife and my little late bird Kiira who helped me initially build out these tools by keeping me company and being my rubber duck, she will forever be my best friend. In loving memory of my late Grandfather, who taught me to always be curious, never stop learning, and to always be kind to others, and my late Grandmother who always encouraged me to learn new things, and stand up for the things I believe in."
  },
  "src/frontend/app-client/node_modules/react-router/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/react-router/CHANGELOG.html",
    "title": "react-router",
    "summary": "react-router 7.5.0 Minor Changes Add granular object-based API for route.lazy to support lazy loading of individual route properties, for example: (#13294) createBrowserRouter([ { path: \"/show/:showId\", lazy: { loader: async () => (await import(\"./show.loader.js\")).loader, action: async () => (await import(\"./show.action.js\")).action, Component: async () => (await import(\"./show.component.js\")).Component, }, }, ]); Breaking change for route.unstable_lazyMiddleware consumers The route.unstable_lazyMiddleware property is no longer supported. If you want to lazily load middleware, you must use the new object-based route.lazy API with route.lazy.unstable_middleware, for example: createBrowserRouter([ { path: \"/show/:showId\", lazy: { unstable_middleware: async () => (await import(\"./show.middleware.js\")).middleware, // etc. }, }, ]); Patch Changes Introduce unstable_subResourceIntegrity future flag that enables generation of an importmap with integrity for the scripts that will be loaded by the browser. (#13163) 7.4.1 Patch Changes Fix types on unstable_MiddlewareFunction to avoid type errors when a middleware doesn't return a value (#13311) Dedupe calls to route.lazy functions (#13260) Add support for route.unstable_lazyMiddleware function to allow lazy loading of middleware logic. (#13210) Breaking change for unstable_middleware consumers The route.unstable_middleware property is no longer supported in the return value from route.lazy. If you want to lazily load middleware, you must use route.unstable_lazyMiddleware. 7.4.0 Patch Changes Fix root loader data on initial load redirects in SPA mode (#13222) Load ancestor pathless/index routes in lazy route discovery for upwards non-eager-discoery routing (#13203) Fix shouldRevalidate behavior for clientLoader-only routes in ssr:true apps (#13221) UNSTABLE: Fix RequestHandler loadContext parameter type when middleware is enabled (#13204) UNSTABLE: Update Route.unstable_MiddlewareFunction to have a return value of Response | undefined instead of Response | void becaue you should not return anything if you aren't returning the Response (#13199) UNSTABLE(BREAKING): If a middleware throws an error, ensure we only bubble the error itself via next() and are no longer leaking the MiddlewareError implementation detail (#13180) 7.3.0 Minor Changes Add fetcherKey as a parameter to patchRoutesOnNavigation (#13061) In framework mode, Lazy Route Discovery will now detect manifest version mismatches after a new deploy On navigations to undiscovered routes, this mismatch will trigger a document reload of the destination path On fetcher calls to undiscovered routes, this mismatch will trigger a document reload of the current path Patch Changes Skip resource route flow in dev server in SPA mode (#13113) Support middleware on routes (unstable) (#12941) Middleware is implemented behind a future.unstable_middleware flag. To enable, you must enable the flag and the types in your react-router-config.ts file: import type { Config } from \"@react-router/dev/config\"; import type { Future } from \"react-router\"; declare module \"react-router\" { interface Future { unstable_middleware: true; // \uD83D\uDC48 Enable middleware types } } export default { future: { unstable_middleware: true, // \uD83D\uDC48 Enable middleware }, } satisfies Config; ⚠️ Middleware is unstable and should not be adopted in production. There is at least one known de-optimization in route module loading for clientMiddleware that we will be addressing this before a stable release. ⚠️ Enabling middleware contains a breaking change to the context parameter passed to your loader/action functions - see below for more information. Once enabled, routes can define an array of middleware functions that will run sequentially before route handlers run. These functions accept the same parameters as loader/action plus an additional next parameter to run the remaining data pipeline. This allows middlewares to perform logic before and after handlers execute. // Framework mode export const unstable_middleware = [serverLogger, serverAuth]; // server export const unstable_clientMiddleware = [clientLogger]; // client // Library mode const routes = [ { path: \"/\", // Middlewares are client-side for library mode SPA's unstable_middleware: [clientLogger, clientAuth], loader: rootLoader, Component: Root, }, ]; Here's a simple example of a client-side logging middleware that can be placed on the root route: const clientLogger: Route.unstable_ClientMiddlewareFunction = async ( { request }, next ) => { let start = performance.now(); // Run the remaining middlewares and all route loaders await next(); let duration = performance.now() - start; console.log(`Navigated to ${request.url} (${duration}ms)`); }; Note that in the above example, the next/middleware functions don't return anything. This is by design as on the client there is no \"response\" to send over the network like there would be for middlewares running on the server. The data is all handled behind the scenes by the stateful router. For a server-side middleware, the next function will return the HTTP Response that React Router will be sending across the wire, thus giving you a chance to make changes as needed. You may throw a new response to short circuit and respond immediately, or you may return a new or altered response to override the default returned by next(). const serverLogger: Route.unstable_MiddlewareFunction = async ( { request, params, context }, next ) => { let start = performance.now(); // \uD83D\uDC47 Grab the response here let res = await next(); let duration = performance.now() - start; console.log(`Navigated to ${request.url} (${duration}ms)`); // \uD83D\uDC47 And return it here (optional if you don't modify the response) return res; }; You can throw a redirect from a middleware to short circuit any remaining processing: import { sessionContext } from \"../context\"; const serverAuth: Route.unstable_MiddlewareFunction = ( { request, params, context }, next ) => { let session = context.get(sessionContext); let user = session.get(\"user\"); if (!user) { session.set(\"returnTo\", request.url); throw redirect(\"/login\", 302); } }; Note that in cases like this where you don't need to do any post-processing you don't need to call the next function or return a Response. Here's another example of using a server middleware to detect 404s and check the CMS for a redirect: const redirects: Route.unstable_MiddlewareFunction = async ({ request, next, }) => { // attempt to handle the request let res = await next(); // if it's a 404, check the CMS for a redirect, do it last // because it's expensive if (res.status === 404) { let cmsRedirect = await checkCMSRedirects(request.url); if (cmsRedirect) { throw redirect(cmsRedirect, 302); } } return res; }; context parameter When middleware is enabled, your application will use a different type of context parameter in your loaders and actions to provide better type safety. Instead of AppLoadContext, context will now be an instance of ContextProvider that you can use with type-safe contexts (similar to React.createContext): import { unstable_createContext } from \"react-router\"; import { Route } from \"./+types/root\"; import type { Session } from \"./sessions.server\"; import { getSession } from \"./sessions.server\"; let sessionContext = unstable_createContext<Session>(); const sessionMiddleware: Route.unstable_MiddlewareFunction = ({ context, request, }) => { let session = await getSession(request); context.set(sessionContext, session); // ^ must be of type Session }; // ... then in some downstream middleware const loggerMiddleware: Route.unstable_MiddlewareFunction = ({ context, request, }) => { let session = context.get(sessionContext); // ^ typeof Session console.log(session.get(\"userId\"), request.method, request.url); }; // ... or some downstream loader export function loader({ context }: Route.LoaderArgs) { let session = context.get(sessionContext); let profile = await getProfile(session.get(\"userId\")); return { profile }; } If you are using a custom server with a getLoadContext function, the return value for initial context values passed from the server adapter layer is no longer an object and should now return an unstable_InitialContext (Map<RouterContext, unknown>): let adapterContext = unstable_createContext<MyAdapterContext>(); function getLoadContext(req, res): unstable_InitialContext { let map = new Map(); map.set(adapterContext, getAdapterContext(req)); return map; } Fix types for loaderData and actionData that contained Records (#13139) UNSTABLE(BREAKING): unstable_SerializesTo added a way to register custom serialization types in Single Fetch for other library and framework authors like Apollo. It was implemented with branded type whose branded property that was made optional so that casting arbitrary values was easy: // without the brand being marked as optional let x1 = 42 as unknown as unstable_SerializesTo<number>; // ^^^^^^^^^^ // with the brand being marked as optional let x2 = 42 as unstable_SerializesTo<number>; However, this broke type inference in loaderData and actionData for any Record types as those would now (incorrectly) match unstable_SerializesTo. This affected all users, not just those that depended on unstable_SerializesTo. To fix this, the branded property of unstable_SerializesTo is marked as required instead of optional. For library and framework authors using unstable_SerializesTo, you may need to add as unknown casts before casting to unstable_SerializesTo. [REMOVE] Remove middleware depth logic and always call middlware for all matches (#13172) Fix single fetch _root.data requests when a basename is used (#12898) Add context support to client side data routers (unstable) (#12941) Your application loader and action functions on the client will now receive a context parameter. This is an instance of unstable_RouterContextProvider that you use with type-safe contexts (similar to React.createContext) and is most useful with the corresponding middleware/clientMiddleware API's: import { unstable_createContext } from \"react-router\"; type User = { /*...*/ }; let userContext = unstable_createContext<User>(); function sessionMiddleware({ context }) { let user = await getUser(); context.set(userContext, user); } // ... then in some downstream loader function loader({ context }) { let user = context.get(userContext); let profile = await getProfile(user.id); return { profile }; } Similar to server-side requests, a fresh context will be created per navigation (or fetcher call). If you have initial data you'd like to populate in the context for every request, you can provide an unstable_getContext function at the root of your app: Library mode - createBrowserRouter(routes, { unstable_getContext }) Framework mode - <HydratedRouter unstable_getContext> This function should return an value of type unstable_InitialContext which is a Map<unstable_RouterContext, unknown> of context's and initial values: const loggerContext = unstable_createContext<(...args: unknown[]) => void>(); function logger(...args: unknown[]) { console.log(new Date.toISOString(), ...args); } function unstable_getContext() { let map = new Map(); map.set(loggerContext, logger); return map; } 7.2.0 Minor Changes New type-safe href utility that guarantees links point to actual paths in your app (#13012) import { href } from \"react-router\"; export default function Component() { const link = href(\"/blog/:slug\", { slug: \"my-first-post\" }); return ( <main> <Link to={href(\"/products/:id\", { id: \"asdf\" })} /> <NavLink to={href(\"/:lang?/about\", { lang: \"en\" })} /> </main> ); } Patch Changes Fix typegen for repeated params (#13012) In React Router, path parameters are keyed by their name. So for a path pattern like /a/:id/b/:id?/c/:id, the last :id will set the value for id in useParams and the params prop. For example, /a/1/b/2/c/3 will result in the value { id: 3 } at runtime. Previously, generated types for params incorrectly modeled repeated params with an array. So /a/1/b/2/c/3 generated a type like { id: [1,2,3] }. To be consistent with runtime behavior, the generated types now correctly model the \"last one wins\" semantics of path parameters. So /a/1/b/2/c/3 now generates a type like { id: 3 }. Don't apply Single Fetch revalidation de-optimization when in SPA mode since there is no server HTTP request (#12948) Properly handle revalidations to across a prerender/SPA boundary (#13021) In \"hybrid\" applications where some routes are pre-rendered and some are served from a SPA fallback, we need to avoid making .data requests if the path wasn't pre-rendered because the request will 404 We don't know all the pre-rendered paths client-side, however: All loader data in ssr:false mode is static because it's generated at build time A route must use a clientLoader to do anything dynamic Therefore, if a route only has a loader and not a clientLoader, we disable revalidation by default because there is no new data to retrieve We short circuit and skip single fetch .data request logic if there are no server loaders with shouldLoad=true in our single fetch dataStrategy This ensures that the route doesn't cause a .data request that would 404 after a submission Error at build time in ssr:false + prerender apps for the edge case scenario of: (#13021) A parent route has only a loader (does not have a clientLoader) The parent route is pre-rendered The parent route has children routes which are not prerendered This means that when the child paths are loaded via the SPA fallback, the parent won't have any loaderData because there is no server on which to run the loader This can be resolved by either adding a parent clientLoader or pre-rendering the child paths If you add a clientLoader, calling the serverLoader() on non-prerendered paths will throw a 404 Add unstable support for splitting route modules in framework mode via future.unstable_splitRouteModules (#11871) Add unstable_SerializesTo brand type for library authors to register types serializable by React Router's streaming format (turbo-stream) (ab5b05b02) Align dev server behavior with static file server behavior when ssr:false is set (#12948) When no prerender config exists, only SSR down to the root HydrateFallback (SPA Mode) When a prerender config exists but the current path is not prerendered, only SSR down to the root HydrateFallback (SPA Fallback) Return a 404 on .data requests to non-pre-rendered paths Improve prefetch performance of CSS side effects in framework mode (#12889) Disable Lazy Route Discovery for all ssr:false apps and not just \"SPA Mode\" because there is no runtime server to serve the search-param-configured __manifest requests (#12894) We previously only disabled this for \"SPA Mode\" which is ssr:false and no prerender config but we realized it should apply to all ssr:false apps, including those prerendering multiple pages In those prerender scenarios we would prerender the /__manifest file assuming the static file server would serve it but that makes some unneccesary assumptions about the static file server behaviors Properly handle interrupted manifest requests in lazy route discovery (#12915) 7.1.5 Patch Changes Fix regression introduced in 7.1.4 via #12800 that caused issues navigating to hash routes inside splat routes for applications using Lazy Route Discovery (patchRoutesOnNavigation) (#12927) 7.1.4 Patch Changes Internal reorg to clean up some duplicated route module types (#12799) Properly handle status codes that cannot have a body in single fetch responses (204, etc.) (#12760) Stop erroring on resource routes that return raw strings/objects and instead serialize them as text/plain or application/json responses (#12848) This only applies when accessed as a resource route without the .data extension When accessed from a Single Fetch .data request, they will still be encoded via turbo-stream Optimize Lazy Route Discovery path discovery to favor a single querySelectorAll call at the body level instead of many calls at the sub-tree level (#12731) Properly bubble headers as errorHeaders when throwing a data() result (#12846) Avoid duplication of Set-Cookie headers could be duplicated if also returned from headers Optimize route matching by skipping redundant matchRoutes calls when possible (#12800) 7.1.3 No changes 7.1.2 Patch Changes Fix issue with fetcher data cleanup in the data layer on fetcher unmount (#12681) Do not rely on symbol for filtering out redirect responses from loader data (#12694) Previously, some projects were getting type checking errors like: error TS4058: Return type of exported function has or is using name 'redirectSymbol' from external module \"node_modules/...\" but cannot be named. Now that symbols are not used for the redirect response type, these errors should no longer be present. 7.1.1 No changes 7.1.0 Patch Changes Throw unwrapped single fetch redirect to align with pre-single fetch behavior (#12506) Ignore redirects when inferring loader data types (#12527) Remove <Link prefetch> warning which suffers from false positives in a lazy route discovery world (#12485) 7.0.2 Patch Changes temporarily only use one build in export map so packages can have a peer dependency on react router (#12437) Generate wide matches and params types for current route and child routes (#12397) At runtime, matches includes child route matches and params include child route path parameters. But previously, we only generated types for parent routes in matches; for params, we only considered the parent routes and the current route. To align our generated types more closely to the runtime behavior, we now generate more permissive, wider types when accessing child route information. 7.0.1 No changes 7.0.0 Major Changes Remove the original defer implementation in favor of using raw promises via single fetch and turbo-stream. This removes these exports from React Router: (#11744) defer AbortedDeferredError type TypedDeferredData UNSAFE_DeferredData UNSAFE_DEFERRED_SYMBOL, Collapse @remix-run/router into react-router (#11505) Collapse react-router-dom into react-router Collapse @remix-run/server-runtime into react-router Collapse @remix-run/testing into react-router Remove single fetch future flag. (#11522) Drop support for Node 16, React Router SSR now requires Node 18 or higher (#11391) Remove future.v7_startTransition flag (#11696) Expose the underlying router promises from the following APIs for compsition in React 19 APIs: (#11521) useNavigate() useSubmit useFetcher().load useFetcher().submit useRevalidator.revalidate Remove future.v7_normalizeFormMethod future flag (#11697) For Remix consumers migrating to React Router, the crypto global from the Web Crypto API is now required when using cookie and session APIs. This means that the following APIs are provided from react-router rather than platform-specific packages: (#11837) createCookie createCookieSessionStorage createMemorySessionStorage createSessionStorage For consumers running older versions of Node, the installGlobals function from @remix-run/node has been updated to define globalThis.crypto, using Node's require('node:crypto').webcrypto implementation. Since platform-specific packages no longer need to implement this API, the following low-level APIs have been removed: createCookieFactory createSessionStorageFactory createCookieSessionStorageFactory createMemorySessionStorageFactory Imports/Exports cleanup (#11840) Removed the following exports that were previously public API from @remix-run/router types AgnosticDataIndexRouteObject AgnosticDataNonIndexRouteObject AgnosticDataRouteMatch AgnosticDataRouteObject AgnosticIndexRouteObject AgnosticNonIndexRouteObject AgnosticRouteMatch AgnosticRouteObject TrackedPromise unstable_AgnosticPatchRoutesOnMissFunction Action -> exported as NavigationType via react-router Router exported as DataRouter to differentiate from RR's <Router> API getToPathname (@private) joinPaths (@private) normalizePathname (@private) resolveTo (@private) stripBasename (@private) createBrowserHistory -> in favor of createBrowserRouter createHashHistory -> in favor of createHashRouter createMemoryHistory -> in favor of createMemoryRouter createRouter createStaticHandler -> in favor of wrapper createStaticHandler in RR Dom getStaticContextFromError Removed the following exports that were previously public API from react-router Hash Pathname Search update minimum node version to 18 (#11690) Remove future.v7_prependBasename from the ionternalized @remix-run/router package (#11726) Migrate Remix type generics to React Router (#12180) These generics are provided for Remix v2 migration purposes These generics and the APIs they exist on should be considered informally deprecated in favor of the new Route.* types Anyone migrating from React Router v6 should probably not leverage these new generics and should migrate straight to the Route.* types For React Router v6 users, these generics are new and should not impact your app, with one exception useFetcher previously had an optional generic (used primarily by Remix v2) that expected the data type This has been updated in v7 to expect the type of the function that generates the data (i.e., typeof loader/typeof action) Therefore, you should update your usages: ❌ useFetcher<LoaderData>() ✅ useFetcher<typeof loader>() Remove future.v7_throwAbortReason from internalized @remix-run/router package (#11728) Add exports field to all packages (#11675) node package no longer re-exports from react-router (#11702) renamed RemixContext to FrameworkContext (#11705) updates the minimum React version to 18 (#11689) PrefetchPageDescriptor replaced by PageLinkDescriptor (#11960) Consolidate types previously duplicated across @remix-run/router, @remix-run/server-runtime, and @remix-run/react now that they all live in react-router (#12177) Examples: LoaderFunction, LoaderFunctionArgs, ActionFunction, ActionFunctionArgs, DataFunctionArgs, RouteManifest, LinksFunction, Route, EntryRoute The RouteManifest type used by the \"remix\" code is now slightly stricter because it is using the former @remix-run/router RouteManifest Record<string, Route> -> Record<string, Route | undefined> Removed AppData type in favor of inlining unknown in the few locations it was used Removed ServerRuntimeMeta* types in favor of the Meta* types they were duplicated from Remove the future.v7_partialHydration flag (#11725) This also removes the <RouterProvider fallbackElement> prop To migrate, move the fallbackElement to a hydrateFallbackElement/HydrateFallback on your root route Also worth nothing there is a related breaking changer with this future flag: Without future.v7_partialHydration (when using fallbackElement), state.navigation was populated during the initial load With future.v7_partialHydration, state.navigation remains in an \"idle\" state during the initial load Remove v7_relativeSplatPath future flag (#11695) Drop support for Node 18, update minimum Node vestion to 20 (#12171) Remove installGlobals() as this should no longer be necessary Remove remaining future flags (#11820) React Router v7_skipActionErrorRevalidation Remix v3_fetcherPersist, v3_relativeSplatPath, v3_throwAbortReason rename createRemixStub to createRoutesStub (#11692) Remove @remix-run/router deprecated detectErrorBoundary option in favor of mapRouteProperties (#11751) Add react-router/dom subpath export to properly enable react-dom as an optional peerDependency (#11851) This ensures that we don't blindly import ReactDOM from \"react-dom\" in <RouterProvider> in order to access ReactDOM.flushSync(), since that would break createMemoryRouter use cases in non-DOM environments DOM environments should import from react-router/dom to get the proper component that makes ReactDOM.flushSync() available: If you are using the Vite plugin, use this in your entry.client.tsx: import { HydratedRouter } from 'react-router/dom' If you are not using the Vite plugin and are manually calling createBrowserRouter/createHashRouter: import { RouterProvider } from \"react-router/dom\" Remove future.v7_fetcherPersist flag (#11731) Update cookie dependency to ^1.0.1 - please see the release notes for any breaking changes (#12172) Minor Changes Add support for prerender config in the React Router vite plugin, to support existing SSG use-cases (#11539) You can use the prerender config to pre-render your .html and .data files at build time and then serve them statically at runtime (either from a running server or a CDN) prerender can either be an array of string paths, or a function (sync or async) that returns an array of strings so that you can dynamically generate the paths by talking to your CMS, etc. // react-router.config.ts import type { Config } from \"@react-router/dev/config\"; export default { async prerender() { let slugs = await fakeGetSlugsFromCms(); // Prerender these paths into `.html` files at build time, and `.data` // files if they have loaders return [\"/\", \"/about\", ...slugs.map((slug) => `/product/${slug}`)]; }, } satisfies Config; async function fakeGetSlugsFromCms() { await new Promise((r) => setTimeout(r, 1000)); return [\"shirt\", \"hat\"]; } Params, loader data, and action data as props for route component exports (#11961) export default function Component({ params, loaderData, actionData }) {} export function HydrateFallback({ params }) {} export function ErrorBoundary({ params, loaderData, actionData }) {} Remove duplicate RouterProvider impliementations (#11679) Typesafety improvements (#12019) React Router now generates types for each of your route modules. You can access those types by importing them from ./+types.<route filename without extension>. For example: // app/routes/product.tsx import type * as Route from \"./+types.product\"; export function loader({ params }: Route.LoaderArgs) {} export default function Component({ loaderData }: Route.ComponentProps) {} This initial implementation targets type inference for: Params : Path parameters from your routing config in routes.ts including file-based routing LoaderData : Loader data from loader and/or clientLoader within your route module ActionData : Action data from action and/or clientAction within your route module In the future, we plan to add types for the rest of the route module exports: meta, links, headers, shouldRevalidate, etc. We also plan to generate types for typesafe Links: <Link to=\"/products/:id\" params={{ id: 1 }} /> // ^^^^^^^^^^^^^ ^^^^^^^^^ // typesafe `to` and `params` based on the available routes in your app Check out our docs for more: Explanations > Type Safety How-To > Setting up type safety Stabilize unstable_dataStrategy (#11969) Stabilize unstable_patchRoutesOnNavigation (#11970) Patch Changes No changes (506329c4e) chore: re-enable development warnings through a development exports condition. (#12269) Remove unstable upload handler. (#12015) Remove unneeded dependency on @web3-storage/multipart-parser (#12274) Fix redirects returned from loaders/actions using data() (#12021) fix(react-router): (v7) fix static prerender of non-ascii characters (#12161) Replace substr with substring (#12080) Remove the deprecated json utility (#12146) You can use Response.json if you still need to construct JSON responses in your app Remove unneeded dependency on source-map (#12275) 6.28.0 Minor Changes Log deprecation warnings for v7 flags (#11750) Add deprecation warnings to json/defer in favor of returning raw objects These methods will be removed in React Router v7 Patch Changes Update JSDoc URLs for new website structure (add /v6/ segment) (#12141) Updated dependencies: @remix-run/router@1.21.0 6.27.0 Minor Changes Stabilize unstable_patchRoutesOnNavigation (#11973) Add new PatchRoutesOnNavigationFunctionArgs type for convenience (#11967) Stabilize unstable_dataStrategy (#11974) Stabilize the unstable_flushSync option for navigations and fetchers (#11989) Stabilize the unstable_viewTransition option for navigations and the corresponding unstable_useViewTransitionState hook (#11989) Patch Changes Fix bug when submitting to the current contextual route (parent route with an index child) when an ?index param already exists from a prior submission (#12003) Fix useFormAction bug - when removing ?index param it would not keep other non-Remix index params (#12003) Fix types for RouteObject within PatchRoutesOnNavigationFunction's patch method so it doesn't expect agnostic route objects passed to patch (#11967) Updated dependencies: @remix-run/router@1.20.0 6.26.2 Patch Changes Updated dependencies: @remix-run/router@1.19.2 6.26.1 Patch Changes Rename unstable_patchRoutesOnMiss to unstable_patchRoutesOnNavigation to match new behavior (#11888) Updated dependencies: @remix-run/router@1.19.1 6.26.0 Minor Changes Add a new replace(url, init?) alternative to redirect(url, init?) that performs a history.replaceState instead of a history.pushState on client-side navigation redirects (#11811) Patch Changes Fix initial hydration behavior when using future.v7_partialHydration along with unstable_patchRoutesOnMiss (#11838) During initial hydration, router.state.matches will now include any partial matches so that we can render ancestor HydrateFallback components Updated dependencies: @remix-run/router@1.19.0 6.25.1 No significant changes to this package were made in this release. See the repo CHANGELOG.md for an overview of all changes in v6.25.1. 6.25.0 Minor Changes Stabilize future.unstable_skipActionErrorRevalidation as future.v7_skipActionErrorRevalidation (#11769) When this flag is enabled, actions will not automatically trigger a revalidation if they return/throw a Response with a 4xx/5xx status code You may still opt-into revalidation via shouldRevalidate This also changes shouldRevalidate's unstable_actionStatus parameter to actionStatus Patch Changes Fix regression and properly decode paths inside useMatch so matches/params reflect decoded params (#11789) Updated dependencies: @remix-run/router@1.18.0 6.24.1 Patch Changes When using future.v7_relativeSplatPath, properly resolve relative paths in splat routes that are children of pathless routes (#11633) Updated dependencies: @remix-run/router@1.17.1 6.24.0 Minor Changes Add support for Lazy Route Discovery (a.k.a. Fog of War) (#11626) RFC: https://github.com/remix-run/react-router/discussions/11113 unstable_patchRoutesOnMiss docs: https://reactrouter.com/v6/routers/create-browser-router Patch Changes Updated dependencies: @remix-run/router@1.17.0 6.23.1 Patch Changes allow undefined to be resolved with <Await> (#11513) Updated dependencies: @remix-run/router@1.16.1 6.23.0 Minor Changes Add a new unstable_dataStrategy configuration option (#11098) This option allows Data Router applications to take control over the approach for executing route loaders and actions The default implementation is today's behavior, to fetch all loaders in parallel, but this option allows users to implement more advanced data flows including Remix single-fetch, middleware/context APIs, automatic loader caching, and more Patch Changes Updated dependencies: @remix-run/router@1.16.0 6.22.3 Patch Changes Updated dependencies: @remix-run/router@1.15.3 6.22.2 Patch Changes Updated dependencies: @remix-run/router@1.15.2 6.22.1 Patch Changes Fix encoding/decoding issues with pre-encoded dynamic parameter values (#11199) Updated dependencies: @remix-run/router@1.15.1 6.22.0 Patch Changes Updated dependencies: @remix-run/router@1.15.0 6.21.3 Patch Changes Remove leftover unstable_ prefix from Blocker/BlockerFunction types (#11187) 6.21.2 Patch Changes Updated dependencies: @remix-run/router@1.14.2 6.21.1 Patch Changes Fix bug with route.lazy not working correctly on initial SPA load when v7_partialHydration is specified (#11121) Updated dependencies: @remix-run/router@1.14.1 6.21.0 Minor Changes Add a new future.v7_relativeSplatPath flag to implement a breaking bug fix to relative routing when inside a splat route. (#11087) This fix was originally added in #10983 and was later reverted in #11078 because it was determined that a large number of existing applications were relying on the buggy behavior (see #11052) The Bug The buggy behavior is that without this flag, the default behavior when resolving relative paths is to ignore any splat (*) portion of the current route path. The Background This decision was originally made thinking that it would make the concept of nested different sections of your apps in <Routes> easier if relative routing would replace the current splat: <BrowserRouter> <Routes> <Route path=\"/\" element={<Home />} /> <Route path=\"dashboard/*\" element={<Dashboard />} /> </Routes> </BrowserRouter> Any paths like /dashboard, /dashboard/team, /dashboard/projects will match the Dashboard route. The dashboard component itself can then render nested <Routes>: function Dashboard() { return ( <div> <h2>Dashboard</h2> <nav> <Link to=\"/\">Dashboard Home</Link> <Link to=\"team\">Team</Link> <Link to=\"projects\">Projects</Link> </nav> <Routes> <Route path=\"/\" element={<DashboardHome />} /> <Route path=\"team\" element={<DashboardTeam />} /> <Route path=\"projects\" element={<DashboardProjects />} /> </Routes> </div> ); } Now, all links and route paths are relative to the router above them. This makes code splitting and compartmentalizing your app really easy. You could render the Dashboard as its own independent app, or embed it into your large app without making any changes to it. The Problem The problem is that this concept of ignoring part of a path breaks a lot of other assumptions in React Router - namely that \".\" always means the current location pathname for that route. When we ignore the splat portion, we start getting invalid paths when using \".\": // If we are on URL /dashboard/team, and we want to link to /dashboard/team: function DashboardTeam() { // ❌ This is broken and results in <a href=\"/dashboard\"> return <Link to=\".\">A broken link to the Current URL</Link>; // ✅ This is fixed but super unintuitive since we're already at /dashboard/team! return <Link to=\"./team\">A broken link to the Current URL</Link>; } We've also introduced an issue that we can no longer move our DashboardTeam component around our route hierarchy easily - since it behaves differently if we're underneath a non-splat route, such as /dashboard/:widget. Now, our \".\" links will, properly point to ourself inclusive of the dynamic param value so behavior will break from it's corresponding usage in a /dashboard/* route. Even worse, consider a nested splat route configuration: <BrowserRouter> <Routes> <Route path=\"dashboard\"> <Route path=\"*\" element={<Dashboard />} /> </Route> </Routes> </BrowserRouter> Now, a <Link to=\".\"> and a <Link to=\"..\"> inside the Dashboard component go to the same place! That is definitely not correct! Another common issue arose in Data Routers (and Remix) where any <Form> should post to it's own route action if you the user doesn't specify a form action: let router = createBrowserRouter({ path: \"/dashboard\", children: [ { path: \"*\", action: dashboardAction, Component() { // ❌ This form is broken! It throws a 405 error when it submits because // it tries to submit to /dashboard (without the splat value) and the parent // `/dashboard` route doesn't have an action return <Form method=\"post\">...</Form>; }, }, ], }); This is just a compounded issue from the above because the default location for a Form to submit to is itself (\".\") - and if we ignore the splat portion, that now resolves to the parent route. The Solution If you are leveraging this behavior, it's recommended to enable the future flag, move your splat to it's own route, and leverage ../ for any links to \"sibling\" pages: <BrowserRouter> <Routes> <Route path=\"dashboard\"> <Route index path=\"*\" element={<Dashboard />} /> </Route> </Routes> </BrowserRouter> function Dashboard() { return ( <div> <h2>Dashboard</h2> <nav> <Link to=\"..\">Dashboard Home</Link> <Link to=\"../team\">Team</Link> <Link to=\"../projects\">Projects</Link> </nav> <Routes> <Route path=\"/\" element={<DashboardHome />} /> <Route path=\"team\" element={<DashboardTeam />} /> <Route path=\"projects\" element={<DashboardProjects />} /> </Router> </div> ); } This way, . means \"the full current pathname for my route\" in all cases (including static, dynamic, and splat routes) and .. always means \"my parents pathname\". Patch Changes Properly handle falsy error values in ErrorBoundary's (#11071) Updated dependencies: @remix-run/router@1.14.0 6.20.1 Patch Changes Revert the useResolvedPath fix for splat routes due to a large number of applications that were relying on the buggy behavior (see https://github.com/remix-run/react-router/issues/11052#issuecomment-1836589329). We plan to re-introduce this fix behind a future flag in the next minor version. (#11078) Updated dependencies: @remix-run/router@1.13.1 6.20.0 Minor Changes Export the PathParam type from the public API (#10719) Patch Changes Fix bug with resolveTo in splat routes (#11045) This is a follow up to #10983 to handle the few other code paths using getPathContributingMatches This removes the UNSAFE_getPathContributingMatches export from @remix-run/router since we no longer need this in the react-router/react-router-dom layers Updated dependencies: @remix-run/router@1.13.0 6.19.0 Minor Changes Add unstable_flushSync option to useNavigate/useSumbit/fetcher.load/fetcher.submit to opt-out of React.startTransition and into ReactDOM.flushSync for state updates (#11005) Remove the unstable_ prefix from the useBlocker hook as it's been in use for enough time that we are confident in the API. We do not plan to remove the prefix from unstable_usePrompt due to differences in how browsers handle window.confirm that prevent React Router from guaranteeing consistent/correct behavior. (#10991) Patch Changes Fix useActionData so it returns proper contextual action data and not any action data in the tree (#11023) Fix bug in useResolvedPath that would cause useResolvedPath(\".\") in a splat route to lose the splat portion of the URL path. (#10983) ⚠️ This fixes a quite long-standing bug specifically for \".\" paths inside a splat route which incorrectly dropped the splat portion of the URL. If you are relative routing via \".\" inside a splat route in your application you should double check that your logic is not relying on this buggy behavior and update accordingly. Updated dependencies: @remix-run/router@1.12.0 6.18.0 Patch Changes Fix the future prop on BrowserRouter, HashRouter and MemoryRouter so that it accepts a Partial<FutureConfig> instead of requiring all flags to be included. (#10962) Updated dependencies: @remix-run/router@1.11.0 6.17.0 Patch Changes Fix RouterProvider future prop type to be a Partial<FutureConfig> so that not all flags must be specified (#10900) Updated dependencies: @remix-run/router@1.10.0 6.16.0 Minor Changes In order to move towards stricter TypeScript support in the future, we're aiming to replace current usages of any with unknown on exposed typings for user-provided data. To do this in Remix v2 without introducing breaking changes in React Router v6, we have added generics to a number of shared types. These continue to default to any in React Router and are overridden with unknown in Remix. In React Router v7 we plan to move these to unknown as a breaking change. (#10843) Location now accepts a generic for the location.state value ActionFunctionArgs/ActionFunction/LoaderFunctionArgs/LoaderFunction now accept a generic for the context parameter (only used in SSR usages via createStaticHandler) The return type of useMatches (now exported as UIMatch) accepts generics for match.data and match.handle - both of which were already set to unknown Move the @private class export ErrorResponse to an UNSAFE_ErrorResponseImpl export since it is an implementation detail and there should be no construction of ErrorResponse instances in userland. This frees us up to export a type ErrorResponse which correlates to an instance of the class via InstanceType. Userland code should only ever be using ErrorResponse as a type and should be type-narrowing via isRouteErrorResponse. (#10811) Export ShouldRevalidateFunctionArgs interface (#10797) Removed private/internal APIs only required for the Remix v1 backwards compatibility layer and no longer needed in Remix v2 (_isFetchActionRedirect, _hasFetcherDoneAnything) (#10715) Patch Changes Updated dependencies: @remix-run/router@1.9.0 6.15.0 Minor Changes Add's a new redirectDocument() function which allows users to specify that a redirect from a loader/action should trigger a document reload (via window.location) instead of attempting to navigate to the redirected location via React Router (#10705) Patch Changes Ensure useRevalidator is referentially stable across re-renders if revalidations are not actively occurring (#10707) Updated dependencies: @remix-run/router@1.8.0 6.14.2 Patch Changes Updated dependencies: @remix-run/router@1.7.2 6.14.1 Patch Changes Fix loop in unstable_useBlocker when used with an unstable blocker function (#10652) Fix issues with reused blockers on subsequent navigations (#10656) Updated dependencies: @remix-run/router@1.7.1 6.14.0 Patch Changes Strip basename from locations provided to unstable_useBlocker functions to match useLocation (#10573) Fix generatePath when passed a numeric 0 value parameter (#10612) Fix unstable_useBlocker key issues in StrictMode (#10573) Fix tsc --skipLibCheck:false issues on React 17 (#10622) Upgrade typescript to 5.1 (#10581) Updated dependencies: @remix-run/router@1.7.0 6.13.0 Minor Changes Move React.startTransition usage behind a future flag to avoid issues with existing incompatible Suspense usages. We recommend folks adopting this flag to be better compatible with React concurrent mode, but if you run into issues you can continue without the use of startTransition until v7. Issues usually boils down to creating net-new promises during the render cycle, so if you run into issues you should either lift your promise creation out of the render cycle or put it behind a useMemo. (#10596) Existing behavior will no longer include React.startTransition: <BrowserRouter> <Routes>{/*...*/}</Routes> </BrowserRouter> <RouterProvider router={router} /> If you wish to enable React.startTransition, pass the future flag to your component: <BrowserRouter future={{ v7_startTransition: true }}> <Routes>{/*...*/}</Routes> </BrowserRouter> <RouterProvider router={router} future={{ v7_startTransition: true }}/> Patch Changes Work around webpack/terser React.startTransition minification bug in production mode (#10588) 6.12.1 [!WARNING] Please use version 6.13.0 or later instead of 6.12.1. This version suffers from a webpack/terser minification issue resulting in invalid minified code in your resulting production bundles which can cause issues in your application. See #10579 for more details. Patch Changes Adjust feature detection of React.startTransition to fix webpack + react 17 compilation error (#10569) 6.12.0 Minor Changes Wrap internal router state updates with React.startTransition if it exists (#10438) Patch Changes Updated dependencies: @remix-run/router@1.6.3 6.11.2 Patch Changes Fix basename duplication in descendant <Routes> inside a <RouterProvider> (#10492) Updated dependencies: @remix-run/router@1.6.2 6.11.1 Patch Changes Fix usage of Component API within descendant <Routes> (#10434) Fix bug when calling useNavigate from <Routes> inside a <RouterProvider> (#10432) Fix usage of <Navigate> in strict mode when using a data router (#10435) Updated dependencies: @remix-run/router@1.6.1 6.11.0 Patch Changes Log loader/action errors to the console in dev for easier stack trace evaluation (#10286) Fix bug preventing rendering of descendant <Routes> when RouterProvider errors existed (#10374) Fix inadvertent re-renders when using Component instead of element on a route definition (#10287) Fix detection of useNavigate in the render cycle by setting the activeRef in a layout effect, allowing the navigate function to be passed to child components and called in a useEffect there. (#10394) Switched from useSyncExternalStore to useState for internal @remix-run/router router state syncing in <RouterProvider>. We found some subtle bugs where router state updates got propagated before other normal useState updates, which could lead to footguns in useEffect calls. (#10377, #10409) Allow useRevalidator() to resolve a loader-driven error boundary scenario (#10369) Avoid unnecessary unsubscribe/resubscribes on router state changes (#10409) When using a RouterProvider, useNavigate/useSubmit/fetcher.submit are now stable across location changes, since we can handle relative routing via the @remix-run/router instance and get rid of our dependence on useLocation(). When using BrowserRouter, these hooks remain unstable across location changes because they still rely on useLocation(). (#10336) Updated dependencies: @remix-run/router@1.6.0 6.10.0 Minor Changes Added support for Future Flags in React Router. The first flag being introduced is future.v7_normalizeFormMethod which will normalize the exposed useNavigation()/useFetcher() formMethod fields as uppercase HTTP methods to align with the fetch() behavior. (#10207) When future.v7_normalizeFormMethod === false (default v6 behavior), useNavigation().formMethod is lowercase useFetcher().formMethod is lowercase When future.v7_normalizeFormMethod === true: useNavigation().formMethod is uppercase useFetcher().formMethod is uppercase Patch Changes Fix route ID generation when using Fragments in createRoutesFromElements (#10193) Updated dependencies: @remix-run/router@1.5.0 6.9.0 Minor Changes React Router now supports an alternative way to define your route element and errorElement fields as React Components instead of React Elements. You can instead pass a React Component to the new Component and ErrorBoundary fields if you choose. There is no functional difference between the two, so use whichever approach you prefer \uD83D\uDE00. You shouldn't be defining both, but if you do Component/ErrorBoundary will \"win\". (#10045) Example JSON Syntax // Both of these work the same: const elementRoutes = [{ path: '/', element: <Home />, errorElement: <HomeError />, }] const componentRoutes = [{ path: '/', Component: Home, ErrorBoundary: HomeError, }] function Home() { ... } function HomeError() { ... } Example JSX Syntax // Both of these work the same: const elementRoutes = createRoutesFromElements( <Route path='/' element={<Home />} errorElement={<HomeError /> } /> ); const componentRoutes = createRoutesFromElements( <Route path='/' Component={Home} ErrorBoundary={HomeError} /> ); function Home() { ... } function HomeError() { ... } Introducing Lazy Route Modules! (#10045) In order to keep your application bundles small and support code-splitting of your routes, we've introduced a new lazy() route property. This is an async function that resolves the non-route-matching portions of your route definition (loader, action, element/Component, errorElement/ErrorBoundary, shouldRevalidate, handle). Lazy routes are resolved on initial load and during the loading or submitting phase of a navigation or fetcher call. You cannot lazily define route-matching properties (path, index, children) since we only execute your lazy route functions after we've matched known routes. Your lazy functions will typically return the result of a dynamic import. // In this example, we assume most folks land on the homepage so we include that // in our critical-path bundle, but then we lazily load modules for /a and /b so // they don't load until the user navigates to those routes let routes = createRoutesFromElements( <Route path=\"/\" element={<Layout />}> <Route index element={<Home />} /> <Route path=\"a\" lazy={() => import(\"./a\")} /> <Route path=\"b\" lazy={() => import(\"./b\")} /> </Route> ); Then in your lazy route modules, export the properties you want defined for the route: export async function loader({ request }) { let data = await fetchData(request); return json(data); } // Export a `Component` directly instead of needing to create a React Element from it export function Component() { let data = useLoaderData(); return ( <> <h1>You made it!</h1> <p>{data}</p> </> ); } // Export an `ErrorBoundary` directly instead of needing to create a React Element from it export function ErrorBoundary() { let error = useRouteError(); return isRouteErrorResponse(error) ? ( <h1> {error.status} {error.statusText} </h1> ) : ( <h1>{error.message || error}</h1> ); } An example of this in action can be found in the examples/lazy-loading-router-provider directory of the repository. \uD83D\uDE4C Huge thanks to @rossipedia for the Initial Proposal and POC Implementation. Updated dependencies: @remix-run/router@1.4.0 Patch Changes Fix generatePath incorrectly applying parameters in some cases (#10078) Improve memoization for context providers to avoid unnecessary re-renders (#9983) 6.8.2 Patch Changes Updated dependencies: @remix-run/router@1.3.3 6.8.1 Patch Changes Remove inaccurate console warning for POP navigations and update active blocker logic (#10030) Updated dependencies: @remix-run/router@1.3.2 6.8.0 Patch Changes Updated dependencies: @remix-run/router@1.3.1 6.7.0 Minor Changes Add unstable_useBlocker hook for blocking navigations within the app's location origin (#9709) Patch Changes Fix generatePath when optional params are present (#9764) Update <Await> to accept ReactNode as children function return result (#9896) Updated dependencies: @remix-run/router@1.3.0 6.6.2 Patch Changes Ensure useId consistency during SSR (#9805) 6.6.1 Patch Changes Updated dependencies: @remix-run/router@1.2.1 6.6.0 Patch Changes Prevent useLoaderData usage in errorElement (#9735) Updated dependencies: @remix-run/router@1.2.0 6.5.0 This release introduces support for Optional Route Segments. Now, adding a ? to the end of any path segment will make that entire segment optional. This works for both static segments and dynamic parameters. Optional Params Examples <Route path=\":lang?/about> will match: /:lang/about /about <Route path=\"/multistep/:widget1?/widget2?/widget3?\"> will match: /multistep /multistep/:widget1 /multistep/:widget1/:widget2 /multistep/:widget1/:widget2/:widget3 Optional Static Segment Example <Route path=\"/home?\"> will match: / /home <Route path=\"/fr?/about\"> will match: /about /fr/about Minor Changes Allows optional routes and optional static segments (#9650) Patch Changes Stop incorrectly matching on partial named parameters, i.e. <Route path=\"prefix-:param\">, to align with how splat parameters work. If you were previously relying on this behavior then it's recommended to extract the static portion of the path at the useParams call site: (#9506) // Old behavior at URL /prefix-123 <Route path=\"prefix-:id\" element={<Comp /> }> function Comp() { let params = useParams(); // { id: '123' } let id = params.id; // \"123\" ... } // New behavior at URL /prefix-123 <Route path=\":id\" element={<Comp /> }> function Comp() { let params = useParams(); // { id: 'prefix-123' } let id = params.id.replace(/^prefix-/, ''); // \"123\" ... } Updated dependencies: @remix-run/router@1.1.0 6.4.5 Patch Changes Updated dependencies: @remix-run/router@1.0.5 6.4.4 Patch Changes Updated dependencies: @remix-run/router@1.0.4 6.4.3 Patch Changes useRoutes should be able to return null when passing locationArg (#9485) fix initialEntries type in createMemoryRouter (#9498) Updated dependencies: @remix-run/router@1.0.3 6.4.2 Patch Changes Fix IndexRouteObject and NonIndexRouteObject types to make hasErrorElement optional (#9394) Enhance console error messages for invalid usage of data router hooks (#9311) If an index route has children, it will result in a runtime error. We have strengthened our RouteObject/RouteProps types to surface the error in TypeScript. (#9366) Updated dependencies: @remix-run/router@1.0.2 6.4.1 Patch Changes Preserve state from initialEntries (#9288) Updated dependencies: @remix-run/router@1.0.1 6.4.0 Whoa this is a big one! 6.4.0 brings all the data loading and mutation APIs over from Remix. Here's a quick high level overview, but it's recommended you go check out the docs, especially the feature overview and the tutorial. New APIs Create your router with createMemoryRouter Render your router with <RouterProvider> Load data with a Route loader and mutate with a Route action Handle errors with Route errorElement Defer non-critical data with defer and Await Bug Fixes Path resolution is now trailing slash agnostic (#8861) useLocation returns the scoped location inside a <Routes location> component (#9094) Updated Dependencies @remix-run/router@1.0.0"
  },
  "src/frontend/app-client/node_modules/react-router/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/react-router/LICENSE.html",
    "title": "",
    "summary": "MIT License Copyright (c) React Training LLC 2015-2019 Copyright (c) Remix Software Inc. 2020-2021 Copyright (c) Shopify Inc. 2022-2023 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/react-router/node_modules/cookie/README.html": {
    "href": "src/frontend/app-client/node_modules/react-router/node_modules/cookie/README.html",
    "title": "cookie",
    "summary": "cookie Basic HTTP cookie parser and serializer for HTTP servers. Installation $ npm install cookie API const cookie = require(\"cookie\"); // import * as cookie from 'cookie'; cookie.parse(str, options) Parse a HTTP Cookie header string and returning an object of all cookie name-value pairs. The str argument is the string representing a Cookie header value and options is an optional object containing additional parsing options. const cookies = cookie.parse(\"foo=bar; equation=E%3Dmc%5E2\"); // { foo: 'bar', equation: 'E=mc^2' } Options cookie.parse accepts these properties in the options object. decode Specifies a function that will be used to decode a cookie-value. Since the value of a cookie has a limited character set (and must be a simple string), this function can be used to decode a previously-encoded cookie value into a JavaScript string. The default function is the global decodeURIComponent, wrapped in a try..catch. If an error is thrown it will return the cookie's original value. If you provide your own encode/decode scheme you must ensure errors are appropriately handled. cookie.serialize(name, value, options) Serialize a cookie name-value pair into a Set-Cookie header string. The name argument is the name for the cookie, the value argument is the value to set the cookie to, and the options argument is an optional object containing additional serialization options. const setCookie = cookie.serialize(\"foo\", \"bar\"); // foo=bar Options cookie.serialize accepts these properties in the options object. encode Specifies a function that will be used to encode a cookie-value. Since value of a cookie has a limited character set (and must be a simple string), this function can be used to encode a value into a string suited for a cookie's value, and should mirror decode when parsing. The default function is the global encodeURIComponent. maxAge Specifies the number (in seconds) to be the value for the Max-Age Set-Cookie attribute. The cookie storage model specification states that if both expires and maxAge are set, then maxAge takes precedence, but it is possible not all clients by obey this, so if both are set, they should point to the same date and time. expires Specifies the Date object to be the value for the Expires Set-Cookie attribute. When no expiration is set clients consider this a \"non-persistent cookie\" and delete it the current session is over. The cookie storage model specification states that if both expires and maxAge are set, then maxAge takes precedence, but it is possible not all clients by obey this, so if both are set, they should point to the same date and time. domain Specifies the value for the Domain Set-Cookie attribute. When no domain is set clients consider the cookie to apply to the current domain only. path Specifies the value for the Path Set-Cookie attribute. When no path is set, the path is considered the \"default path\". httpOnly Enables the HttpOnly Set-Cookie attribute. When enabled, clients will not allow client-side JavaScript to see the cookie in document.cookie. secure Enables the Secure Set-Cookie attribute. When enabled, clients will only send the cookie back if the browser has a HTTPS connection. partitioned Enables the Partitioned Set-Cookie attribute. When enabled, clients will only send the cookie back when the current domain and top-level domain matches. This is an attribute that has not yet been fully standardized, and may change in the future. This also means clients may ignore this attribute until they understand it. More information about can be found in the proposal. priority Specifies the value for the Priority Set-Cookie attribute. 'low' will set the Priority attribute to Low. 'medium' will set the Priority attribute to Medium, the default priority when not set. 'high' will set the Priority attribute to High. More information about priority levels can be found in the specification. sameSite Specifies the value for the SameSite Set-Cookie attribute. true will set the SameSite attribute to Strict for strict same site enforcement. 'lax' will set the SameSite attribute to Lax for lax same site enforcement. 'none' will set the SameSite attribute to None for an explicit cross-site cookie. 'strict' will set the SameSite attribute to Strict for strict same site enforcement. More information about enforcement levels can be found in the specification. Example The following example uses this module in conjunction with the Node.js core HTTP server to prompt a user for their name and display it back on future visits. var cookie = require(\"cookie\"); var escapeHtml = require(\"escape-html\"); var http = require(\"http\"); var url = require(\"url\"); function onRequest(req, res) { // Parse the query string var query = url.parse(req.url, true, true).query; if (query && query.name) { // Set a new cookie with the name res.setHeader( \"Set-Cookie\", cookie.serialize(\"name\", String(query.name), { httpOnly: true, maxAge: 60 * 60 * 24 * 7, // 1 week }), ); // Redirect back after setting cookie res.statusCode = 302; res.setHeader(\"Location\", req.headers.referer || \"/\"); res.end(); return; } // Parse the cookies on the request var cookies = cookie.parse(req.headers.cookie || \"\"); // Get the visitor name set in the cookie var name = cookies.name; res.setHeader(\"Content-Type\", \"text/html; charset=UTF-8\"); if (name) { res.write(\"<p>Welcome back, <b>\" + escapeHtml(name) + \"</b>!</p>\"); } else { res.write(\"<p>Hello, new visitor!</p>\"); } res.write('<form method=\"GET\">'); res.write( '<input placeholder=\"enter your name\" name=\"name\"> <input type=\"submit\" value=\"Set Name\">', ); res.end(\"</form>\"); } http.createServer(onRequest).listen(3000); Testing npm test Benchmark npm run bench name hz min max mean p75 p99 p995 p999 rme samples · simple 8,566,313.09 0.0000 0.3694 0.0001 0.0001 0.0002 0.0002 0.0003 ±0.64% 4283157 fastest · decode 3,834,348.85 0.0001 0.2465 0.0003 0.0003 0.0003 0.0004 0.0006 ±0.38% 1917175 · unquote 8,315,355.96 0.0000 0.3824 0.0001 0.0001 0.0002 0.0002 0.0003 ±0.72% 4157880 · duplicates 1,944,765.97 0.0004 0.2959 0.0005 0.0005 0.0006 0.0006 0.0008 ±0.24% 972384 · 10 cookies 675,345.67 0.0012 0.4328 0.0015 0.0015 0.0019 0.0020 0.0058 ±0.75% 337673 · 100 cookies 61,040.71 0.0152 0.4092 0.0164 0.0160 0.0196 0.0228 0.2260 ±0.71% 30521 slowest ✓ parse top-sites (15) 22945ms name hz min max mean p75 p99 p995 p999 rme samples · parse accounts.google.com 7,164,349.17 0.0000 0.0929 0.0001 0.0002 0.0002 0.0002 0.0003 ±0.09% 3582184 · parse apple.com 7,817,686.84 0.0000 0.6048 0.0001 0.0001 0.0002 0.0002 0.0003 ±1.05% 3908844 · parse cloudflare.com 7,189,841.70 0.0000 0.0390 0.0001 0.0002 0.0002 0.0002 0.0003 ±0.06% 3594921 · parse docs.google.com 7,051,765.61 0.0000 0.0296 0.0001 0.0002 0.0002 0.0002 0.0003 ±0.06% 3525883 · parse drive.google.com 7,349,104.77 0.0000 0.0368 0.0001 0.0001 0.0002 0.0002 0.0003 ±0.05% 3674553 · parse en.wikipedia.org 1,929,909.49 0.0004 0.3598 0.0005 0.0005 0.0007 0.0007 0.0012 ±0.16% 964955 · parse linkedin.com 2,225,658.01 0.0003 0.0595 0.0004 0.0005 0.0005 0.0005 0.0006 ±0.06% 1112830 · parse maps.google.com 4,423,511.68 0.0001 0.0942 0.0002 0.0003 0.0003 0.0003 0.0005 ±0.08% 2211756 · parse microsoft.com 3,387,601.88 0.0002 0.0725 0.0003 0.0003 0.0004 0.0004 0.0005 ±0.09% 1693801 · parse play.google.com 7,375,980.86 0.0000 0.1994 0.0001 0.0001 0.0002 0.0002 0.0003 ±0.12% 3687991 · parse support.google.com 4,912,267.94 0.0001 2.8958 0.0002 0.0002 0.0003 0.0003 0.0005 ±1.28% 2456134 · parse www.google.com 3,443,035.87 0.0002 0.2783 0.0003 0.0003 0.0004 0.0004 0.0007 ±0.51% 1721518 · parse youtu.be 1,910,492.87 0.0004 0.3490 0.0005 0.0005 0.0007 0.0007 0.0011 ±0.46% 955247 · parse youtube.com 1,895,082.62 0.0004 0.7454 0.0005 0.0005 0.0006 0.0007 0.0013 ±0.64% 947542 slowest · parse example.com 21,582,835.27 0.0000 0.1095 0.0000 0.0000 0.0001 0.0001 0.0001 ±0.13% 10791418 References RFC 6265: HTTP State Management Mechanism Same-site Cookies License MIT"
  },
  "src/frontend/app-client/node_modules/react-router/README.html": {
    "href": "src/frontend/app-client/node_modules/react-router/README.html",
    "title": "",
    "summary": "react-router is the primary package in the React Router project. Installation npm i react-router"
  },
  "src/frontend/app-client/node_modules/react-style-singleton/README.html": {
    "href": "src/frontend/app-client/node_modules/react-style-singleton/README.html",
    "title": "react-style-singleton",
    "summary": "react-style-singleton 300b with all dependencies, minified and gzipped Creates a style component with internal tracker. Adds styles to the browser on the first instance mount. Removes after the last instance unmount. Thus helps you deliver styles you need to the customer, and clean up later. Is not server-side rendering compatible! API Component import {styleSingleton} from 'react-style-singleton' const Style = styleSingleton(); export const App = () => ( <Style styles={'body {color:red}'} /> ); Hook import {styleHookSingleton} from 'react-style-singleton'; const useStyle = styleHookSingleton(); const useAnotherStyle = styleHookSingleton(); export const App = () => { useStyle('div {color:red}'); useAnotherStyle('body { background-color:red }'); return (<div />); } License MIT"
  },
  "src/frontend/app-client/node_modules/react-tooltip/CODE_OF_CONDUCT.html": {
    "href": "src/frontend/app-client/node_modules/react-tooltip/CODE_OF_CONDUCT.html",
    "title": "",
    "summary": "Code of Conduct Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others’ private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities Project maintainers are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope This Code of Conduct applies within all community spaces and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the project team responsible for enforcement. All complaints will be reviewed and investigated promptly and fairly. All project maintainers are obligated to respect the privacy and security of the reporter of any incident. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct/"
  },
  "src/frontend/app-client/node_modules/react-tooltip/CONTRIBUTION.html": {
    "href": "src/frontend/app-client/node_modules/react-tooltip/CONTRIBUTION.html",
    "title": "Contribution",
    "summary": "Contribution Running project locally ReactTooltip (root) Run npm install || yarn to install dependencies You can test by: yarn dev to run dev mode, or you can run docs directly using root folder instead of NPM, for this, please check docs section. Docs You still need step 1 from ReactTooltip (root) section. Docs are commited using npm packages, but with this steps, you can use local ReactTooltip package build. In docs folder, run npm install || yarn to install dependencies In root folder (parent of docs folder), run yarn build to generate a production build (you can use yarn build --watch to always generate a new build when a file changes) Change package.json: From this: \"react\": \"18.2.0\", \"react-dom\": \"18.2.0\", \"react-tooltip\": \"5.0.0\" To this: \"react\": \"link:../node_modules/react\", \"react-dom\": \"link:../node_modules/react-dom\", \"react-tooltip\": \"link:..\" Run yarn start and open localhost:3000 to see docs running locally. OBS: do not commit this change or the docs will broken the deployment and will not be updated."
  },
  "src/frontend/app-client/node_modules/react-tooltip/README.html": {
    "href": "src/frontend/app-client/node_modules/react-tooltip/README.html",
    "title": "react-tooltip",
    "summary": "react-tooltip If you like the project, please give the project a GitHub \uD83C\uDF1F Why do we show ads on our docs? ReactTooltip is an open source project, this is the way we found to be financed by the community. Demo Documentation for V4 - Github Page. Documentation for V5 - ReactTooltip. Installation npm install react-tooltip or yarn add react-tooltip Sponsors Gold Sponsors \uD83C\uDF1F React Tooltip is proud to be sponsored by Frigade, a developer tool for building better product onboarding: guided tours, getting started checklists, announcements, etc. Silver Sponsors ✪ Powered by Usage 1 . Import the CSS file to set default styling. [!WARNING] If you are using a version before than v5.13.0, you must import the CSS file or the tooltip won't show! import 'react-tooltip/dist/react-tooltip.css' This needs to be done only once and only if you are using a version before than 5.13.0. We suggest you do it on your src/index.js or equivalent file. 2 . Import react-tooltip after installation. import { Tooltip } from 'react-tooltip' or if you want to still use the name ReactTooltip as V4: import { Tooltip as ReactTooltip } from 'react-tooltip' 3 . Add data-tooltip-id=\"<tooltip id>\" and data-tooltip-content=\"<your placeholder>\" to your element. data-tooltip-id is the equivalent of V4's data-for. <a data-tooltip-id=\"my-tooltip\" data-tooltip-content=\"Hello world!\"> ◕‿‿◕ </a> 4 . Include the <Tooltip /> element. [!NOTE] Don't forget to set the id, it won't work without it! <Tooltip id=\"my-tooltip\" /> Troubleshooting Before trying these, make sure you're running the latest ReactTooltip version with npm install react-tooltip@latest or yarn add react-tooltip@latest Please check our troubleshooting section on our docs. If you can't find your problem here, make sure there isn't an open issue already covering it. If there isn't, feel free to submit a new issue. Article How I insert sass into react component Maintainers danielbarion Maintainer - Creator of React Tooltip >= V5. gabrieljablonski Maintainer. aronhelser (inactive). alexgurr (inactive). pdeszynski (inactive). roggervalf (inactive). huumanoid (inactive) wwayne (inactive) - Creator of the original React Tooltip (V1.x ~ V4.x.) We would gladly accept a new maintainer to help out! Contributing We welcome your contribution! Fork the repo, make some changes, submit a pull-request! Our contributing doc has some details. License MIT"
  },
  "src/frontend/app-client/node_modules/react/README.html": {
    "href": "src/frontend/app-client/node_modules/react/README.html",
    "title": "react",
    "summary": "react React is a JavaScript library for creating user interfaces. The react package contains only the functionality necessary to define React components. It is typically used together with a React renderer like react-dom for the web, or react-native for the native environments. Note: by default, React will be in development mode. The development version includes extra warnings about common mistakes, whereas the production version includes extra performance optimizations and strips all error messages. Don't forget to use the production build when deploying your application. Usage import { useState } from 'react'; import { createRoot } from 'react-dom/client'; function Counter() { const [count, setCount] = useState(0); return ( <> <h1>{count}</h1> <button onClick={() => setCount(count + 1)}> Increment </button> </> ); } const root = createRoot(document.getElementById('root')); root.render(<Counter />); Documentation See https://react.dev/ API See https://react.dev/reference/react"
  },
  "src/frontend/app-client/node_modules/readable-stream/CONTRIBUTING.html": {
    "href": "src/frontend/app-client/node_modules/readable-stream/CONTRIBUTING.html",
    "title": "Developer's Certificate of Origin 1.1",
    "summary": "Developer's Certificate of Origin 1.1 By making a contribution to this project, I certify that: (a) The contribution was created in whole or in part by me and I have the right to submit it under the open source license indicated in the file; or (b) The contribution is based upon previous work that, to the best of my knowledge, is covered under an appropriate open source license and I have the right under that license to submit that work with modifications, whether created in whole or in part by me, under the same open source license (unless I am permitted to submit under a different license), as indicated in the file; or (c) The contribution was provided directly to me by some other person who certified (a), (b) or (c) and I have not modified it. (d) I understand and agree that this project and the contribution are public and that a record of the contribution (including all personal information I submit with it, including my sign-off) is maintained indefinitely and may be redistributed consistent with this project or the open source license(s) involved. Moderation Policy The Node.js Moderation Policy applies to this WG. Code of Conduct The Node.js Code of Conduct applies to this WG."
  },
  "src/frontend/app-client/node_modules/readable-stream/doc/wg-meetings/2015-01-30.html": {
    "href": "src/frontend/app-client/node_modules/readable-stream/doc/wg-meetings/2015-01-30.html",
    "title": "streams WG Meeting 2015-01-30",
    "summary": "streams WG Meeting 2015-01-30 Links Google Hangouts Video: http://www.youtube.com/watch?v=I9nDOSGfwZg GitHub Issue: https://github.com/iojs/readable-stream/issues/106 Original Minutes Google Doc: https://docs.google.com/document/d/17aTgLnjMXIrfjgNaTUnHQO7m3xgzHR2VXBTmi03Qii4/ Agenda Extracted from https://github.com/iojs/readable-stream/labels/wg-agenda prior to meeting. adopt a charter #105 release and versioning strategy #101 simpler stream creation #102 proposal: deprecate implicit flowing of streams #99 Minutes adopt a charter group: +1's all around What versioning scheme should be adopted? group: +1’s 3.0.0 domenic+group: pulling in patches from other sources where appropriate mikeal: version independently, suggesting versions for io.js mikeal+domenic: work with TC to notify in advance of changes simpler stream creation streamline creation of streams sam: streamline creation of streams domenic: nice simple solution posted but, we lose the opportunity to change the model may not be backwards incompatible (double check keys) action item: domenic will check remove implicit flowing of streams on(‘data’) add isFlowing / isPaused mikeal: worrying that we’re documenting polyfill methods – confuses users domenic: more reflective API is probably good, with warning labels for users new section for mad scientists (reflective stream access) calvin: name the “third state” mikeal: maybe borrow the name from whatwg? domenic: we’re missing the “third state” consensus: kind of difficult to name the third state mikeal: figure out differences in states / compat mathias: always flow on data – eliminates third state explore what it breaks action items: ask isaac for ability to list packages by what public io.js APIs they use (esp. Stream) ask rod/build for infrastructure chris: explore the “flow on data” approach add isPaused/isFlowing add new docs section move isPaused to that section"
  },
  "src/frontend/app-client/node_modules/readable-stream/GOVERNANCE.html": {
    "href": "src/frontend/app-client/node_modules/readable-stream/GOVERNANCE.html",
    "title": "",
    "summary": "Streams Working Group The Node.js Streams is jointly governed by a Working Group (WG) that is responsible for high-level guidance of the project. The WG has final authority over this project including: Technical direction Project governance and process (including this policy) Contribution policy GitHub repository hosting Conduct guidelines Maintaining the list of additional Collaborators For the current list of WG members, see the project README.md. Collaborators The readable-stream GitHub repository is maintained by the WG and additional Collaborators who are added by the WG on an ongoing basis. Individuals making significant and valuable contributions are made Collaborators and given commit-access to the project. These individuals are identified by the WG and their addition as Collaborators is discussed during the WG meeting. Note: If you make a significant contribution and are not considered for commit-access log an issue or contact a WG member directly and it will be brought up in the next WG meeting. Modifications of the contents of the readable-stream repository are made on a collaborative basis. Anybody with a GitHub account may propose a modification via pull request and it will be considered by the project Collaborators. All pull requests must be reviewed and accepted by a Collaborator with sufficient expertise who is able to take full responsibility for the change. In the case of pull requests proposed by an existing Collaborator, an additional Collaborator is required for sign-off. Consensus should be sought if additional Collaborators participate and there is disagreement around a particular modification. See Consensus Seeking Process below for further detail on the consensus model used for governance. Collaborators may opt to elevate significant or controversial modifications, or modifications that have not found consensus to the WG for discussion by assigning the WG-agenda tag to a pull request or issue. The WG should serve as the final arbiter where required. For the current list of Collaborators, see the project README.md. WG Membership WG seats are not time-limited. There is no fixed size of the WG. However, the expected target is between 6 and 12, to ensure adequate coverage of important areas of expertise, balanced with the ability to make decisions efficiently. There is no specific set of requirements or qualifications for WG membership beyond these rules. The WG may add additional members to the WG by unanimous consensus. A WG member may be removed from the WG by voluntary resignation, or by unanimous consensus of all other WG members. Changes to WG membership should be posted in the agenda, and may be suggested as any other agenda item (see \"WG Meetings\" below). If an addition or removal is proposed during a meeting, and the full WG is not in attendance to participate, then the addition or removal is added to the agenda for the subsequent meeting. This is to ensure that all members are given the opportunity to participate in all membership decisions. If a WG member is unable to attend a meeting where a planned membership decision is being made, then their consent is assumed. No more than 1/3 of the WG members may be affiliated with the same employer. If removal or resignation of a WG member, or a change of employment by a WG member, creates a situation where more than 1/3 of the WG membership shares an employer, then the situation must be immediately remedied by the resignation or removal of one or more WG members affiliated with the over-represented employer(s). WG Meetings The WG meets occasionally on a Google Hangout On Air. A designated moderator approved by the WG runs the meeting. Each meeting should be published to YouTube. Items are added to the WG agenda that are considered contentious or are modifications of governance, contribution policy, WG membership, or release process. The intention of the agenda is not to approve or review all patches; that should happen continuously on GitHub and be handled by the larger group of Collaborators. Any community member or contributor can ask that something be added to the next meeting's agenda by logging a GitHub Issue. Any Collaborator, WG member or the moderator can add the item to the agenda by adding the WG-agenda tag to the issue. Prior to each WG meeting the moderator will share the Agenda with members of the WG. WG members can add any items they like to the agenda at the beginning of each meeting. The moderator and the WG cannot veto or remove items. The WG may invite persons or representatives from certain projects to participate in a non-voting capacity. The moderator is responsible for summarizing the discussion of each agenda item and sends it as a pull request after the meeting. Consensus Seeking Process The WG follows a Consensus Seeking decision-making model. When an agenda item has appeared to reach a consensus the moderator will ask \"Does anyone object?\" as a final call for dissent from the consensus. If an agenda item cannot reach a consensus a WG member can call for either a closing vote or a vote to table the issue to the next meeting. The call for a vote must be seconded by a majority of the WG or else the discussion will continue. Simple majority wins. Note that changes to WG membership require a majority consensus. See \"WG Membership\" above."
  },
  "src/frontend/app-client/node_modules/readable-stream/node_modules/safe-buffer/README.html": {
    "href": "src/frontend/app-client/node_modules/readable-stream/node_modules/safe-buffer/README.html",
    "title": "safe-buffer",
    "summary": "safe-buffer Safer Node.js Buffer API Use the new Node.js Buffer APIs (Buffer.from, Buffer.alloc, Buffer.allocUnsafe, Buffer.allocUnsafeSlow) in all versions of Node.js. Uses the built-in implementation when available. install npm install safe-buffer usage The goal of this package is to provide a safe replacement for the node.js Buffer. It's a drop-in replacement for Buffer. You can use it by adding one require line to the top of your node.js modules: var Buffer = require('safe-buffer').Buffer // Existing buffer code will continue to work without issues: new Buffer('hey', 'utf8') new Buffer([1, 2, 3], 'utf8') new Buffer(obj) new Buffer(16) // create an uninitialized buffer (potentially unsafe) // But you can use these new explicit APIs to make clear what you want: Buffer.from('hey', 'utf8') // convert from many types to a Buffer Buffer.alloc(16) // create a zero-filled buffer (safe) Buffer.allocUnsafe(16) // create an uninitialized buffer (potentially unsafe) api Class Method: Buffer.from(array) array {Array} Allocates a new Buffer using an array of octets. const buf = Buffer.from([0x62,0x75,0x66,0x66,0x65,0x72]); // creates a new Buffer containing ASCII bytes // ['b','u','f','f','e','r'] A TypeError will be thrown if array is not an Array. Class Method: Buffer.from(arrayBuffer[, byteOffset[, length]]) arrayBuffer {ArrayBuffer} The .buffer property of a TypedArray or a new ArrayBuffer() byteOffset {Number} Default: 0 length {Number} Default: arrayBuffer.length - byteOffset When passed a reference to the .buffer property of a TypedArray instance, the newly created Buffer will share the same allocated memory as the TypedArray. const arr = new Uint16Array(2); arr[0] = 5000; arr[1] = 4000; const buf = Buffer.from(arr.buffer); // shares the memory with arr; console.log(buf); // Prints: <Buffer 88 13 a0 0f> // changing the TypedArray changes the Buffer also arr[1] = 6000; console.log(buf); // Prints: <Buffer 88 13 70 17> The optional byteOffset and length arguments specify a memory range within the arrayBuffer that will be shared by the Buffer. const ab = new ArrayBuffer(10); const buf = Buffer.from(ab, 0, 2); console.log(buf.length); // Prints: 2 A TypeError will be thrown if arrayBuffer is not an ArrayBuffer. Class Method: Buffer.from(buffer) buffer {Buffer} Copies the passed buffer data onto a new Buffer instance. const buf1 = Buffer.from('buffer'); const buf2 = Buffer.from(buf1); buf1[0] = 0x61; console.log(buf1.toString()); // 'auffer' console.log(buf2.toString()); // 'buffer' (copy is not changed) A TypeError will be thrown if buffer is not a Buffer. Class Method: Buffer.from(str[, encoding]) str {String} String to encode. encoding {String} Encoding to use, Default: 'utf8' Creates a new Buffer containing the given JavaScript string str. If provided, the encoding parameter identifies the character encoding. If not provided, encoding defaults to 'utf8'. const buf1 = Buffer.from('this is a tést'); console.log(buf1.toString()); // prints: this is a tést console.log(buf1.toString('ascii')); // prints: this is a tC)st const buf2 = Buffer.from('7468697320697320612074c3a97374', 'hex'); console.log(buf2.toString()); // prints: this is a tést A TypeError will be thrown if str is not a string. Class Method: Buffer.alloc(size[, fill[, encoding]]) size {Number} fill {Value} Default: undefined encoding {String} Default: utf8 Allocates a new Buffer of size bytes. If fill is undefined, the Buffer will be zero-filled. const buf = Buffer.alloc(5); console.log(buf); // <Buffer 00 00 00 00 00> The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. If fill is specified, the allocated Buffer will be initialized by calling buf.fill(fill). See [buf.fill()][] for more information. const buf = Buffer.alloc(5, 'a'); console.log(buf); // <Buffer 61 61 61 61 61> If both fill and encoding are specified, the allocated Buffer will be initialized by calling buf.fill(fill, encoding). For example: const buf = Buffer.alloc(11, 'aGVsbG8gd29ybGQ=', 'base64'); console.log(buf); // <Buffer 68 65 6c 6c 6f 20 77 6f 72 6c 64> Calling Buffer.alloc(size) can be significantly slower than the alternative Buffer.allocUnsafe(size) but ensures that the newly created Buffer instance contents will never contain sensitive data. A TypeError will be thrown if size is not a number. Class Method: Buffer.allocUnsafe(size) size {Number} Allocates a new non-zero-filled Buffer of size bytes. The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. The underlying memory for Buffer instances created in this way is not initialized. The contents of the newly created Buffer are unknown and may contain sensitive data. Use [buf.fill(0)][] to initialize such Buffer instances to zeroes. const buf = Buffer.allocUnsafe(5); console.log(buf); // <Buffer 78 e0 82 02 01> // (octets will be different, every time) buf.fill(0); console.log(buf); // <Buffer 00 00 00 00 00> A TypeError will be thrown if size is not a number. Note that the Buffer module pre-allocates an internal Buffer instance of size Buffer.poolSize that is used as a pool for the fast allocation of new Buffer instances created using Buffer.allocUnsafe(size) (and the deprecated new Buffer(size) constructor) only when size is less than or equal to Buffer.poolSize >> 1 (floor of Buffer.poolSize divided by two). The default value of Buffer.poolSize is 8192 but can be modified. Use of this pre-allocated internal memory pool is a key difference between calling Buffer.alloc(size, fill) vs. Buffer.allocUnsafe(size).fill(fill). Specifically, Buffer.alloc(size, fill) will never use the internal Buffer pool, while Buffer.allocUnsafe(size).fill(fill) will use the internal Buffer pool if size is less than or equal to half Buffer.poolSize. The difference is subtle but can be important when an application requires the additional performance that Buffer.allocUnsafe(size) provides. Class Method: Buffer.allocUnsafeSlow(size) size {Number} Allocates a new non-zero-filled and non-pooled Buffer of size bytes. The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. The underlying memory for Buffer instances created in this way is not initialized. The contents of the newly created Buffer are unknown and may contain sensitive data. Use [buf.fill(0)][] to initialize such Buffer instances to zeroes. When using Buffer.allocUnsafe() to allocate new Buffer instances, allocations under 4KB are, by default, sliced from a single pre-allocated Buffer. This allows applications to avoid the garbage collection overhead of creating many individually allocated Buffers. This approach improves both performance and memory usage by eliminating the need to track and cleanup as many Persistent objects. However, in the case where a developer may need to retain a small chunk of memory from a pool for an indeterminate amount of time, it may be appropriate to create an un-pooled Buffer instance using Buffer.allocUnsafeSlow() then copy out the relevant bits. // need to keep around a few small chunks of memory const store = []; socket.on('readable', () => { const data = socket.read(); // allocate for retained data const sb = Buffer.allocUnsafeSlow(10); // copy the data into the new allocation data.copy(sb, 0, 0, 10); store.push(sb); }); Use of Buffer.allocUnsafeSlow() should be used only as a last resort after a developer has observed undue memory retention in their applications. A TypeError will be thrown if size is not a number. All the Rest The rest of the Buffer API is exactly the same as in node.js. See the docs. Related links Node.js issue: Buffer(number) is unsafe Node.js Enhancement Proposal: Buffer.from/Buffer.alloc/Buffer.zalloc/Buffer() soft-deprecate Why is Buffer unsafe? Today, the node.js Buffer constructor is overloaded to handle many different argument types like String, Array, Object, TypedArrayView (Uint8Array, etc.), ArrayBuffer, and also Number. The API is optimized for convenience: you can throw any type at it, and it will try to do what you want. Because the Buffer constructor is so powerful, you often see code like this: // Convert UTF-8 strings to hex function toHex (str) { return new Buffer(str).toString('hex') } But what happens if toHex is called with a Number argument? Remote Memory Disclosure If an attacker can make your program call the Buffer constructor with a Number argument, then they can make it allocate uninitialized memory from the node.js process. This could potentially disclose TLS private keys, user data, or database passwords. When the Buffer constructor is passed a Number argument, it returns an UNINITIALIZED block of memory of the specified size. When you create a Buffer like this, you MUST overwrite the contents before returning it to the user. From the node.js docs: new Buffer(size) size Number The underlying memory for Buffer instances created in this way is not initialized. The contents of a newly created Buffer are unknown and could contain sensitive data. Use buf.fill(0) to initialize a Buffer to zeroes. (Emphasis our own.) Whenever the programmer intended to create an uninitialized Buffer you often see code like this: var buf = new Buffer(16) // Immediately overwrite the uninitialized buffer with data from another buffer for (var i = 0; i < buf.length; i++) { buf[i] = otherBuf[i] } Would this ever be a problem in real code? Yes. It's surprisingly common to forget to check the type of your variables in a dynamically-typed language like JavaScript. Usually the consequences of assuming the wrong type is that your program crashes with an uncaught exception. But the failure mode for forgetting to check the type of arguments to the Buffer constructor is more catastrophic. Here's an example of a vulnerable service that takes a JSON payload and converts it to hex: // Take a JSON payload {str: \"some string\"} and convert it to hex var server = http.createServer(function (req, res) { var data = '' req.setEncoding('utf8') req.on('data', function (chunk) { data += chunk }) req.on('end', function () { var body = JSON.parse(data) res.end(new Buffer(body.str).toString('hex')) }) }) server.listen(8080) In this example, an http client just has to send: { \"str\": 1000 } and it will get back 1,000 bytes of uninitialized memory from the server. This is a very serious bug. It's similar in severity to the the Heartbleed bug that allowed disclosure of OpenSSL process memory by remote attackers. Which real-world packages were vulnerable? bittorrent-dht Mathias Buus and I (Feross Aboukhadijeh) found this issue in one of our own packages, bittorrent-dht. The bug would allow anyone on the internet to send a series of messages to a user of bittorrent-dht and get them to reveal 20 bytes at a time of uninitialized memory from the node.js process. Here's the commit that fixed it. We released a new fixed version, created a Node Security Project disclosure, and deprecated all vulnerable versions on npm so users will get a warning to upgrade to a newer version. ws That got us wondering if there were other vulnerable packages. Sure enough, within a short period of time, we found the same issue in ws, the most popular WebSocket implementation in node.js. If certain APIs were called with Number parameters instead of String or Buffer as expected, then uninitialized server memory would be disclosed to the remote peer. These were the vulnerable methods: socket.send(number) socket.ping(number) socket.pong(number) Here's a vulnerable socket server with some echo functionality: server.on('connection', function (socket) { socket.on('message', function (message) { message = JSON.parse(message) if (message.type === 'echo') { socket.send(message.data) // send back the user's message } }) }) socket.send(number) called on the server, will disclose server memory. Here's the release where the issue was fixed, with a more detailed explanation. Props to Arnout Kazemier for the quick fix. Here's the Node Security Project disclosure. What's the solution? It's important that node.js offers a fast way to get memory otherwise performance-critical applications would needlessly get a lot slower. But we need a better way to signal our intent as programmers. When we want uninitialized memory, we should request it explicitly. Sensitive functionality should not be packed into a developer-friendly API that loosely accepts many different types. This type of API encourages the lazy practice of passing variables in without checking the type very carefully. A new API: Buffer.allocUnsafe(number) The functionality of creating buffers with uninitialized memory should be part of another API. We propose Buffer.allocUnsafe(number). This way, it's not part of an API that frequently gets user input of all sorts of different types passed into it. var buf = Buffer.allocUnsafe(16) // careful, uninitialized memory! // Immediately overwrite the uninitialized buffer with data from another buffer for (var i = 0; i < buf.length; i++) { buf[i] = otherBuf[i] } How do we fix node.js core? We sent a PR to node.js core (merged as semver-major) which defends against one case: var str = 16 new Buffer(str, 'utf8') In this situation, it's implied that the programmer intended the first argument to be a string, since they passed an encoding as a second argument. Today, node.js will allocate uninitialized memory in the case of new Buffer(number, encoding), which is probably not what the programmer intended. But this is only a partial solution, since if the programmer does new Buffer(variable) (without an encoding parameter) there's no way to know what they intended. If variable is sometimes a number, then uninitialized memory will sometimes be returned. What's the real long-term fix? We could deprecate and remove new Buffer(number) and use Buffer.allocUnsafe(number) when we need uninitialized memory. But that would break 1000s of packages. We believe the best solution is to: 1. Change new Buffer(number) to return safe, zeroed-out memory 2. Create a new API for creating uninitialized Buffers. We propose: Buffer.allocUnsafe(number) Update We now support adding three new APIs: Buffer.from(value) - convert from any type to a buffer Buffer.alloc(size) - create a zero-filled buffer Buffer.allocUnsafe(size) - create an uninitialized buffer with given size This solves the core problem that affected ws and bittorrent-dht which is Buffer(variable) getting tricked into taking a number argument. This way, existing code continues working and the impact on the npm ecosystem will be minimal. Over time, npm maintainers can migrate performance-critical code to use Buffer.allocUnsafe(number) instead of new Buffer(number). Conclusion We think there's a serious design issue with the Buffer API as it exists today. It promotes insecure software by putting high-risk functionality into a convenient API with friendly \"developer ergonomics\". This wasn't merely a theoretical exercise because we found the issue in some of the most popular npm packages. Fortunately, there's an easy fix that can be applied today. Use safe-buffer in place of buffer. var Buffer = require('safe-buffer').Buffer Eventually, we hope that node.js core can switch to this new, safer behavior. We believe the impact on the ecosystem would be minimal since it's not a breaking change. Well-maintained, popular packages would be updated to use Buffer.alloc quickly, while older, insecure packages would magically become safe from this attack vector. links Node.js PR: buffer: throw if both length and enc are passed Node Security Project disclosure for ws Node Security Project disclosure forbittorrent-dht credit The original issues in bittorrent-dht (disclosure) and ws (disclosure) were discovered by Mathias Buus and Feross Aboukhadijeh. Thanks to Adam Baldwin for helping disclose these issues and for his work running the Node Security Project. Thanks to John Hiesey for proofreading this README and auditing the code. license MIT. Copyright (C) Feross Aboukhadijeh"
  },
  "src/frontend/app-client/node_modules/readable-stream/README.html": {
    "href": "src/frontend/app-client/node_modules/readable-stream/README.html",
    "title": "readable-stream",
    "summary": "readable-stream Node-core v8.17.0 streams for userland npm install --save readable-stream Node-core streams for userland This package is a mirror of the Streams2 and Streams3 implementations in Node-core. Full documentation may be found on the Node.js website. If you want to guarantee a stable streams base, regardless of what version of Node you, or the users of your libraries are using, use readable-stream only and avoid the \"stream\" module in Node-core, for background see this blogpost. As of version 2.0.0 readable-stream uses semantic versioning. Streams Working Group readable-stream is maintained by the Streams Working Group, which oversees the development and maintenance of the Streams API within Node.js. The responsibilities of the Streams Working Group include: Addressing stream issues on the Node.js issue tracker. Authoring and editing stream documentation within the Node.js project. Reviewing changes to stream subclasses within the Node.js project. Redirecting changes to streams from the Node.js project to this project. Assisting in the implementation of stream providers within Node.js. Recommending versions of readable-stream to be included in Node.js. Messaging about the future of streams to give the community advance notice of changes. Team Members Chris Dickinson (@chrisdickinson) <christopher.s.dickinson@gmail.com&gt; Release GPG key: 9554F04D7259F04124DE6B476D5A82AC7E37093B Calvin Metcalf (@calvinmetcalf) <calvin.metcalf@gmail.com&gt; Release GPG key: F3EF5F62A87FC27A22E643F714CE4FF5015AA242 Rod Vagg (@rvagg) <rod@vagg.org&gt; Release GPG key: DD8F2338BAE7501E3DD5AC78C273792F7D83545D Sam Newman (@sonewman) <newmansam@outlook.com&gt; Mathias Buus (@mafintosh) <mathiasbuus@gmail.com&gt; Domenic Denicola (@domenic) <d@domenic.me&gt; Matteo Collina (@mcollina) <matteo.collina@gmail.com&gt; Release GPG key: 3ABC01543F22DD2239285CDD818674489FBC127E Irina Shestak (@lrlna) <shestak.irina@gmail.com&gt;"
  },
  "src/frontend/app-client/node_modules/readdirp/README.html": {
    "href": "src/frontend/app-client/node_modules/readdirp/README.html",
    "title": "readdirp",
    "summary": "readdirp Recursive version of fs.readdir. Exposes a stream API (with small RAM & CPU footprint) and a promise API. npm install readdirp jsr add jsr:@paulmillr/readdirp // Use streams to achieve small RAM & CPU footprint. // 1) Streams example with for-await. import readdirp from 'readdirp'; for await (const entry of readdirp('.')) { const {path} = entry; console.log(`${JSON.stringify({path})}`); } // 2) Streams example, non for-await. // Print out all JS files along with their size within the current folder & subfolders. import readdirp from 'readdirp'; readdirp('.', {alwaysStat: true, fileFilter: (f) => f.basename.endsWith('.js')}) .on('data', (entry) => { const {path, stats: {size}} = entry; console.log(`${JSON.stringify({path, size})}`); }) // Optionally call stream.destroy() in `warn()` in order to abort and cause 'close' to be emitted .on('warn', error => console.error('non-fatal error', error)) .on('error', error => console.error('fatal error', error)) .on('end', () => console.log('done')); // 3) Promise example. More RAM and CPU than streams / for-await. import { readdirpPromise } from 'readdirp'; const files = await readdirpPromise('.'); console.log(files.map(file => file.path)); // Other options. import readdirp from 'readdirp'; readdirp('test', { fileFilter: (f) => f.basename.endsWith('.js'), directoryFilter: (d) => d.basename !== '.git', // directoryFilter: (di) => di.basename.length === 9 type: 'files_directories', depth: 1 }); API const stream = readdirp(root[, options]) — Stream API Reads given root recursively and returns a stream of entry infos Optionally can be used like for await (const entry of stream) with node.js 10+ (asyncIterator). on('data', (entry) => {}) entry info for every file / dir. on('warn', (error) => {}) non-fatal Error that prevents a file / dir from being processed. Example: inaccessible to the user. on('error', (error) => {}) fatal Error which also ends the stream. Example: illegal options where passed. on('end') — we are done. Called when all entries were found and no more will be emitted. on('close') — stream is destroyed via stream.destroy(). Could be useful if you want to manually abort even on a non fatal error. At that point the stream is no longer readable and no more entries, warning or errors are emitted To learn more about streams, consult the very detailed nodejs streams documentation or the stream-handbook const entries = await readdirp.promise(root[, options]) — Promise API. Returns a list of entry infos. First argument is awalys root, path in which to start reading and recursing into subdirectories. options fileFilter: filter to include or exclude files Function: a function that takes an entry info as a parameter and returns true to include or false to exclude the entry directoryFilter: filter to include/exclude directories found and to recurse into. Directories that do not pass a filter will not be recursed into. depth: 5: depth at which to stop recursing even if more subdirectories are found type: 'files': determines if data events on the stream should be emitted for 'files' (default), 'directories', 'files_directories', or 'all'. Setting to 'all' will also include entries for other types of file descriptors like character devices, unix sockets and named pipes. alwaysStat: false: always return stats property for every file. Default is false, readdirp will return Dirent entries. Setting it to true can double readdir execution time - use it only when you need file size, mtime etc. Cannot be enabled on node <10.10.0. lstat: false: include symlink entries in the stream along with files. When true, fs.lstat would be used instead of fs.stat EntryInfo Has the following properties: path: 'assets/javascripts/react.js': path to the file/directory (relative to given root) fullPath: '/Users/dev/projects/app/assets/javascripts/react.js': full path to the file/directory found basename: 'react.js': name of the file/directory dirent: fs.Dirent: built-in dir entry object - only with alwaysStat: false stats: fs.Stats: built in stat object - only with alwaysStat: true Changelog 4.0 (Aug 25, 2024) rewritten in typescript, producing hybrid common.js / esm module. Remove glob support and all dependencies Make sure you're using let {readdirp} = require('readdirp') in common.js 3.5 (Oct 13, 2020) disallows recursive directory-based symlinks. Before, it could have entered infinite loop. 3.4 (Mar 19, 2020) adds support for directory-based symlinks. 3.3 (Dec 6, 2019) stabilizes RAM consumption and enables perf management with highWaterMark option. Fixes race conditions related to for-await looping. 3.2 (Oct 14, 2019) improves performance by 250% and makes streams implementation more idiomatic. 3.1 (Jul 7, 2019) brings bigint support to stat output on Windows. This is backwards-incompatible for some cases. Be careful. It you use it incorrectly, you'll see \"TypeError: Cannot mix BigInt and other types, use explicit conversions\". 3.0 brings huge performance improvements and stream backpressure support. Upgrading 2.x to 3.x: Signature changed from readdirp(options) to readdirp(root, options) Replaced callback API with promise API. Renamed entryType option to type Renamed entryType: 'both' to 'files_directories' EntryInfo Renamed stat to stats Emitted only when alwaysStat: true dirent is emitted instead of stats by default with alwaysStat: false Renamed name to basename Removed parentDir and fullParentDir properties Supported node.js versions: 4.x: node 14+ 3.x: node 8+ 2.x: node 0.6+ License Copyright (c) 2012-2019 Thorsten Lorenz, Paul Miller (https://paulmillr.com) MIT License, see LICENSE file."
  },
  "src/frontend/app-client/node_modules/regenerator-runtime/README.html": {
    "href": "src/frontend/app-client/node_modules/regenerator-runtime/README.html",
    "title": "regenerator-runtime",
    "summary": "regenerator-runtime Standalone runtime for Regenerator-compiled generator and async functions. To import the runtime as a module (recommended), either of the following import styles will work: // CommonJS const regeneratorRuntime = require(\"regenerator-runtime\"); // ECMAScript 2015 import regeneratorRuntime from \"regenerator-runtime\"; To ensure that regeneratorRuntime is defined globally, either of the following styles will work: // CommonJS require(\"regenerator-runtime/runtime\"); // ECMAScript 2015 import \"regenerator-runtime/runtime.js\"; To get the absolute file system path of runtime.js, evaluate the following expression: require(\"regenerator-runtime/path\").path"
  },
  "src/frontend/app-client/node_modules/resolve-from/readme.html": {
    "href": "src/frontend/app-client/node_modules/resolve-from/readme.html",
    "title": "resolve-from",
    "summary": "resolve-from Resolve the path of a module like require.resolve() but from a given path Install $ npm install resolve-from Usage const resolveFrom = require('resolve-from'); // There is a file at `./foo/bar.js` resolveFrom('foo', './bar'); //=> '/Users/sindresorhus/dev/test/foo/bar.js' API resolveFrom(fromDir, moduleId) Like require(), throws when the module can't be found. resolveFrom.silent(fromDir, moduleId) Returns null instead of throwing when the module can't be found. fromDir Type: string Directory to resolve from. moduleId Type: string What you would use in require(). Tip Create a partial using a bound function if you want to resolve from the same fromDir multiple times: const resolveFromFoo = resolveFrom.bind(null, 'foo'); resolveFromFoo('./bar'); resolveFromFoo('./baz'); Related resolve-cwd - Resolve the path of a module from the current working directory import-from - Import a module from a given path import-cwd - Import a module from the current working directory resolve-pkg - Resolve the path of a package regardless of it having an entry point import-lazy - Import a module lazily resolve-global - Resolve the path of a globally installed module License MIT © Sindre Sorhus"
  },
  "src/frontend/app-client/node_modules/resolve/SECURITY.html": {
    "href": "src/frontend/app-client/node_modules/resolve/SECURITY.html",
    "title": "Security",
    "summary": "Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report."
  },
  "src/frontend/app-client/node_modules/retry/README.html": {
    "href": "src/frontend/app-client/node_modules/retry/README.html",
    "title": "retry",
    "summary": "retry Abstraction for exponential and custom retry strategies for failed operations. Installation npm install retry Current Status This module has been tested and is ready to be used. Tutorial The example below will retry a potentially failing dns.resolve operation 10 times using an exponential backoff strategy. With the default settings, this means the last attempt is made after 17 minutes and 3 seconds. var dns = require('dns'); var retry = require('retry'); function faultTolerantResolve(address, cb) { var operation = retry.operation(); operation.attempt(function(currentAttempt) { dns.resolve(address, function(err, addresses) { if (operation.retry(err)) { return; } cb(err ? operation.mainError() : null, addresses); }); }); } faultTolerantResolve('nodejs.org', function(err, addresses) { console.log(err, addresses); }); Of course you can also configure the factors that go into the exponential backoff. See the API documentation below for all available settings. currentAttempt is an int representing the number of attempts so far. var operation = retry.operation({ retries: 5, factor: 3, minTimeout: 1 * 1000, maxTimeout: 60 * 1000, randomize: true, }); API retry.operation([options]) Creates a new RetryOperation object. options is the same as retry.timeouts()'s options, with two additions: forever: Whether to retry forever, defaults to false. unref: Whether to unref the setTimeout's, defaults to false. maxRetryTime: The maximum time (in milliseconds) that the retried operation is allowed to run. Default is Infinity. retry.timeouts([options]) Returns an array of timeouts. All time options and return values are in milliseconds. If options is an array, a copy of that array is returned. options is a JS object that can contain any of the following keys: retries: The maximum amount of times to retry the operation. Default is 10. Seting this to 1 means do it once, then retry it once. factor: The exponential factor to use. Default is 2. minTimeout: The number of milliseconds before starting the first retry. Default is 1000. maxTimeout: The maximum number of milliseconds between two retries. Default is Infinity. randomize: Randomizes the timeouts by multiplying with a factor between 1 to 2. Default is false. The formula used to calculate the individual timeouts is: Math.min(random * minTimeout * Math.pow(factor, attempt), maxTimeout) Have a look at this article for a better explanation of approach. If you want to tune your factor / times settings to attempt the last retry after a certain amount of time, you can use wolfram alpha. For example in order to tune for 10 attempts in 5 minutes, you can use this equation: Explaining the various values from left to right: k = 0 ... 9: The retries value (10) 1000: The minTimeout value in ms (1000) x^k: No need to change this, x will be your resulting factor 5 * 60 * 1000: The desired total amount of time for retrying in ms (5 minutes) To make this a little easier for you, use wolfram alpha to do the calculations: http://www.wolframalpha.com/input/?i=Sum%5B1000*x^k%2C+{k%2C+0%2C+9}%5D+%3D+5+*+60+*+1000 retry.createTimeout(attempt, opts) Returns a new timeout (integer in milliseconds) based on the given parameters. attempt is an integer representing for which retry the timeout should be calculated. If your retry operation was executed 4 times you had one attempt and 3 retries. If you then want to calculate a new timeout, you should set attempt to 4 (attempts are zero-indexed). opts can include factor, minTimeout, randomize (boolean) and maxTimeout. They are documented above. retry.createTimeout() is used internally by retry.timeouts() and is public for you to be able to create your own timeouts for reinserting an item, see issue #13. retry.wrap(obj, [options], [methodNames]) Wrap all functions of the obj with retry. Optionally you can pass operation options and an array of method names which need to be wrapped. retry.wrap(obj) retry.wrap(obj, ['method1', 'method2']) retry.wrap(obj, {retries: 3}) retry.wrap(obj, {retries: 3}, ['method1', 'method2']) The options object can take any options that the usual call to retry.operation can take. new RetryOperation(timeouts, [options]) Creates a new RetryOperation where timeouts is an array where each value is a timeout given in milliseconds. Available options: forever: Whether to retry forever, defaults to false. unref: Wether to unref the setTimeout's, defaults to false. If forever is true, the following changes happen: RetryOperation.errors() will only output an array of one item: the last error. RetryOperation will repeatedly use the timeouts array. Once all of its timeouts have been used up, it restarts with the first timeout, then uses the second and so on. retryOperation.errors() Returns an array of all errors that have been passed to retryOperation.retry() so far. The returning array has the errors ordered chronologically based on when they were passed to retryOperation.retry(), which means the first passed error is at index zero and the last is at the last index. retryOperation.mainError() A reference to the error object that occured most frequently. Errors are compared using the error.message property. If multiple error messages occured the same amount of time, the last error object with that message is returned. If no errors occured so far, the value is null. retryOperation.attempt(fn, timeoutOps) Defines the function fn that is to be retried and executes it for the first time right away. The fn function can receive an optional currentAttempt callback that represents the number of attempts to execute fn so far. Optionally defines timeoutOps which is an object having a property timeout in miliseconds and a property cb callback function. Whenever your retry operation takes longer than timeout to execute, the timeout callback function cb is called. retryOperation.try(fn) This is an alias for retryOperation.attempt(fn). This is deprecated. Please use retryOperation.attempt(fn) instead. retryOperation.start(fn) This is an alias for retryOperation.attempt(fn). This is deprecated. Please use retryOperation.attempt(fn) instead. retryOperation.retry(error) Returns false when no error value is given, or the maximum amount of retries has been reached. Otherwise it returns true, and retries the operation after the timeout for the current attempt number. retryOperation.stop() Allows you to stop the operation being retried. Useful for aborting the operation on a fatal error etc. retryOperation.reset() Resets the internal state of the operation object, so that you can call attempt() again as if this was a new operation object. retryOperation.attempts() Returns an int representing the number of attempts it took to call fn before it was successful. License retry is licensed under the MIT license. Changelog 0.10.0 Adding stop functionality, thanks to @maxnachlinger. 0.9.0 Adding unref functionality, thanks to @satazor. 0.8.0 Implementing retry.wrap. 0.7.0 Some bug fixes and made retry.createTimeout() public. Fixed issues #10, #12, and #13. 0.6.0 Introduced optional timeOps parameter for the attempt() function which is an object having a property timeout in milliseconds and a property cb callback function. Whenever your retry operation takes longer than timeout to execute, the timeout callback function cb is called. 0.5.0 Some minor refactoring. 0.4.0 Changed retryOperation.try() to retryOperation.attempt(). Deprecated the aliases start() and try() for it. 0.3.0 Added retryOperation.start() which is an alias for retryOperation.try(). 0.2.0 Added attempts() function and parameter to retryOperation.try() representing the number of attempts it took to call fn()."
  },
  "src/frontend/app-client/node_modules/rollup/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/rollup/LICENSE.html",
    "title": "Rollup core license",
    "summary": "Rollup core license Rollup is released under the MIT license: The MIT License (MIT) Copyright (c) 2017 these people Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Licenses of bundled dependencies The published Rollup artifact additionally contains code with the following licenses: MIT, ISC, 0BSD Bundled dependencies: @jridgewell/sourcemap-codec License: MIT By: Rich Harris Repository: git+https://github.com/jridgewell/sourcemap-codec.git The MIT License Copyright (c) 2015 Rich Harris Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @rollup/pluginutils License: MIT By: Rich Harris Repository: rollup/plugins The MIT License (MIT) Copyright (c) 2019 RollupJS Plugin Contributors (https://github.com/rollup/plugins/graphs/contributors) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. anymatch License: ISC By: Elan Shanker Repository: https://github.com/micromatch/anymatch The ISC License Copyright (c) 2019 Elan Shanker, Paul Miller (https://paulmillr.com) Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. binary-extensions License: MIT By: Sindre Sorhus Repository: sindresorhus/binary-extensions MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Copyright (c) Paul Miller (https://paulmillr.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. braces License: MIT By: Jon Schlinkert, Brian Woodward, Elan Shanker, Eugene Sharygin, hemanth.hm Repository: micromatch/braces The MIT License (MIT) Copyright (c) 2014-present, Jon Schlinkert. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. builtin-modules License: MIT By: Sindre Sorhus Repository: sindresorhus/builtin-modules MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. chokidar License: MIT By: Paul Miller, Elan Shanker Repository: git+https://github.com/paulmillr/chokidar.git The MIT License (MIT) Copyright (c) 2012-2019 Paul Miller (https://paulmillr.com), Elan Shanker Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. date-time License: MIT By: Sindre Sorhus Repository: sindresorhus/date-time MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. fill-range License: MIT By: Jon Schlinkert, Edo Rivai, Paul Miller, Rouven Weßling Repository: jonschlinkert/fill-range The MIT License (MIT) Copyright (c) 2014-present, Jon Schlinkert. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. flru License: MIT By: Luke Edwards Repository: lukeed/flru MIT License Copyright (c) Luke Edwards luke.edwards05@gmail.com (lukeed.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. glob-parent License: ISC By: Gulp Team, Elan Shanker, Blaine Bublitz Repository: gulpjs/glob-parent The ISC License Copyright (c) 2015, 2019 Elan Shanker Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. is-binary-path License: MIT By: Sindre Sorhus Repository: sindresorhus/is-binary-path MIT License Copyright (c) 2019 Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com), Paul Miller (https://paulmillr.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. is-extglob License: MIT By: Jon Schlinkert Repository: jonschlinkert/is-extglob The MIT License (MIT) Copyright (c) 2014-2016, Jon Schlinkert Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. is-glob License: MIT By: Jon Schlinkert, Brian Woodward, Daniel Perez Repository: micromatch/is-glob The MIT License (MIT) Copyright (c) 2014-2017, Jon Schlinkert. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. is-number License: MIT By: Jon Schlinkert, Olsten Larck, Rouven Weßling Repository: jonschlinkert/is-number The MIT License (MIT) Copyright (c) 2014-present, Jon Schlinkert. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. is-reference License: MIT By: Rich Harris Repository: git+https://github.com/Rich-Harris/is-reference.git locate-character License: MIT By: Rich Harris Repository: git+https://gitlab.com/Rich-Harris/locate-character.git magic-string License: MIT By: Rich Harris Repository: https://github.com/rich-harris/magic-string Copyright 2018 Rich Harris Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. normalize-path License: MIT By: Jon Schlinkert, Blaine Bublitz Repository: jonschlinkert/normalize-path The MIT License (MIT) Copyright (c) 2014-2018, Jon Schlinkert. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. parse-ms License: MIT By: Sindre Sorhus Repository: sindresorhus/parse-ms MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. picocolors License: ISC By: Alexey Raspopov Repository: alexeyraspopov/picocolors ISC License Copyright (c) 2021-2024 Oleksii Raspopov, Kostiantyn Denysov, Anton Verinov Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. picomatch License: MIT By: Jon Schlinkert Repository: micromatch/picomatch The MIT License (MIT) Copyright (c) 2017-present, Jon Schlinkert. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. pretty-bytes License: MIT By: Sindre Sorhus Repository: sindresorhus/pretty-bytes MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. pretty-ms License: MIT By: Sindre Sorhus Repository: sindresorhus/pretty-ms MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. readdirp License: MIT By: Thorsten Lorenz, Paul Miller Repository: git://github.com/paulmillr/readdirp.git MIT License Copyright (c) 2012-2019 Thorsten Lorenz, Paul Miller (https://paulmillr.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. signal-exit License: ISC By: Ben Coe Repository: https://github.com/tapjs/signal-exit.git The ISC License Copyright (c) 2015-2023 Benjamin Coe, Isaac Z. Schlueter, and Contributors Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. time-zone License: MIT By: Sindre Sorhus Repository: sindresorhus/time-zone MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. to-regex-range License: MIT By: Jon Schlinkert, Rouven Weßling Repository: micromatch/to-regex-range The MIT License (MIT) Copyright (c) 2015-present, Jon Schlinkert. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. tslib License: 0BSD By: Microsoft Corp. Repository: https://github.com/Microsoft/tslib.git Copyright (c) Microsoft Corporation. Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. yargs-parser License: ISC By: Ben Coe Repository: https://github.com/yargs/yargs-parser.git Copyright (c) 2016, Contributors Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE."
  },
  "src/frontend/app-client/node_modules/rollup/README.html": {
    "href": "src/frontend/app-client/node_modules/rollup/README.html",
    "title": "Rollup",
    "summary": "Rollup Overview Rollup is a module bundler for JavaScript which compiles small pieces of code into something larger and more complex, such as a library or application. It uses the standardized ES module format for code, instead of previous idiosyncratic solutions such as CommonJS and AMD. ES modules let you freely and seamlessly combine the most useful individual functions from your favorite libraries. Rollup can optimize ES modules for faster native loading in modern browsers, or output a legacy module format allowing ES module workflows today. Quick Start Guide Install with npm install --global rollup. Rollup can be used either through a command line interface with an optional configuration file or else through its JavaScript API. Run rollup --help to see the available options and parameters. The starter project templates, rollup-starter-lib and rollup-starter-app, demonstrate common configuration options, and more detailed instructions are available throughout the user guide. Commands These commands assume the entry point to your application is named main.js, and that you'd like all imports compiled into a single file named bundle.js. For browsers: # compile to a <script> containing a self-executing function rollup main.js --format iife --name \"myBundle\" --file bundle.js For Node.js: # compile to a CommonJS module rollup main.js --format cjs --file bundle.js For both browsers and Node.js: # UMD format requires a bundle name rollup main.js --format umd --name \"myBundle\" --file bundle.js Why Developing software is usually easier if you break your project into smaller separate pieces, since that often removes unexpected interactions and dramatically reduces the complexity of the problems you'll need to solve, and simply writing smaller projects in the first place isn't necessarily the answer. Unfortunately, JavaScript has not historically included this capability as a core feature in the language. This finally changed with ES modules support in JavaScript, which provides a syntax for importing and exporting functions and data so they can be shared between separate scripts. Most browsers and Node.js support ES modules. However, Node.js releases before 12.17 support ES modules only behind the --experimental-modules flag, and older browsers like Internet Explorer do not support ES modules at all. Rollup allows you to write your code using ES modules, and run your application even in environments that do not support ES modules natively. For environments that support them, Rollup can output optimized ES modules; for environments that don't, Rollup can compile your code to other formats such as CommonJS modules, AMD modules, and IIFE-style scripts. This means that you get to write future-proof code, and you also get the tremendous benefits of... Tree Shaking In addition to enabling the use of ES modules, Rollup also statically analyzes and optimizes the code you are importing, and will exclude anything that isn't actually used. This allows you to build on top of existing tools and modules without adding extra dependencies or bloating the size of your project. For example, with CommonJS, the entire tool or library must be imported. // import the entire utils object with CommonJS var utils = require('node:utils'); var query = 'Rollup'; // use the ajax method of the utils object utils.ajax('https://api.example.com?search=' + query).then(handleResponse); But with ES modules, instead of importing the whole utils object, we can just import the one ajax function we need: // import the ajax function with an ES import statement import { ajax } from 'node:utils'; var query = 'Rollup'; // call the ajax function ajax('https://api.example.com?search=' + query).then(handleResponse); Because Rollup includes the bare minimum, it results in lighter, faster, and less complicated libraries and applications. Since this approach is based on explicit import and export statements, it is vastly more effective than simply running an automated minifier to detect unused variables in the compiled output code. Compatibility Importing CommonJS Rollup can import existing CommonJS modules through a plugin. Publishing ES Modules To make sure your ES modules are immediately usable by tools that work with CommonJS such as Node.js and webpack, you can use Rollup to compile to UMD or CommonJS format, and then point to that compiled version with the main property in your package.json file. If your package.json file also has a module field, ES-module-aware tools like Rollup and webpack will import the ES module version directly. Contributors This project exists thanks to all the people who contribute. [Contribute]. . If you want to contribute yourself, head over to the contribution guidelines. Backers Thank you to all our backers! \uD83D\uDE4F [Become a backer] Sponsors Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [Become a sponsor] Special Sponsor TNG has been supporting the work of Lukas Taegert-Atkinson on Rollup since 2017. License MIT"
  },
  "src/frontend/app-client/node_modules/safe-buffer/README.html": {
    "href": "src/frontend/app-client/node_modules/safe-buffer/README.html",
    "title": "safe-buffer",
    "summary": "safe-buffer Safer Node.js Buffer API Use the new Node.js Buffer APIs (Buffer.from, Buffer.alloc, Buffer.allocUnsafe, Buffer.allocUnsafeSlow) in all versions of Node.js. Uses the built-in implementation when available. install npm install safe-buffer usage The goal of this package is to provide a safe replacement for the node.js Buffer. It's a drop-in replacement for Buffer. You can use it by adding one require line to the top of your node.js modules: var Buffer = require('safe-buffer').Buffer // Existing buffer code will continue to work without issues: new Buffer('hey', 'utf8') new Buffer([1, 2, 3], 'utf8') new Buffer(obj) new Buffer(16) // create an uninitialized buffer (potentially unsafe) // But you can use these new explicit APIs to make clear what you want: Buffer.from('hey', 'utf8') // convert from many types to a Buffer Buffer.alloc(16) // create a zero-filled buffer (safe) Buffer.allocUnsafe(16) // create an uninitialized buffer (potentially unsafe) api Class Method: Buffer.from(array) array {Array} Allocates a new Buffer using an array of octets. const buf = Buffer.from([0x62,0x75,0x66,0x66,0x65,0x72]); // creates a new Buffer containing ASCII bytes // ['b','u','f','f','e','r'] A TypeError will be thrown if array is not an Array. Class Method: Buffer.from(arrayBuffer[, byteOffset[, length]]) arrayBuffer {ArrayBuffer} The .buffer property of a TypedArray or a new ArrayBuffer() byteOffset {Number} Default: 0 length {Number} Default: arrayBuffer.length - byteOffset When passed a reference to the .buffer property of a TypedArray instance, the newly created Buffer will share the same allocated memory as the TypedArray. const arr = new Uint16Array(2); arr[0] = 5000; arr[1] = 4000; const buf = Buffer.from(arr.buffer); // shares the memory with arr; console.log(buf); // Prints: <Buffer 88 13 a0 0f> // changing the TypedArray changes the Buffer also arr[1] = 6000; console.log(buf); // Prints: <Buffer 88 13 70 17> The optional byteOffset and length arguments specify a memory range within the arrayBuffer that will be shared by the Buffer. const ab = new ArrayBuffer(10); const buf = Buffer.from(ab, 0, 2); console.log(buf.length); // Prints: 2 A TypeError will be thrown if arrayBuffer is not an ArrayBuffer. Class Method: Buffer.from(buffer) buffer {Buffer} Copies the passed buffer data onto a new Buffer instance. const buf1 = Buffer.from('buffer'); const buf2 = Buffer.from(buf1); buf1[0] = 0x61; console.log(buf1.toString()); // 'auffer' console.log(buf2.toString()); // 'buffer' (copy is not changed) A TypeError will be thrown if buffer is not a Buffer. Class Method: Buffer.from(str[, encoding]) str {String} String to encode. encoding {String} Encoding to use, Default: 'utf8' Creates a new Buffer containing the given JavaScript string str. If provided, the encoding parameter identifies the character encoding. If not provided, encoding defaults to 'utf8'. const buf1 = Buffer.from('this is a tést'); console.log(buf1.toString()); // prints: this is a tést console.log(buf1.toString('ascii')); // prints: this is a tC)st const buf2 = Buffer.from('7468697320697320612074c3a97374', 'hex'); console.log(buf2.toString()); // prints: this is a tést A TypeError will be thrown if str is not a string. Class Method: Buffer.alloc(size[, fill[, encoding]]) size {Number} fill {Value} Default: undefined encoding {String} Default: utf8 Allocates a new Buffer of size bytes. If fill is undefined, the Buffer will be zero-filled. const buf = Buffer.alloc(5); console.log(buf); // <Buffer 00 00 00 00 00> The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. If fill is specified, the allocated Buffer will be initialized by calling buf.fill(fill). See [buf.fill()][] for more information. const buf = Buffer.alloc(5, 'a'); console.log(buf); // <Buffer 61 61 61 61 61> If both fill and encoding are specified, the allocated Buffer will be initialized by calling buf.fill(fill, encoding). For example: const buf = Buffer.alloc(11, 'aGVsbG8gd29ybGQ=', 'base64'); console.log(buf); // <Buffer 68 65 6c 6c 6f 20 77 6f 72 6c 64> Calling Buffer.alloc(size) can be significantly slower than the alternative Buffer.allocUnsafe(size) but ensures that the newly created Buffer instance contents will never contain sensitive data. A TypeError will be thrown if size is not a number. Class Method: Buffer.allocUnsafe(size) size {Number} Allocates a new non-zero-filled Buffer of size bytes. The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. The underlying memory for Buffer instances created in this way is not initialized. The contents of the newly created Buffer are unknown and may contain sensitive data. Use [buf.fill(0)][] to initialize such Buffer instances to zeroes. const buf = Buffer.allocUnsafe(5); console.log(buf); // <Buffer 78 e0 82 02 01> // (octets will be different, every time) buf.fill(0); console.log(buf); // <Buffer 00 00 00 00 00> A TypeError will be thrown if size is not a number. Note that the Buffer module pre-allocates an internal Buffer instance of size Buffer.poolSize that is used as a pool for the fast allocation of new Buffer instances created using Buffer.allocUnsafe(size) (and the deprecated new Buffer(size) constructor) only when size is less than or equal to Buffer.poolSize >> 1 (floor of Buffer.poolSize divided by two). The default value of Buffer.poolSize is 8192 but can be modified. Use of this pre-allocated internal memory pool is a key difference between calling Buffer.alloc(size, fill) vs. Buffer.allocUnsafe(size).fill(fill). Specifically, Buffer.alloc(size, fill) will never use the internal Buffer pool, while Buffer.allocUnsafe(size).fill(fill) will use the internal Buffer pool if size is less than or equal to half Buffer.poolSize. The difference is subtle but can be important when an application requires the additional performance that Buffer.allocUnsafe(size) provides. Class Method: Buffer.allocUnsafeSlow(size) size {Number} Allocates a new non-zero-filled and non-pooled Buffer of size bytes. The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. The underlying memory for Buffer instances created in this way is not initialized. The contents of the newly created Buffer are unknown and may contain sensitive data. Use [buf.fill(0)][] to initialize such Buffer instances to zeroes. When using Buffer.allocUnsafe() to allocate new Buffer instances, allocations under 4KB are, by default, sliced from a single pre-allocated Buffer. This allows applications to avoid the garbage collection overhead of creating many individually allocated Buffers. This approach improves both performance and memory usage by eliminating the need to track and cleanup as many Persistent objects. However, in the case where a developer may need to retain a small chunk of memory from a pool for an indeterminate amount of time, it may be appropriate to create an un-pooled Buffer instance using Buffer.allocUnsafeSlow() then copy out the relevant bits. // need to keep around a few small chunks of memory const store = []; socket.on('readable', () => { const data = socket.read(); // allocate for retained data const sb = Buffer.allocUnsafeSlow(10); // copy the data into the new allocation data.copy(sb, 0, 0, 10); store.push(sb); }); Use of Buffer.allocUnsafeSlow() should be used only as a last resort after a developer has observed undue memory retention in their applications. A TypeError will be thrown if size is not a number. All the Rest The rest of the Buffer API is exactly the same as in node.js. See the docs. Related links Node.js issue: Buffer(number) is unsafe Node.js Enhancement Proposal: Buffer.from/Buffer.alloc/Buffer.zalloc/Buffer() soft-deprecate Why is Buffer unsafe? Today, the node.js Buffer constructor is overloaded to handle many different argument types like String, Array, Object, TypedArrayView (Uint8Array, etc.), ArrayBuffer, and also Number. The API is optimized for convenience: you can throw any type at it, and it will try to do what you want. Because the Buffer constructor is so powerful, you often see code like this: // Convert UTF-8 strings to hex function toHex (str) { return new Buffer(str).toString('hex') } But what happens if toHex is called with a Number argument? Remote Memory Disclosure If an attacker can make your program call the Buffer constructor with a Number argument, then they can make it allocate uninitialized memory from the node.js process. This could potentially disclose TLS private keys, user data, or database passwords. When the Buffer constructor is passed a Number argument, it returns an UNINITIALIZED block of memory of the specified size. When you create a Buffer like this, you MUST overwrite the contents before returning it to the user. From the node.js docs: new Buffer(size) size Number The underlying memory for Buffer instances created in this way is not initialized. The contents of a newly created Buffer are unknown and could contain sensitive data. Use buf.fill(0) to initialize a Buffer to zeroes. (Emphasis our own.) Whenever the programmer intended to create an uninitialized Buffer you often see code like this: var buf = new Buffer(16) // Immediately overwrite the uninitialized buffer with data from another buffer for (var i = 0; i < buf.length; i++) { buf[i] = otherBuf[i] } Would this ever be a problem in real code? Yes. It's surprisingly common to forget to check the type of your variables in a dynamically-typed language like JavaScript. Usually the consequences of assuming the wrong type is that your program crashes with an uncaught exception. But the failure mode for forgetting to check the type of arguments to the Buffer constructor is more catastrophic. Here's an example of a vulnerable service that takes a JSON payload and converts it to hex: // Take a JSON payload {str: \"some string\"} and convert it to hex var server = http.createServer(function (req, res) { var data = '' req.setEncoding('utf8') req.on('data', function (chunk) { data += chunk }) req.on('end', function () { var body = JSON.parse(data) res.end(new Buffer(body.str).toString('hex')) }) }) server.listen(8080) In this example, an http client just has to send: { \"str\": 1000 } and it will get back 1,000 bytes of uninitialized memory from the server. This is a very serious bug. It's similar in severity to the the Heartbleed bug that allowed disclosure of OpenSSL process memory by remote attackers. Which real-world packages were vulnerable? bittorrent-dht Mathias Buus and I (Feross Aboukhadijeh) found this issue in one of our own packages, bittorrent-dht. The bug would allow anyone on the internet to send a series of messages to a user of bittorrent-dht and get them to reveal 20 bytes at a time of uninitialized memory from the node.js process. Here's the commit that fixed it. We released a new fixed version, created a Node Security Project disclosure, and deprecated all vulnerable versions on npm so users will get a warning to upgrade to a newer version. ws That got us wondering if there were other vulnerable packages. Sure enough, within a short period of time, we found the same issue in ws, the most popular WebSocket implementation in node.js. If certain APIs were called with Number parameters instead of String or Buffer as expected, then uninitialized server memory would be disclosed to the remote peer. These were the vulnerable methods: socket.send(number) socket.ping(number) socket.pong(number) Here's a vulnerable socket server with some echo functionality: server.on('connection', function (socket) { socket.on('message', function (message) { message = JSON.parse(message) if (message.type === 'echo') { socket.send(message.data) // send back the user's message } }) }) socket.send(number) called on the server, will disclose server memory. Here's the release where the issue was fixed, with a more detailed explanation. Props to Arnout Kazemier for the quick fix. Here's the Node Security Project disclosure. What's the solution? It's important that node.js offers a fast way to get memory otherwise performance-critical applications would needlessly get a lot slower. But we need a better way to signal our intent as programmers. When we want uninitialized memory, we should request it explicitly. Sensitive functionality should not be packed into a developer-friendly API that loosely accepts many different types. This type of API encourages the lazy practice of passing variables in without checking the type very carefully. A new API: Buffer.allocUnsafe(number) The functionality of creating buffers with uninitialized memory should be part of another API. We propose Buffer.allocUnsafe(number). This way, it's not part of an API that frequently gets user input of all sorts of different types passed into it. var buf = Buffer.allocUnsafe(16) // careful, uninitialized memory! // Immediately overwrite the uninitialized buffer with data from another buffer for (var i = 0; i < buf.length; i++) { buf[i] = otherBuf[i] } How do we fix node.js core? We sent a PR to node.js core (merged as semver-major) which defends against one case: var str = 16 new Buffer(str, 'utf8') In this situation, it's implied that the programmer intended the first argument to be a string, since they passed an encoding as a second argument. Today, node.js will allocate uninitialized memory in the case of new Buffer(number, encoding), which is probably not what the programmer intended. But this is only a partial solution, since if the programmer does new Buffer(variable) (without an encoding parameter) there's no way to know what they intended. If variable is sometimes a number, then uninitialized memory will sometimes be returned. What's the real long-term fix? We could deprecate and remove new Buffer(number) and use Buffer.allocUnsafe(number) when we need uninitialized memory. But that would break 1000s of packages. We believe the best solution is to: 1. Change new Buffer(number) to return safe, zeroed-out memory 2. Create a new API for creating uninitialized Buffers. We propose: Buffer.allocUnsafe(number) Update We now support adding three new APIs: Buffer.from(value) - convert from any type to a buffer Buffer.alloc(size) - create a zero-filled buffer Buffer.allocUnsafe(size) - create an uninitialized buffer with given size This solves the core problem that affected ws and bittorrent-dht which is Buffer(variable) getting tricked into taking a number argument. This way, existing code continues working and the impact on the npm ecosystem will be minimal. Over time, npm maintainers can migrate performance-critical code to use Buffer.allocUnsafe(number) instead of new Buffer(number). Conclusion We think there's a serious design issue with the Buffer API as it exists today. It promotes insecure software by putting high-risk functionality into a convenient API with friendly \"developer ergonomics\". This wasn't merely a theoretical exercise because we found the issue in some of the most popular npm packages. Fortunately, there's an easy fix that can be applied today. Use safe-buffer in place of buffer. var Buffer = require('safe-buffer').Buffer Eventually, we hope that node.js core can switch to this new, safer behavior. We believe the impact on the ecosystem would be minimal since it's not a breaking change. Well-maintained, popular packages would be updated to use Buffer.alloc quickly, while older, insecure packages would magically become safe from this attack vector. links Node.js PR: buffer: throw if both length and enc are passed Node Security Project disclosure for ws Node Security Project disclosure forbittorrent-dht credit The original issues in bittorrent-dht (disclosure) and ws (disclosure) were discovered by Mathias Buus and Feross Aboukhadijeh. Thanks to Adam Baldwin for helping disclose these issues and for his work running the Node Security Project. Thanks to John Hiesey for proofreading this README and auditing the code. license MIT. Copyright (C) Feross Aboukhadijeh"
  },
  "src/frontend/app-client/node_modules/safer-buffer/Porting-Buffer.html": {
    "href": "src/frontend/app-client/node_modules/safer-buffer/Porting-Buffer.html",
    "title": "Porting to the Buffer.from/Buffer.alloc API",
    "summary": "Porting to the Buffer.from/Buffer.alloc API Overview Variant 1: Drop support for Node.js ≤ 4.4.x and 5.0.0 — 5.9.x. (recommended) Variant 2: Use a polyfill Variant 3: manual detection, with safeguards Finding problematic bits of code using grep Just run grep -nrE '[^a-zA-Z](Slow)?Buffer\\s*\\(' --exclude-dir node_modules. It will find all the potentially unsafe places in your own code (with some considerably unlikely exceptions). Finding problematic bits of code using Node.js 8 If you’re using Node.js ≥ 8.0.0 (which is recommended), Node.js exposes multiple options that help with finding the relevant pieces of code: --trace-warnings will make Node.js show a stack trace for this warning and other warnings that are printed by Node.js. --trace-deprecation does the same thing, but only for deprecation warnings. --pending-deprecation will show more types of deprecation warnings. In particular, it will show the Buffer() deprecation warning, even on Node.js 8. You can set these flags using an environment variable: $ export NODE_OPTIONS='--trace-warnings --pending-deprecation' $ cat example.js 'use strict'; const foo = new Buffer('foo'); $ node example.js (node:7147) [DEP0005] DeprecationWarning: The Buffer() and new Buffer() constructors are not recommended for use due to security and usability concerns. Please use the new Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() construction methods instead. at showFlaggedDeprecation (buffer.js:127:13) at new Buffer (buffer.js:148:3) at Object.<anonymous> (/path/to/example.js:2:13) [... more stack trace lines ...] Finding problematic bits of code using linters Eslint rules no-buffer-constructor or node/no-deprecated-api also find calls to deprecated Buffer() API. Those rules are included in some pre-sets. There is a drawback, though, that it doesn't always work correctly when Buffer is overriden e.g. with a polyfill, so recommended is a combination of this and some other method described above. Variant 1: Drop support for Node.js ≤ 4.4.x and 5.0.0 — 5.9.x. This is the recommended solution nowadays that would imply only minimal overhead. The Node.js 5.x release line has been unsupported since July 2016, and the Node.js 4.x release line reaches its End of Life in April 2018 (→ Schedule). This means that these versions of Node.js will not receive any updates, even in case of security issues, so using these release lines should be avoided, if at all possible. What you would do in this case is to convert all new Buffer() or Buffer() calls to use Buffer.alloc() or Buffer.from(), in the following way: For new Buffer(number), replace it with Buffer.alloc(number). For new Buffer(string) (or new Buffer(string, encoding)), replace it with Buffer.from(string) (or Buffer.from(string, encoding)). For all other combinations of arguments (these are much rarer), also replace new Buffer(...arguments) with Buffer.from(...arguments). Note that Buffer.alloc() is also faster on the current Node.js versions than new Buffer(size).fill(0), which is what you would otherwise need to ensure zero-filling. Enabling eslint rule no-buffer-constructor or node/no-deprecated-api is recommended to avoid accidential unsafe Buffer API usage. There is also a JSCodeshift codemod for automatically migrating Buffer constructors to Buffer.alloc() or Buffer.from(). Note that it currently only works with cases where the arguments are literals or where the constructor is invoked with two arguments. If you currently support those older Node.js versions and dropping them would be a semver-major change for you, or if you support older branches of your packages, consider using Variant 2 or Variant 3 on older branches, so people using those older branches will also receive the fix. That way, you will eradicate potential issues caused by unguarded Buffer API usage and your users will not observe a runtime deprecation warning when running your code on Node.js 10. Variant 2: Use a polyfill Utilize safer-buffer as a polyfill to support older Node.js versions. You would take exacly the same steps as in Variant 1, but with a polyfill const Buffer = require('safer-buffer').Buffer in all files where you use the new Buffer api. Make sure that you do not use old new Buffer API — in any files where the line above is added, using old new Buffer() API will throw. It will be easy to notice that in CI, though. Alternatively, you could use buffer-from and/or buffer-alloc ponyfills — those are great, the only downsides being 4 deps in the tree and slightly more code changes to migrate off them (as you would be using e.g. Buffer.from under a different name). If you need only Buffer.from polyfilled — buffer-from alone which comes with no extra dependencies. Alternatively, you could use safe-buffer — it also provides a polyfill, but takes a different approach which has it's drawbacks. It will allow you to also use the older new Buffer() API in your code, though — but that's arguably a benefit, as it is problematic, can cause issues in your code, and will start emitting runtime deprecation warnings starting with Node.js 10. Note that in either case, it is important that you also remove all calls to the old Buffer API manually — just throwing in safe-buffer doesn't fix the problem by itself, it just provides a polyfill for the new API. I have seen people doing that mistake. Enabling eslint rule no-buffer-constructor or node/no-deprecated-api is recommended. Don't forget to drop the polyfill usage once you drop support for Node.js < 4.5.0. Variant 3 — manual detection, with safeguards This is useful if you create Buffer instances in only a few places (e.g. one), or you have your own wrapper around them. Buffer(0) This special case for creating empty buffers can be safely replaced with Buffer.concat([]), which returns the same result all the way down to Node.js 0.8.x. Buffer(notNumber) Before: var buf = new Buffer(notNumber, encoding); After: var buf; if (Buffer.from && Buffer.from !== Uint8Array.from) { buf = Buffer.from(notNumber, encoding); } else { if (typeof notNumber === 'number') throw new Error('The \"size\" argument must be of type number.'); buf = new Buffer(notNumber, encoding); } encoding is optional. Note that the typeof notNumber before new Buffer is required (for cases when notNumber argument is not hard-coded) and is not caused by the deprecation of Buffer constructor — it's exactly why the Buffer constructor is deprecated. Ecosystem packages lacking this type-check caused numereous security issues — situations when unsanitized user input could end up in the Buffer(arg) create problems ranging from DoS to leaking sensitive information to the attacker from the process memory. When notNumber argument is hardcoded (e.g. literal \"abc\" or [0,1,2]), the typeof check can be omitted. Also note that using TypeScript does not fix this problem for you — when libs written in TypeScript are used from JS, or when user input ends up there — it behaves exactly as pure JS, as all type checks are translation-time only and are not present in the actual JS code which TS compiles to. Buffer(number) For Node.js 0.10.x (and below) support: var buf; if (Buffer.alloc) { buf = Buffer.alloc(number); } else { buf = new Buffer(number); buf.fill(0); } Otherwise (Node.js ≥ 0.12.x): const buf = Buffer.alloc ? Buffer.alloc(number) : new Buffer(number).fill(0); Regarding Buffer.allocUnsafe Be extra cautious when using Buffer.allocUnsafe: Don't use it if you don't have a good reason to e.g. you probably won't ever see a performance difference for small buffers, in fact, those might be even faster with Buffer.alloc(), if your code is not in the hot code path — you also probably won't notice a difference, keep in mind that zero-filling minimizes the potential risks. If you use it, make sure that you never return the buffer in a partially-filled state, if you are writing to it sequentially — always truncate it to the actuall written length Errors in handling buffers allocated with Buffer.allocUnsafe could result in various issues, ranged from undefined behaviour of your code to sensitive data (user input, passwords, certs) leaking to the remote attacker. Note that the same applies to new Buffer usage without zero-filling, depending on the Node.js version (and lacking type checks also adds DoS to the list of potential problems). FAQ What is wrong with the Buffer constructor? The Buffer constructor could be used to create a buffer in many different ways: new Buffer(42) creates a Buffer of 42 bytes. Before Node.js 8, this buffer contained arbitrary memory for performance reasons, which could include anything ranging from program source code to passwords and encryption keys. new Buffer('abc') creates a Buffer that contains the UTF-8-encoded version of the string 'abc'. A second argument could specify another encoding: For example, new Buffer(string, 'base64') could be used to convert a Base64 string into the original sequence of bytes that it represents. There are several other combinations of arguments. This meant that, in code like var buffer = new Buffer(foo);, it is not possible to tell what exactly the contents of the generated buffer are without knowing the type of foo. Sometimes, the value of foo comes from an external source. For example, this function could be exposed as a service on a web server, converting a UTF-8 string into its Base64 form: function stringToBase64(req, res) { // The request body should have the format of `{ string: 'foobar' }` const rawBytes = new Buffer(req.body.string) const encoded = rawBytes.toString('base64') res.end({ encoded: encoded }) } Note that this code does not validate the type of req.body.string: req.body.string is expected to be a string. If this is the case, all goes well. req.body.string is controlled by the client that sends the request. If req.body.string is the number 50, the rawBytes would be 50 bytes: Before Node.js 8, the content would be uninitialized After Node.js 8, the content would be 50 bytes with the value 0 Because of the missing type check, an attacker could intentionally send a number as part of the request. Using this, they can either: Read uninitialized memory. This will leak passwords, encryption keys and other kinds of sensitive information. (Information leak) Force the program to allocate a large amount of memory. For example, when specifying 500000000 as the input value, each request will allocate 500MB of memory. This can be used to either exhaust the memory available of a program completely and make it crash, or slow it down significantly. (Denial of Service) Both of these scenarios are considered serious security issues in a real-world web server context. when using Buffer.from(req.body.string) instead, passing a number will always throw an exception instead, giving a controlled behaviour that can always be handled by the program. The Buffer() constructor has been deprecated for a while. Is this really an issue? Surveys of code in the npm ecosystem have shown that the Buffer() constructor is still widely used. This includes new code, and overall usage of such code has actually been increasing."
  },
  "src/frontend/app-client/node_modules/safer-buffer/Readme.html": {
    "href": "src/frontend/app-client/node_modules/safer-buffer/Readme.html",
    "title": "safer-buffer",
    "summary": "safer-buffer Modern Buffer API polyfill without footguns, working on Node.js from 0.8 to current. How to use? First, port all Buffer() and new Buffer() calls to Buffer.alloc() and Buffer.from() API. Then, to achieve compatibility with outdated Node.js versions (<4.5.0 and 5.x <5.9.0), use const Buffer = require('safer-buffer').Buffer in all files where you make calls to the new Buffer API. Use var instead of const if you need that for your Node.js version range support. Also, see the porting Buffer guide. Do I need it? Hopefully, not — dropping support for outdated Node.js versions should be fine nowdays, and that is the recommended path forward. You do need to port to the Buffer.alloc() and Buffer.from() though. See the porting guide for a better description. Why not safe-buffer? In short: while safe-buffer serves as a polyfill for the new API, it allows old API usage and itself contains footguns. safe-buffer could be used safely to get the new API while still keeping support for older Node.js versions (like this module), but while analyzing ecosystem usage of the old Buffer API I found out that safe-buffer is itself causing problems in some cases. For example, consider the following snippet: $ cat example.unsafe.js console.log(Buffer(20)) $ ./node-v6.13.0-linux-x64/bin/node example.unsafe.js <Buffer 0a 00 00 00 00 00 00 00 28 13 de 02 00 00 00 00 05 00 00 00> $ standard example.unsafe.js standard: Use JavaScript Standard Style (https://standardjs.com) /home/chalker/repo/safer-buffer/example.unsafe.js:2:13: 'Buffer()' was deprecated since v6. Use 'Buffer.alloc()' or 'Buffer.from()' (use 'https://www.npmjs.com/package/safe-buffer' for '<4.5.0') instead. This is allocates and writes to console an uninitialized chunk of memory. standard linter (among others) catch that and warn people to avoid using unsafe API. Let's now throw in safe-buffer! $ cat example.safe-buffer.js const Buffer = require('safe-buffer').Buffer console.log(Buffer(20)) $ standard example.safe-buffer.js $ ./node-v6.13.0-linux-x64/bin/node example.safe-buffer.js <Buffer 08 00 00 00 00 00 00 00 28 58 01 82 fe 7f 00 00 00 00 00 00> See the problem? Adding in safe-buffer magically removes the lint warning, but the behavior remains identiсal to what we had before, and when launched on Node.js 6.x LTS — this dumps out chunks of uninitialized memory. And this code will still emit runtime warnings on Node.js 10.x and above. That was done by design. I first considered changing safe-buffer, prohibiting old API usage or emitting warnings on it, but that significantly diverges from safe-buffer design. After some discussion, it was decided to move my approach into a separate package, and this is that separate package. This footgun is not imaginary — I observed top-downloaded packages doing that kind of thing, «fixing» the lint warning by blindly including safe-buffer without any actual changes. Also in some cases, even if the API was migrated to use of safe Buffer API — a random pull request can bring unsafe Buffer API usage back to the codebase by adding new calls — and that could go unnoticed even if you have a linter prohibiting that (becase of the reason stated above), and even pass CI. I also observed that being done in popular packages. Some examples: webdriverio (a module with 548 759 downloads/month), websocket-stream (218 288 d/m, fix in maxogden/websocket-stream#142), node-serialport (113 138 d/m, fix in node-serialport/node-serialport#1510), karma (3 973 193 d/m, fix in karma-runner/karma#2947), spdy-transport (5 970 727 d/m, fix in spdy-http2/spdy-transport#53). And there are a lot more over the ecosystem. I filed a PR at mysticatea/eslint-plugin-node#110 to partially fix that (for cases when that lint rule is used), but it is a semver-major change for linter rules and presets, so it would take significant time for that to reach actual setups. It also hasn't been released yet (2018-03-20). Also, safer-buffer discourages the usage of .allocUnsafe(), which is often done by a mistake. It still supports it with an explicit concern barier, by placing it under require('safer-buffer/dangereous'). But isn't throwing bad? Not really. It's an error that could be noticed and fixed early, instead of causing havoc later like unguarded new Buffer() calls that end up receiving user input can do. This package affects only the files where var Buffer = require('safer-buffer').Buffer was done, so it is really simple to keep track of things and make sure that you don't mix old API usage with that. Also, CI should hint anything that you might have missed. New commits, if tested, won't land new usage of unsafe Buffer API this way. Node.js 10.x also deals with that by printing a runtime depecation warning. Would it affect third-party modules? No, unless you explicitly do an awful thing like monkey-patching or overriding the built-in Buffer. Don't do that. But I don't want throwing… That is also fine! Also, it could be better in some cases when you don't comprehensive enough test coverage. In that case — just don't override Buffer and use var SaferBuffer = require('safer-buffer').Buffer instead. That way, everything using Buffer natively would still work, but there would be two drawbacks: Buffer.from/Buffer.alloc won't be polyfilled — use SaferBuffer.from and SaferBuffer.alloc instead. You are still open to accidentally using the insecure deprecated API — use a linter to catch that. Note that using a linter to catch accidential Buffer constructor usage in this case is strongly recommended. Buffer is not overriden in this usecase, so linters won't get confused. «Without footguns»? Well, it is still possible to do some things with Buffer API, e.g. accessing .buffer property on older versions and duping things from there. You shouldn't do that in your code, probabably. The intention is to remove the most significant footguns that affect lots of packages in the ecosystem, and to do it in the proper way. Also, this package doesn't protect against security issues affecting some Node.js versions, so for usage in your own production code, it is still recommended to update to a Node.js version supported by upstream."
  },
  "src/frontend/app-client/node_modules/scheduler/README.html": {
    "href": "src/frontend/app-client/node_modules/scheduler/README.html",
    "title": "scheduler",
    "summary": "scheduler This is a package for cooperative scheduling in a browser environment. It is currently used internally by React, but we plan to make it more generic. The public API for this package is not yet finalized. Thanks The React team thanks Anton Podviaznikov for donating the scheduler package name."
  },
  "src/frontend/app-client/node_modules/semver/README.html": {
    "href": "src/frontend/app-client/node_modules/semver/README.html",
    "title": "semver(1) -- The semantic versioner for npm",
    "summary": "semver(1) -- The semantic versioner for npm Install npm install semver Usage As a node module: const semver = require('semver') semver.valid('1.2.3') // '1.2.3' semver.valid('a.b.c') // null semver.clean(' =v1.2.3 ') // '1.2.3' semver.satisfies('1.2.3', '1.x || >=2.5.0 || 5.0.0 - 7.2.3') // true semver.gt('1.2.3', '9.8.7') // false semver.lt('1.2.3', '9.8.7') // true semver.minVersion('>=1.0.0') // '1.0.0' semver.valid(semver.coerce('v2')) // '2.0.0' semver.valid(semver.coerce('42.6.7.9.3-alpha')) // '42.6.7' You can also just load the module for the function that you care about if you'd like to minimize your footprint. // load the whole API at once in a single object const semver = require('semver') // or just load the bits you need // all of them listed here, just pick and choose what you want // classes const SemVer = require('semver/classes/semver') const Comparator = require('semver/classes/comparator') const Range = require('semver/classes/range') // functions for working with versions const semverParse = require('semver/functions/parse') const semverValid = require('semver/functions/valid') const semverClean = require('semver/functions/clean') const semverInc = require('semver/functions/inc') const semverDiff = require('semver/functions/diff') const semverMajor = require('semver/functions/major') const semverMinor = require('semver/functions/minor') const semverPatch = require('semver/functions/patch') const semverPrerelease = require('semver/functions/prerelease') const semverCompare = require('semver/functions/compare') const semverRcompare = require('semver/functions/rcompare') const semverCompareLoose = require('semver/functions/compare-loose') const semverCompareBuild = require('semver/functions/compare-build') const semverSort = require('semver/functions/sort') const semverRsort = require('semver/functions/rsort') // low-level comparators between versions const semverGt = require('semver/functions/gt') const semverLt = require('semver/functions/lt') const semverEq = require('semver/functions/eq') const semverNeq = require('semver/functions/neq') const semverGte = require('semver/functions/gte') const semverLte = require('semver/functions/lte') const semverCmp = require('semver/functions/cmp') const semverCoerce = require('semver/functions/coerce') // working with ranges const semverSatisfies = require('semver/functions/satisfies') const semverMaxSatisfying = require('semver/ranges/max-satisfying') const semverMinSatisfying = require('semver/ranges/min-satisfying') const semverToComparators = require('semver/ranges/to-comparators') const semverMinVersion = require('semver/ranges/min-version') const semverValidRange = require('semver/ranges/valid') const semverOutside = require('semver/ranges/outside') const semverGtr = require('semver/ranges/gtr') const semverLtr = require('semver/ranges/ltr') const semverIntersects = require('semver/ranges/intersects') const semverSimplifyRange = require('semver/ranges/simplify') const semverRangeSubset = require('semver/ranges/subset') As a command-line utility: $ semver -h A JavaScript implementation of the https://semver.org/ specification Copyright Isaac Z. Schlueter Usage: semver [options] <version> [<version> [...]] Prints valid versions sorted by SemVer precedence Options: -r --range <range> Print versions that match the specified range. -i --increment [<level>] Increment a version by the specified level. Level can be one of: major, minor, patch, premajor, preminor, prepatch, prerelease, or release. Default level is 'patch'. Only one version may be specified. --preid <identifier> Identifier to be used to prefix premajor, preminor, prepatch or prerelease version increments. -l --loose Interpret versions and ranges loosely -n <0|1> This is the base to be used for the prerelease identifier. -p --include-prerelease Always include prerelease versions in range matching -c --coerce Coerce a string into SemVer if possible (does not imply --loose) --rtl Coerce version strings right to left --ltr Coerce version strings left to right (default) Program exits successfully if any valid version satisfies all supplied ranges, and prints all satisfying versions. If no satisfying versions are found, then exits failure. Versions are printed in ascending order, so supplying multiple versions to the utility will just sort them. Versions A \"version\" is described by the v2.0.0 specification found at https://semver.org/. A leading \"=\" or \"v\" character is stripped off and ignored. Support for stripping a leading \"v\" is kept for compatibility with v1.0.0 of the SemVer specification but should not be used anymore. Ranges A version range is a set of comparators that specify versions that satisfy the range. A comparator is composed of an operator and a version. The set of primitive operators is: < Less than <= Less than or equal to > Greater than >= Greater than or equal to = Equal. If no operator is specified, then equality is assumed, so this operator is optional but MAY be included. For example, the comparator >=1.2.7 would match the versions 1.2.7, 1.2.8, 2.5.3, and 1.3.9, but not the versions 1.2.6 or 1.1.0. The comparator >1 is equivalent to >=2.0.0 and would match the versions 2.0.0 and 3.1.0, but not the versions 1.0.1 or 1.1.0. Comparators can be joined by whitespace to form a comparator set, which is satisfied by the intersection of all of the comparators it includes. A range is composed of one or more comparator sets, joined by ||. A version matches a range if and only if every comparator in at least one of the ||-separated comparator sets is satisfied by the version. For example, the range >=1.2.7 <1.3.0 would match the versions 1.2.7, 1.2.8, and 1.2.99, but not the versions 1.2.6, 1.3.0, or 1.1.0. The range 1.2.7 || >=1.2.9 <2.0.0 would match the versions 1.2.7, 1.2.9, and 1.4.6, but not the versions 1.2.8 or 2.0.0. Prerelease Tags If a version has a prerelease tag (for example, 1.2.3-alpha.3) then it will only be allowed to satisfy comparator sets if at least one comparator with the same [major, minor, patch] tuple also has a prerelease tag. For example, the range >1.2.3-alpha.3 would be allowed to match the version 1.2.3-alpha.7, but it would not be satisfied by 3.4.5-alpha.9, even though 3.4.5-alpha.9 is technically \"greater than\" 1.2.3-alpha.3 according to the SemVer sort rules. The version range only accepts prerelease tags on the 1.2.3 version. Version 3.4.5 would satisfy the range because it does not have a prerelease flag, and 3.4.5 is greater than 1.2.3-alpha.7. The purpose of this behavior is twofold. First, prerelease versions frequently are updated very quickly, and contain many breaking changes that are (by the author's design) not yet fit for public consumption. Therefore, by default, they are excluded from range-matching semantics. Second, a user who has opted into using a prerelease version has indicated the intent to use that specific set of alpha/beta/rc versions. By including a prerelease tag in the range, the user is indicating that they are aware of the risk. However, it is still not appropriate to assume that they have opted into taking a similar risk on the next set of prerelease versions. Note that this behavior can be suppressed (treating all prerelease versions as if they were normal versions, for range-matching) by setting the includePrerelease flag on the options object to any functions that do range matching. Prerelease Identifiers The method .inc takes an additional identifier string argument that will append the value of the string as a prerelease identifier: semver.inc('1.2.3', 'prerelease', 'beta') // '1.2.4-beta.0' command-line example: $ semver 1.2.3 -i prerelease --preid beta 1.2.4-beta.0 Which then can be used to increment further: $ semver 1.2.4-beta.0 -i prerelease 1.2.4-beta.1 To get out of the prerelease phase, use the release option: $ semver 1.2.4-beta.1 -i release 1.2.4 Prerelease Identifier Base The method .inc takes an optional parameter 'identifierBase' string that will let you let your prerelease number as zero-based or one-based. Set to false to omit the prerelease number altogether. If you do not specify this parameter, it will default to zero-based. semver.inc('1.2.3', 'prerelease', 'beta', '1') // '1.2.4-beta.1' semver.inc('1.2.3', 'prerelease', 'beta', false) // '1.2.4-beta' command-line example: $ semver 1.2.3 -i prerelease --preid beta -n 1 1.2.4-beta.1 $ semver 1.2.3 -i prerelease --preid beta -n false 1.2.4-beta Advanced Range Syntax Advanced range syntax desugars to primitive comparators in deterministic ways. Advanced ranges may be combined in the same way as primitive comparators using white space or ||. Hyphen Ranges X.Y.Z - A.B.C Specifies an inclusive set. 1.2.3 - 2.3.4 := >=1.2.3 <=2.3.4 If a partial version is provided as the first version in the inclusive range, then the missing pieces are replaced with zeroes. 1.2 - 2.3.4 := >=1.2.0 <=2.3.4 If a partial version is provided as the second version in the inclusive range, then all versions that start with the supplied parts of the tuple are accepted, but nothing that would be greater than the provided tuple parts. 1.2.3 - 2.3 := >=1.2.3 <2.4.0-0 1.2.3 - 2 := >=1.2.3 <3.0.0-0 X-Ranges 1.2.x 1.X 1.2.* * Any of X, x, or * may be used to \"stand in\" for one of the numeric values in the [major, minor, patch] tuple. * := >=0.0.0 (Any non-prerelease version satisfies, unless includePrerelease is specified, in which case any version at all satisfies) 1.x := >=1.0.0 <2.0.0-0 (Matching major version) 1.2.x := >=1.2.0 <1.3.0-0 (Matching major and minor versions) A partial version range is treated as an X-Range, so the special character is in fact optional. \"\" (empty string) := * := >=0.0.0 1 := 1.x.x := >=1.0.0 <2.0.0-0 1.2 := 1.2.x := >=1.2.0 <1.3.0-0 Tilde Ranges ~1.2.3 ~1.2 ~1 Allows patch-level changes if a minor version is specified on the comparator. Allows minor-level changes if not. ~1.2.3 := >=1.2.3 <1.(2+1).0 := >=1.2.3 <1.3.0-0 ~1.2 := >=1.2.0 <1.(2+1).0 := >=1.2.0 <1.3.0-0 (Same as 1.2.x) ~1 := >=1.0.0 <(1+1).0.0 := >=1.0.0 <2.0.0-0 (Same as 1.x) ~0.2.3 := >=0.2.3 <0.(2+1).0 := >=0.2.3 <0.3.0-0 ~0.2 := >=0.2.0 <0.(2+1).0 := >=0.2.0 <0.3.0-0 (Same as 0.2.x) ~0 := >=0.0.0 <(0+1).0.0 := >=0.0.0 <1.0.0-0 (Same as 0.x) ~1.2.3-beta.2 := >=1.2.3-beta.2 <1.3.0-0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. Caret Ranges ^1.2.3 ^0.2.5 ^0.0.4 Allows changes that do not modify the left-most non-zero element in the [major, minor, patch] tuple. In other words, this allows patch and minor updates for versions 1.0.0 and above, patch updates for versions 0.X >=0.1.0, and no updates for versions 0.0.X. Many authors treat a 0.x version as if the x were the major \"breaking-change\" indicator. Caret ranges are ideal when an author may make breaking changes between 0.2.4 and 0.3.0 releases, which is a common practice. However, it presumes that there will not be breaking changes between 0.2.4 and 0.2.5. It allows for changes that are presumed to be additive (but non-breaking), according to commonly observed practices. ^1.2.3 := >=1.2.3 <2.0.0-0 ^0.2.3 := >=0.2.3 <0.3.0-0 ^0.0.3 := >=0.0.3 <0.0.4-0 ^1.2.3-beta.2 := >=1.2.3-beta.2 <2.0.0-0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. ^0.0.3-beta := >=0.0.3-beta <0.0.4-0 Note that prereleases in the 0.0.3 version only will be allowed, if they are greater than or equal to beta. So, 0.0.3-pr.2 would be allowed. When parsing caret ranges, a missing patch value desugars to the number 0, but will allow flexibility within that value, even if the major and minor versions are both 0. ^1.2.x := >=1.2.0 <2.0.0-0 ^0.0.x := >=0.0.0 <0.1.0-0 ^0.0 := >=0.0.0 <0.1.0-0 A missing minor and patch values will desugar to zero, but also allow flexibility within those values, even if the major version is zero. ^1.x := >=1.0.0 <2.0.0-0 ^0.x := >=0.0.0 <1.0.0-0 Range Grammar Putting all this together, here is a Backus-Naur grammar for ranges, for the benefit of parser authors: range-set ::= range ( logical-or range ) * logical-or ::= ( ' ' ) * '||' ( ' ' ) * range ::= hyphen | simple ( ' ' simple ) * | '' hyphen ::= partial ' - ' partial simple ::= primitive | partial | tilde | caret primitive ::= ( '<' | '>' | '>=' | '<=' | '=' ) partial partial ::= xr ( '.' xr ( '.' xr qualifier ? )? )? xr ::= 'x' | 'X' | '*' | nr nr ::= '0' | ['1'-'9'] ( ['0'-'9'] ) * tilde ::= '~' partial caret ::= '^' partial qualifier ::= ( '-' pre )? ( '+' build )? pre ::= parts build ::= parts parts ::= part ( '.' part ) * part ::= nr | [-0-9A-Za-z]+ Functions All methods and classes take a final options object argument. All options in this object are false by default. The options supported are: loose: Be more forgiving about not-quite-valid semver strings. (Any resulting output will always be 100% strict compliant, of course.) For backwards compatibility reasons, if the options argument is a boolean value instead of an object, it is interpreted to be the loose param. includePrerelease: Set to suppress the default behavior of excluding prerelease tagged versions from ranges unless they are explicitly opted into. Strict-mode Comparators and Ranges will be strict about the SemVer strings that they parse. valid(v): Return the parsed version, or null if it's not valid. inc(v, releaseType, options, identifier, identifierBase): Return the version incremented by the release type (major, premajor, minor, preminor, patch, prepatch, prerelease, or release), or null if it's not valid premajor in one call will bump the version up to the next major version and down to a prerelease of that major version. preminor, and prepatch work the same way. If called from a non-prerelease version, prerelease will work the same as prepatch. It increments the patch version and then makes a prerelease. If the input version is already a prerelease it simply increments it. release will remove any prerelease part of the version. identifier can be used to prefix premajor, preminor, prepatch, or prerelease version increments. identifierBase is the base to be used for the prerelease identifier. prerelease(v): Returns an array of prerelease components, or null if none exist. Example: prerelease('1.2.3-alpha.1') -> ['alpha', 1] major(v): Return the major version number. minor(v): Return the minor version number. patch(v): Return the patch version number. intersects(r1, r2, loose): Return true if the two supplied ranges or comparators intersect. parse(v): Attempt to parse a string as a semantic version, returning either a SemVer object or null. Comparison gt(v1, v2): v1 > v2 gte(v1, v2): v1 >= v2 lt(v1, v2): v1 < v2 lte(v1, v2): v1 <= v2 eq(v1, v2): v1 == v2 This is true if they're logically equivalent, even if they're not the same string. You already know how to compare strings. neq(v1, v2): v1 != v2 The opposite of eq. cmp(v1, comparator, v2): Pass in a comparison string, and it'll call the corresponding function above. \"===\" and \"!==\" do simple string comparison, but are included for completeness. Throws if an invalid comparison string is provided. compare(v1, v2): Return 0 if v1 == v2, or 1 if v1 is greater, or -1 if v2 is greater. Sorts in ascending order if passed to Array.sort(). rcompare(v1, v2): The reverse of compare. Sorts an array of versions in descending order when passed to Array.sort(). compareBuild(v1, v2): The same as compare but considers build when two versions are equal. Sorts in ascending order if passed to Array.sort(). compareLoose(v1, v2): Short for compare(v1, v2, { loose: true }). diff(v1, v2): Returns the difference between two versions by the release type (major, premajor, minor, preminor, patch, prepatch, or prerelease), or null if the versions are the same. Sorting sort(versions): Returns a sorted array of versions based on the compareBuild function. rsort(versions): The reverse of sort. Returns an array of versions based on the compareBuild function in descending order. Comparators intersects(comparator): Return true if the comparators intersect Ranges validRange(range): Return the valid range or null if it's not valid. satisfies(version, range): Return true if the version satisfies the range. maxSatisfying(versions, range): Return the highest version in the list that satisfies the range, or null if none of them do. minSatisfying(versions, range): Return the lowest version in the list that satisfies the range, or null if none of them do. minVersion(range): Return the lowest version that can match the given range. gtr(version, range): Return true if the version is greater than all the versions possible in the range. ltr(version, range): Return true if the version is less than all the versions possible in the range. outside(version, range, hilo): Return true if the version is outside the bounds of the range in either the high or low direction. The hilo argument must be either the string '>' or '<'. (This is the function called by gtr and ltr.) intersects(range): Return true if any of the range comparators intersect. simplifyRange(versions, range): Return a \"simplified\" range that matches the same items in the versions list as the range specified. Note that it does not guarantee that it would match the same versions in all cases, only for the set of versions provided. This is useful when generating ranges by joining together multiple versions with || programmatically, to provide the user with something a bit more ergonomic. If the provided range is shorter in string-length than the generated range, then that is returned. subset(subRange, superRange): Return true if the subRange range is entirely contained by the superRange range. Note that, since ranges may be non-contiguous, a version might not be greater than a range, less than a range, or satisfy a range! For example, the range 1.2 <1.2.9 || >2.0.0 would have a hole from 1.2.9 until 2.0.0, so version 1.2.10 would not be greater than the range (because 2.0.1 satisfies, which is higher), nor less than the range (since 1.2.8 satisfies, which is lower), and it also does not satisfy the range. If you want to know if a version satisfies or does not satisfy a range, use the satisfies(version, range) function. Coercion coerce(version, options): Coerces a string to semver if possible This aims to provide a very forgiving translation of a non-semver string to semver. It looks for the first digit in a string and consumes all remaining characters which satisfy at least a partial semver (e.g., 1, 1.2, 1.2.3) up to the max permitted length (256 characters). Longer versions are simply truncated (4.6.3.9.2-alpha2 becomes 4.6.3). All surrounding text is simply ignored (v3.4 replaces v3.3.1 becomes 3.4.0). Only text which lacks digits will fail coercion (version one is not valid). The maximum length for any semver component considered for coercion is 16 characters; longer components will be ignored (10000000000000000.4.7.4 becomes 4.7.4). The maximum value for any semver component is Number.MAX_SAFE_INTEGER || (2**53 - 1); higher value components are invalid (9999999999999999.4.7.4 is likely invalid). If the options.rtl flag is set, then coerce will return the right-most coercible tuple that does not share an ending index with a longer coercible tuple. For example, 1.2.3.4 will return 2.3.4 in rtl mode, not 4.0.0. 1.2.3/4 will return 4.0.0, because the 4 is not a part of any other overlapping SemVer tuple. If the options.includePrerelease flag is set, then the coerce result will contain prerelease and build parts of a version. For example, 1.2.3.4-rc.1+rev.2 will preserve prerelease rc.1 and build rev.2 in the result. Clean clean(version): Clean a string to be a valid semver if possible This will return a cleaned and trimmed semver version. If the provided version is not valid a null will be returned. This does not work for ranges. ex. s.clean(' = v 2.1.5foo'): null s.clean(' = v 2.1.5foo', { loose: true }): '2.1.5-foo' s.clean(' = v 2.1.5-foo'): null s.clean(' = v 2.1.5-foo', { loose: true }): '2.1.5-foo' s.clean('=v2.1.5'): '2.1.5' s.clean(' =v2.1.5'): '2.1.5' s.clean(' 2.1.5 '): '2.1.5' s.clean('~1.0.0'): null Constants As a convenience, helper constants are exported to provide information about what node-semver supports: RELEASE_TYPES major premajor minor preminor patch prepatch prerelease const semver = require('semver'); if (semver.RELEASE_TYPES.includes(arbitraryUserInput)) { console.log('This is a valid release type!'); } else { console.warn('This is NOT a valid release type!'); } SEMVER_SPEC_VERSION 2.0.0 const semver = require('semver'); console.log('We are currently using the semver specification version:', semver.SEMVER_SPEC_VERSION); Exported Modules You may pull in just the part of this semver utility that you need if you are sensitive to packing and tree-shaking concerns. The main require('semver') export uses getter functions to lazily load the parts of the API that are used. The following modules are available: require('semver') require('semver/classes') require('semver/classes/comparator') require('semver/classes/range') require('semver/classes/semver') require('semver/functions/clean') require('semver/functions/cmp') require('semver/functions/coerce') require('semver/functions/compare') require('semver/functions/compare-build') require('semver/functions/compare-loose') require('semver/functions/diff') require('semver/functions/eq') require('semver/functions/gt') require('semver/functions/gte') require('semver/functions/inc') require('semver/functions/lt') require('semver/functions/lte') require('semver/functions/major') require('semver/functions/minor') require('semver/functions/neq') require('semver/functions/parse') require('semver/functions/patch') require('semver/functions/prerelease') require('semver/functions/rcompare') require('semver/functions/rsort') require('semver/functions/satisfies') require('semver/functions/sort') require('semver/functions/valid') require('semver/ranges/gtr') require('semver/ranges/intersects') require('semver/ranges/ltr') require('semver/ranges/max-satisfying') require('semver/ranges/min-satisfying') require('semver/ranges/min-version') require('semver/ranges/outside') require('semver/ranges/simplify') require('semver/ranges/subset') require('semver/ranges/to-comparators') require('semver/ranges/valid')"
  },
  "src/frontend/app-client/node_modules/send/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/send/HISTORY.html",
    "title": "0.19.0 / 2024-09-10",
    "summary": "0.19.0 / 2024-09-10 Remove link renderization in html while redirecting 0.18.0 / 2022-03-23 Fix emitted 416 error missing headers property Limit the headers removed for 304 response deps: depd@2.0.0 Replace internal eval usage with Function constructor Use instance methods on process to check for listeners deps: destroy@1.2.0 deps: http-errors@2.0.0 deps: depd@2.0.0 deps: statuses@2.0.1 deps: on-finished@2.4.1 deps: statuses@2.0.1 0.17.2 / 2021-12-11 pref: ignore empty http tokens deps: http-errors@1.8.1 deps: inherits@2.0.4 deps: toidentifier@1.0.1 deps: setprototypeof@1.2.0 deps: ms@2.1.3 0.17.1 / 2019-05-10 Set stricter CSP header in redirect & error responses deps: range-parser@~1.2.1 0.17.0 / 2019-05-03 deps: http-errors@~1.7.2 Set constructor name when possible Use toidentifier module to make class names deps: depd@~1.1.2 deps: setprototypeof@1.1.1 deps: statuses@'>= 1.5.0 < 2' deps: mime@1.6.0 Add extensions for JPEG-2000 images Add new font/* types from IANA Add WASM mapping Update .bdoc to application/bdoc Update .bmp to image/bmp Update .m4a to audio/mp4 Update .rtf to application/rtf Update .wav to audio/wav Update .xml to application/xml Update generic extensions to application/octet-stream: .deb, .dll, .dmg, .exe, .iso, .msi Use mime-score module to resolve extension conflicts deps: ms@2.1.1 Add week/w support Fix negative number handling deps: statuses@~1.5.0 perf: remove redundant path.normalize call 0.16.2 / 2018-02-07 Fix incorrect end tag in default error & redirects deps: depd@~1.1.2 perf: remove argument reassignment deps: encodeurl@~1.0.2 Fix encoding % as last character deps: statuses@~1.4.0 0.16.1 / 2017-09-29 Fix regression in edge-case behavior for empty path 0.16.0 / 2017-09-27 Add immutable option Fix missing </html> in default error & redirects Use instance methods on steam to check for listeners deps: mime@1.4.1 Add 70 new types for file extensions Set charset as \"UTF-8\" for .js and .json perf: improve path validation speed 0.15.6 / 2017-09-22 deps: debug@2.6.9 perf: improve If-Match token parsing 0.15.5 / 2017-09-20 deps: etag@~1.8.1 perf: replace regular expression with substring deps: fresh@0.5.2 Fix handling of modified headers with invalid dates perf: improve ETag match loop perf: improve If-None-Match token parsing 0.15.4 / 2017-08-05 deps: debug@2.6.8 deps: depd@~1.1.1 Remove unnecessary Buffer loading deps: http-errors@~1.6.2 deps: depd@1.1.1 0.15.3 / 2017-05-16 deps: debug@2.6.7 deps: ms@2.0.0 deps: ms@2.0.0 0.15.2 / 2017-04-26 deps: debug@2.6.4 Fix DEBUG_MAX_ARRAY_LENGTH deps: ms@0.7.3 deps: ms@1.0.0 0.15.1 / 2017-03-04 Fix issue when Date.parse does not return NaN on invalid date Fix strict violation in broken environments 0.15.0 / 2017-02-25 Support If-Match and If-Unmodified-Since headers Add res and path arguments to directory event Remove usage of res._headers private field Improves compatibility with Node.js 8 nightly Send complete HTML document in redirect & error responses Set default CSP header in redirect & error responses Use res.getHeaderNames() when available Use res.headersSent when available deps: debug@2.6.1 Allow colors in workers Deprecated DEBUG_FD environment variable set to 3 or higher Fix error when running under React Native Use same color for same namespace deps: ms@0.7.2 deps: etag@~1.8.0 deps: fresh@0.5.0 Fix false detection of no-cache request directive Fix incorrect result when If-None-Match has both * and ETags Fix weak ETag matching to match spec perf: delay reading header values until needed perf: enable strict mode perf: hoist regular expressions perf: remove duplicate conditional perf: remove unnecessary boolean coercions perf: skip checking modified time if ETag check failed perf: skip parsing If-None-Match when no ETag header perf: use Date.parse instead of new Date deps: http-errors@~1.6.1 Make message property enumerable for HttpErrors deps: setprototypeof@1.0.3 0.14.2 / 2017-01-23 deps: http-errors@~1.5.1 deps: inherits@2.0.3 deps: setprototypeof@1.0.2 deps: statuses@'>= 1.3.1 < 2' deps: ms@0.7.2 deps: statuses@~1.3.1 0.14.1 / 2016-06-09 Fix redirect error when path contains raw non-URL characters Fix redirect when path starts with multiple forward slashes 0.14.0 / 2016-06-06 Add acceptRanges option Add cacheControl option Attempt to combine multiple ranges into single range Correctly inherit from Stream class Fix Content-Range header in 416 responses when using start/end options Fix Content-Range header missing from default 416 responses Ignore non-byte Range headers deps: http-errors@~1.5.0 Add HttpError export, for err instanceof createError.HttpError Support new code 421 Misdirected Request Use setprototypeof module to replace __proto__ setting deps: inherits@2.0.1 deps: statuses@'>= 1.3.0 < 2' perf: enable strict mode deps: range-parser@~1.2.0 Fix incorrectly returning -1 when there is at least one valid range perf: remove internal function deps: statuses@~1.3.0 Add 421 Misdirected Request perf: enable strict mode perf: remove argument reassignment 0.13.2 / 2016-03-05 Fix invalid Content-Type header when send.mime.default_type unset 0.13.1 / 2016-01-16 deps: depd@~1.1.0 Support web browser loading perf: enable strict mode deps: destroy@~1.0.4 perf: enable strict mode deps: escape-html@~1.0.3 perf: enable strict mode perf: optimize string replacement perf: use faster string coercion deps: range-parser@~1.0.3 perf: enable strict mode 0.13.0 / 2015-06-16 Allow Node.js HTTP server to set Date response header Fix incorrectly removing Content-Location on 304 response Improve the default redirect response headers Send appropriate headers on default error response Use http-errors for standard emitted errors Use statuses instead of http module for status messages deps: escape-html@1.0.2 deps: etag@~1.7.0 Improve stat performance by removing hashing deps: fresh@0.3.0 Add weak ETag matching support deps: on-finished@~2.3.0 Add defined behavior for HTTP CONNECT requests Add defined behavior for HTTP Upgrade requests deps: ee-first@1.1.1 perf: enable strict mode perf: remove unnecessary array allocations 0.12.3 / 2015-05-13 deps: debug@~2.2.0 deps: ms@0.7.1 deps: depd@~1.0.1 deps: etag@~1.6.0 Improve support for JXcore Support \"fake\" stats objects in environments without fs deps: ms@0.7.1 Prevent extraordinarily long inputs deps: on-finished@~2.2.1 0.12.2 / 2015-03-13 Throw errors early for invalid extensions or index options deps: debug@~2.1.3 Fix high intensity foreground color for bold deps: ms@0.7.0 0.12.1 / 2015-02-17 Fix regression sending zero-length files 0.12.0 / 2015-02-16 Always read the stat size from the file Fix mutating passed-in options deps: mime@1.3.4 0.11.1 / 2015-01-20 Fix root path disclosure 0.11.0 / 2015-01-05 deps: debug@~2.1.1 deps: etag@~1.5.1 deps: crc@3.2.1 deps: ms@0.7.0 Add milliseconds Add msecs Add secs Add mins Add hrs Add yrs deps: on-finished@~2.2.0 0.10.1 / 2014-10-22 deps: on-finished@~2.1.1 Fix handling of pipelined requests 0.10.0 / 2014-10-15 deps: debug@~2.1.0 Implement DEBUG_FD env variable support deps: depd@~1.0.0 deps: etag@~1.5.0 Improve string performance Slightly improve speed for weak ETags over 1KB 0.9.3 / 2014-09-24 deps: etag@~1.4.0 Support \"fake\" stats objects 0.9.2 / 2014-09-15 deps: depd@0.4.5 deps: etag@~1.3.1 deps: range-parser@~1.0.2 0.9.1 / 2014-09-07 deps: fresh@0.2.4 0.9.0 / 2014-09-07 Add lastModified option Use etag to generate ETag header deps: debug@~2.0.0 0.8.5 / 2014-09-04 Fix malicious path detection for empty string path 0.8.4 / 2014-09-04 Fix a path traversal issue when using root 0.8.3 / 2014-08-16 deps: destroy@1.0.3 renamed from dethroy deps: on-finished@2.1.0 0.8.2 / 2014-08-14 Work around fd leak in Node.js 0.10 for fs.ReadStream deps: dethroy@1.0.2 0.8.1 / 2014-08-05 Fix extensions behavior when file already has extension 0.8.0 / 2014-08-05 Add extensions option 0.7.4 / 2014-08-04 Fix serving index files without root dir 0.7.3 / 2014-07-29 Fix incorrect 403 on Windows and Node.js 0.11 0.7.2 / 2014-07-27 deps: depd@0.4.4 Work-around v8 generating empty stack traces 0.7.1 / 2014-07-26 deps: depd@0.4.3 Fix exception when global Error.stackTraceLimit is too low 0.7.0 / 2014-07-20 Deprecate hidden option; use dotfiles option Add dotfiles option deps: debug@1.0.4 deps: depd@0.4.2 Add TRACE_DEPRECATION environment variable Remove non-standard grey color from color output Support --no-deprecation argument Support --trace-deprecation argument 0.6.0 / 2014-07-11 Deprecate from option; use root option Deprecate send.etag() -- use etag in options Deprecate send.hidden() -- use hidden in options Deprecate send.index() -- use index in options Deprecate send.maxage() -- use maxAge in options Deprecate send.root() -- use root in options Cap maxAge value to 1 year deps: debug@1.0.3 Add support for multiple wildcards in namespaces 0.5.0 / 2014-06-28 Accept string for maxAge (converted by ms) Add headers event Include link in default redirect response Use EventEmitter.listenerCount to count listeners 0.4.3 / 2014-06-11 Do not throw un-catchable error on file open race condition Use escape-html for HTML escaping deps: debug@1.0.2 fix some debugging output colors on node.js 0.8 deps: finished@1.2.2 deps: fresh@0.2.2 0.4.2 / 2014-06-09 fix \"event emitter leak\" warnings deps: debug@1.0.1 deps: finished@1.2.1 0.4.1 / 2014-06-02 Send max-age in Cache-Control in correct format 0.4.0 / 2014-05-27 Calculate ETag with md5 for reduced collisions Fix wrong behavior when index file matches directory Ignore stream errors after request ends Goodbye EBADF, read Skip directories in index file search deps: debug@0.8.1 0.3.0 / 2014-04-24 Fix sending files with dots without root set Coerce option types Accept API options in options object Set etags to \"weak\" Include file path in etag Make \"Can't set headers after they are sent.\" catchable Send full entity-body for multi range requests Default directory access to 403 when index disabled Support multiple index paths Support \"If-Range\" header Control whether to generate etags deps: mime@1.2.11 0.2.0 / 2014-01-29 update range-parser and fresh 0.1.4 / 2013-08-11 update fresh 0.1.3 / 2013-07-08 Revert \"Fix fd leak\" 0.1.2 / 2013-07-03 Fix fd leak 0.1.0 / 2012-08-25 add options parameter to send() that is passed to fs.createReadStream() [kanongil] 0.0.4 / 2012-08-16 allow custom \"Accept-Ranges\" definition 0.0.3 / 2012-07-16 fix normalization of the root directory. Closes #3 0.0.2 / 2012-07-09 add passing of req explicitly for now (YUCK) 0.0.1 / 2010-01-03 Initial release"
  },
  "src/frontend/app-client/node_modules/send/node_modules/debug/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/send/node_modules/debug/CHANGELOG.html",
    "title": "2.6.9 / 2017-09-22",
    "summary": "2.6.9 / 2017-09-22 remove ReDoS regexp in %o formatter (#504) 2.6.8 / 2017-05-18 Fix: Check for undefined on browser globals (#462, @marbemac) 2.6.7 / 2017-05-16 Fix: Update ms to 2.0.0 to fix regular expression denial of service vulnerability (#458, @hubdotcom) Fix: Inline extend function in node implementation (#452, @dougwilson) Docs: Fix typo (#455, @msasad) 2.6.5 / 2017-04-27 Fix: null reference check on window.documentElement.style.WebkitAppearance (#447, @thebigredgeek) Misc: clean up browser reference checks (#447, @thebigredgeek) Misc: add npm-debug.log to .gitignore (@thebigredgeek) 2.6.4 / 2017-04-20 Fix: bug that would occure if process.env.DEBUG is a non-string value. (#444, @LucianBuzzo) Chore: ignore bower.json in npm installations. (#437, @joaovieira) Misc: update \"ms\" to v0.7.3 (@tootallnate) 2.6.3 / 2017-03-13 Fix: Electron reference to process.env.DEBUG (#431, @paulcbetts) Docs: Changelog fix (@thebigredgeek) 2.6.2 / 2017-03-10 Fix: DEBUG_MAX_ARRAY_LENGTH (#420, @slavaGanzin) Docs: Add backers and sponsors from Open Collective (#422, @piamancini) Docs: Add Slackin invite badge (@tootallnate) 2.6.1 / 2017-02-10 Fix: Module's export default syntax fix for IE8 Expected identifier error Fix: Whitelist DEBUG_FD for values 1 and 2 only (#415, @pi0) Fix: IE8 \"Expected identifier\" error (#414, @vgoma) Fix: Namespaces would not disable once enabled (#409, @musikov) 2.6.0 / 2016-12-28 Fix: added better null pointer checks for browser useColors (@thebigredgeek) Improvement: removed explicit window.debug export (#404, @tootallnate) Improvement: deprecated DEBUG_FD environment variable (#405, @tootallnate) 2.5.2 / 2016-12-25 Fix: reference error on window within webworkers (#393, @KlausTrainer) Docs: fixed README typo (#391, @lurch) Docs: added notice about v3 api discussion (@thebigredgeek) 2.5.1 / 2016-12-20 Fix: babel-core compatibility 2.5.0 / 2016-12-20 Fix: wrong reference in bower file (@thebigredgeek) Fix: webworker compatibility (@thebigredgeek) Fix: output formatting issue (#388, @kribblo) Fix: babel-loader compatibility (#383, @escwald) Misc: removed built asset from repo and publications (@thebigredgeek) Misc: moved source files to /src (#378, @yamikuronue) Test: added karma integration and replaced babel with browserify for browser tests (#378, @yamikuronue) Test: coveralls integration (#378, @yamikuronue) Docs: simplified language in the opening paragraph (#373, @yamikuronue) 2.4.5 / 2016-12-17 Fix: navigator undefined in Rhino (#376, @jochenberger) Fix: custom log function (#379, @hsiliev) Improvement: bit of cleanup + linting fixes (@thebigredgeek) Improvement: rm non-maintainted dist/ dir (#375, @freewil) Docs: simplified language in the opening paragraph. (#373, @yamikuronue) 2.4.4 / 2016-12-14 Fix: work around debug being loaded in preload scripts for electron (#368, @paulcbetts) 2.4.3 / 2016-12-14 Fix: navigation.userAgent error for react native (#364, @escwald) 2.4.2 / 2016-12-14 Fix: browser colors (#367, @tootallnate) Misc: travis ci integration (@thebigredgeek) Misc: added linting and testing boilerplate with sanity check (@thebigredgeek) 2.4.1 / 2016-12-13 Fix: typo that broke the package (#356) 2.4.0 / 2016-12-13 Fix: bower.json references unbuilt src entry point (#342, @justmatt) Fix: revert \"handle regex special characters\" (@tootallnate) Feature: configurable util.inspect()`options for NodeJS (#327, @tootallnate) Feature: %O`(big O) pretty-prints objects (#322, @tootallnate) Improvement: allow colors in workers (#335, @botverse) Improvement: use same color for same namespace. (#338, @lchenay) 2.3.3 / 2016-11-09 Fix: Catch JSON.stringify() errors (#195, Jovan Alleyne) Fix: Returning localStorage saved values (#331, Levi Thomason) Improvement: Don't create an empty object when no process (Nathan Rajlich) 2.3.2 / 2016-11-09 Fix: be super-safe in index.js as well (@TooTallNate) Fix: should check whether process exists (Tom Newby) 2.3.1 / 2016-11-09 Fix: Added electron compatibility (#324, @paulcbetts) Improvement: Added performance optimizations (@tootallnate) Readme: Corrected PowerShell environment variable example (#252, @gimre) Misc: Removed yarn lock file from source control (#321, @fengmk2) 2.3.0 / 2016-11-07 Fix: Consistent placement of ms diff at end of output (#215, @gorangajic) Fix: Escaping of regex special characters in namespace strings (#250, @zacronos) Fix: Fixed bug causing crash on react-native (#282, @vkarpov15) Feature: Enabled ES6+ compatible import via default export (#212 @bucaran) Feature: Added %O formatter to reflect Chrome's console.log capability (#279, @oncletom) Package: Update \"ms\" to 0.7.2 (#315, @DevSide) Package: removed superfluous version property from bower.json (#207 @kkirsche) Readme: fix USE_COLORS to DEBUG_COLORS Readme: Doc fixes for format string sugar (#269, @mlucool) Readme: Updated docs for DEBUG_FD and DEBUG_COLORS environment variables (#232, @mattlyons0) Readme: doc fixes for PowerShell (#271 #243, @exoticknight @unreadable) Readme: better docs for browser support (#224, @matthewmueller) Tooling: Added yarn integration for development (#317, @thebigredgeek) Misc: Renamed History.md to CHANGELOG.md (@thebigredgeek) Misc: Added license file (#226 #274, @CantemoInternal @sdaitzman) Misc: Updated contributors (@thebigredgeek) 2.2.0 / 2015-05-09 package: update \"ms\" to v0.7.1 (#202, @dougwilson) README: add logging to file example (#193, @DanielOchoa) README: fixed a typo (#191, @amir-s) browser: expose storage (#190, @stephenmathieson) Makefile: add a distclean target (#189, @stephenmathieson) 2.1.3 / 2015-03-13 Updated stdout/stderr example (#186) Updated example/stdout.js to match debug current behaviour Renamed example/stderr.js to stdout.js Update Readme.md (#184) replace high intensity foreground color for bold (#182, #183) 2.1.2 / 2015-03-01 dist: recompile update \"ms\" to v0.7.0 package: update \"browserify\" to v9.0.3 component: fix \"ms.js\" repo location changed bower package name updated documentation about using debug in a browser fix: security error on safari (#167, #168, @yields) 2.1.1 / 2014-12-29 browser: use typeof to check for console existence browser: check for console.log truthiness (fix IE 8/9) browser: add support for Chrome apps Readme: added Windows usage remarks Add bower.json to properly support bower install 2.1.0 / 2014-10-15 node: implement DEBUG_FD env variable support package: update \"browserify\" to v6.1.0 package: add \"license\" field to package.json (#135, @panuhorsmalahti) 2.0.0 / 2014-09-01 package: update \"browserify\" to v5.11.0 node: use stderr rather than stdout for logging (#29, @stephenmathieson) 1.0.4 / 2014-07-15 dist: recompile example: remove console.info() log usage example: add \"Content-Type\" UTF-8 header to browser example browser: place %c marker after the space character browser: reset the \"content\" color via color: inherit browser: add colors support for Firefox >= v31 debug: prefer an instance log() function over the global one (#119) Readme: update documentation about styled console logs for FF v31 (#116, @wryk) 1.0.3 / 2014-07-09 Add support for multiple wildcards in namespaces (#122, @seegno) browser: fix lint 1.0.2 / 2014-06-10 browser: update color palette (#113, @gscottolson) common: make console logging function configurable (#108, @timoxley) node: fix %o colors on old node <= 0.8.x Makefile: find node path using shell/which (#109, @timoxley) 1.0.1 / 2014-06-06 browser: use removeItem() to clear localStorage browser, node: don't set DEBUG if namespaces is undefined (#107, @leedm777) package: add \"contributors\" section node: fix comment typo README: list authors 1.0.0 / 2014-06-04 make ms diff be global, not be scope debug: ignore empty strings in enable() node: make DEBUG_COLORS able to disable coloring *: export the colors array npmignore: don't publish the dist dir Makefile: refactor to use browserify package: add \"browserify\" as a dev dependency Readme: add Web Inspector Colors section node: reset terminal color for the debug content node: map \"%o\" to util.inspect() browser: map \"%j\" to JSON.stringify() debug: add custom \"formatters\" debug: use \"ms\" module for humanizing the diff Readme: add \"bash\" syntax highlighting browser: add Firebug color support browser: add colors for WebKit browsers node: apply log to console rewrite: abstract common logic for Node & browsers add .jshintrc file 0.8.1 / 2014-04-14 package: re-add the \"component\" section 0.8.0 / 2014-03-30 add enable() method for nodejs. Closes #27 change from stderr to stdout remove unnecessary index.js file 0.7.4 / 2013-11-13 remove \"browserify\" key from package.json (fixes something in browserify) 0.7.3 / 2013-10-30 fix: catch localStorage security error when cookies are blocked (Chrome) add debug(err) support. Closes #46 add .browser prop to package.json. Closes #42 0.7.2 / 2013-02-06 fix package.json fix: Mobile Safari (private mode) is broken with debug fix: Use unicode to send escape character to shell instead of octal to work with strict mode javascript 0.7.1 / 2013-02-05 add repository URL to package.json add DEBUG_COLORED to force colored output add browserify support fix component. Closes #24 0.7.0 / 2012-05-04 Added .component to package.json Added debug.component.js build 0.6.0 / 2012-03-16 Added support for \"-\" prefix in DEBUG [Vinay Pulim] Added .enabled flag to the node version [TooTallNate] 0.5.0 / 2012-02-02 Added: humanize diffs. Closes #8 Added debug.disable() to the CS variant Removed padding. Closes #10 Fixed: persist client-side variant again. Closes #9 0.4.0 / 2012-02-01 Added browser variant support for older browsers [TooTallNate] Added debug.enable('project:*') to browser variant [TooTallNate] Added padding to diff (moved it to the right) 0.3.0 / 2012-01-26 Added millisecond diff when isatty, otherwise UTC string 0.2.0 / 2012-01-22 Added wildcard support 0.1.0 / 2011-12-02 Added: remove colors unless stderr isatty [TooTallNate] 0.0.1 / 2010-01-03 Initial release"
  },
  "src/frontend/app-client/node_modules/send/node_modules/debug/node_modules/ms/license.html": {
    "href": "src/frontend/app-client/node_modules/send/node_modules/debug/node_modules/ms/license.html",
    "title": "",
    "summary": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/send/node_modules/debug/node_modules/ms/readme.html": {
    "href": "src/frontend/app-client/node_modules/send/node_modules/debug/node_modules/ms/readme.html",
    "title": "ms",
    "summary": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 Convert from milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(ms('10 hours')) // \"10h\" Time format written-out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in node and in the browser. If a number is supplied to ms, a string with a unit is returned. If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100'). If you pass a string with a number and a valid unit, the number of equivalent ms is returned. Caught a bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, node will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "src/frontend/app-client/node_modules/send/node_modules/debug/README.html": {
    "href": "src/frontend/app-client/node_modules/send/node_modules/debug/README.html",
    "title": "debug",
    "summary": "debug A tiny node.js debugging utility modelled after node core's debugging technique. Discussion around the V3 API is under way here Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %s', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var debug = require('debug')('worker'); setInterval(function(){ debug('doing some work'); }, 1000); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows note On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Note that PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Then, run the program to be debugged as usual. Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toUTCString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); Web Inspector Colors Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Colored output looks something like: Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2016 TJ Holowaychuk <tj@vision-media.ca&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/send/node_modules/encodeurl/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/send/node_modules/encodeurl/HISTORY.html",
    "title": "1.0.2 / 2018-01-21",
    "summary": "1.0.2 / 2018-01-21 Fix encoding % as last character 1.0.1 / 2016-06-09 Fix encoding unpaired surrogates at start/end of string 1.0.0 / 2016-06-08 Initial release"
  },
  "src/frontend/app-client/node_modules/send/node_modules/encodeurl/README.html": {
    "href": "src/frontend/app-client/node_modules/send/node_modules/encodeurl/README.html",
    "title": "encodeurl",
    "summary": "encodeurl Encode a URL to a percent-encoded form, excluding already-encoded sequences Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install encodeurl API var encodeUrl = require('encodeurl') encodeUrl(url) Encode a URL to a percent-encoded form, excluding already-encoded sequences. This function will take an already-encoded URL and encode all the non-URL code points (as UTF-8 byte sequences). This function will not encode the \"%\" character unless it is not part of a valid sequence (%20 will be left as-is, but %foo will be encoded as %25foo). This encode is meant to be \"safe\" and does not throw errors. It will try as hard as it can to properly encode the given URL, including replacing any raw, unpaired surrogate pairs with the Unicode replacement character prior to encoding. This function is similar to the intrinsic function encodeURI, except it will not encode the % character if that is part of a valid sequence, will not encode [ and ] (for IPv6 hostnames) and will replace raw, unpaired surrogate pairs with the Unicode replacement character (instead of throwing). Examples Encode a URL containing user-controled data var encodeUrl = require('encodeurl') var escapeHtml = require('escape-html') http.createServer(function onRequest (req, res) { // get encoded form of inbound url var url = encodeUrl(req.url) // create html message var body = '<p>Location ' + escapeHtml(url) + ' not found</p>' // send a 404 res.statusCode = 404 res.setHeader('Content-Type', 'text/html; charset=UTF-8') res.setHeader('Content-Length', String(Buffer.byteLength(body, 'utf-8'))) res.end(body, 'utf-8') }) Encode a URL for use in a header field var encodeUrl = require('encodeurl') var escapeHtml = require('escape-html') var url = require('url') http.createServer(function onRequest (req, res) { // parse inbound url var href = url.parse(req) // set new host for redirect href.host = 'localhost' href.protocol = 'https:' href.slashes = true // create location header var location = encodeUrl(url.format(href)) // create html message var body = '<p>Redirecting to new site: ' + escapeHtml(location) + '</p>' // send a 301 res.statusCode = 301 res.setHeader('Content-Type', 'text/html; charset=UTF-8') res.setHeader('Content-Length', String(Buffer.byteLength(body, 'utf-8'))) res.setHeader('Location', location) res.end(body, 'utf-8') }) Testing $ npm test $ npm run lint References RFC 3986: Uniform Resource Identifier (URI): Generic Syntax WHATWG URL Living Standard License MIT"
  },
  "src/frontend/app-client/node_modules/send/README.html": {
    "href": "src/frontend/app-client/node_modules/send/README.html",
    "title": "send",
    "summary": "send Send is a library for streaming files from the file system as a http response supporting partial responses (Ranges), conditional-GET negotiation (If-Match, If-Unmodified-Since, If-None-Match, If-Modified-Since), high test coverage, and granular events which may be leveraged to take appropriate actions in your application or framework. Looking to serve up entire folders mapped to URLs? Try serve-static. Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install send API var send = require('send') send(req, path, [options]) Create a new SendStream for the given path to send to a res. The req is the Node.js HTTP request and the path is a urlencoded path to send (urlencoded, not the actual file-system path). Options acceptRanges Enable or disable accepting ranged requests, defaults to true. Disabling this will not send Accept-Ranges and ignore the contents of the Range request header. cacheControl Enable or disable setting Cache-Control response header, defaults to true. Disabling this will ignore the immutable and maxAge options. dotfiles Set how \"dotfiles\" are treated when encountered. A dotfile is a file or directory that begins with a dot (\".\"). Note this check is done on the path itself without checking if the path actually exists on the disk. If root is specified, only the dotfiles above the root are checked (i.e. the root itself can be within a dotfile when when set to \"deny\"). 'allow' No special treatment for dotfiles. 'deny' Send a 403 for any request for a dotfile. 'ignore' Pretend like the dotfile does not exist and 404. The default value is similar to 'ignore', with the exception that this default will not ignore the files within a directory that begins with a dot, for backward-compatibility. end Byte offset at which the stream ends, defaults to the length of the file minus 1. The end is inclusive in the stream, meaning end: 3 will include the 4th byte in the stream. etag Enable or disable etag generation, defaults to true. extensions If a given file doesn't exist, try appending one of the given extensions, in the given order. By default, this is disabled (set to false). An example value that will serve extension-less HTML files: ['html', 'htm']. This is skipped if the requested file already has an extension. immutable Enable or disable the immutable directive in the Cache-Control response header, defaults to false. If set to true, the maxAge option should also be specified to enable caching. The immutable directive will prevent supported clients from making conditional requests during the life of the maxAge option to check if the file has changed. index By default send supports \"index.html\" files, to disable this set false or to supply a new index pass a string or an array in preferred order. lastModified Enable or disable Last-Modified header, defaults to true. Uses the file system's last modified value. maxAge Provide a max-age in milliseconds for http caching, defaults to 0. This can also be a string accepted by the ms module. root Serve files relative to path. start Byte offset at which the stream starts, defaults to 0. The start is inclusive, meaning start: 2 will include the 3rd byte in the stream. Events The SendStream is an event emitter and will emit the following events: error an error occurred (err) directory a directory was requested (res, path) file a file was requested (path, stat) headers the headers are about to be set on a file (res, path, stat) stream file streaming has started (stream) end streaming has completed .pipe The pipe method is used to pipe the response into the Node.js HTTP response object, typically send(req, path, options).pipe(res). .mime The mime export is the global instance of of the mime npm module. This is used to configure the MIME types that are associated with file extensions as well as other options for how to resolve the MIME type of a file (like the default type to use for an unknown file extension). Error-handling By default when no error listeners are present an automatic response will be made, otherwise you have full control over the response, aka you may show a 5xx page etc. Caching It does not perform internal caching, you should use a reverse proxy cache such as Varnish for this, or those fancy things called CDNs. If your application is small enough that it would benefit from single-node memory caching, it's small enough that it does not need caching at all ;). Debugging To enable debug() instrumentation output export DEBUG: $ DEBUG=send node app Running tests $ npm install $ npm test Examples Serve a specific file This simple example will send a specific file to all requests. var http = require('http') var send = require('send') var server = http.createServer(function onRequest (req, res) { send(req, '/path/to/index.html') .pipe(res) }) server.listen(3000) Serve all files from a directory This simple example will just serve up all the files in a given directory as the top-level. For example, a request GET /foo.txt will send back /www/public/foo.txt. var http = require('http') var parseUrl = require('parseurl') var send = require('send') var server = http.createServer(function onRequest (req, res) { send(req, parseUrl(req).pathname, { root: '/www/public' }) .pipe(res) }) server.listen(3000) Custom file types var http = require('http') var parseUrl = require('parseurl') var send = require('send') // Default unknown types to text/plain send.mime.default_type = 'text/plain' // Add a custom type send.mime.define({ 'application/x-my-type': ['x-mt', 'x-mtt'] }) var server = http.createServer(function onRequest (req, res) { send(req, parseUrl(req).pathname, { root: '/www/public' }) .pipe(res) }) server.listen(3000) Custom directory index view This is a example of serving up a structure of directories with a custom function to render a listing of a directory. var http = require('http') var fs = require('fs') var parseUrl = require('parseurl') var send = require('send') // Transfer arbitrary files from within /www/example.com/public/* // with a custom handler for directory listing var server = http.createServer(function onRequest (req, res) { send(req, parseUrl(req).pathname, { index: false, root: '/www/public' }) .once('directory', directory) .pipe(res) }) server.listen(3000) // Custom directory handler function directory (res, path) { var stream = this // redirect to trailing slash for consistent url if (!stream.hasTrailingSlash()) { return stream.redirect(path) } // get directory list fs.readdir(path, function onReaddir (err, list) { if (err) return stream.error(err) // render an index for the directory res.setHeader('Content-Type', 'text/plain; charset=UTF-8') res.end(list.join('\\n') + '\\n') }) } Serving from a root directory with custom error-handling var http = require('http') var parseUrl = require('parseurl') var send = require('send') var server = http.createServer(function onRequest (req, res) { // your custom error-handling logic: function error (err) { res.statusCode = err.status || 500 res.end(err.message) } // your custom headers function headers (res, path, stat) { // serve all files for download res.setHeader('Content-Disposition', 'attachment') } // your custom directory handling logic: function redirect () { res.statusCode = 301 res.setHeader('Location', req.url + '/') res.end('Redirecting to ' + req.url + '/') } // transfer arbitrary files from within // /www/example.com/public/* send(req, parseUrl(req).pathname, { root: '/www/public' }) .on('error', error) .on('directory', redirect) .on('headers', headers) .pipe(res) }) server.listen(3000) License MIT"
  },
  "src/frontend/app-client/node_modules/send/SECURITY.html": {
    "href": "src/frontend/app-client/node_modules/send/SECURITY.html",
    "title": "Security Policies and Procedures",
    "summary": "Security Policies and Procedures Reporting a Bug The send team and community take all security bugs seriously. Thank you for improving the security of Express. We appreciate your efforts and responsible disclosure and will make every effort to acknowledge your contributions. Report security bugs by emailing the current owner(s) of send. This information can be found in the npm registry using the command npm owner ls send. If unsure or unable to get the information from the above, open an issue in the project issue tracker asking for the current contact information. To ensure the timely response to your report, please ensure that the entirety of the report is contained within the email body and not solely behind a web link or an attachment. At least one owner will acknowledge your email within 48 hours, and will send a more detailed response within 48 hours indicating the next steps in handling your report. After the initial reply to your report, the owners will endeavor to keep you informed of the progress towards a fix and full announcement, and may ask for additional information or guidance."
  },
  "src/frontend/app-client/node_modules/serve-static/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/serve-static/HISTORY.html",
    "title": "1.16.2 / 2024-09-11",
    "summary": "1.16.2 / 2024-09-11 deps: encodeurl@~2.0.0 1.16.1 / 2024-09-11 deps: send@0.19.0 1.16.0 / 2024-09-10 Remove link renderization in html while redirecting 1.15.0 / 2022-03-24 deps: send@0.18.0 Fix emitted 416 error missing headers property Limit the headers removed for 304 response deps: depd@2.0.0 deps: destroy@1.2.0 deps: http-errors@2.0.0 deps: on-finished@2.4.1 deps: statuses@2.0.1 1.14.2 / 2021-12-15 deps: send@0.17.2 deps: http-errors@1.8.1 deps: ms@2.1.3 pref: ignore empty http tokens 1.14.1 / 2019-05-10 Set stricter CSP header in redirect response deps: send@0.17.1 deps: range-parser@~1.2.1 1.14.0 / 2019-05-07 deps: parseurl@~1.3.3 deps: send@0.17.0 deps: http-errors@~1.7.2 deps: mime@1.6.0 deps: ms@2.1.1 deps: statuses@~1.5.0 perf: remove redundant path.normalize call 1.13.2 / 2018-02-07 Fix incorrect end tag in redirects deps: encodeurl@~1.0.2 Fix encoding % as last character deps: send@0.16.2 deps: depd@~1.1.2 deps: encodeurl@~1.0.2 deps: statuses@~1.4.0 1.13.1 / 2017-09-29 Fix regression when root is incorrectly set to a file deps: send@0.16.1 1.13.0 / 2017-09-27 deps: send@0.16.0 Add 70 new types for file extensions Add immutable option Fix missing </html> in default error & redirects Set charset as \"UTF-8\" for .js and .json Use instance methods on steam to check for listeners deps: mime@1.4.1 perf: improve path validation speed 1.12.6 / 2017-09-22 deps: send@0.15.6 deps: debug@2.6.9 perf: improve If-Match token parsing perf: improve slash collapsing 1.12.5 / 2017-09-21 deps: parseurl@~1.3.2 perf: reduce overhead for full URLs perf: unroll the \"fast-path\" RegExp deps: send@0.15.5 Fix handling of modified headers with invalid dates deps: etag@~1.8.1 deps: fresh@0.5.2 1.12.4 / 2017-08-05 deps: send@0.15.4 deps: debug@2.6.8 deps: depd@~1.1.1 deps: http-errors@~1.6.2 1.12.3 / 2017-05-16 deps: send@0.15.3 deps: debug@2.6.7 1.12.2 / 2017-04-26 deps: send@0.15.2 deps: debug@2.6.4 1.12.1 / 2017-03-04 deps: send@0.15.1 Fix issue when Date.parse does not return NaN on invalid date Fix strict violation in broken environments 1.12.0 / 2017-02-25 Send complete HTML document in redirect response Set default CSP header in redirect response deps: send@0.15.0 Fix false detection of no-cache request directive Fix incorrect result when If-None-Match has both * and ETags Fix weak ETag matching to match spec Remove usage of res._headers private field Support If-Match and If-Unmodified-Since headers Use res.getHeaderNames() when available Use res.headersSent when available deps: debug@2.6.1 deps: etag@~1.8.0 deps: fresh@0.5.0 deps: http-errors@~1.6.1 1.11.2 / 2017-01-23 deps: send@0.14.2 deps: http-errors@~1.5.1 deps: ms@0.7.2 deps: statuses@~1.3.1 1.11.1 / 2016-06-10 Fix redirect error when req.url contains raw non-URL characters deps: send@0.14.1 1.11.0 / 2016-06-07 Use status code 301 for redirects deps: send@0.14.0 Add acceptRanges option Add cacheControl option Attempt to combine multiple ranges into single range Correctly inherit from Stream class Fix Content-Range header in 416 responses when using start/end options Fix Content-Range header missing from default 416 responses Ignore non-byte Range headers deps: http-errors@~1.5.0 deps: range-parser@~1.2.0 deps: statuses@~1.3.0 perf: remove argument reassignment 1.10.3 / 2016-05-30 deps: send@0.13.2 Fix invalid Content-Type header when send.mime.default_type unset 1.10.2 / 2016-01-19 deps: parseurl@~1.3.1 perf: enable strict mode 1.10.1 / 2016-01-16 deps: escape-html@~1.0.3 perf: enable strict mode perf: optimize string replacement perf: use faster string coercion deps: send@0.13.1 deps: depd@~1.1.0 deps: destroy@~1.0.4 deps: escape-html@~1.0.3 deps: range-parser@~1.0.3 1.10.0 / 2015-06-17 Add fallthrough option Allows declaring this middleware is the final destination Provides better integration with Express patterns Fix reading options from options prototype Improve the default redirect response headers deps: escape-html@1.0.2 deps: send@0.13.0 Allow Node.js HTTP server to set Date response header Fix incorrectly removing Content-Location on 304 response Improve the default redirect response headers Send appropriate headers on default error response Use http-errors for standard emitted errors Use statuses instead of http module for status messages deps: escape-html@1.0.2 deps: etag@~1.7.0 deps: fresh@0.3.0 deps: on-finished@~2.3.0 perf: enable strict mode perf: remove unnecessary array allocations perf: enable strict mode perf: remove argument reassignment 1.9.3 / 2015-05-14 deps: send@0.12.3 deps: debug@~2.2.0 deps: depd@~1.0.1 deps: etag@~1.6.0 deps: ms@0.7.1 deps: on-finished@~2.2.1 1.9.2 / 2015-03-14 deps: send@0.12.2 Throw errors early for invalid extensions or index options deps: debug@~2.1.3 1.9.1 / 2015-02-17 deps: send@0.12.1 Fix regression sending zero-length files 1.9.0 / 2015-02-16 deps: send@0.12.0 Always read the stat size from the file Fix mutating passed-in options deps: mime@1.3.4 1.8.1 / 2015-01-20 Fix redirect loop in Node.js 0.11.14 deps: send@0.11.1 Fix root path disclosure 1.8.0 / 2015-01-05 deps: send@0.11.0 deps: debug@~2.1.1 deps: etag@~1.5.1 deps: ms@0.7.0 deps: on-finished@~2.2.0 1.7.2 / 2015-01-02 Fix potential open redirect when mounted at root 1.7.1 / 2014-10-22 deps: send@0.10.1 deps: on-finished@~2.1.1 1.7.0 / 2014-10-15 deps: send@0.10.0 deps: debug@~2.1.0 deps: depd@~1.0.0 deps: etag@~1.5.0 1.6.5 / 2015-02-04 Fix potential open redirect when mounted at root Back-ported from v1.7.2 1.6.4 / 2014-10-08 Fix redirect loop when index file serving disabled 1.6.3 / 2014-09-24 deps: send@0.9.3 deps: etag@~1.4.0 1.6.2 / 2014-09-15 deps: send@0.9.2 deps: depd@0.4.5 deps: etag@~1.3.1 deps: range-parser@~1.0.2 1.6.1 / 2014-09-07 deps: send@0.9.1 deps: fresh@0.2.4 1.6.0 / 2014-09-07 deps: send@0.9.0 Add lastModified option Use etag to generate ETag header deps: debug@~2.0.0 1.5.4 / 2014-09-04 deps: send@0.8.5 Fix a path traversal issue when using root Fix malicious path detection for empty string path 1.5.3 / 2014-08-17 deps: send@0.8.3 1.5.2 / 2014-08-14 deps: send@0.8.2 Work around fd leak in Node.js 0.10 for fs.ReadStream 1.5.1 / 2014-08-09 Fix parsing of weird req.originalUrl values deps: parseurl@~1.3.0 deps: utils-merge@1.0.0 1.5.0 / 2014-08-05 deps: send@0.8.1 Add extensions option 1.4.4 / 2014-08-04 deps: send@0.7.4 Fix serving index files without root dir 1.4.3 / 2014-07-29 deps: send@0.7.3 Fix incorrect 403 on Windows and Node.js 0.11 1.4.2 / 2014-07-27 deps: send@0.7.2 deps: depd@0.4.4 1.4.1 / 2014-07-26 deps: send@0.7.1 deps: depd@0.4.3 1.4.0 / 2014-07-21 deps: parseurl@~1.2.0 Cache URLs based on original value Remove no-longer-needed URL mis-parse work-around Simplify the \"fast-path\" RegExp deps: send@0.7.0 Add dotfiles option deps: debug@1.0.4 deps: depd@0.4.2 1.3.2 / 2014-07-11 deps: send@0.6.0 Cap maxAge value to 1 year deps: debug@1.0.3 1.3.1 / 2014-07-09 deps: parseurl@~1.1.3 faster parsing of href-only URLs 1.3.0 / 2014-06-28 Add setHeaders option Include HTML link in redirect response deps: send@0.5.0 Accept string for maxAge (converted by ms) 1.2.3 / 2014-06-11 deps: send@0.4.3 Do not throw un-catchable error on file open race condition Use escape-html for HTML escaping deps: debug@1.0.2 deps: finished@1.2.2 deps: fresh@0.2.2 1.2.2 / 2014-06-09 deps: send@0.4.2 fix \"event emitter leak\" warnings deps: debug@1.0.1 deps: finished@1.2.1 1.2.1 / 2014-06-02 use escape-html for escaping deps: send@0.4.1 Send max-age in Cache-Control in correct format 1.2.0 / 2014-05-29 deps: send@0.4.0 Calculate ETag with md5 for reduced collisions Fix wrong behavior when index file matches directory Ignore stream errors after request ends Skip directories in index file search deps: debug@0.8.1 1.1.0 / 2014-04-24 Accept options directly to send module deps: send@0.3.0 1.0.4 / 2014-04-07 Resolve relative paths at middleware setup Use parseurl to parse the URL from request 1.0.3 / 2014-03-20 Do not rely on connect-like environments 1.0.2 / 2014-03-06 deps: send@0.2.0 1.0.1 / 2014-03-05 Add mime export for back-compat 1.0.0 / 2014-03-05 Genesis from connect"
  },
  "src/frontend/app-client/node_modules/serve-static/README.html": {
    "href": "src/frontend/app-client/node_modules/serve-static/README.html",
    "title": "serve-static",
    "summary": "serve-static Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install serve-static API var serveStatic = require('serve-static') serveStatic(root, options) Create a new middleware function to serve files from within a given root directory. The file to serve will be determined by combining req.url with the provided root directory. When a file is not found, instead of sending a 404 response, this module will instead call next() to move on to the next middleware, allowing for stacking and fall-backs. Options acceptRanges Enable or disable accepting ranged requests, defaults to true. Disabling this will not send Accept-Ranges and ignore the contents of the Range request header. cacheControl Enable or disable setting Cache-Control response header, defaults to true. Disabling this will ignore the immutable and maxAge options. dotfiles Set how \"dotfiles\" are treated when encountered. A dotfile is a file or directory that begins with a dot (\".\"). Note this check is done on the path itself without checking if the path actually exists on the disk. If root is specified, only the dotfiles above the root are checked (i.e. the root itself can be within a dotfile when set to \"deny\"). 'allow' No special treatment for dotfiles. 'deny' Deny a request for a dotfile and 403/next(). 'ignore' Pretend like the dotfile does not exist and 404/next(). The default value is similar to 'ignore', with the exception that this default will not ignore the files within a directory that begins with a dot. etag Enable or disable etag generation, defaults to true. extensions Set file extension fallbacks. When set, if a file is not found, the given extensions will be added to the file name and search for. The first that exists will be served. Example: ['html', 'htm']. The default value is false. fallthrough Set the middleware to have client errors fall-through as just unhandled requests, otherwise forward a client error. The difference is that client errors like a bad request or a request to a non-existent file will cause this middleware to simply next() to your next middleware when this value is true. When this value is false, these errors (even 404s), will invoke next(err). Typically true is desired such that multiple physical directories can be mapped to the same web address or for routes to fill in non-existent files. The value false can be used if this middleware is mounted at a path that is designed to be strictly a single file system directory, which allows for short-circuiting 404s for less overhead. This middleware will also reply to all methods. The default value is true. immutable Enable or disable the immutable directive in the Cache-Control response header, defaults to false. If set to true, the maxAge option should also be specified to enable caching. The immutable directive will prevent supported clients from making conditional requests during the life of the maxAge option to check if the file has changed. index By default this module will send \"index.html\" files in response to a request on a directory. To disable this set false or to supply a new index pass a string or an array in preferred order. lastModified Enable or disable Last-Modified header, defaults to true. Uses the file system's last modified value. maxAge Provide a max-age in milliseconds for http caching, defaults to 0. This can also be a string accepted by the ms module. redirect Redirect to trailing \"/\" when the pathname is a dir. Defaults to true. setHeaders Function to set custom headers on response. Alterations to the headers need to occur synchronously. The function is called as fn(res, path, stat), where the arguments are: res the response object path the file path that is being sent stat the stat object of the file that is being sent Examples Serve files with vanilla node.js http server var finalhandler = require('finalhandler') var http = require('http') var serveStatic = require('serve-static') // Serve up public/ftp folder var serve = serveStatic('public/ftp', { index: ['index.html', 'index.htm'] }) // Create server var server = http.createServer(function onRequest (req, res) { serve(req, res, finalhandler(req, res)) }) // Listen server.listen(3000) Serve all files as downloads var contentDisposition = require('content-disposition') var finalhandler = require('finalhandler') var http = require('http') var serveStatic = require('serve-static') // Serve up public/ftp folder var serve = serveStatic('public/ftp', { index: false, setHeaders: setHeaders }) // Set header to force download function setHeaders (res, path) { res.setHeader('Content-Disposition', contentDisposition(path)) } // Create server var server = http.createServer(function onRequest (req, res) { serve(req, res, finalhandler(req, res)) }) // Listen server.listen(3000) Serving using express Simple This is a simple example of using Express. var express = require('express') var serveStatic = require('serve-static') var app = express() app.use(serveStatic('public/ftp', { index: ['default.html', 'default.htm'] })) app.listen(3000) Multiple roots This example shows a simple way to search through multiple directories. Files are searched for in public-optimized/ first, then public/ second as a fallback. var express = require('express') var path = require('path') var serveStatic = require('serve-static') var app = express() app.use(serveStatic(path.join(__dirname, 'public-optimized'))) app.use(serveStatic(path.join(__dirname, 'public'))) app.listen(3000) Different settings for paths This example shows how to set a different max age depending on the served file type. In this example, HTML files are not cached, while everything else is for 1 day. var express = require('express') var path = require('path') var serveStatic = require('serve-static') var app = express() app.use(serveStatic(path.join(__dirname, 'public'), { maxAge: '1d', setHeaders: setCustomCacheControl })) app.listen(3000) function setCustomCacheControl (res, path) { if (serveStatic.mime.lookup(path) === 'text/html') { // Custom Cache-Control for HTML files res.setHeader('Cache-Control', 'public, max-age=0') } } License MIT"
  },
  "src/frontend/app-client/node_modules/set-cookie-parser/README.html": {
    "href": "src/frontend/app-client/node_modules/set-cookie-parser/README.html",
    "title": "set-cookie-parser",
    "summary": "set-cookie-parser ℹ️ Note for current users: I'm considering some changes for the next major version and would appreciate your feedback: https://github.com/nfriedly/set-cookie-parser/discussions/68 Parses set-cookie headers into JavaScript objects Accepts a single set-cookie header value, an array of set-cookie header values, a Node.js response object, or a fetch() Response object that may have 0 or more set-cookie headers. Also accepts an optional options object. Defaults: { decodeValues: true, // Calls decodeURIComponent on each value - default: true map: false, // Return an object instead of an array - default: false silent: false, // Suppress the warning that is logged when called on a request instead of a response - default: false } Returns either an array of cookie objects or a map of name => cookie object with {map: true}. Each cookie object will have, at a minimum name and value properties, and may have additional properties depending on the set-cookie header: name - cookie name (string) value - cookie value (string) path - URL path to limit the scope to (string or undefined) domain - domain to expand the scope to (string or undefined, may begin with \".\" to indicate the named domain or any subdomain of it) expires - absolute expiration date for the cookie (Date object or undefined) maxAge - relative expiration time of the cookie in seconds from when the client receives it (integer or undefined) Note: when using with express's res.cookie() method, multiply maxAge by 1000 to convert to milliseconds. secure - indicates cookie should only be sent over HTTPs (true or undefined) httpOnly - indicates cookie should not be accessible to client-side JavaScript (true or undefined) sameSite - indicates if cookie should be included in cross-site requests (more info) (string or undefined) Note: valid values are \"Strict\", \"Lax\", and \"None\", but set-cookie-parser coppies the value verbatim and does not perform any validation. partitioned - indicates cookie should be scoped to the combination of 3rd party domain + top page domain (more info) (true or undefined) (The output format is loosely based on the input format of https://www.npmjs.com/package/cookie) Install $ npm install --save set-cookie-parser Usage Get array of cookie objects var http = require('http'); var setCookie = require('set-cookie-parser'); http.get('http://example.com', function(res) { var cookies = setCookie.parse(res, { decodeValues: true // default: true }); cookies.forEach(console.log); } Example output: [ { name: 'bam', value: 'baz' }, { name: 'foo', value: 'bar', path: '/', expires: new Date('Tue Jul 01 2025 06:01:11 GMT-0400 (EDT)'), maxAge: 1000, domain: '.example.com', secure: true, httpOnly: true, sameSite: 'lax' } ] Get map of cookie objects var http = require('http'); var setCookie = require('set-cookie-parser'); http.get('http://example.com', function(res) { var cookies = setCookie.parse(res, { decodeValues: true, // default: true map: true // default: false }); var desiredCookie = cookies['session']; console.log(desiredCookie); }); Example output: { bam: { name: 'bam', value: 'baz' }, foo: { name: 'foo', value: 'bar', path: '/', expires: new Date('Tue Jul 01 2025 06:01:11 GMT-0400 (EDT)'), maxAge: 1000, domain: '.example.com', secure: true, httpOnly: true, sameSite: 'lax' } } Creating a new, modified set-cookie header This library can be used in conjunction with the cookie library to modify and replace set-cookie headers: const libCookie = require('cookie'); const setCookie = require('set-cookie-parser'); function modifySetCookie(res){ // parse the set-cookie headers with this library let cookies = setCookie.parse(res); // modify the cookies here // ... // create new set-cookie headers using the cookie library res.headers['set-cookie'] = cookies.map(function(cookie) { return libCookie.serialize(cookie.name, cookie.value, cookie); }); } See a real-world example of this in unblocker Usage in React Native (and with some other fetch implementations) React Native follows the Fetch spec more closely and combines all of the Set-Cookie header values into a single string. The splitCookiesString method reverses this. var setCookie = require('set-cookie-parser'); var response = fetch(/*...*/); // This is mainly for React Native; Node.js does not combine set-cookie headers. var combinedCookieHeader = response.headers.get('Set-Cookie'); var splitCookieHeaders = setCookie.splitCookiesString(combinedCookieHeader) var cookies = setCookie.parse(splitCookieHeaders); console.log(cookies); // should be an array of cookies This behavior may become a default part of parse in the next major release, but requires the extra step for now. Note that the fetch() spec now includes a getSetCookie() method that provides un-combined Set-Cookie headers. This library will automatically use that method if it is present. API parse(input, [options]) Parses cookies from a string, array of strings, or a http response object. Always returns an array, regardless of input format. (Unless the map option is set, in which case it always returns an object.) parseString(individualSetCookieHeader, [options]) Parses a single set-cookie header value string. Options default is {decodeValues: true}. Used under-the-hood by parse(). Returns an object. splitCookiesString(combinedSetCookieHeader) It's uncommon, but the HTTP spec does allow for multiple of the same header to have their values combined (comma-separated) into a single header. This method splits apart a combined header without choking on commas that appear within a cookie's value (or expiration date). Returns an array of strings that may be passed to parse(). References RFC 6265: HTTP State Management Mechanism draft-ietf-httpbis-rfc6265bis-10 License MIT © Nathan Friedly"
  },
  "src/frontend/app-client/node_modules/setprototypeof/README.html": {
    "href": "src/frontend/app-client/node_modules/setprototypeof/README.html",
    "title": "Polyfill for Object.setPrototypeOf",
    "summary": "Polyfill for Object.setPrototypeOf A simple cross platform implementation to set the prototype of an instianted object. Supports all modern browsers and at least back to IE8. Usage: $ npm install --save setprototypeof var setPrototypeOf = require('setprototypeof') var obj = {} setPrototypeOf(obj, { foo: function () { return 'bar' } }) obj.foo() // bar TypeScript is also supported: import setPrototypeOf from 'setprototypeof'"
  },
  "src/frontend/app-client/node_modules/shebang-command/readme.html": {
    "href": "src/frontend/app-client/node_modules/shebang-command/readme.html",
    "title": "shebang-command",
    "summary": "shebang-command Get the command from a shebang Install $ npm install shebang-command Usage const shebangCommand = require('shebang-command'); shebangCommand('#!/usr/bin/env node'); //=> 'node' shebangCommand('#!/bin/bash'); //=> 'bash' API shebangCommand(string) string Type: string String containing a shebang."
  },
  "src/frontend/app-client/node_modules/shebang-regex/readme.html": {
    "href": "src/frontend/app-client/node_modules/shebang-regex/readme.html",
    "title": "shebang-regex",
    "summary": "shebang-regex Regular expression for matching a shebang line Install $ npm install shebang-regex Usage const shebangRegex = require('shebang-regex'); const string = '#!/usr/bin/env node\\nconsole.log(\"unicorns\");'; shebangRegex.test(string); //=> true shebangRegex.exec(string)[0]; //=> '#!/usr/bin/env node' shebangRegex.exec(string)[1]; //=> '/usr/bin/env node' License MIT © Sindre Sorhus"
  },
  "src/frontend/app-client/node_modules/side-channel-list/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/side-channel-list/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.0 - 2024-12-10 Commits Initial implementation, tests, readme, types 5d6baee Initial commit 3ae784c npm init 07055a4 Only apps should have lockfiles 9573058"
  },
  "src/frontend/app-client/node_modules/side-channel-list/README.html": {
    "href": "src/frontend/app-client/node_modules/side-channel-list/README.html",
    "title": "side-channel-list",
    "summary": "side-channel-list Store information about any JS value in a side channel, using a linked list. Warning: this implementation will leak memory until you delete the key. Use side-channel for the best available strategy. Getting started npm install --save side-channel-list Usage/Examples const assert = require('assert'); const getSideChannelList = require('side-channel-list'); const channel = getSideChannelList(); const key = {}; assert.equal(channel.has(key), false); assert.throws(() => channel.assert(key), TypeError); channel.set(key, 42); channel.assert(key); // does not throw assert.equal(channel.has(key), true); assert.equal(channel.get(key), 42); channel.delete(key); assert.equal(channel.has(key), false); assert.throws(() => channel.assert(key), TypeError); Tests Clone the repo, npm install, and run npm test"
  },
  "src/frontend/app-client/node_modules/side-channel-map/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/side-channel-map/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.1 - 2024-12-10 Commits [Deps] update call-bound 6d05aaa [types] fix generics ordering 11c0184 v1.0.0 - 2024-12-10 Commits Initial implementation, tests, readme, types ad877b4 Initial commit 28f8879 npm init 2c9604e Only apps should have lockfiles 5e7ba9c"
  },
  "src/frontend/app-client/node_modules/side-channel-map/README.html": {
    "href": "src/frontend/app-client/node_modules/side-channel-map/README.html",
    "title": "side-channel-map",
    "summary": "side-channel-map Store information about any JS value in a side channel, using a Map. Warning: if the key is an object, this implementation will leak memory until you delete it. Use side-channel for the best available strategy. Getting started npm install --save side-channel-map Usage/Examples const assert = require('assert'); const getSideChannelMap = require('side-channel-map'); const channel = getSideChannelMap(); const key = {}; assert.equal(channel.has(key), false); assert.throws(() => channel.assert(key), TypeError); channel.set(key, 42); channel.assert(key); // does not throw assert.equal(channel.has(key), true); assert.equal(channel.get(key), 42); channel.delete(key); assert.equal(channel.has(key), false); assert.throws(() => channel.assert(key), TypeError); Tests Clone the repo, npm install, and run npm test"
  },
  "src/frontend/app-client/node_modules/side-channel-weakmap/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/side-channel-weakmap/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.2 - 2024-12-10 Commits [types] fix generics ordering 1b62e94 v1.0.1 - 2024-12-10 Commits [types] fix generics ordering 08a4a5d [Deps] update side-channel-map b53fe44 v1.0.0 - 2024-12-10 Commits Initial implementation, tests, readme, types 53c0fa4 Initial commit a157947 npm init 54dfc55 Only apps should have lockfiles 0ddd6c7"
  },
  "src/frontend/app-client/node_modules/side-channel-weakmap/README.html": {
    "href": "src/frontend/app-client/node_modules/side-channel-weakmap/README.html",
    "title": "side-channel-weakmap",
    "summary": "side-channel-weakmap Store information about any JS value in a side channel. Uses WeakMap if available. Warning: this implementation will leak memory until you delete the key. Use side-channel for the best available strategy. Getting started npm install --save side-channel-weakmap Usage/Examples const assert = require('assert'); const getSideChannelList = require('side-channel-weakmap'); const channel = getSideChannelList(); const key = {}; assert.equal(channel.has(key), false); assert.throws(() => channel.assert(key), TypeError); channel.set(key, 42); channel.assert(key); // does not throw assert.equal(channel.has(key), true); assert.equal(channel.get(key), 42); channel.delete(key); assert.equal(channel.has(key), false); assert.throws(() => channel.assert(key), TypeError); Tests Clone the repo, npm install, and run npm test"
  },
  "src/frontend/app-client/node_modules/side-channel/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/side-channel/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.1.0 - 2024-12-11 Commits [Refactor] extract implementations to side-channel-weakmap, side-channel-map, side-channel-list ada5955 [New] add channel.delete c01d2d3 [types] improve types 0c54356 [readme] add content be24868 [actions] split out node 10-20, and 20+ c4488e2 [types] use shared tsconfig 0e0d57c [Dev Deps] update @ljharb/eslint-config, @ljharb/tsconfig, @types/get-intrinsic, @types/object-inspect, @types/tape, auto-changelog, tape fb4f622 [Deps] update call-bind, get-intrinsic, object-inspect b78336b [Tests] replace aud with npm audit ee3ab46 [Dev Deps] add missing peer dep c03e21a v1.0.6 - 2024-02-29 Commits add types 9beef66 [meta] simplify exports 4334cf9 [Deps] update call-bind d6043c4 [Dev Deps] update tape 6aca376 v1.0.5 - 2024-02-06 Commits [actions] reuse common workflows 3d2e1ff [meta] use npmignore to autogenerate an npmignore file 04296ea [meta] add .editorconfig; add eclint 130f0a6 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, safe-publish-latest, tape d480c2f [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape ecbe70e [actions] update rebase action 75240b9 [Dev Deps] update @ljharb/eslint-config, aud, npmignore, tape ae8d281 [Dev Deps] update @ljharb/eslint-config, aud, tape 7125b88 [Deps] update call-bind, get-intrinsic, object-inspect 82577c9 [Deps] update call-bind, get-intrinsic, object-inspect 550aadf [Tests] increase coverage 5130877 [Deps] update get-intrinsic, object-inspect ba0194c [meta] add missing engines.node 985fd24 [Refactor] use es-errors, so things that only need those do not need get-intrinsic 40227a8 [Deps] update get-intrinsic a989b40 [Deps] update object-inspect aec42d2 v1.0.4 - 2020-12-29 Commits [Tests] migrate tests to Github Actions 10909cb [Refactor] Use a linked list rather than an array, and move accessed nodes to the beginning 195613f [meta] do not publish github action workflow files 290ec29 [Tests] run nyc on all tests; use tape runner ea6d030 [actions] add \"Allow Edits\" workflow d464d8f [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog 02daca8 [Refactor] use call-bind and get-intrinsic instead of es-abstract e09d481 [Deps] update object.assign ee83aa8 [actions] update rebase action to use checkout v2 7726b0b v1.0.3 - 2020-08-23 Commits [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 1f10561 [Deps] update es-abstract, object-inspect bc20159 [Dev Deps] update @ljharb/eslint-config, tape b9b2b22 [Dev Deps] update eslint, @ljharb/eslint-config, tape 7055ab4 [Dev Deps] update auto-changelog; add aud d278c37 [actions] switch Automatic Rebase workflow to pull_request_target event 3bcf982 [Tests] only audit prod deps 18d01c4 [Deps] update es-abstract 6ab096d [Dev Deps] update tape 9dc174c [Deps] update es-abstract 431d0f0 [Deps] update es-abstract 49869fd [meta] Add package.json to package's exports 77d9cdc v1.0.2 - 2019-12-20 Commits [Dev Deps] update @ljharb/eslint-config, tape 4a526df [Deps] update es-abstract d4f6e62 v1.0.1 - 2019-12-01 Commits [Fix] add missing \"exports\" d212907 v1.0.0 - 2019-12-01 Commits Initial implementation dbebd3a Initial tests 73bdefe Initial commit 43c03e1 npm init 5c090a7 [meta] add auto-changelog a5c4e56 [actions] add automatic rebasing / merge commit blocking bab1683 [meta] add funding field; create FUNDING.yml 63d7aea [Tests] add npm run lint 46a5a81 Only apps should have lockfiles 8b16b03 [meta] add safe-publish-latest 2f098ef"
  },
  "src/frontend/app-client/node_modules/side-channel/README.html": {
    "href": "src/frontend/app-client/node_modules/side-channel/README.html",
    "title": "side-channel",
    "summary": "side-channel Store information about any JS value in a side channel. Uses WeakMap if available. Warning: in an environment that lacks WeakMap, this implementation will leak memory until you delete the key. Getting started npm install --save side-channel Usage/Examples const assert = require('assert'); const getSideChannel = require('side-channel'); const channel = getSideChannel(); const key = {}; assert.equal(channel.has(key), false); assert.throws(() => channel.assert(key), TypeError); channel.set(key, 42); channel.assert(key); // does not throw assert.equal(channel.has(key), true); assert.equal(channel.get(key), 42); channel.delete(key); assert.equal(channel.has(key), false); assert.throws(() => channel.assert(key), TypeError); Tests Clone the repo, npm install, and run npm test"
  },
  "src/frontend/app-client/node_modules/signal-exit/README.html": {
    "href": "src/frontend/app-client/node_modules/signal-exit/README.html",
    "title": "signal-exit",
    "summary": "signal-exit When you want to fire an event no matter how a process exits: reaching the end of execution. explicitly having process.exit(code) called. having process.kill(pid, sig) called. receiving a fatal signal from outside the process Use signal-exit. // Hybrid module, either works import { onExit } from 'signal-exit' // or: // const { onExit } = require('signal-exit') onExit((code, signal) => { console.log('process exited!', code, signal) }) API remove = onExit((code, signal) => {}, options) The return value of the function is a function that will remove the handler. Note that the function only fires for signals if the signal would cause the process to exit. That is, there are no other listeners, and it is a fatal signal. If the global process object is not suitable for this purpose (ie, it's unset, or doesn't have an emit method, etc.) then the onExit function is a no-op that returns a no-op remove method. Options alwaysLast: Run this handler after any other signal or exit handlers. This causes process.emit to be monkeypatched. Capturing Signal Exits If the handler returns an exact boolean true, and the exit is a due to signal, then the signal will be considered handled, and will not trigger a synthetic process.kill(process.pid, signal) after firing the onExit handlers. In this case, it your responsibility as the caller to exit with a signal (for example, by calling process.kill()) if you wish to preserve the same exit status that would otherwise have occurred. If you do not, then the process will likely exit gracefully with status 0 at some point, assuming that no other terminating signal or other exit trigger occurs. Prior to calling handlers, the onExit machinery is unloaded, so any subsequent exits or signals will not be handled, even if the signal is captured and the exit is thus prevented. Note that numeric code exits may indicate that the process is already committed to exiting, for example due to a fatal exception or unhandled promise rejection, and so there is no way to prevent it safely. Browser Fallback The 'signal-exit/browser' module is the same fallback shim that just doesn't do anything, but presents the same function interface. Patches welcome to add something that hooks onto window.onbeforeunload or similar, but it might just not be a thing that makes sense there."
  },
  "src/frontend/app-client/node_modules/sonner/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/sonner/LICENSE.html",
    "title": "",
    "summary": "MIT License Copyright (c) 2023 Emil Kowalski Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/sonner/README.html": {
    "href": "src/frontend/app-client/node_modules/sonner/README.html",
    "title": "",
    "summary": "https://github.com/vallezw/sonner/assets/50796600/59b95cb7-9068-4f3e-8469-0b35d9de5cf0 Sonner is an opinionated toast component for React. You can read more about why and how it was built here. Usage To start using the library, install it in your project: npm install sonner Add <Toaster /> to your app, it will be the place where all your toasts will be rendered. After that you can use toast() from anywhere in your app. import { Toaster, toast } from 'sonner'; // ... function App() { return ( <div> <Toaster /> <button onClick={() => toast('My first toast')}>Give me a toast</button> </div> ); } Documentation Find the full API reference in the documentation."
  },
  "src/frontend/app-client/node_modules/source-map-js/README.html": {
    "href": "src/frontend/app-client/node_modules/source-map-js/README.html",
    "title": "Source Map JS",
    "summary": "Source Map JS Difference between original source-map: TL,DR: it's fork of original source-map@0.6, but with perfomance optimizations. This journey starts from source-map@0.7.0. Some part of it was rewritten to Rust and WASM and API became async. It's still a major block for many libraries like PostCSS or Sass for example because they need to migrate the whole API to the async way. This is the reason why 0.6.1 has 2x more downloads than 0.7.3 while it's faster several times. More important that WASM version has some optimizations in JS code too. This is why community asked to create branch for 0.6 version and port these optimizations but, sadly, the answer was «no». A bit later I discovered the issue created by Ben Rothman (@benthemonkey) with no response at all. Roman Dvornov (@lahmatiy) wrote a serveral posts (russian, only, sorry) about source-map library in his own Telegram channel. He mentioned the article «Maybe you don't need Rust and WASM to speed up your JS» written by Vyacheslav Egorov (@mraleph). This article contains optimizations and hacks that lead to almost the same performance compare to WASM implementation. I decided to fork the original source-map and port these optimizations from the article and several others PR from the original source-map. This is a library to generate and consume the source map format described here. Use with Node $ npm install source-map-js Table of Contents Examples Consuming a source map Generating a source map With SourceNode (high level API) With SourceMapGenerator (low level API) API SourceMapConsumer new SourceMapConsumer(rawSourceMap) SourceMapConsumer.prototype.computeColumnSpans() SourceMapConsumer.prototype.originalPositionFor(generatedPosition) SourceMapConsumer.prototype.generatedPositionFor(originalPosition) SourceMapConsumer.prototype.allGeneratedPositionsFor(originalPosition) SourceMapConsumer.prototype.hasContentsOfAllSources() SourceMapConsumer.prototype.sourceContentFor(source[, returnNullOnMissing]) SourceMapConsumer.prototype.eachMapping(callback, context, order) SourceMapGenerator new SourceMapGenerator([startOfSourceMap]) SourceMapGenerator.fromSourceMap(sourceMapConsumer) SourceMapGenerator.prototype.addMapping(mapping) SourceMapGenerator.prototype.setSourceContent(sourceFile, sourceContent) SourceMapGenerator.prototype.applySourceMap(sourceMapConsumer[, sourceFile[, sourceMapPath]]) SourceMapGenerator.prototype.toString() SourceNode new SourceNode([line, column, source[, chunk[, name]]]) SourceNode.fromStringWithSourceMap(code, sourceMapConsumer[, relativePath]) SourceNode.prototype.add(chunk) SourceNode.prototype.prepend(chunk) SourceNode.prototype.setSourceContent(sourceFile, sourceContent) SourceNode.prototype.walk(fn) SourceNode.prototype.walkSourceContents(fn) SourceNode.prototype.join(sep) SourceNode.prototype.replaceRight(pattern, replacement) SourceNode.prototype.toString() SourceNode.prototype.toStringWithSourceMap([startOfSourceMap]) Examples Consuming a source map var rawSourceMap = { version: 3, file: 'min.js', names: ['bar', 'baz', 'n'], sources: ['one.js', 'two.js'], sourceRoot: 'http://example.com/www/js/', mappings: 'CAAC,IAAI,IAAM,SAAUA,GAClB,OAAOC,IAAID;CCDb,IAAI,IAAM,SAAUE,GAClB,OAAOA' }; var smc = new SourceMapConsumer(rawSourceMap); console.log(smc.sources); // [ 'http://example.com/www/js/one.js', // 'http://example.com/www/js/two.js' ] console.log(smc.originalPositionFor({ line: 2, column: 28 })); // { source: 'http://example.com/www/js/two.js', // line: 2, // column: 10, // name: 'n' } console.log(smc.generatedPositionFor({ source: 'http://example.com/www/js/two.js', line: 2, column: 10 })); // { line: 2, column: 28 } smc.eachMapping(function (m) { // ... }); Generating a source map In depth guide: Compiling to JavaScript, and Debugging with Source Maps With SourceNode (high level API) function compile(ast) { switch (ast.type) { case 'BinaryExpression': return new SourceNode( ast.location.line, ast.location.column, ast.location.source, [compile(ast.left), \" + \", compile(ast.right)] ); case 'Literal': return new SourceNode( ast.location.line, ast.location.column, ast.location.source, String(ast.value) ); // ... default: throw new Error(\"Bad AST\"); } } var ast = parse(\"40 + 2\", \"add.js\"); console.log(compile(ast).toStringWithSourceMap({ file: 'add.js' })); // { code: '40 + 2', // map: [object SourceMapGenerator] } With SourceMapGenerator (low level API) var map = new SourceMapGenerator({ file: \"source-mapped.js\" }); map.addMapping({ generated: { line: 10, column: 35 }, source: \"foo.js\", original: { line: 33, column: 2 }, name: \"christopher\" }); console.log(map.toString()); // '{\"version\":3,\"file\":\"source-mapped.js\",\"sources\":[\"foo.js\"],\"names\":[\"christopher\"],\"mappings\":\";;;;;;;;;mCAgCEA\"}' API Get a reference to the module: // Node.js var sourceMap = require('source-map'); // Browser builds var sourceMap = window.sourceMap; // Inside Firefox const sourceMap = require(\"devtools/toolkit/sourcemap/source-map.js\"); SourceMapConsumer A SourceMapConsumer instance represents a parsed source map which we can query for information about the original file positions by giving it a file position in the generated source. new SourceMapConsumer(rawSourceMap) The only parameter is the raw source map (either as a string which can be JSON.parse'd, or an object). According to the spec, source maps have the following attributes: version: Which version of the source map spec this map is following. sources: An array of URLs to the original source files. names: An array of identifiers which can be referenced by individual mappings. sourceRoot: Optional. The URL root from which all sources are relative. sourcesContent: Optional. An array of contents of the original source files. mappings: A string of base64 VLQs which contain the actual mappings. file: Optional. The generated filename this source map is associated with. var consumer = new sourceMap.SourceMapConsumer(rawSourceMapJsonData); SourceMapConsumer.prototype.computeColumnSpans() Compute the last column for each generated mapping. The last column is inclusive. // Before: consumer.allGeneratedPositionsFor({ line: 2, source: \"foo.coffee\" }) // [ { line: 2, // column: 1 }, // { line: 2, // column: 10 }, // { line: 2, // column: 20 } ] consumer.computeColumnSpans(); // After: consumer.allGeneratedPositionsFor({ line: 2, source: \"foo.coffee\" }) // [ { line: 2, // column: 1, // lastColumn: 9 }, // { line: 2, // column: 10, // lastColumn: 19 }, // { line: 2, // column: 20, // lastColumn: Infinity } ] SourceMapConsumer.prototype.originalPositionFor(generatedPosition) Returns the original source, line, and column information for the generated source's line and column positions provided. The only argument is an object with the following properties: line: The line number in the generated source. Line numbers in this library are 1-based (note that the underlying source map specification uses 0-based line numbers -- this library handles the translation). column: The column number in the generated source. Column numbers in this library are 0-based. bias: Either SourceMapConsumer.GREATEST_LOWER_BOUND or SourceMapConsumer.LEAST_UPPER_BOUND. Specifies whether to return the closest element that is smaller than or greater than the one we are searching for, respectively, if the exact element cannot be found. Defaults to SourceMapConsumer.GREATEST_LOWER_BOUND. and an object is returned with the following properties: source: The original source file, or null if this information is not available. line: The line number in the original source, or null if this information is not available. The line number is 1-based. column: The column number in the original source, or null if this information is not available. The column number is 0-based. name: The original identifier, or null if this information is not available. consumer.originalPositionFor({ line: 2, column: 10 }) // { source: 'foo.coffee', // line: 2, // column: 2, // name: null } consumer.originalPositionFor({ line: 99999999999999999, column: 999999999999999 }) // { source: null, // line: null, // column: null, // name: null } SourceMapConsumer.prototype.generatedPositionFor(originalPosition) Returns the generated line and column information for the original source, line, and column positions provided. The only argument is an object with the following properties: source: The filename of the original source. line: The line number in the original source. The line number is 1-based. column: The column number in the original source. The column number is 0-based. and an object is returned with the following properties: line: The line number in the generated source, or null. The line number is 1-based. column: The column number in the generated source, or null. The column number is 0-based. consumer.generatedPositionFor({ source: \"example.js\", line: 2, column: 10 }) // { line: 1, // column: 56 } SourceMapConsumer.prototype.allGeneratedPositionsFor(originalPosition) Returns all generated line and column information for the original source, line, and column provided. If no column is provided, returns all mappings corresponding to a either the line we are searching for or the next closest line that has any mappings. Otherwise, returns all mappings corresponding to the given line and either the column we are searching for or the next closest column that has any offsets. The only argument is an object with the following properties: source: The filename of the original source. line: The line number in the original source. The line number is 1-based. column: Optional. The column number in the original source. The column number is 0-based. and an array of objects is returned, each with the following properties: line: The line number in the generated source, or null. The line number is 1-based. column: The column number in the generated source, or null. The column number is 0-based. consumer.allGeneratedpositionsfor({ line: 2, source: \"foo.coffee\" }) // [ { line: 2, // column: 1 }, // { line: 2, // column: 10 }, // { line: 2, // column: 20 } ] SourceMapConsumer.prototype.hasContentsOfAllSources() Return true if we have the embedded source content for every source listed in the source map, false otherwise. In other words, if this method returns true, then consumer.sourceContentFor(s) will succeed for every source s in consumer.sources. // ... if (consumer.hasContentsOfAllSources()) { consumerReadyCallback(consumer); } else { fetchSources(consumer, consumerReadyCallback); } // ... SourceMapConsumer.prototype.sourceContentFor(source[, returnNullOnMissing]) Returns the original source content for the source provided. The only argument is the URL of the original source file. If the source content for the given source is not found, then an error is thrown. Optionally, pass true as the second param to have null returned instead. consumer.sources // [ \"my-cool-lib.clj\" ] consumer.sourceContentFor(\"my-cool-lib.clj\") // \"...\" consumer.sourceContentFor(\"this is not in the source map\"); // Error: \"this is not in the source map\" is not in the source map consumer.sourceContentFor(\"this is not in the source map\", true); // null SourceMapConsumer.prototype.eachMapping(callback, context, order) Iterate over each mapping between an original source/line/column and a generated line/column in this source map. callback: The function that is called with each mapping. Mappings have the form { source, generatedLine, generatedColumn, originalLine, originalColumn, name } context: Optional. If specified, this object will be the value of this every time that callback is called. order: Either SourceMapConsumer.GENERATED_ORDER or SourceMapConsumer.ORIGINAL_ORDER. Specifies whether you want to iterate over the mappings sorted by the generated file's line/column order or the original's source/line/column order, respectively. Defaults to SourceMapConsumer.GENERATED_ORDER. consumer.eachMapping(function (m) { console.log(m); }) // ... // { source: 'illmatic.js', // generatedLine: 1, // generatedColumn: 0, // originalLine: 1, // originalColumn: 0, // name: null } // { source: 'illmatic.js', // generatedLine: 2, // generatedColumn: 0, // originalLine: 2, // originalColumn: 0, // name: null } // ... SourceMapGenerator An instance of the SourceMapGenerator represents a source map which is being built incrementally. new SourceMapGenerator([startOfSourceMap]) You may pass an object with the following properties: file: The filename of the generated source that this source map is associated with. sourceRoot: A root for all relative URLs in this source map. skipValidation: Optional. When true, disables validation of mappings as they are added. This can improve performance but should be used with discretion, as a last resort. Even then, one should avoid using this flag when running tests, if possible. ignoreInvalidMapping: Optional. When true, instead of throwing error on invalid mapping, it will be ignored. var generator = new sourceMap.SourceMapGenerator({ file: \"my-generated-javascript-file.js\", sourceRoot: \"http://example.com/app/js/\" }); SourceMapGenerator.fromSourceMap(sourceMapConsumer, sourceMapGeneratorOptions) Creates a new SourceMapGenerator from an existing SourceMapConsumer instance. sourceMapConsumer The SourceMap. sourceMapGeneratorOptions options that will be passed to the SourceMapGenerator constructor which used under the hood. var generator = sourceMap.SourceMapGenerator.fromSourceMap(consumer, { ignoreInvalidMapping: true, }); SourceMapGenerator.prototype.addMapping(mapping) Add a single mapping from original source line and column to the generated source's line and column for this source map being created. The mapping object should have the following properties: generated: An object with the generated line and column positions. original: An object with the original line and column positions. source: The original source file (relative to the sourceRoot). name: An optional original token name for this mapping. generator.addMapping({ source: \"module-one.scm\", original: { line: 128, column: 0 }, generated: { line: 3, column: 456 } }) SourceMapGenerator.prototype.setSourceContent(sourceFile, sourceContent) Set the source content for an original source file. sourceFile the URL of the original source file. sourceContent the content of the source file. generator.setSourceContent(\"module-one.scm\", fs.readFileSync(\"path/to/module-one.scm\")) SourceMapGenerator.prototype.applySourceMap(sourceMapConsumer[, sourceFile[, sourceMapPath]]) Applies a SourceMap for a source file to the SourceMap. Each mapping to the supplied source file is rewritten using the supplied SourceMap. Note: The resolution for the resulting mappings is the minimum of this map and the supplied map. sourceMapConsumer: The SourceMap to be applied. sourceFile: Optional. The filename of the source file. If omitted, sourceMapConsumer.file will be used, if it exists. Otherwise an error will be thrown. sourceMapPath: Optional. The dirname of the path to the SourceMap to be applied. If relative, it is relative to the SourceMap. This parameter is needed when the two SourceMaps aren't in the same directory, and the SourceMap to be applied contains relative source paths. If so, those relative source paths need to be rewritten relative to the SourceMap. If omitted, it is assumed that both SourceMaps are in the same directory, thus not needing any rewriting. (Supplying '.' has the same effect.) SourceMapGenerator.prototype.toString() Renders the source map being generated to a string. generator.toString() // '{\"version\":3,\"sources\":[\"module-one.scm\"],\"names\":[],\"mappings\":\"...snip...\",\"file\":\"my-generated-javascript-file.js\",\"sourceRoot\":\"http://example.com/app/js/\"}' SourceNode SourceNodes provide a way to abstract over interpolating and/or concatenating snippets of generated JavaScript source code, while maintaining the line and column information associated between those snippets and the original source code. This is useful as the final intermediate representation a compiler might use before outputting the generated JS and source map. new SourceNode([line, column, source[, chunk[, name]]]) line: The original line number associated with this source node, or null if it isn't associated with an original line. The line number is 1-based. column: The original column number associated with this source node, or null if it isn't associated with an original column. The column number is 0-based. source: The original source's filename; null if no filename is provided. chunk: Optional. Is immediately passed to SourceNode.prototype.add, see below. name: Optional. The original identifier. var node = new SourceNode(1, 2, \"a.cpp\", [ new SourceNode(3, 4, \"b.cpp\", \"extern int status;\\n\"), new SourceNode(5, 6, \"c.cpp\", \"std::string* make_string(size_t n);\\n\"), new SourceNode(7, 8, \"d.cpp\", \"int main(int argc, char** argv) {}\\n\"), ]); SourceNode.fromStringWithSourceMap(code, sourceMapConsumer[, relativePath]) Creates a SourceNode from generated code and a SourceMapConsumer. code: The generated code sourceMapConsumer The SourceMap for the generated code relativePath The optional path that relative sources in sourceMapConsumer should be relative to. var consumer = new SourceMapConsumer(fs.readFileSync(\"path/to/my-file.js.map\", \"utf8\")); var node = SourceNode.fromStringWithSourceMap(fs.readFileSync(\"path/to/my-file.js\"), consumer); SourceNode.prototype.add(chunk) Add a chunk of generated JS to this source node. chunk: A string snippet of generated JS code, another instance of SourceNode, or an array where each member is one of those things. node.add(\" + \"); node.add(otherNode); node.add([leftHandOperandNode, \" + \", rightHandOperandNode]); SourceNode.prototype.prepend(chunk) Prepend a chunk of generated JS to this source node. chunk: A string snippet of generated JS code, another instance of SourceNode, or an array where each member is one of those things. node.prepend(\"/** Build Id: f783haef86324gf **/\\n\\n\"); SourceNode.prototype.setSourceContent(sourceFile, sourceContent) Set the source content for a source file. This will be added to the SourceMap in the sourcesContent field. sourceFile: The filename of the source file sourceContent: The content of the source file node.setSourceContent(\"module-one.scm\", fs.readFileSync(\"path/to/module-one.scm\")) SourceNode.prototype.walk(fn) Walk over the tree of JS snippets in this node and its children. The walking function is called once for each snippet of JS and is passed that snippet and the its original associated source's line/column location. fn: The traversal function. var node = new SourceNode(1, 2, \"a.js\", [ new SourceNode(3, 4, \"b.js\", \"uno\"), \"dos\", [ \"tres\", new SourceNode(5, 6, \"c.js\", \"quatro\") ] ]); node.walk(function (code, loc) { console.log(\"WALK:\", code, loc); }) // WALK: uno { source: 'b.js', line: 3, column: 4, name: null } // WALK: dos { source: 'a.js', line: 1, column: 2, name: null } // WALK: tres { source: 'a.js', line: 1, column: 2, name: null } // WALK: quatro { source: 'c.js', line: 5, column: 6, name: null } SourceNode.prototype.walkSourceContents(fn) Walk over the tree of SourceNodes. The walking function is called for each source file content and is passed the filename and source content. fn: The traversal function. var a = new SourceNode(1, 2, \"a.js\", \"generated from a\"); a.setSourceContent(\"a.js\", \"original a\"); var b = new SourceNode(1, 2, \"b.js\", \"generated from b\"); b.setSourceContent(\"b.js\", \"original b\"); var c = new SourceNode(1, 2, \"c.js\", \"generated from c\"); c.setSourceContent(\"c.js\", \"original c\"); var node = new SourceNode(null, null, null, [a, b, c]); node.walkSourceContents(function (source, contents) { console.log(\"WALK:\", source, \":\", contents); }) // WALK: a.js : original a // WALK: b.js : original b // WALK: c.js : original c SourceNode.prototype.join(sep) Like Array.prototype.join except for SourceNodes. Inserts the separator between each of this source node's children. sep: The separator. var lhs = new SourceNode(1, 2, \"a.rs\", \"my_copy\"); var operand = new SourceNode(3, 4, \"a.rs\", \"=\"); var rhs = new SourceNode(5, 6, \"a.rs\", \"orig.clone()\"); var node = new SourceNode(null, null, null, [ lhs, operand, rhs ]); var joinedNode = node.join(\" \"); SourceNode.prototype.replaceRight(pattern, replacement) Call String.prototype.replace on the very right-most source snippet. Useful for trimming white space from the end of a source node, etc. pattern: The pattern to replace. replacement: The thing to replace the pattern with. // Trim trailing white space. node.replaceRight(/\\s*$/, \"\"); SourceNode.prototype.toString() Return the string representation of this source node. Walks over the tree and concatenates all the various snippets together to one string. var node = new SourceNode(1, 2, \"a.js\", [ new SourceNode(3, 4, \"b.js\", \"uno\"), \"dos\", [ \"tres\", new SourceNode(5, 6, \"c.js\", \"quatro\") ] ]); node.toString() // 'unodostresquatro' SourceNode.prototype.toStringWithSourceMap([startOfSourceMap]) Returns the string representation of this tree of source nodes, plus a SourceMapGenerator which contains all the mappings between the generated and original sources. The arguments are the same as those to new SourceMapGenerator. var node = new SourceNode(1, 2, \"a.js\", [ new SourceNode(3, 4, \"b.js\", \"uno\"), \"dos\", [ \"tres\", new SourceNode(5, 6, \"c.js\", \"quatro\") ] ]); node.toStringWithSourceMap({ file: \"my-output-file.js\" }) // { code: 'unodostresquatro', // map: [object SourceMapGenerator] }"
  },
  "src/frontend/app-client/node_modules/source-map-support/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/source-map-support/LICENSE.html",
    "title": "",
    "summary": "The MIT License (MIT) Copyright (c) 2014 Evan Wallace Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/source-map-support/node_modules/source-map/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/source-map-support/node_modules/source-map/CHANGELOG.html",
    "title": "Change Log",
    "summary": "Change Log 0.5.6 Fix for regression when people were using numbers as names in source maps. See #236. 0.5.5 Fix \"regression\" of unsupported, implementation behavior that half the world happens to have come to depend on. See #235. Fix regression involving function hoisting in SpiderMonkey. See #233. 0.5.4 Large performance improvements to source-map serialization. See #228 and #229. 0.5.3 Do not include unnecessary distribution files. See commit ef7006f8d1647e0a83fdc60f04f5a7ca54886f86. 0.5.2 Include browser distributions of the library in package.json's files. See issue #212. 0.5.1 Fix latent bugs in IndexedSourceMapConsumer.prototype._parseMappings. See ff05274becc9e6e1295ed60f3ea090d31d843379. 0.5.0 Node 0.8 is no longer supported. Use webpack instead of dryice for bundling. Big speedups serializing source maps. See pull request #203. Fix a bug with SourceMapConsumer.prototype.sourceContentFor and sources that explicitly start with the source root. See issue #199. 0.4.4 Fix an issue where using a SourceMapGenerator after having created a SourceMapConsumer from it via SourceMapConsumer.fromSourceMap failed. See issue #191. Fix an issue with where SourceMapGenerator would mistakenly consider different mappings as duplicates of each other and avoid generating them. See issue #192. 0.4.3 A very large number of performance improvements, particularly when parsing source maps. Collectively about 75% of time shaved off of the source map parsing benchmark! Fix a bug in SourceMapConsumer.prototype.allGeneratedPositionsFor and fuzzy searching in the presence of a column option. See issue #177. Fix a bug with joining a source and its source root when the source is above the root. See issue #182. Add the SourceMapConsumer.prototype.hasContentsOfAllSources method to determine when all sources' contents are inlined into the source map. See issue #190. 0.4.2 Add an .npmignore file so that the benchmarks aren't pulled down by dependent projects. Issue #169. Add an optional column argument to SourceMapConsumer.prototype.allGeneratedPositionsFor and better handle lines with no mappings. Issues #172 and #173. 0.4.1 Fix accidentally defining a global variable. #170. 0.4.0 The default direction for fuzzy searching was changed back to its original direction. See #164. There is now a bias option you can supply to SourceMapConsumer to control the fuzzy searching direction. See #167. About an 8% speed up in parsing source maps. See #159. Added a benchmark for parsing and generating source maps. 0.3.0 Change the default direction that searching for positions fuzzes when there is not an exact match. See #154. Support for environments using json2.js for JSON serialization. See #156. 0.2.0 Support for consuming \"indexed\" source maps which do not have any remote sections. See pull request #127. This introduces a minor backwards incompatibility if you are monkey patching SourceMapConsumer.prototype methods. 0.1.43 Performance improvements for SourceMapGenerator and SourceNode. See issue #148 for some discussion and issues #150, #151, and #152 for implementations. 0.1.42 Fix an issue where SourceNodes from different versions of the source-map library couldn't be used in conjunction with each other. See issue #142. 0.1.41 Fix a bug with getting the source content of relative sources with a \"./\" prefix. See issue #145 and Bug 1090768. Add the SourceMapConsumer.prototype.computeColumnSpans method to compute the column span of each mapping. Add the SourceMapConsumer.prototype.allGeneratedPositionsFor method to find all generated positions associated with a given original source and line. 0.1.40 Performance improvements for parsing source maps in SourceMapConsumer. 0.1.39 Fix a bug where setting a source's contents to null before any source content had been set before threw a TypeError. See issue #131. 0.1.38 Fix a bug where finding relative paths from an empty path were creating absolute paths. See issue #129. 0.1.37 Fix a bug where if the source root was an empty string, relative source paths would turn into absolute source paths. Issue #124. 0.1.36 Allow the names mapping property to be an empty string. Issue #121. 0.1.35 A third optional parameter was added to SourceNode.fromStringWithSourceMap to specify a path that relative sources in the second parameter should be relative to. Issue #105. If no file property is given to a SourceMapGenerator, then the resulting source map will no longer have a null file property. The property will simply not exist. Issue #104. Fixed a bug where consecutive newlines were ignored in SourceNodes. Issue #116. 0.1.34 Make SourceNode work with windows style (\"\\r\\n\") newlines. Issue #103. Fix bug involving source contents and the SourceMapGenerator.prototype.applySourceMap. Issue #100. 0.1.33 Fix some edge cases surrounding path joining and URL resolution. Add a third parameter for relative path to SourceMapGenerator.prototype.applySourceMap. Fix issues with mappings and EOLs. 0.1.32 Fixed a bug where SourceMapConsumer couldn't handle negative relative columns (issue 92). Fixed test runner to actually report number of failed tests as its process exit code. Fixed a typo when reporting bad mappings (issue 87). 0.1.31 Delay parsing the mappings in SourceMapConsumer until queried for a source location. Support Sass source maps (which at the time of writing deviate from the spec in small ways) in SourceMapConsumer. 0.1.30 Do not join source root with a source, when the source is a data URI. Extend the test runner to allow running single specific test files at a time. Performance improvements in SourceNode.prototype.walk and SourceMapConsumer.prototype.eachMapping. Source map browser builds will now work inside Workers. Better error messages when attempting to add an invalid mapping to a SourceMapGenerator. 0.1.29 Allow duplicate entries in the names and sources arrays of source maps (usually from TypeScript) we are parsing. Fixes github issue 72. 0.1.28 Skip duplicate mappings when creating source maps from SourceNode; github issue 75. 0.1.27 Don't throw an error when the file property is missing in SourceMapConsumer, we don't use it anyway. 0.1.26 Fix SourceNode.fromStringWithSourceMap for empty maps. Fixes github issue 70. 0.1.25 Make compatible with browserify 0.1.24 Fix issue with absolute paths and file:// URIs. See https://bugzilla.mozilla.org/show_bug.cgi?id=885597 0.1.23 Fix issue with absolute paths and sourcesContent, github issue 64. 0.1.22 Ignore duplicate mappings in SourceMapGenerator. Fixes github issue 21. 0.1.21 Fixed handling of sources that start with a slash so that they are relative to the source root's host. 0.1.20 Fixed github issue #43: absolute URLs aren't joined with the source root anymore. 0.1.19 Using Travis CI to run tests. 0.1.18 Fixed a bug in the handling of sourceRoot. 0.1.17 Added SourceNode.fromStringWithSourceMap. 0.1.16 Added missing documentation. Fixed the generating of empty mappings in SourceNode. 0.1.15 Added SourceMapGenerator.applySourceMap. 0.1.14 The sourceRoot is now handled consistently. 0.1.13 Added SourceMapGenerator.fromSourceMap. 0.1.12 SourceNode now generates empty mappings too. 0.1.11 Added name support to SourceNode. 0.1.10 Added sourcesContent support to the customer and generator."
  },
  "src/frontend/app-client/node_modules/source-map-support/node_modules/source-map/README.html": {
    "href": "src/frontend/app-client/node_modules/source-map-support/node_modules/source-map/README.html",
    "title": "Source Map",
    "summary": "Source Map This is a library to generate and consume the source map format described here. Use with Node $ npm install source-map Use on the Web <script src=\"https://raw.githubusercontent.com/mozilla/source-map/master/dist/source-map.min.js\" defer></script> Table of Contents Examples Consuming a source map Generating a source map With SourceNode (high level API) With SourceMapGenerator (low level API) API SourceMapConsumer new SourceMapConsumer(rawSourceMap) SourceMapConsumer.prototype.computeColumnSpans() SourceMapConsumer.prototype.originalPositionFor(generatedPosition) SourceMapConsumer.prototype.generatedPositionFor(originalPosition) SourceMapConsumer.prototype.allGeneratedPositionsFor(originalPosition) SourceMapConsumer.prototype.hasContentsOfAllSources() SourceMapConsumer.prototype.sourceContentFor(source[, returnNullOnMissing]) SourceMapConsumer.prototype.eachMapping(callback, context, order) SourceMapGenerator new SourceMapGenerator([startOfSourceMap]) SourceMapGenerator.fromSourceMap(sourceMapConsumer) SourceMapGenerator.prototype.addMapping(mapping) SourceMapGenerator.prototype.setSourceContent(sourceFile, sourceContent) SourceMapGenerator.prototype.applySourceMap(sourceMapConsumer[, sourceFile[, sourceMapPath]]) SourceMapGenerator.prototype.toString() SourceNode new SourceNode([line, column, source[, chunk[, name]]]) SourceNode.fromStringWithSourceMap(code, sourceMapConsumer[, relativePath]) SourceNode.prototype.add(chunk) SourceNode.prototype.prepend(chunk) SourceNode.prototype.setSourceContent(sourceFile, sourceContent) SourceNode.prototype.walk(fn) SourceNode.prototype.walkSourceContents(fn) SourceNode.prototype.join(sep) SourceNode.prototype.replaceRight(pattern, replacement) SourceNode.prototype.toString() SourceNode.prototype.toStringWithSourceMap([startOfSourceMap]) Examples Consuming a source map var rawSourceMap = { version: 3, file: 'min.js', names: ['bar', 'baz', 'n'], sources: ['one.js', 'two.js'], sourceRoot: 'http://example.com/www/js/', mappings: 'CAAC,IAAI,IAAM,SAAUA,GAClB,OAAOC,IAAID;CCDb,IAAI,IAAM,SAAUE,GAClB,OAAOA' }; var smc = new SourceMapConsumer(rawSourceMap); console.log(smc.sources); // [ 'http://example.com/www/js/one.js', // 'http://example.com/www/js/two.js' ] console.log(smc.originalPositionFor({ line: 2, column: 28 })); // { source: 'http://example.com/www/js/two.js', // line: 2, // column: 10, // name: 'n' } console.log(smc.generatedPositionFor({ source: 'http://example.com/www/js/two.js', line: 2, column: 10 })); // { line: 2, column: 28 } smc.eachMapping(function (m) { // ... }); Generating a source map In depth guide: Compiling to JavaScript, and Debugging with Source Maps With SourceNode (high level API) function compile(ast) { switch (ast.type) { case 'BinaryExpression': return new SourceNode( ast.location.line, ast.location.column, ast.location.source, [compile(ast.left), \" + \", compile(ast.right)] ); case 'Literal': return new SourceNode( ast.location.line, ast.location.column, ast.location.source, String(ast.value) ); // ... default: throw new Error(\"Bad AST\"); } } var ast = parse(\"40 + 2\", \"add.js\"); console.log(compile(ast).toStringWithSourceMap({ file: 'add.js' })); // { code: '40 + 2', // map: [object SourceMapGenerator] } With SourceMapGenerator (low level API) var map = new SourceMapGenerator({ file: \"source-mapped.js\" }); map.addMapping({ generated: { line: 10, column: 35 }, source: \"foo.js\", original: { line: 33, column: 2 }, name: \"christopher\" }); console.log(map.toString()); // '{\"version\":3,\"file\":\"source-mapped.js\",\"sources\":[\"foo.js\"],\"names\":[\"christopher\"],\"mappings\":\";;;;;;;;;mCAgCEA\"}' API Get a reference to the module: // Node.js var sourceMap = require('source-map'); // Browser builds var sourceMap = window.sourceMap; // Inside Firefox const sourceMap = require(\"devtools/toolkit/sourcemap/source-map.js\"); SourceMapConsumer A SourceMapConsumer instance represents a parsed source map which we can query for information about the original file positions by giving it a file position in the generated source. new SourceMapConsumer(rawSourceMap) The only parameter is the raw source map (either as a string which can be JSON.parse'd, or an object). According to the spec, source maps have the following attributes: version: Which version of the source map spec this map is following. sources: An array of URLs to the original source files. names: An array of identifiers which can be referenced by individual mappings. sourceRoot: Optional. The URL root from which all sources are relative. sourcesContent: Optional. An array of contents of the original source files. mappings: A string of base64 VLQs which contain the actual mappings. file: Optional. The generated filename this source map is associated with. var consumer = new sourceMap.SourceMapConsumer(rawSourceMapJsonData); SourceMapConsumer.prototype.computeColumnSpans() Compute the last column for each generated mapping. The last column is inclusive. // Before: consumer.allGeneratedPositionsFor({ line: 2, source: \"foo.coffee\" }) // [ { line: 2, // column: 1 }, // { line: 2, // column: 10 }, // { line: 2, // column: 20 } ] consumer.computeColumnSpans(); // After: consumer.allGeneratedPositionsFor({ line: 2, source: \"foo.coffee\" }) // [ { line: 2, // column: 1, // lastColumn: 9 }, // { line: 2, // column: 10, // lastColumn: 19 }, // { line: 2, // column: 20, // lastColumn: Infinity } ] SourceMapConsumer.prototype.originalPositionFor(generatedPosition) Returns the original source, line, and column information for the generated source's line and column positions provided. The only argument is an object with the following properties: line: The line number in the generated source. Line numbers in this library are 1-based (note that the underlying source map specification uses 0-based line numbers -- this library handles the translation). column: The column number in the generated source. Column numbers in this library are 0-based. bias: Either SourceMapConsumer.GREATEST_LOWER_BOUND or SourceMapConsumer.LEAST_UPPER_BOUND. Specifies whether to return the closest element that is smaller than or greater than the one we are searching for, respectively, if the exact element cannot be found. Defaults to SourceMapConsumer.GREATEST_LOWER_BOUND. and an object is returned with the following properties: source: The original source file, or null if this information is not available. line: The line number in the original source, or null if this information is not available. The line number is 1-based. column: The column number in the original source, or null if this information is not available. The column number is 0-based. name: The original identifier, or null if this information is not available. consumer.originalPositionFor({ line: 2, column: 10 }) // { source: 'foo.coffee', // line: 2, // column: 2, // name: null } consumer.originalPositionFor({ line: 99999999999999999, column: 999999999999999 }) // { source: null, // line: null, // column: null, // name: null } SourceMapConsumer.prototype.generatedPositionFor(originalPosition) Returns the generated line and column information for the original source, line, and column positions provided. The only argument is an object with the following properties: source: The filename of the original source. line: The line number in the original source. The line number is 1-based. column: The column number in the original source. The column number is 0-based. and an object is returned with the following properties: line: The line number in the generated source, or null. The line number is 1-based. column: The column number in the generated source, or null. The column number is 0-based. consumer.generatedPositionFor({ source: \"example.js\", line: 2, column: 10 }) // { line: 1, // column: 56 } SourceMapConsumer.prototype.allGeneratedPositionsFor(originalPosition) Returns all generated line and column information for the original source, line, and column provided. If no column is provided, returns all mappings corresponding to a either the line we are searching for or the next closest line that has any mappings. Otherwise, returns all mappings corresponding to the given line and either the column we are searching for or the next closest column that has any offsets. The only argument is an object with the following properties: source: The filename of the original source. line: The line number in the original source. The line number is 1-based. column: Optional. The column number in the original source. The column number is 0-based. and an array of objects is returned, each with the following properties: line: The line number in the generated source, or null. The line number is 1-based. column: The column number in the generated source, or null. The column number is 0-based. consumer.allGeneratedpositionsfor({ line: 2, source: \"foo.coffee\" }) // [ { line: 2, // column: 1 }, // { line: 2, // column: 10 }, // { line: 2, // column: 20 } ] SourceMapConsumer.prototype.hasContentsOfAllSources() Return true if we have the embedded source content for every source listed in the source map, false otherwise. In other words, if this method returns true, then consumer.sourceContentFor(s) will succeed for every source s in consumer.sources. // ... if (consumer.hasContentsOfAllSources()) { consumerReadyCallback(consumer); } else { fetchSources(consumer, consumerReadyCallback); } // ... SourceMapConsumer.prototype.sourceContentFor(source[, returnNullOnMissing]) Returns the original source content for the source provided. The only argument is the URL of the original source file. If the source content for the given source is not found, then an error is thrown. Optionally, pass true as the second param to have null returned instead. consumer.sources // [ \"my-cool-lib.clj\" ] consumer.sourceContentFor(\"my-cool-lib.clj\") // \"...\" consumer.sourceContentFor(\"this is not in the source map\"); // Error: \"this is not in the source map\" is not in the source map consumer.sourceContentFor(\"this is not in the source map\", true); // null SourceMapConsumer.prototype.eachMapping(callback, context, order) Iterate over each mapping between an original source/line/column and a generated line/column in this source map. callback: The function that is called with each mapping. Mappings have the form { source, generatedLine, generatedColumn, originalLine, originalColumn, name } context: Optional. If specified, this object will be the value of this every time that callback is called. order: Either SourceMapConsumer.GENERATED_ORDER or SourceMapConsumer.ORIGINAL_ORDER. Specifies whether you want to iterate over the mappings sorted by the generated file's line/column order or the original's source/line/column order, respectively. Defaults to SourceMapConsumer.GENERATED_ORDER. consumer.eachMapping(function (m) { console.log(m); }) // ... // { source: 'illmatic.js', // generatedLine: 1, // generatedColumn: 0, // originalLine: 1, // originalColumn: 0, // name: null } // { source: 'illmatic.js', // generatedLine: 2, // generatedColumn: 0, // originalLine: 2, // originalColumn: 0, // name: null } // ... SourceMapGenerator An instance of the SourceMapGenerator represents a source map which is being built incrementally. new SourceMapGenerator([startOfSourceMap]) You may pass an object with the following properties: file: The filename of the generated source that this source map is associated with. sourceRoot: A root for all relative URLs in this source map. skipValidation: Optional. When true, disables validation of mappings as they are added. This can improve performance but should be used with discretion, as a last resort. Even then, one should avoid using this flag when running tests, if possible. var generator = new sourceMap.SourceMapGenerator({ file: \"my-generated-javascript-file.js\", sourceRoot: \"http://example.com/app/js/\" }); SourceMapGenerator.fromSourceMap(sourceMapConsumer) Creates a new SourceMapGenerator from an existing SourceMapConsumer instance. sourceMapConsumer The SourceMap. var generator = sourceMap.SourceMapGenerator.fromSourceMap(consumer); SourceMapGenerator.prototype.addMapping(mapping) Add a single mapping from original source line and column to the generated source's line and column for this source map being created. The mapping object should have the following properties: generated: An object with the generated line and column positions. original: An object with the original line and column positions. source: The original source file (relative to the sourceRoot). name: An optional original token name for this mapping. generator.addMapping({ source: \"module-one.scm\", original: { line: 128, column: 0 }, generated: { line: 3, column: 456 } }) SourceMapGenerator.prototype.setSourceContent(sourceFile, sourceContent) Set the source content for an original source file. sourceFile the URL of the original source file. sourceContent the content of the source file. generator.setSourceContent(\"module-one.scm\", fs.readFileSync(\"path/to/module-one.scm\")) SourceMapGenerator.prototype.applySourceMap(sourceMapConsumer[, sourceFile[, sourceMapPath]]) Applies a SourceMap for a source file to the SourceMap. Each mapping to the supplied source file is rewritten using the supplied SourceMap. Note: The resolution for the resulting mappings is the minimum of this map and the supplied map. sourceMapConsumer: The SourceMap to be applied. sourceFile: Optional. The filename of the source file. If omitted, sourceMapConsumer.file will be used, if it exists. Otherwise an error will be thrown. sourceMapPath: Optional. The dirname of the path to the SourceMap to be applied. If relative, it is relative to the SourceMap. This parameter is needed when the two SourceMaps aren't in the same directory, and the SourceMap to be applied contains relative source paths. If so, those relative source paths need to be rewritten relative to the SourceMap. If omitted, it is assumed that both SourceMaps are in the same directory, thus not needing any rewriting. (Supplying '.' has the same effect.) SourceMapGenerator.prototype.toString() Renders the source map being generated to a string. generator.toString() // '{\"version\":3,\"sources\":[\"module-one.scm\"],\"names\":[],\"mappings\":\"...snip...\",\"file\":\"my-generated-javascript-file.js\",\"sourceRoot\":\"http://example.com/app/js/\"}' SourceNode SourceNodes provide a way to abstract over interpolating and/or concatenating snippets of generated JavaScript source code, while maintaining the line and column information associated between those snippets and the original source code. This is useful as the final intermediate representation a compiler might use before outputting the generated JS and source map. new SourceNode([line, column, source[, chunk[, name]]]) line: The original line number associated with this source node, or null if it isn't associated with an original line. The line number is 1-based. column: The original column number associated with this source node, or null if it isn't associated with an original column. The column number is 0-based. source: The original source's filename; null if no filename is provided. chunk: Optional. Is immediately passed to SourceNode.prototype.add, see below. name: Optional. The original identifier. var node = new SourceNode(1, 2, \"a.cpp\", [ new SourceNode(3, 4, \"b.cpp\", \"extern int status;\\n\"), new SourceNode(5, 6, \"c.cpp\", \"std::string* make_string(size_t n);\\n\"), new SourceNode(7, 8, \"d.cpp\", \"int main(int argc, char** argv) {}\\n\"), ]); SourceNode.fromStringWithSourceMap(code, sourceMapConsumer[, relativePath]) Creates a SourceNode from generated code and a SourceMapConsumer. code: The generated code sourceMapConsumer The SourceMap for the generated code relativePath The optional path that relative sources in sourceMapConsumer should be relative to. var consumer = new SourceMapConsumer(fs.readFileSync(\"path/to/my-file.js.map\", \"utf8\")); var node = SourceNode.fromStringWithSourceMap(fs.readFileSync(\"path/to/my-file.js\"), consumer); SourceNode.prototype.add(chunk) Add a chunk of generated JS to this source node. chunk: A string snippet of generated JS code, another instance of SourceNode, or an array where each member is one of those things. node.add(\" + \"); node.add(otherNode); node.add([leftHandOperandNode, \" + \", rightHandOperandNode]); SourceNode.prototype.prepend(chunk) Prepend a chunk of generated JS to this source node. chunk: A string snippet of generated JS code, another instance of SourceNode, or an array where each member is one of those things. node.prepend(\"/** Build Id: f783haef86324gf **/\\n\\n\"); SourceNode.prototype.setSourceContent(sourceFile, sourceContent) Set the source content for a source file. This will be added to the SourceMap in the sourcesContent field. sourceFile: The filename of the source file sourceContent: The content of the source file node.setSourceContent(\"module-one.scm\", fs.readFileSync(\"path/to/module-one.scm\")) SourceNode.prototype.walk(fn) Walk over the tree of JS snippets in this node and its children. The walking function is called once for each snippet of JS and is passed that snippet and the its original associated source's line/column location. fn: The traversal function. var node = new SourceNode(1, 2, \"a.js\", [ new SourceNode(3, 4, \"b.js\", \"uno\"), \"dos\", [ \"tres\", new SourceNode(5, 6, \"c.js\", \"quatro\") ] ]); node.walk(function (code, loc) { console.log(\"WALK:\", code, loc); }) // WALK: uno { source: 'b.js', line: 3, column: 4, name: null } // WALK: dos { source: 'a.js', line: 1, column: 2, name: null } // WALK: tres { source: 'a.js', line: 1, column: 2, name: null } // WALK: quatro { source: 'c.js', line: 5, column: 6, name: null } SourceNode.prototype.walkSourceContents(fn) Walk over the tree of SourceNodes. The walking function is called for each source file content and is passed the filename and source content. fn: The traversal function. var a = new SourceNode(1, 2, \"a.js\", \"generated from a\"); a.setSourceContent(\"a.js\", \"original a\"); var b = new SourceNode(1, 2, \"b.js\", \"generated from b\"); b.setSourceContent(\"b.js\", \"original b\"); var c = new SourceNode(1, 2, \"c.js\", \"generated from c\"); c.setSourceContent(\"c.js\", \"original c\"); var node = new SourceNode(null, null, null, [a, b, c]); node.walkSourceContents(function (source, contents) { console.log(\"WALK:\", source, \":\", contents); }) // WALK: a.js : original a // WALK: b.js : original b // WALK: c.js : original c SourceNode.prototype.join(sep) Like Array.prototype.join except for SourceNodes. Inserts the separator between each of this source node's children. sep: The separator. var lhs = new SourceNode(1, 2, \"a.rs\", \"my_copy\"); var operand = new SourceNode(3, 4, \"a.rs\", \"=\"); var rhs = new SourceNode(5, 6, \"a.rs\", \"orig.clone()\"); var node = new SourceNode(null, null, null, [ lhs, operand, rhs ]); var joinedNode = node.join(\" \"); SourceNode.prototype.replaceRight(pattern, replacement) Call String.prototype.replace on the very right-most source snippet. Useful for trimming white space from the end of a source node, etc. pattern: The pattern to replace. replacement: The thing to replace the pattern with. // Trim trailing white space. node.replaceRight(/\\s*$/, \"\"); SourceNode.prototype.toString() Return the string representation of this source node. Walks over the tree and concatenates all the various snippets together to one string. var node = new SourceNode(1, 2, \"a.js\", [ new SourceNode(3, 4, \"b.js\", \"uno\"), \"dos\", [ \"tres\", new SourceNode(5, 6, \"c.js\", \"quatro\") ] ]); node.toString() // 'unodostresquatro' SourceNode.prototype.toStringWithSourceMap([startOfSourceMap]) Returns the string representation of this tree of source nodes, plus a SourceMapGenerator which contains all the mappings between the generated and original sources. The arguments are the same as those to new SourceMapGenerator. var node = new SourceNode(1, 2, \"a.js\", [ new SourceNode(3, 4, \"b.js\", \"uno\"), \"dos\", [ \"tres\", new SourceNode(5, 6, \"c.js\", \"quatro\") ] ]); node.toStringWithSourceMap({ file: \"my-output-file.js\" }) // { code: 'unodostresquatro', // map: [object SourceMapGenerator] }"
  },
  "src/frontend/app-client/node_modules/source-map-support/README.html": {
    "href": "src/frontend/app-client/node_modules/source-map-support/README.html",
    "title": "Source Map Support",
    "summary": "Source Map Support This module provides source map support for stack traces in node via the V8 stack trace API. It uses the source-map module to replace the paths and line numbers of source-mapped files with their original paths and line numbers. The output mimics node's stack trace format with the goal of making every compile-to-JS language more of a first-class citizen. Source maps are completely general (not specific to any one language) so you can use source maps with multiple compile-to-JS languages in the same node process. Installation and Usage Node support $ npm install source-map-support Source maps can be generated using libraries such as source-map-index-generator. Once you have a valid source map, place a source mapping comment somewhere in the file (usually done automatically or with an option by your transpiler): //# sourceMappingURL=path/to/source.map If multiple sourceMappingURL comments exist in one file, the last sourceMappingURL comment will be respected (e.g. if a file mentions the comment in code, or went through multiple transpilers). The path should either be absolute or relative to the compiled file. From here you have two options. CLI Usage node -r source-map-support/register compiled.js Programmatic Usage Put the following line at the top of the compiled file. require('source-map-support').install(); It is also possible to install the source map support directly by requiring the register module which can be handy with ES6: import 'source-map-support/register' // Instead of: import sourceMapSupport from 'source-map-support' sourceMapSupport.install() Note: if you're using babel-register, it includes source-map-support already. It is also very useful with Mocha: $ mocha --require source-map-support/register tests/ Browser support This library also works in Chrome. While the DevTools console already supports source maps, the V8 engine doesn't and Error.prototype.stack will be incorrect without this library. Everything will just work if you deploy your source files using browserify. Just make sure to pass the --debug flag to the browserify command so your source maps are included in the bundled code. This library also works if you use another build process or just include the source files directly. In this case, include the file browser-source-map-support.js in your page and call sourceMapSupport.install(). It contains the whole library already bundled for the browser using browserify. <script src=\"browser-source-map-support.js\"></script> <script>sourceMapSupport.install();</script> This library also works if you use AMD (Asynchronous Module Definition), which is used in tools like RequireJS. Just list browser-source-map-support as a dependency: <script> define(['browser-source-map-support'], function(sourceMapSupport) { sourceMapSupport.install(); }); </script> Options This module installs two things: a change to the stack property on Error objects and a handler for uncaught exceptions that mimics node's default exception handler (the handler can be seen in the demos below). You may want to disable the handler if you have your own uncaught exception handler. This can be done by passing an argument to the installer: require('source-map-support').install({ handleUncaughtExceptions: false }); This module loads source maps from the filesystem by default. You can provide alternate loading behavior through a callback as shown below. For example, Meteor keeps all source maps cached in memory to avoid disk access. require('source-map-support').install({ retrieveSourceMap: function(source) { if (source === 'compiled.js') { return { url: 'original.js', map: fs.readFileSync('compiled.js.map', 'utf8') }; } return null; } }); The module will by default assume a browser environment if XMLHttpRequest and window are defined. If either of these do not exist it will instead assume a node environment. In some rare cases, e.g. when running a browser emulation and where both variables are also set, you can explictly specify the environment to be either 'browser' or 'node'. require('source-map-support').install({ environment: 'node' }); To support files with inline source maps, the hookRequire options can be specified, which will monitor all source files for inline source maps. require('source-map-support').install({ hookRequire: true }); This monkey patches the require module loading chain, so is not enabled by default and is not recommended for any sort of production usage. Demos Basic Demo original.js: throw new Error('test'); // This is the original code compiled.js: require('source-map-support').install(); throw new Error('test'); // This is the compiled code // The next line defines the sourceMapping. //# sourceMappingURL=compiled.js.map compiled.js.map: { \"version\": 3, \"file\": \"compiled.js\", \"sources\": [\"original.js\"], \"names\": [], \"mappings\": \";;AAAA,MAAM,IAAI\" } Run compiled.js using node (notice how the stack trace uses original.js instead of compiled.js): $ node compiled.js original.js:1 throw new Error('test'); // This is the original code ^ Error: test at Object.<anonymous> (original.js:1:7) at Module._compile (module.js:456:26) at Object.Module._extensions..js (module.js:474:10) at Module.load (module.js:356:32) at Function.Module._load (module.js:312:12) at Function.Module.runMain (module.js:497:10) at startup (node.js:119:16) at node.js:901:3 TypeScript Demo demo.ts: declare function require(name: string); require('source-map-support').install(); class Foo { constructor() { this.bar(); } bar() { throw new Error('this is a demo'); } } new Foo(); Compile and run the file using the TypeScript compiler from the terminal: $ npm install source-map-support typescript $ node_modules/typescript/bin/tsc -sourcemap demo.ts $ node demo.js demo.ts:5 bar() { throw new Error('this is a demo'); } ^ Error: this is a demo at Foo.bar (demo.ts:5:17) at new Foo (demo.ts:4:24) at Object.<anonymous> (demo.ts:7:1) at Module._compile (module.js:456:26) at Object.Module._extensions..js (module.js:474:10) at Module.load (module.js:356:32) at Function.Module._load (module.js:312:12) at Function.Module.runMain (module.js:497:10) at startup (node.js:119:16) at node.js:901:3 There is also the option to use -r source-map-support/register with typescript, without the need add the require('source-map-support').install() in the code base: $ npm install source-map-support typescript $ node_modules/typescript/bin/tsc -sourcemap demo.ts $ node -r source-map-support/register demo.js demo.ts:5 bar() { throw new Error('this is a demo'); } ^ Error: this is a demo at Foo.bar (demo.ts:5:17) at new Foo (demo.ts:4:24) at Object.<anonymous> (demo.ts:7:1) at Module._compile (module.js:456:26) at Object.Module._extensions..js (module.js:474:10) at Module.load (module.js:356:32) at Function.Module._load (module.js:312:12) at Function.Module.runMain (module.js:497:10) at startup (node.js:119:16) at node.js:901:3 CoffeeScript Demo demo.coffee: require('source-map-support').install() foo = -> bar = -> throw new Error 'this is a demo' bar() foo() Compile and run the file using the CoffeeScript compiler from the terminal: $ npm install source-map-support coffeescript $ node_modules/.bin/coffee --map --compile demo.coffee $ node demo.js demo.coffee:3 bar = -> throw new Error 'this is a demo' ^ Error: this is a demo at bar (demo.coffee:3:22) at foo (demo.coffee:4:3) at Object.<anonymous> (demo.coffee:5:1) at Object.<anonymous> (demo.coffee:1:1) at Module._compile (module.js:456:26) at Object.Module._extensions..js (module.js:474:10) at Module.load (module.js:356:32) at Function.Module._load (module.js:312:12) at Function.Module.runMain (module.js:497:10) at startup (node.js:119:16) Tests This repo contains both automated tests for node and manual tests for the browser. The automated tests can be run using mocha (type mocha in the root directory). To run the manual tests: Build the tests using build.js Launch the HTTP server (npm run serve-tests) and visit http://127.0.0.1:1336/amd-test http://127.0.0.1:1336/browser-test http://127.0.0.1:1336/browserify-test - Currently not working due to a bug with browserify (see pull request #66 for details). For header-test, run server.js inside that directory and visit http://127.0.0.1:1337/ License This code is available under the MIT license."
  },
  "src/frontend/app-client/node_modules/source-map/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/source-map/CHANGELOG.html",
    "title": "Change Log",
    "summary": "Change Log 0.5.6 Fix for regression when people were using numbers as names in source maps. See #236. 0.5.5 Fix \"regression\" of unsupported, implementation behavior that half the world happens to have come to depend on. See #235. Fix regression involving function hoisting in SpiderMonkey. See #233. 0.5.4 Large performance improvements to source-map serialization. See #228 and #229. 0.5.3 Do not include unnecessary distribution files. See commit ef7006f8d1647e0a83fdc60f04f5a7ca54886f86. 0.5.2 Include browser distributions of the library in package.json's files. See issue #212. 0.5.1 Fix latent bugs in IndexedSourceMapConsumer.prototype._parseMappings. See ff05274becc9e6e1295ed60f3ea090d31d843379. 0.5.0 Node 0.8 is no longer supported. Use webpack instead of dryice for bundling. Big speedups serializing source maps. See pull request #203. Fix a bug with SourceMapConsumer.prototype.sourceContentFor and sources that explicitly start with the source root. See issue #199. 0.4.4 Fix an issue where using a SourceMapGenerator after having created a SourceMapConsumer from it via SourceMapConsumer.fromSourceMap failed. See issue #191. Fix an issue with where SourceMapGenerator would mistakenly consider different mappings as duplicates of each other and avoid generating them. See issue #192. 0.4.3 A very large number of performance improvements, particularly when parsing source maps. Collectively about 75% of time shaved off of the source map parsing benchmark! Fix a bug in SourceMapConsumer.prototype.allGeneratedPositionsFor and fuzzy searching in the presence of a column option. See issue #177. Fix a bug with joining a source and its source root when the source is above the root. See issue #182. Add the SourceMapConsumer.prototype.hasContentsOfAllSources method to determine when all sources' contents are inlined into the source map. See issue #190. 0.4.2 Add an .npmignore file so that the benchmarks aren't pulled down by dependent projects. Issue #169. Add an optional column argument to SourceMapConsumer.prototype.allGeneratedPositionsFor and better handle lines with no mappings. Issues #172 and #173. 0.4.1 Fix accidentally defining a global variable. #170. 0.4.0 The default direction for fuzzy searching was changed back to its original direction. See #164. There is now a bias option you can supply to SourceMapConsumer to control the fuzzy searching direction. See #167. About an 8% speed up in parsing source maps. See #159. Added a benchmark for parsing and generating source maps. 0.3.0 Change the default direction that searching for positions fuzzes when there is not an exact match. See #154. Support for environments using json2.js for JSON serialization. See #156. 0.2.0 Support for consuming \"indexed\" source maps which do not have any remote sections. See pull request #127. This introduces a minor backwards incompatibility if you are monkey patching SourceMapConsumer.prototype methods. 0.1.43 Performance improvements for SourceMapGenerator and SourceNode. See issue #148 for some discussion and issues #150, #151, and #152 for implementations. 0.1.42 Fix an issue where SourceNodes from different versions of the source-map library couldn't be used in conjunction with each other. See issue #142. 0.1.41 Fix a bug with getting the source content of relative sources with a \"./\" prefix. See issue #145 and Bug 1090768. Add the SourceMapConsumer.prototype.computeColumnSpans method to compute the column span of each mapping. Add the SourceMapConsumer.prototype.allGeneratedPositionsFor method to find all generated positions associated with a given original source and line. 0.1.40 Performance improvements for parsing source maps in SourceMapConsumer. 0.1.39 Fix a bug where setting a source's contents to null before any source content had been set before threw a TypeError. See issue #131. 0.1.38 Fix a bug where finding relative paths from an empty path were creating absolute paths. See issue #129. 0.1.37 Fix a bug where if the source root was an empty string, relative source paths would turn into absolute source paths. Issue #124. 0.1.36 Allow the names mapping property to be an empty string. Issue #121. 0.1.35 A third optional parameter was added to SourceNode.fromStringWithSourceMap to specify a path that relative sources in the second parameter should be relative to. Issue #105. If no file property is given to a SourceMapGenerator, then the resulting source map will no longer have a null file property. The property will simply not exist. Issue #104. Fixed a bug where consecutive newlines were ignored in SourceNodes. Issue #116. 0.1.34 Make SourceNode work with windows style (\"\\r\\n\") newlines. Issue #103. Fix bug involving source contents and the SourceMapGenerator.prototype.applySourceMap. Issue #100. 0.1.33 Fix some edge cases surrounding path joining and URL resolution. Add a third parameter for relative path to SourceMapGenerator.prototype.applySourceMap. Fix issues with mappings and EOLs. 0.1.32 Fixed a bug where SourceMapConsumer couldn't handle negative relative columns (issue 92). Fixed test runner to actually report number of failed tests as its process exit code. Fixed a typo when reporting bad mappings (issue 87). 0.1.31 Delay parsing the mappings in SourceMapConsumer until queried for a source location. Support Sass source maps (which at the time of writing deviate from the spec in small ways) in SourceMapConsumer. 0.1.30 Do not join source root with a source, when the source is a data URI. Extend the test runner to allow running single specific test files at a time. Performance improvements in SourceNode.prototype.walk and SourceMapConsumer.prototype.eachMapping. Source map browser builds will now work inside Workers. Better error messages when attempting to add an invalid mapping to a SourceMapGenerator. 0.1.29 Allow duplicate entries in the names and sources arrays of source maps (usually from TypeScript) we are parsing. Fixes github issue 72. 0.1.28 Skip duplicate mappings when creating source maps from SourceNode; github issue 75. 0.1.27 Don't throw an error when the file property is missing in SourceMapConsumer, we don't use it anyway. 0.1.26 Fix SourceNode.fromStringWithSourceMap for empty maps. Fixes github issue 70. 0.1.25 Make compatible with browserify 0.1.24 Fix issue with absolute paths and file:// URIs. See https://bugzilla.mozilla.org/show_bug.cgi?id=885597 0.1.23 Fix issue with absolute paths and sourcesContent, github issue 64. 0.1.22 Ignore duplicate mappings in SourceMapGenerator. Fixes github issue 21. 0.1.21 Fixed handling of sources that start with a slash so that they are relative to the source root's host. 0.1.20 Fixed github issue #43: absolute URLs aren't joined with the source root anymore. 0.1.19 Using Travis CI to run tests. 0.1.18 Fixed a bug in the handling of sourceRoot. 0.1.17 Added SourceNode.fromStringWithSourceMap. 0.1.16 Added missing documentation. Fixed the generating of empty mappings in SourceNode. 0.1.15 Added SourceMapGenerator.applySourceMap. 0.1.14 The sourceRoot is now handled consistently. 0.1.13 Added SourceMapGenerator.fromSourceMap. 0.1.12 SourceNode now generates empty mappings too. 0.1.11 Added name support to SourceNode. 0.1.10 Added sourcesContent support to the customer and generator."
  },
  "src/frontend/app-client/node_modules/source-map/README.html": {
    "href": "src/frontend/app-client/node_modules/source-map/README.html",
    "title": "Source Map",
    "summary": "Source Map This is a library to generate and consume the source map format described here. Use with Node $ npm install source-map Use on the Web <script src=\"https://raw.githubusercontent.com/mozilla/source-map/master/dist/source-map.min.js\" defer></script> Table of Contents Examples Consuming a source map Generating a source map With SourceNode (high level API) With SourceMapGenerator (low level API) API SourceMapConsumer new SourceMapConsumer(rawSourceMap) SourceMapConsumer.prototype.computeColumnSpans() SourceMapConsumer.prototype.originalPositionFor(generatedPosition) SourceMapConsumer.prototype.generatedPositionFor(originalPosition) SourceMapConsumer.prototype.allGeneratedPositionsFor(originalPosition) SourceMapConsumer.prototype.hasContentsOfAllSources() SourceMapConsumer.prototype.sourceContentFor(source[, returnNullOnMissing]) SourceMapConsumer.prototype.eachMapping(callback, context, order) SourceMapGenerator new SourceMapGenerator([startOfSourceMap]) SourceMapGenerator.fromSourceMap(sourceMapConsumer) SourceMapGenerator.prototype.addMapping(mapping) SourceMapGenerator.prototype.setSourceContent(sourceFile, sourceContent) SourceMapGenerator.prototype.applySourceMap(sourceMapConsumer[, sourceFile[, sourceMapPath]]) SourceMapGenerator.prototype.toString() SourceNode new SourceNode([line, column, source[, chunk[, name]]]) SourceNode.fromStringWithSourceMap(code, sourceMapConsumer[, relativePath]) SourceNode.prototype.add(chunk) SourceNode.prototype.prepend(chunk) SourceNode.prototype.setSourceContent(sourceFile, sourceContent) SourceNode.prototype.walk(fn) SourceNode.prototype.walkSourceContents(fn) SourceNode.prototype.join(sep) SourceNode.prototype.replaceRight(pattern, replacement) SourceNode.prototype.toString() SourceNode.prototype.toStringWithSourceMap([startOfSourceMap]) Examples Consuming a source map var rawSourceMap = { version: 3, file: 'min.js', names: ['bar', 'baz', 'n'], sources: ['one.js', 'two.js'], sourceRoot: 'http://example.com/www/js/', mappings: 'CAAC,IAAI,IAAM,SAAUA,GAClB,OAAOC,IAAID;CCDb,IAAI,IAAM,SAAUE,GAClB,OAAOA' }; var smc = new SourceMapConsumer(rawSourceMap); console.log(smc.sources); // [ 'http://example.com/www/js/one.js', // 'http://example.com/www/js/two.js' ] console.log(smc.originalPositionFor({ line: 2, column: 28 })); // { source: 'http://example.com/www/js/two.js', // line: 2, // column: 10, // name: 'n' } console.log(smc.generatedPositionFor({ source: 'http://example.com/www/js/two.js', line: 2, column: 10 })); // { line: 2, column: 28 } smc.eachMapping(function (m) { // ... }); Generating a source map In depth guide: Compiling to JavaScript, and Debugging with Source Maps With SourceNode (high level API) function compile(ast) { switch (ast.type) { case 'BinaryExpression': return new SourceNode( ast.location.line, ast.location.column, ast.location.source, [compile(ast.left), \" + \", compile(ast.right)] ); case 'Literal': return new SourceNode( ast.location.line, ast.location.column, ast.location.source, String(ast.value) ); // ... default: throw new Error(\"Bad AST\"); } } var ast = parse(\"40 + 2\", \"add.js\"); console.log(compile(ast).toStringWithSourceMap({ file: 'add.js' })); // { code: '40 + 2', // map: [object SourceMapGenerator] } With SourceMapGenerator (low level API) var map = new SourceMapGenerator({ file: \"source-mapped.js\" }); map.addMapping({ generated: { line: 10, column: 35 }, source: \"foo.js\", original: { line: 33, column: 2 }, name: \"christopher\" }); console.log(map.toString()); // '{\"version\":3,\"file\":\"source-mapped.js\",\"sources\":[\"foo.js\"],\"names\":[\"christopher\"],\"mappings\":\";;;;;;;;;mCAgCEA\"}' API Get a reference to the module: // Node.js var sourceMap = require('source-map'); // Browser builds var sourceMap = window.sourceMap; // Inside Firefox const sourceMap = require(\"devtools/toolkit/sourcemap/source-map.js\"); SourceMapConsumer A SourceMapConsumer instance represents a parsed source map which we can query for information about the original file positions by giving it a file position in the generated source. new SourceMapConsumer(rawSourceMap) The only parameter is the raw source map (either as a string which can be JSON.parse'd, or an object). According to the spec, source maps have the following attributes: version: Which version of the source map spec this map is following. sources: An array of URLs to the original source files. names: An array of identifiers which can be referenced by individual mappings. sourceRoot: Optional. The URL root from which all sources are relative. sourcesContent: Optional. An array of contents of the original source files. mappings: A string of base64 VLQs which contain the actual mappings. file: Optional. The generated filename this source map is associated with. var consumer = new sourceMap.SourceMapConsumer(rawSourceMapJsonData); SourceMapConsumer.prototype.computeColumnSpans() Compute the last column for each generated mapping. The last column is inclusive. // Before: consumer.allGeneratedPositionsFor({ line: 2, source: \"foo.coffee\" }) // [ { line: 2, // column: 1 }, // { line: 2, // column: 10 }, // { line: 2, // column: 20 } ] consumer.computeColumnSpans(); // After: consumer.allGeneratedPositionsFor({ line: 2, source: \"foo.coffee\" }) // [ { line: 2, // column: 1, // lastColumn: 9 }, // { line: 2, // column: 10, // lastColumn: 19 }, // { line: 2, // column: 20, // lastColumn: Infinity } ] SourceMapConsumer.prototype.originalPositionFor(generatedPosition) Returns the original source, line, and column information for the generated source's line and column positions provided. The only argument is an object with the following properties: line: The line number in the generated source. column: The column number in the generated source. bias: Either SourceMapConsumer.GREATEST_LOWER_BOUND or SourceMapConsumer.LEAST_UPPER_BOUND. Specifies whether to return the closest element that is smaller than or greater than the one we are searching for, respectively, if the exact element cannot be found. Defaults to SourceMapConsumer.GREATEST_LOWER_BOUND. and an object is returned with the following properties: source: The original source file, or null if this information is not available. line: The line number in the original source, or null if this information is not available. column: The column number in the original source, or null if this information is not available. name: The original identifier, or null if this information is not available. consumer.originalPositionFor({ line: 2, column: 10 }) // { source: 'foo.coffee', // line: 2, // column: 2, // name: null } consumer.originalPositionFor({ line: 99999999999999999, column: 999999999999999 }) // { source: null, // line: null, // column: null, // name: null } SourceMapConsumer.prototype.generatedPositionFor(originalPosition) Returns the generated line and column information for the original source, line, and column positions provided. The only argument is an object with the following properties: source: The filename of the original source. line: The line number in the original source. column: The column number in the original source. and an object is returned with the following properties: line: The line number in the generated source, or null. column: The column number in the generated source, or null. consumer.generatedPositionFor({ source: \"example.js\", line: 2, column: 10 }) // { line: 1, // column: 56 } SourceMapConsumer.prototype.allGeneratedPositionsFor(originalPosition) Returns all generated line and column information for the original source, line, and column provided. If no column is provided, returns all mappings corresponding to a either the line we are searching for or the next closest line that has any mappings. Otherwise, returns all mappings corresponding to the given line and either the column we are searching for or the next closest column that has any offsets. The only argument is an object with the following properties: source: The filename of the original source. line: The line number in the original source. column: Optional. The column number in the original source. and an array of objects is returned, each with the following properties: line: The line number in the generated source, or null. column: The column number in the generated source, or null. consumer.allGeneratedpositionsfor({ line: 2, source: \"foo.coffee\" }) // [ { line: 2, // column: 1 }, // { line: 2, // column: 10 }, // { line: 2, // column: 20 } ] SourceMapConsumer.prototype.hasContentsOfAllSources() Return true if we have the embedded source content for every source listed in the source map, false otherwise. In other words, if this method returns true, then consumer.sourceContentFor(s) will succeed for every source s in consumer.sources. // ... if (consumer.hasContentsOfAllSources()) { consumerReadyCallback(consumer); } else { fetchSources(consumer, consumerReadyCallback); } // ... SourceMapConsumer.prototype.sourceContentFor(source[, returnNullOnMissing]) Returns the original source content for the source provided. The only argument is the URL of the original source file. If the source content for the given source is not found, then an error is thrown. Optionally, pass true as the second param to have null returned instead. consumer.sources // [ \"my-cool-lib.clj\" ] consumer.sourceContentFor(\"my-cool-lib.clj\") // \"...\" consumer.sourceContentFor(\"this is not in the source map\"); // Error: \"this is not in the source map\" is not in the source map consumer.sourceContentFor(\"this is not in the source map\", true); // null SourceMapConsumer.prototype.eachMapping(callback, context, order) Iterate over each mapping between an original source/line/column and a generated line/column in this source map. callback: The function that is called with each mapping. Mappings have the form { source, generatedLine, generatedColumn, originalLine, originalColumn, name } context: Optional. If specified, this object will be the value of this every time that callback is called. order: Either SourceMapConsumer.GENERATED_ORDER or SourceMapConsumer.ORIGINAL_ORDER. Specifies whether you want to iterate over the mappings sorted by the generated file's line/column order or the original's source/line/column order, respectively. Defaults to SourceMapConsumer.GENERATED_ORDER. consumer.eachMapping(function (m) { console.log(m); }) // ... // { source: 'illmatic.js', // generatedLine: 1, // generatedColumn: 0, // originalLine: 1, // originalColumn: 0, // name: null } // { source: 'illmatic.js', // generatedLine: 2, // generatedColumn: 0, // originalLine: 2, // originalColumn: 0, // name: null } // ... SourceMapGenerator An instance of the SourceMapGenerator represents a source map which is being built incrementally. new SourceMapGenerator([startOfSourceMap]) You may pass an object with the following properties: file: The filename of the generated source that this source map is associated with. sourceRoot: A root for all relative URLs in this source map. skipValidation: Optional. When true, disables validation of mappings as they are added. This can improve performance but should be used with discretion, as a last resort. Even then, one should avoid using this flag when running tests, if possible. var generator = new sourceMap.SourceMapGenerator({ file: \"my-generated-javascript-file.js\", sourceRoot: \"http://example.com/app/js/\" }); SourceMapGenerator.fromSourceMap(sourceMapConsumer) Creates a new SourceMapGenerator from an existing SourceMapConsumer instance. sourceMapConsumer The SourceMap. var generator = sourceMap.SourceMapGenerator.fromSourceMap(consumer); SourceMapGenerator.prototype.addMapping(mapping) Add a single mapping from original source line and column to the generated source's line and column for this source map being created. The mapping object should have the following properties: generated: An object with the generated line and column positions. original: An object with the original line and column positions. source: The original source file (relative to the sourceRoot). name: An optional original token name for this mapping. generator.addMapping({ source: \"module-one.scm\", original: { line: 128, column: 0 }, generated: { line: 3, column: 456 } }) SourceMapGenerator.prototype.setSourceContent(sourceFile, sourceContent) Set the source content for an original source file. sourceFile the URL of the original source file. sourceContent the content of the source file. generator.setSourceContent(\"module-one.scm\", fs.readFileSync(\"path/to/module-one.scm\")) SourceMapGenerator.prototype.applySourceMap(sourceMapConsumer[, sourceFile[, sourceMapPath]]) Applies a SourceMap for a source file to the SourceMap. Each mapping to the supplied source file is rewritten using the supplied SourceMap. Note: The resolution for the resulting mappings is the minimum of this map and the supplied map. sourceMapConsumer: The SourceMap to be applied. sourceFile: Optional. The filename of the source file. If omitted, sourceMapConsumer.file will be used, if it exists. Otherwise an error will be thrown. sourceMapPath: Optional. The dirname of the path to the SourceMap to be applied. If relative, it is relative to the SourceMap. This parameter is needed when the two SourceMaps aren't in the same directory, and the SourceMap to be applied contains relative source paths. If so, those relative source paths need to be rewritten relative to the SourceMap. If omitted, it is assumed that both SourceMaps are in the same directory, thus not needing any rewriting. (Supplying '.' has the same effect.) SourceMapGenerator.prototype.toString() Renders the source map being generated to a string. generator.toString() // '{\"version\":3,\"sources\":[\"module-one.scm\"],\"names\":[],\"mappings\":\"...snip...\",\"file\":\"my-generated-javascript-file.js\",\"sourceRoot\":\"http://example.com/app/js/\"}' SourceNode SourceNodes provide a way to abstract over interpolating and/or concatenating snippets of generated JavaScript source code, while maintaining the line and column information associated between those snippets and the original source code. This is useful as the final intermediate representation a compiler might use before outputting the generated JS and source map. new SourceNode([line, column, source[, chunk[, name]]]) line: The original line number associated with this source node, or null if it isn't associated with an original line. column: The original column number associated with this source node, or null if it isn't associated with an original column. source: The original source's filename; null if no filename is provided. chunk: Optional. Is immediately passed to SourceNode.prototype.add, see below. name: Optional. The original identifier. var node = new SourceNode(1, 2, \"a.cpp\", [ new SourceNode(3, 4, \"b.cpp\", \"extern int status;\\n\"), new SourceNode(5, 6, \"c.cpp\", \"std::string* make_string(size_t n);\\n\"), new SourceNode(7, 8, \"d.cpp\", \"int main(int argc, char** argv) {}\\n\"), ]); SourceNode.fromStringWithSourceMap(code, sourceMapConsumer[, relativePath]) Creates a SourceNode from generated code and a SourceMapConsumer. code: The generated code sourceMapConsumer The SourceMap for the generated code relativePath The optional path that relative sources in sourceMapConsumer should be relative to. var consumer = new SourceMapConsumer(fs.readFileSync(\"path/to/my-file.js.map\", \"utf8\")); var node = SourceNode.fromStringWithSourceMap(fs.readFileSync(\"path/to/my-file.js\"), consumer); SourceNode.prototype.add(chunk) Add a chunk of generated JS to this source node. chunk: A string snippet of generated JS code, another instance of SourceNode, or an array where each member is one of those things. node.add(\" + \"); node.add(otherNode); node.add([leftHandOperandNode, \" + \", rightHandOperandNode]); SourceNode.prototype.prepend(chunk) Prepend a chunk of generated JS to this source node. chunk: A string snippet of generated JS code, another instance of SourceNode, or an array where each member is one of those things. node.prepend(\"/** Build Id: f783haef86324gf **/\\n\\n\"); SourceNode.prototype.setSourceContent(sourceFile, sourceContent) Set the source content for a source file. This will be added to the SourceMap in the sourcesContent field. sourceFile: The filename of the source file sourceContent: The content of the source file node.setSourceContent(\"module-one.scm\", fs.readFileSync(\"path/to/module-one.scm\")) SourceNode.prototype.walk(fn) Walk over the tree of JS snippets in this node and its children. The walking function is called once for each snippet of JS and is passed that snippet and the its original associated source's line/column location. fn: The traversal function. var node = new SourceNode(1, 2, \"a.js\", [ new SourceNode(3, 4, \"b.js\", \"uno\"), \"dos\", [ \"tres\", new SourceNode(5, 6, \"c.js\", \"quatro\") ] ]); node.walk(function (code, loc) { console.log(\"WALK:\", code, loc); }) // WALK: uno { source: 'b.js', line: 3, column: 4, name: null } // WALK: dos { source: 'a.js', line: 1, column: 2, name: null } // WALK: tres { source: 'a.js', line: 1, column: 2, name: null } // WALK: quatro { source: 'c.js', line: 5, column: 6, name: null } SourceNode.prototype.walkSourceContents(fn) Walk over the tree of SourceNodes. The walking function is called for each source file content and is passed the filename and source content. fn: The traversal function. var a = new SourceNode(1, 2, \"a.js\", \"generated from a\"); a.setSourceContent(\"a.js\", \"original a\"); var b = new SourceNode(1, 2, \"b.js\", \"generated from b\"); b.setSourceContent(\"b.js\", \"original b\"); var c = new SourceNode(1, 2, \"c.js\", \"generated from c\"); c.setSourceContent(\"c.js\", \"original c\"); var node = new SourceNode(null, null, null, [a, b, c]); node.walkSourceContents(function (source, contents) { console.log(\"WALK:\", source, \":\", contents); }) // WALK: a.js : original a // WALK: b.js : original b // WALK: c.js : original c SourceNode.prototype.join(sep) Like Array.prototype.join except for SourceNodes. Inserts the separator between each of this source node's children. sep: The separator. var lhs = new SourceNode(1, 2, \"a.rs\", \"my_copy\"); var operand = new SourceNode(3, 4, \"a.rs\", \"=\"); var rhs = new SourceNode(5, 6, \"a.rs\", \"orig.clone()\"); var node = new SourceNode(null, null, null, [ lhs, operand, rhs ]); var joinedNode = node.join(\" \"); SourceNode.prototype.replaceRight(pattern, replacement) Call String.prototype.replace on the very right-most source snippet. Useful for trimming white space from the end of a source node, etc. pattern: The pattern to replace. replacement: The thing to replace the pattern with. // Trim trailing white space. node.replaceRight(/\\s*$/, \"\"); SourceNode.prototype.toString() Return the string representation of this source node. Walks over the tree and concatenates all the various snippets together to one string. var node = new SourceNode(1, 2, \"a.js\", [ new SourceNode(3, 4, \"b.js\", \"uno\"), \"dos\", [ \"tres\", new SourceNode(5, 6, \"c.js\", \"quatro\") ] ]); node.toString() // 'unodostresquatro' SourceNode.prototype.toStringWithSourceMap([startOfSourceMap]) Returns the string representation of this tree of source nodes, plus a SourceMapGenerator which contains all the mappings between the generated and original sources. The arguments are the same as those to new SourceMapGenerator. var node = new SourceNode(1, 2, \"a.js\", [ new SourceNode(3, 4, \"b.js\", \"uno\"), \"dos\", [ \"tres\", new SourceNode(5, 6, \"c.js\", \"quatro\") ] ]); node.toStringWithSourceMap({ file: \"my-output-file.js\" }) // { code: 'unodostresquatro', // map: [object SourceMapGenerator] }"
  },
  "src/frontend/app-client/node_modules/spdx-correct/README.html": {
    "href": "src/frontend/app-client/node_modules/spdx-correct/README.html",
    "title": "",
    "summary": "Usage var correct = require('spdx-correct') var assert = require('assert') assert.strictEqual(correct('mit'), 'MIT') assert.strictEqual(correct('Apache 2'), 'Apache-2.0') assert(correct('No idea what license') === null) // disable upgrade option assert(correct('GPL-3.0'), 'GPL-3.0-or-later') assert(correct('GPL-3.0', { upgrade: false }), 'GPL-3.0') Contributors spdx-correct has benefited from the work of several contributors. See the GitHub repository for more information."
  },
  "src/frontend/app-client/node_modules/spdx-exceptions/README.html": {
    "href": "src/frontend/app-client/node_modules/spdx-exceptions/README.html",
    "title": "",
    "summary": "The package exports an array of strings. Each string is an identifier for a license exception under the Software Package Data Exchange (SPDX) software license metadata standard. Copyright and Licensing SPDX \"SPDX\" is a federally registered United States trademark of The Linux Foundation Corporation. From version 2.0 of the SPDX specification: Copyright © 2010-2015 Linux Foundation and its Contributors. Licensed under the Creative Commons Attribution License 3.0 Unported. All other rights are expressly reserved. The Linux Foundation and the SPDX working groups are good people. Only they decide what \"SPDX\" means, as a standard and otherwise. I respect their work and their rights. You should, too. This Package I created this package by copying exception identifiers out of the SPDX specification. That work was mechanical, routine, and required no creativity whatsoever. - Kyle Mitchell, package author United States users concerned about intellectual property may wish to discuss the following Supreme Court decisions with their attorneys: Baker v. Selden, 101 U.S. 99 (1879) Feist Publications, Inc., v. Rural Telephone Service Co., 499 U.S. 340 (1991)"
  },
  "src/frontend/app-client/node_modules/spdx-expression-parse/README.html": {
    "href": "src/frontend/app-client/node_modules/spdx-expression-parse/README.html",
    "title": "",
    "summary": "This package parses SPDX license expression strings describing license terms, like package.json license strings, into consistently structured ECMAScript objects. The npm command-line interface depends on this package, as do many automatic license-audit tools. In a nutshell: var parse = require('spdx-expression-parse') var assert = require('assert') assert.deepEqual( // Licensed under the terms of the Two-Clause BSD License. parse('BSD-2-Clause'), {license: 'BSD-2-Clause'} ) assert.throws(function () { // An invalid SPDX license expression. // Should be `Apache-2.0`. parse('Apache 2') }) assert.deepEqual( // Dual licensed under either: // - LGPL 2.1 // - a combination of Three-Clause BSD and MIT parse('(LGPL-2.1 OR BSD-3-Clause AND MIT)'), { left: {license: 'LGPL-2.1'}, conjunction: 'or', right: { left: {license: 'BSD-3-Clause'}, conjunction: 'and', right: {license: 'MIT'} } } ) The syntax comes from the Software Package Data eXchange (SPDX), a standard from the Linux Foundation for shareable data about software package license terms. SPDX aims to make sharing and auditing license data easy, especially for users of open-source software. The bulk of the SPDX standard describes syntax and semantics of XML metadata files. This package implements two lightweight, plain-text components of that larger standard: The license list, a mapping from specific string identifiers, like Apache-2.0, to standard form license texts and bolt-on license exceptions. The spdx-license-ids and spdx-exceptions packages implement the license list. spdx-expression-parse depends on and require()s them. Any license identifier from the license list is a valid license expression: var identifiers = [] .concat(require('spdx-license-ids')) .concat(require('spdx-license-ids/deprecated')) identifiers.forEach(function (id) { assert.deepEqual(parse(id), {license: id}) }) So is any license identifier WITH a standardized license exception: identifiers.forEach(function (id) { require('spdx-exceptions').forEach(function (e) { assert.deepEqual( parse(id + ' WITH ' + e), {license: id, exception: e} ) }) }) The license expression language, for describing simple and complex license terms, like MIT for MIT-licensed and (GPL-2.0 OR Apache-2.0) for dual-licensing under GPL 2.0 and Apache 2.0. spdx-expression-parse itself implements license expression language, exporting a parser. assert.deepEqual( // Licensed under a combination of: // - the MIT License AND // - a combination of: // - LGPL 2.1 (or a later version) AND // - Three-Clause BSD parse('(MIT AND (LGPL-2.1+ AND BSD-3-Clause))'), { left: {license: 'MIT'}, conjunction: 'and', right: { left: {license: 'LGPL-2.1', plus: true}, conjunction: 'and', right: {license: 'BSD-3-Clause'} } } ) The Linux Foundation and its contributors license the SPDX standard under the terms of the Creative Commons Attribution License 3.0 Unported (SPDX: \"CC-BY-3.0\"). \"SPDX\" is a United States federally registered trademark of the Linux Foundation. The authors of this package license their work under the terms of the MIT License."
  },
  "src/frontend/app-client/node_modules/spdx-license-ids/README.html": {
    "href": "src/frontend/app-client/node_modules/spdx-license-ids/README.html",
    "title": "spdx-license-ids",
    "summary": "spdx-license-ids A list of SPDX license identifiers Installation Download JSON directly, or use npm: npm install spdx-license-ids Node.js API require('spdx-license-ids') Type: string[] All license IDs except for the currently deprecated ones. const ids = require('spdx-license-ids'); //=> ['0BSD', 'AAL', 'ADSL', 'AFL-1.1', 'AFL-1.2', 'AFL-2.0', 'AFL-2.1', 'AFL-3.0', 'AGPL-1.0-only', ...] ids.includes('BSD-3-Clause'); //=> true ids.includes('CC-BY-1.0'); //=> true ids.includes('GPL-3.0'); //=> false require('spdx-license-ids/deprecated') Type: string[] Deprecated license IDs. const deprecatedIds = require('spdx-license-ids/deprecated'); //=> ['AGPL-1.0', 'AGPL-3.0', 'GFDL-1.1', 'GFDL-1.2', 'GFDL-1.3', 'GPL-1.0', 'GPL-2.0', ...] deprecatedIds.includes('BSD-3-Clause'); //=> false deprecatedIds.includes('CC-BY-1.0'); //=> false deprecatedIds.includes('GPL-3.0'); //=> true License Creative Commons Zero v1.0 Universal"
  },
  "src/frontend/app-client/node_modules/statuses/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/statuses/HISTORY.html",
    "title": "2.0.1 / 2021-01-03",
    "summary": "2.0.1 / 2021-01-03 Fix returning values from Object.prototype 2.0.0 / 2020-04-19 Drop support for Node.js 0.6 Fix messaging casing of 418 I'm a Teapot Remove code 306 Remove status[code] exports; use status.message[code] Remove status[msg] exports; use status.code[msg] Rename 425 Unordered Collection to standard 425 Too Early Rename STATUS_CODES export to message Return status message for statuses(code) when given code 1.5.0 / 2018-03-27 Add 103 Early Hints 1.4.0 / 2017-10-20 Add STATUS_CODES export 1.3.1 / 2016-11-11 Fix return type in JSDoc 1.3.0 / 2016-05-17 Add 421 Misdirected Request perf: enable strict mode 1.2.1 / 2015-02-01 Fix message for status 451 451 Unavailable For Legal Reasons 1.2.0 / 2014-09-28 Add 208 Already Repored Add 226 IM Used Add 306 (Unused) Add 415 Unable For Legal Reasons Add 508 Loop Detected 1.1.1 / 2014-09-24 Add missing 308 to codes.json 1.1.0 / 2014-09-21 Add codes.json for universal support 1.0.4 / 2014-08-20 Package cleanup 1.0.3 / 2014-06-08 Add 308 to .redirect category 1.0.2 / 2014-03-13 Add .retry category 1.0.1 / 2014-03-12 Initial release"
  },
  "src/frontend/app-client/node_modules/statuses/README.html": {
    "href": "src/frontend/app-client/node_modules/statuses/README.html",
    "title": "statuses",
    "summary": "statuses HTTP status utility for node. This module provides a list of status codes and messages sourced from a few different projects: The IANA Status Code Registry The Node.js project The NGINX project The Apache HTTP Server project Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install statuses API var status = require('statuses') status(code) Returns the status message string for a known HTTP status code. The code may be a number or a string. An error is thrown for an unknown status code. status(403) // => 'Forbidden' status('403') // => 'Forbidden' status(306) // throws status(msg) Returns the numeric status code for a known HTTP status message. The message is case-insensitive. An error is thrown for an unknown status message. status('forbidden') // => 403 status('Forbidden') // => 403 status('foo') // throws status.codes Returns an array of all the status codes as Integers. status.code[msg] Returns the numeric status code for a known status message (in lower-case), otherwise undefined. status['not found'] // => 404 status.empty[code] Returns true if a status code expects an empty body. status.empty[200] // => undefined status.empty[204] // => true status.empty[304] // => true status.message[code] Returns the string message for a known numeric status code, otherwise undefined. This object is the same format as the Node.js http module http.STATUS_CODES. status.message[404] // => 'Not Found' status.redirect[code] Returns true if a status code is a valid redirect status. status.redirect[200] // => undefined status.redirect[301] // => true status.retry[code] Returns true if you should retry the rest. status.retry[501] // => undefined status.retry[503] // => true License MIT"
  },
  "src/frontend/app-client/node_modules/stream-slice/README.html": {
    "href": "src/frontend/app-client/node_modules/stream-slice/README.html",
    "title": "stream-slice",
    "summary": "stream-slice slicing stream like buffer/string Installation $ npm install stream-slice --save Usage var fs = require('fs'); var slice = require('stream-slice').slice; fs.createReadStream('your path') .pipe(slice(10, 100)) .on('data', function() { // here we only get the buffer from 10th to 100th. }); slicing file var fs = require('fs'); var slice = require('stream-slice').slice; fs.createReadStream('sourc file path') .pipe(slice(0, 200)) .pipe(fs.createWriteStream('dest file path')); License MIT"
  },
  "src/frontend/app-client/node_modules/string_decoder/node_modules/safe-buffer/README.html": {
    "href": "src/frontend/app-client/node_modules/string_decoder/node_modules/safe-buffer/README.html",
    "title": "safe-buffer",
    "summary": "safe-buffer Safer Node.js Buffer API Use the new Node.js Buffer APIs (Buffer.from, Buffer.alloc, Buffer.allocUnsafe, Buffer.allocUnsafeSlow) in all versions of Node.js. Uses the built-in implementation when available. install npm install safe-buffer usage The goal of this package is to provide a safe replacement for the node.js Buffer. It's a drop-in replacement for Buffer. You can use it by adding one require line to the top of your node.js modules: var Buffer = require('safe-buffer').Buffer // Existing buffer code will continue to work without issues: new Buffer('hey', 'utf8') new Buffer([1, 2, 3], 'utf8') new Buffer(obj) new Buffer(16) // create an uninitialized buffer (potentially unsafe) // But you can use these new explicit APIs to make clear what you want: Buffer.from('hey', 'utf8') // convert from many types to a Buffer Buffer.alloc(16) // create a zero-filled buffer (safe) Buffer.allocUnsafe(16) // create an uninitialized buffer (potentially unsafe) api Class Method: Buffer.from(array) array {Array} Allocates a new Buffer using an array of octets. const buf = Buffer.from([0x62,0x75,0x66,0x66,0x65,0x72]); // creates a new Buffer containing ASCII bytes // ['b','u','f','f','e','r'] A TypeError will be thrown if array is not an Array. Class Method: Buffer.from(arrayBuffer[, byteOffset[, length]]) arrayBuffer {ArrayBuffer} The .buffer property of a TypedArray or a new ArrayBuffer() byteOffset {Number} Default: 0 length {Number} Default: arrayBuffer.length - byteOffset When passed a reference to the .buffer property of a TypedArray instance, the newly created Buffer will share the same allocated memory as the TypedArray. const arr = new Uint16Array(2); arr[0] = 5000; arr[1] = 4000; const buf = Buffer.from(arr.buffer); // shares the memory with arr; console.log(buf); // Prints: <Buffer 88 13 a0 0f> // changing the TypedArray changes the Buffer also arr[1] = 6000; console.log(buf); // Prints: <Buffer 88 13 70 17> The optional byteOffset and length arguments specify a memory range within the arrayBuffer that will be shared by the Buffer. const ab = new ArrayBuffer(10); const buf = Buffer.from(ab, 0, 2); console.log(buf.length); // Prints: 2 A TypeError will be thrown if arrayBuffer is not an ArrayBuffer. Class Method: Buffer.from(buffer) buffer {Buffer} Copies the passed buffer data onto a new Buffer instance. const buf1 = Buffer.from('buffer'); const buf2 = Buffer.from(buf1); buf1[0] = 0x61; console.log(buf1.toString()); // 'auffer' console.log(buf2.toString()); // 'buffer' (copy is not changed) A TypeError will be thrown if buffer is not a Buffer. Class Method: Buffer.from(str[, encoding]) str {String} String to encode. encoding {String} Encoding to use, Default: 'utf8' Creates a new Buffer containing the given JavaScript string str. If provided, the encoding parameter identifies the character encoding. If not provided, encoding defaults to 'utf8'. const buf1 = Buffer.from('this is a tést'); console.log(buf1.toString()); // prints: this is a tést console.log(buf1.toString('ascii')); // prints: this is a tC)st const buf2 = Buffer.from('7468697320697320612074c3a97374', 'hex'); console.log(buf2.toString()); // prints: this is a tést A TypeError will be thrown if str is not a string. Class Method: Buffer.alloc(size[, fill[, encoding]]) size {Number} fill {Value} Default: undefined encoding {String} Default: utf8 Allocates a new Buffer of size bytes. If fill is undefined, the Buffer will be zero-filled. const buf = Buffer.alloc(5); console.log(buf); // <Buffer 00 00 00 00 00> The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. If fill is specified, the allocated Buffer will be initialized by calling buf.fill(fill). See [buf.fill()][] for more information. const buf = Buffer.alloc(5, 'a'); console.log(buf); // <Buffer 61 61 61 61 61> If both fill and encoding are specified, the allocated Buffer will be initialized by calling buf.fill(fill, encoding). For example: const buf = Buffer.alloc(11, 'aGVsbG8gd29ybGQ=', 'base64'); console.log(buf); // <Buffer 68 65 6c 6c 6f 20 77 6f 72 6c 64> Calling Buffer.alloc(size) can be significantly slower than the alternative Buffer.allocUnsafe(size) but ensures that the newly created Buffer instance contents will never contain sensitive data. A TypeError will be thrown if size is not a number. Class Method: Buffer.allocUnsafe(size) size {Number} Allocates a new non-zero-filled Buffer of size bytes. The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. The underlying memory for Buffer instances created in this way is not initialized. The contents of the newly created Buffer are unknown and may contain sensitive data. Use [buf.fill(0)][] to initialize such Buffer instances to zeroes. const buf = Buffer.allocUnsafe(5); console.log(buf); // <Buffer 78 e0 82 02 01> // (octets will be different, every time) buf.fill(0); console.log(buf); // <Buffer 00 00 00 00 00> A TypeError will be thrown if size is not a number. Note that the Buffer module pre-allocates an internal Buffer instance of size Buffer.poolSize that is used as a pool for the fast allocation of new Buffer instances created using Buffer.allocUnsafe(size) (and the deprecated new Buffer(size) constructor) only when size is less than or equal to Buffer.poolSize >> 1 (floor of Buffer.poolSize divided by two). The default value of Buffer.poolSize is 8192 but can be modified. Use of this pre-allocated internal memory pool is a key difference between calling Buffer.alloc(size, fill) vs. Buffer.allocUnsafe(size).fill(fill). Specifically, Buffer.alloc(size, fill) will never use the internal Buffer pool, while Buffer.allocUnsafe(size).fill(fill) will use the internal Buffer pool if size is less than or equal to half Buffer.poolSize. The difference is subtle but can be important when an application requires the additional performance that Buffer.allocUnsafe(size) provides. Class Method: Buffer.allocUnsafeSlow(size) size {Number} Allocates a new non-zero-filled and non-pooled Buffer of size bytes. The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. The underlying memory for Buffer instances created in this way is not initialized. The contents of the newly created Buffer are unknown and may contain sensitive data. Use [buf.fill(0)][] to initialize such Buffer instances to zeroes. When using Buffer.allocUnsafe() to allocate new Buffer instances, allocations under 4KB are, by default, sliced from a single pre-allocated Buffer. This allows applications to avoid the garbage collection overhead of creating many individually allocated Buffers. This approach improves both performance and memory usage by eliminating the need to track and cleanup as many Persistent objects. However, in the case where a developer may need to retain a small chunk of memory from a pool for an indeterminate amount of time, it may be appropriate to create an un-pooled Buffer instance using Buffer.allocUnsafeSlow() then copy out the relevant bits. // need to keep around a few small chunks of memory const store = []; socket.on('readable', () => { const data = socket.read(); // allocate for retained data const sb = Buffer.allocUnsafeSlow(10); // copy the data into the new allocation data.copy(sb, 0, 0, 10); store.push(sb); }); Use of Buffer.allocUnsafeSlow() should be used only as a last resort after a developer has observed undue memory retention in their applications. A TypeError will be thrown if size is not a number. All the Rest The rest of the Buffer API is exactly the same as in node.js. See the docs. Related links Node.js issue: Buffer(number) is unsafe Node.js Enhancement Proposal: Buffer.from/Buffer.alloc/Buffer.zalloc/Buffer() soft-deprecate Why is Buffer unsafe? Today, the node.js Buffer constructor is overloaded to handle many different argument types like String, Array, Object, TypedArrayView (Uint8Array, etc.), ArrayBuffer, and also Number. The API is optimized for convenience: you can throw any type at it, and it will try to do what you want. Because the Buffer constructor is so powerful, you often see code like this: // Convert UTF-8 strings to hex function toHex (str) { return new Buffer(str).toString('hex') } But what happens if toHex is called with a Number argument? Remote Memory Disclosure If an attacker can make your program call the Buffer constructor with a Number argument, then they can make it allocate uninitialized memory from the node.js process. This could potentially disclose TLS private keys, user data, or database passwords. When the Buffer constructor is passed a Number argument, it returns an UNINITIALIZED block of memory of the specified size. When you create a Buffer like this, you MUST overwrite the contents before returning it to the user. From the node.js docs: new Buffer(size) size Number The underlying memory for Buffer instances created in this way is not initialized. The contents of a newly created Buffer are unknown and could contain sensitive data. Use buf.fill(0) to initialize a Buffer to zeroes. (Emphasis our own.) Whenever the programmer intended to create an uninitialized Buffer you often see code like this: var buf = new Buffer(16) // Immediately overwrite the uninitialized buffer with data from another buffer for (var i = 0; i < buf.length; i++) { buf[i] = otherBuf[i] } Would this ever be a problem in real code? Yes. It's surprisingly common to forget to check the type of your variables in a dynamically-typed language like JavaScript. Usually the consequences of assuming the wrong type is that your program crashes with an uncaught exception. But the failure mode for forgetting to check the type of arguments to the Buffer constructor is more catastrophic. Here's an example of a vulnerable service that takes a JSON payload and converts it to hex: // Take a JSON payload {str: \"some string\"} and convert it to hex var server = http.createServer(function (req, res) { var data = '' req.setEncoding('utf8') req.on('data', function (chunk) { data += chunk }) req.on('end', function () { var body = JSON.parse(data) res.end(new Buffer(body.str).toString('hex')) }) }) server.listen(8080) In this example, an http client just has to send: { \"str\": 1000 } and it will get back 1,000 bytes of uninitialized memory from the server. This is a very serious bug. It's similar in severity to the the Heartbleed bug that allowed disclosure of OpenSSL process memory by remote attackers. Which real-world packages were vulnerable? bittorrent-dht Mathias Buus and I (Feross Aboukhadijeh) found this issue in one of our own packages, bittorrent-dht. The bug would allow anyone on the internet to send a series of messages to a user of bittorrent-dht and get them to reveal 20 bytes at a time of uninitialized memory from the node.js process. Here's the commit that fixed it. We released a new fixed version, created a Node Security Project disclosure, and deprecated all vulnerable versions on npm so users will get a warning to upgrade to a newer version. ws That got us wondering if there were other vulnerable packages. Sure enough, within a short period of time, we found the same issue in ws, the most popular WebSocket implementation in node.js. If certain APIs were called with Number parameters instead of String or Buffer as expected, then uninitialized server memory would be disclosed to the remote peer. These were the vulnerable methods: socket.send(number) socket.ping(number) socket.pong(number) Here's a vulnerable socket server with some echo functionality: server.on('connection', function (socket) { socket.on('message', function (message) { message = JSON.parse(message) if (message.type === 'echo') { socket.send(message.data) // send back the user's message } }) }) socket.send(number) called on the server, will disclose server memory. Here's the release where the issue was fixed, with a more detailed explanation. Props to Arnout Kazemier for the quick fix. Here's the Node Security Project disclosure. What's the solution? It's important that node.js offers a fast way to get memory otherwise performance-critical applications would needlessly get a lot slower. But we need a better way to signal our intent as programmers. When we want uninitialized memory, we should request it explicitly. Sensitive functionality should not be packed into a developer-friendly API that loosely accepts many different types. This type of API encourages the lazy practice of passing variables in without checking the type very carefully. A new API: Buffer.allocUnsafe(number) The functionality of creating buffers with uninitialized memory should be part of another API. We propose Buffer.allocUnsafe(number). This way, it's not part of an API that frequently gets user input of all sorts of different types passed into it. var buf = Buffer.allocUnsafe(16) // careful, uninitialized memory! // Immediately overwrite the uninitialized buffer with data from another buffer for (var i = 0; i < buf.length; i++) { buf[i] = otherBuf[i] } How do we fix node.js core? We sent a PR to node.js core (merged as semver-major) which defends against one case: var str = 16 new Buffer(str, 'utf8') In this situation, it's implied that the programmer intended the first argument to be a string, since they passed an encoding as a second argument. Today, node.js will allocate uninitialized memory in the case of new Buffer(number, encoding), which is probably not what the programmer intended. But this is only a partial solution, since if the programmer does new Buffer(variable) (without an encoding parameter) there's no way to know what they intended. If variable is sometimes a number, then uninitialized memory will sometimes be returned. What's the real long-term fix? We could deprecate and remove new Buffer(number) and use Buffer.allocUnsafe(number) when we need uninitialized memory. But that would break 1000s of packages. We believe the best solution is to: 1. Change new Buffer(number) to return safe, zeroed-out memory 2. Create a new API for creating uninitialized Buffers. We propose: Buffer.allocUnsafe(number) Update We now support adding three new APIs: Buffer.from(value) - convert from any type to a buffer Buffer.alloc(size) - create a zero-filled buffer Buffer.allocUnsafe(size) - create an uninitialized buffer with given size This solves the core problem that affected ws and bittorrent-dht which is Buffer(variable) getting tricked into taking a number argument. This way, existing code continues working and the impact on the npm ecosystem will be minimal. Over time, npm maintainers can migrate performance-critical code to use Buffer.allocUnsafe(number) instead of new Buffer(number). Conclusion We think there's a serious design issue with the Buffer API as it exists today. It promotes insecure software by putting high-risk functionality into a convenient API with friendly \"developer ergonomics\". This wasn't merely a theoretical exercise because we found the issue in some of the most popular npm packages. Fortunately, there's an easy fix that can be applied today. Use safe-buffer in place of buffer. var Buffer = require('safe-buffer').Buffer Eventually, we hope that node.js core can switch to this new, safer behavior. We believe the impact on the ecosystem would be minimal since it's not a breaking change. Well-maintained, popular packages would be updated to use Buffer.alloc quickly, while older, insecure packages would magically become safe from this attack vector. links Node.js PR: buffer: throw if both length and enc are passed Node Security Project disclosure for ws Node Security Project disclosure forbittorrent-dht credit The original issues in bittorrent-dht (disclosure) and ws (disclosure) were discovered by Mathias Buus and Feross Aboukhadijeh. Thanks to Adam Baldwin for helping disclose these issues and for his work running the Node Security Project. Thanks to John Hiesey for proofreading this README and auditing the code. license MIT. Copyright (C) Feross Aboukhadijeh"
  },
  "src/frontend/app-client/node_modules/string_decoder/README.html": {
    "href": "src/frontend/app-client/node_modules/string_decoder/README.html",
    "title": "string_decoder",
    "summary": "string_decoder Node-core v8.9.4 string_decoder for userland npm install --save string_decoder Node-core string_decoder for userland This package is a mirror of the string_decoder implementation in Node-core. Full documentation may be found on the Node.js website. As of version 1.0.0 string_decoder uses semantic versioning. Previous versions Previous version numbers match the versions found in Node core, e.g. 0.10.24 matches Node 0.10.24, likewise 0.11.10 matches Node 0.11.10. Update The build/ directory contains a build script that will scrape the source from the nodejs/node repo given a specific Node version. Streams Working Group string_decoder is maintained by the Streams Working Group, which oversees the development and maintenance of the Streams API within Node.js. The responsibilities of the Streams Working Group include: Addressing stream issues on the Node.js issue tracker. Authoring and editing stream documentation within the Node.js project. Reviewing changes to stream subclasses within the Node.js project. Redirecting changes to streams from the Node.js project to this project. Assisting in the implementation of stream providers within Node.js. Recommending versions of readable-stream to be included in Node.js. Messaging about the future of streams to give the community advance notice of changes. See readable-stream for more details."
  },
  "src/frontend/app-client/node_modules/string-width-cjs/node_modules/ansi-regex/readme.html": {
    "href": "src/frontend/app-client/node_modules/string-width-cjs/node_modules/ansi-regex/readme.html",
    "title": "ansi-regex",
    "summary": "ansi-regex Regular expression for matching ANSI escape codes Install $ npm install ansi-regex Usage const ansiRegex = require('ansi-regex'); ansiRegex().test('\\u001B[4mcake\\u001B[0m'); //=> true ansiRegex().test('cake'); //=> false '\\u001B[4mcake\\u001B[0m'.match(ansiRegex()); //=> ['\\u001B[4m', '\\u001B[0m'] '\\u001B[4mcake\\u001B[0m'.match(ansiRegex({onlyFirst: true})); //=> ['\\u001B[4m'] '\\u001B]8;;https://github.com\\u0007click\\u001B]8;;\\u0007'.match(ansiRegex()); //=> ['\\u001B]8;;https://github.com\\u0007', '\\u001B]8;;\\u0007'] API ansiRegex(options?) Returns a regex for matching ANSI escape codes. options Type: object onlyFirst Type: boolean Default: false (Matches any ANSI escape codes in a string) Match only the first ANSI escape. FAQ Why do you test for codes not in the ECMA 48 standard? Some of the codes we run as a test are codes that we acquired finding various lists of non-standard or manufacturer specific codes. We test for both standard and non-standard codes, as most of them follow the same or similar format and can be safely matched in strings without the risk of removing actual string content. There are a few non-standard control codes that do not follow the traditional format (i.e. they end in numbers) thus forcing us to exclude them from the test because we cannot reliably match them. On the historical side, those ECMA standards were established in the early 90's whereas the VT100, for example, was designed in the mid/late 70's. At that point in time, control codes were still pretty ungoverned and engineers used them for a multitude of things, namely to activate hardware ports that may have been proprietary. Somewhere else you see a similar 'anarchy' of codes is in the x86 architecture for processors; there are a ton of \"interrupts\" that can mean different things on certain brands of processors, most of which have been phased out. Maintainers Sindre Sorhus Josh Junon Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "src/frontend/app-client/node_modules/string-width-cjs/node_modules/emoji-regex/README.html": {
    "href": "src/frontend/app-client/node_modules/string-width-cjs/node_modules/emoji-regex/README.html",
    "title": "emoji-regex",
    "summary": "emoji-regex emoji-regex offers a regular expression to match all emoji symbols (including textual representations of emoji) as per the Unicode Standard. This repository contains a script that generates this regular expression based on the data from Unicode v12. Because of this, the regular expression can easily be updated whenever new emoji are added to the Unicode standard. Installation Via npm: npm install emoji-regex In Node.js: const emojiRegex = require('emoji-regex'); // Note: because the regular expression has the global flag set, this module // exports a function that returns the regex rather than exporting the regular // expression itself, to make it impossible to (accidentally) mutate the // original regular expression. const text = ` \\u{231A}: ⌚ default emoji presentation character (Emoji_Presentation) \\u{2194}\\u{FE0F}: ↔️ default text presentation character rendered as emoji \\u{1F469}: \uD83D\uDC69 emoji modifier base (Emoji_Modifier_Base) \\u{1F469}\\u{1F3FF}: \uD83D\uDC69\uD83C\uDFFF emoji modifier base followed by a modifier `; const regex = emojiRegex(); let match; while (match = regex.exec(text)) { const emoji = match[0]; console.log(`Matched sequence ${ emoji } — code points: ${ [...emoji].length }`); } Console output: Matched sequence ⌚ — code points: 1 Matched sequence ⌚ — code points: 1 Matched sequence ↔️ — code points: 2 Matched sequence ↔️ — code points: 2 Matched sequence \uD83D\uDC69 — code points: 1 Matched sequence \uD83D\uDC69 — code points: 1 Matched sequence \uD83D\uDC69\uD83C\uDFFF — code points: 2 Matched sequence \uD83D\uDC69\uD83C\uDFFF — code points: 2 To match emoji in their textual representation as well (i.e. emoji that are not Emoji_Presentation symbols and that aren’t forced to render as emoji by a variation selector), require the other regex: const emojiRegex = require('emoji-regex/text.js'); Additionally, in environments which support ES2015 Unicode escapes, you may require ES2015-style versions of the regexes: const emojiRegex = require('emoji-regex/es2015/index.js'); const emojiRegexText = require('emoji-regex/es2015/text.js'); Author Mathias Bynens License emoji-regex is available under the MIT license."
  },
  "src/frontend/app-client/node_modules/string-width-cjs/node_modules/strip-ansi/readme.html": {
    "href": "src/frontend/app-client/node_modules/string-width-cjs/node_modules/strip-ansi/readme.html",
    "title": "strip-ansi",
    "summary": "strip-ansi Strip ANSI escape codes from a string Install $ npm install strip-ansi Usage const stripAnsi = require('strip-ansi'); stripAnsi('\\u001B[4mUnicorn\\u001B[0m'); //=> 'Unicorn' stripAnsi('\\u001B]8;;https://github.com\\u0007Click\\u001B]8;;\\u0007'); //=> 'Click' strip-ansi for enterprise Available as part of the Tidelift Subscription. The maintainers of strip-ansi and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more. Related strip-ansi-cli - CLI for this module strip-ansi-stream - Streaming version of this module has-ansi - Check if a string has ANSI escape codes ansi-regex - Regular expression for matching ANSI escape codes chalk - Terminal string styling done right Maintainers Sindre Sorhus Josh Junon"
  },
  "src/frontend/app-client/node_modules/string-width-cjs/readme.html": {
    "href": "src/frontend/app-client/node_modules/string-width-cjs/readme.html",
    "title": "string-width",
    "summary": "string-width Get the visual width of a string - the number of columns required to display it Some Unicode characters are fullwidth and use double the normal width. ANSI escape codes are stripped and doesn't affect the width. Useful to be able to measure the actual width of command-line output. Install $ npm install string-width Usage const stringWidth = require('string-width'); stringWidth('a'); //=> 1 stringWidth('古'); //=> 2 stringWidth('\\u001B[1m古\\u001B[22m'); //=> 2 Related string-width-cli - CLI for this module string-length - Get the real length of a string widest-line - Get the visual width of the widest line in a string Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "src/frontend/app-client/node_modules/string-width/readme.html": {
    "href": "src/frontend/app-client/node_modules/string-width/readme.html",
    "title": "string-width",
    "summary": "string-width Get the visual width of a string - the number of columns required to display it Some Unicode characters are fullwidth and use double the normal width. ANSI escape codes are stripped and doesn't affect the width. Useful to be able to measure the actual width of command-line output. Install $ npm install string-width Usage import stringWidth from 'string-width'; stringWidth('a'); //=> 1 stringWidth('古'); //=> 2 stringWidth('\\u001B[1m古\\u001B[22m'); //=> 2 API stringWidth(string, options?) string Type: string The string to be counted. options Type: object ambiguousIsNarrow Type: boolean Default: false Count ambiguous width characters as having narrow width (count of 1) instead of wide width (count of 2). Related string-width-cli - CLI for this module string-length - Get the real length of a string widest-line - Get the visual width of the widest line in a string Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "src/frontend/app-client/node_modules/strip-ansi-cjs/node_modules/ansi-regex/readme.html": {
    "href": "src/frontend/app-client/node_modules/strip-ansi-cjs/node_modules/ansi-regex/readme.html",
    "title": "ansi-regex",
    "summary": "ansi-regex Regular expression for matching ANSI escape codes Install $ npm install ansi-regex Usage const ansiRegex = require('ansi-regex'); ansiRegex().test('\\u001B[4mcake\\u001B[0m'); //=> true ansiRegex().test('cake'); //=> false '\\u001B[4mcake\\u001B[0m'.match(ansiRegex()); //=> ['\\u001B[4m', '\\u001B[0m'] '\\u001B[4mcake\\u001B[0m'.match(ansiRegex({onlyFirst: true})); //=> ['\\u001B[4m'] '\\u001B]8;;https://github.com\\u0007click\\u001B]8;;\\u0007'.match(ansiRegex()); //=> ['\\u001B]8;;https://github.com\\u0007', '\\u001B]8;;\\u0007'] API ansiRegex(options?) Returns a regex for matching ANSI escape codes. options Type: object onlyFirst Type: boolean Default: false (Matches any ANSI escape codes in a string) Match only the first ANSI escape. FAQ Why do you test for codes not in the ECMA 48 standard? Some of the codes we run as a test are codes that we acquired finding various lists of non-standard or manufacturer specific codes. We test for both standard and non-standard codes, as most of them follow the same or similar format and can be safely matched in strings without the risk of removing actual string content. There are a few non-standard control codes that do not follow the traditional format (i.e. they end in numbers) thus forcing us to exclude them from the test because we cannot reliably match them. On the historical side, those ECMA standards were established in the early 90's whereas the VT100, for example, was designed in the mid/late 70's. At that point in time, control codes were still pretty ungoverned and engineers used them for a multitude of things, namely to activate hardware ports that may have been proprietary. Somewhere else you see a similar 'anarchy' of codes is in the x86 architecture for processors; there are a ton of \"interrupts\" that can mean different things on certain brands of processors, most of which have been phased out. Maintainers Sindre Sorhus Josh Junon Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "src/frontend/app-client/node_modules/strip-ansi-cjs/readme.html": {
    "href": "src/frontend/app-client/node_modules/strip-ansi-cjs/readme.html",
    "title": "strip-ansi",
    "summary": "strip-ansi Strip ANSI escape codes from a string Install $ npm install strip-ansi Usage const stripAnsi = require('strip-ansi'); stripAnsi('\\u001B[4mUnicorn\\u001B[0m'); //=> 'Unicorn' stripAnsi('\\u001B]8;;https://github.com\\u0007Click\\u001B]8;;\\u0007'); //=> 'Click' strip-ansi for enterprise Available as part of the Tidelift Subscription. The maintainers of strip-ansi and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more. Related strip-ansi-cli - CLI for this module strip-ansi-stream - Streaming version of this module has-ansi - Check if a string has ANSI escape codes ansi-regex - Regular expression for matching ANSI escape codes chalk - Terminal string styling done right Maintainers Sindre Sorhus Josh Junon"
  },
  "src/frontend/app-client/node_modules/strip-ansi/readme.html": {
    "href": "src/frontend/app-client/node_modules/strip-ansi/readme.html",
    "title": "strip-ansi",
    "summary": "strip-ansi Strip ANSI escape codes from a string Install $ npm install strip-ansi Usage import stripAnsi from 'strip-ansi'; stripAnsi('\\u001B[4mUnicorn\\u001B[0m'); //=> 'Unicorn' stripAnsi('\\u001B]8;;https://github.com\\u0007Click\\u001B]8;;\\u0007'); //=> 'Click' strip-ansi for enterprise Available as part of the Tidelift Subscription. The maintainers of strip-ansi and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more. Related strip-ansi-cli - CLI for this module strip-ansi-stream - Streaming version of this module has-ansi - Check if a string has ANSI escape codes ansi-regex - Regular expression for matching ANSI escape codes chalk - Terminal string styling done right Maintainers Sindre Sorhus Josh Junon"
  },
  "src/frontend/app-client/node_modules/stylis/README.html": {
    "href": "src/frontend/app-client/node_modules/stylis/README.html",
    "title": "STYLIS",
    "summary": "STYLIS A Light–weight CSS Preprocessor. Installation Use a Direct Download: <script src=stylis.js></script> Use a CDN: <script src=unpkg.com/stylis></script> Use NPM: npm install stylis --save Features nesting a { &:hover {} } selector namespacing vendor prefixing (flex-box, etc...) minification esm module compatible tree-shaking-able Abstract Syntax Structure const declaration = { value: 'color:red;', type: 'decl', props: 'color', children: 'red', line: 1, column: 1 } const comment = { value: '/*@noflip*/', type: 'comm', props: '/', children: '@noflip', line: 1, column: 1 } const ruleset = { value: 'h1,h2', type: 'rule', props: ['h1', 'h2'], children: [/* ... */], line: 1, column: 1 } const atruleset = { value: '@media (max-width:100), (min-width:100)', type: '@media', props: ['(max-width:100)', '(min-width:100)'], children: [/* ... */], line: 1, column: 1 } Example: import {compile, serialize, stringify} from 'stylis' serialize(compile(`h1{all:unset}`), stringify) Compile compile('h1{all:unset}') === [{value: 'h1', type: 'rule', props: ['h1'], children: [/* ... */]}] compile('--foo:unset;') === [{value: '--foo:unset;', type: 'decl', props: '--foo', children: 'unset'}] Tokenize tokenize('h1 h2 h3 [h4 h5] fn(args) \"a b c\"') === ['h1', 'h2', 'h3', '[h4 h5]', 'fn', '(args)', '\"a b c\"'] Serialize serialize(compile('h1{all:unset}'), stringify) Vendor Prefixing import {compile, serialize, stringify, middleware, prefixer } from 'stylis'; serialize(compile('div{display:flex;}'), middleware([prefixer, stringify])) Middleware The middleware helper is a convenient helper utility, that for all intents and purposes you can do without if you intend to implement your own traversal logic. The stringify middleware is one such middleware that can be used in conjunction with it. Elements passed to middlewares have a root property that is the immediate root/parent of the current element in the compiled output, so it references the parent in the already expanded CSS-like structure. Elements have also parent property that is the immediate parent of the current element from the input structure (structure representing the input string). Traversal serialize(compile('h1{all:unset}'), middleware([(element, index, children) => { assert(children === element.root.children && children[index] === element.children) }, stringify])) === 'h1{all:unset;}' The abstract syntax tree also includes an additional return property for more niche uses. Prefixing serialize(compile('h1{all:unset}'), middleware([(element, index, children, callback) => { if (element.type === 'decl' && element.props === 'all' && element.children === 'unset') element.return = 'color:red;' + element.value }, stringify])) === 'h1{color:red;all:unset;}' serialize(compile('h1{all:unset}'), middleware([(element, index, children, callback) => { if (element.type === 'rule' && element.props.indexOf('h1') > -1) return serialize([{...element, props: ['h2', 'h3']}], callback) }, stringify])) === 'h2,h3{all:unset;}h1{all:unset;}' Reading serialize(compile('h1{all:unset}'), middleware([stringify, (element, index, children) => { assert(element.return === 'h1{all:unset;}') }])) === 'h1{all:unset;color:red;}' The middlewares in src/Middleware.js dive into tangible examples of how you might implement a middleware, alternatively you could also create your own middleware system as compile returns all the nessessary structure to fork from. Variables CSS variables are supported but a note should be made about the exotic use of css variables. The css spec mentions the following The allowed syntax for custom properties is extremely permissive. The production matches any sequence of one or more tokens, so long as the sequence does not contain , , unmatched <)-token>, <]-token>, or <}-token>, or top-level tokens or tokens with a value of \"!\". That is to say css variables according to the spec allows: --foo: if(x > 5) this.width = 10; and while this value is obviously useless as a variable, and would be invalid in any normal property, it still might be read and acted on by JavaScript and this is supported by Stylis, however things become slightly undefined when we start to include the { and } productions in our use of exotic css variables. For example consider the following: --foo: {}; While this is valid CSS and supported. It is unclear what should happen when the rule collides with the implicit block termination rule that allows i.e h1{color:red}(notice the omitted semicolon) to also be a valid CSS production. This results in the following contradiction in: h1{--example: {} is it to be treated as h1{--foo:{;} or h1{--foo:{} the later of which is an unterminated block or in the following: h1{--foo:{} h1{color:red;} should it be h1 {--foo:{}h1{color:red;}; where {}h1{color:red; is part of the css variable --foo and not a new rule or should it be something else? Nevertheless Stylis still supports the exotic forms highlighted in the spec, however you should consider it as a general rule to delimit such exotic uses of variables in strings or parentheses i.e: h1{--foo:'{'} or h1{--foo:({)}. Benchmark Stylis is at-least 2X faster than its predecesor. License Stylis is MIT licensed."
  },
  "src/frontend/app-client/node_modules/supports-preserve-symlinks-flag/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/supports-preserve-symlinks-flag/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.0 - 2022-01-02 Commits Tests e2f59ad Initial commit dc222aa [meta] do not publish workflow files 5ef77f7 npm init 992b068 read me 6c9afa9 Initial implementation 2f98925 [meta] add auto-changelog 6c476ae [Dev Deps] add eslint, @ljharb/eslint-config d0fffc8 Only apps should have lockfiles ab318ed [meta] add safe-publish-latest 2bb23b3 [meta] add sideEffects flag 600223b"
  },
  "src/frontend/app-client/node_modules/supports-preserve-symlinks-flag/README.html": {
    "href": "src/frontend/app-client/node_modules/supports-preserve-symlinks-flag/README.html",
    "title": "node-supports-preserve-symlinks-flag",
    "summary": "node-supports-preserve-symlinks-flag Determine if the current node version supports the --preserve-symlinks flag. Example var supportsPreserveSymlinks = require('node-supports-preserve-symlinks-flag'); var assert = require('assert'); assert.equal(supportsPreserveSymlinks, null); // in a browser assert.equal(supportsPreserveSymlinks, false); // in node < v6.2 assert.equal(supportsPreserveSymlinks, true); // in node v6.2+ Tests Simply clone the repo, npm install, and run npm test"
  },
  "src/frontend/app-client/node_modules/tailwindcss/README.html": {
    "href": "src/frontend/app-client/node_modules/tailwindcss/README.html",
    "title": "",
    "summary": "A utility-first CSS framework for rapidly building custom user interfaces. Documentation For full documentation, visit tailwindcss.com. Community For help, discussion about best practices, or any other conversation that would benefit from being searchable: Discuss Tailwind CSS on GitHub For chatting with others using the framework: Join the Tailwind CSS Discord Server Contributing If you're interested in contributing to Tailwind CSS, please read our contributing docs before submitting a pull request."
  },
  "src/frontend/app-client/node_modules/tapable/README.html": {
    "href": "src/frontend/app-client/node_modules/tapable/README.html",
    "title": "Tapable",
    "summary": "Tapable The tapable package expose many Hook classes, which can be used to create hooks for plugins. const { SyncHook, SyncBailHook, SyncWaterfallHook, SyncLoopHook, AsyncParallelHook, AsyncParallelBailHook, AsyncSeriesHook, AsyncSeriesBailHook, AsyncSeriesWaterfallHook } = require(\"tapable\"); Installation npm install --save tapable Usage All Hook constructors take one optional argument, which is a list of argument names as strings. const hook = new SyncHook([\"arg1\", \"arg2\", \"arg3\"]); The best practice is to expose all hooks of a class in a hooks property: class Car { constructor() { this.hooks = { accelerate: new SyncHook([\"newSpeed\"]), brake: new SyncHook(), calculateRoutes: new AsyncParallelHook([\"source\", \"target\", \"routesList\"]) }; } /* ... */ } Other people can now use these hooks: const myCar = new Car(); // Use the tap method to add a consument myCar.hooks.brake.tap(\"WarningLampPlugin\", () => warningLamp.on()); It's required to pass a name to identify the plugin/reason. You may receive arguments: myCar.hooks.accelerate.tap(\"LoggerPlugin\", newSpeed => console.log(`Accelerating to ${newSpeed}`)); For sync hooks, tap is the only valid method to add a plugin. Async hooks also support async plugins: myCar.hooks.calculateRoutes.tapPromise(\"GoogleMapsPlugin\", (source, target, routesList) => { // return a promise return google.maps.findRoute(source, target).then(route => { routesList.add(route); }); }); myCar.hooks.calculateRoutes.tapAsync(\"BingMapsPlugin\", (source, target, routesList, callback) => { bing.findRoute(source, target, (err, route) => { if(err) return callback(err); routesList.add(route); // call the callback callback(); }); }); // You can still use sync plugins myCar.hooks.calculateRoutes.tap(\"CachedRoutesPlugin\", (source, target, routesList) => { const cachedRoute = cache.get(source, target); if(cachedRoute) routesList.add(cachedRoute); }) The class declaring these hooks need to call them: class Car { /** * You won't get returned value from SyncHook or AsyncParallelHook, * to do that, use SyncWaterfallHook and AsyncSeriesWaterfallHook respectively **/ setSpeed(newSpeed) { // following call returns undefined even when you returned values this.hooks.accelerate.call(newSpeed); } useNavigationSystemPromise(source, target) { const routesList = new List(); return this.hooks.calculateRoutes.promise(source, target, routesList).then((res) => { // res is undefined for AsyncParallelHook return routesList.getRoutes(); }); } useNavigationSystemAsync(source, target, callback) { const routesList = new List(); this.hooks.calculateRoutes.callAsync(source, target, routesList, err => { if(err) return callback(err); callback(null, routesList.getRoutes()); }); } } The Hook will compile a method with the most efficient way of running your plugins. It generates code depending on: The number of registered plugins (none, one, many) The kind of registered plugins (sync, async, promise) The used call method (sync, async, promise) The number of arguments Whether interception is used This ensures fastest possible execution. Hook types Each hook can be tapped with one or several functions. How they are executed depends on the hook type: Basic hook (without “Waterfall”, “Bail” or “Loop” in its name). This hook simply calls every function it tapped in a row. Waterfall. A waterfall hook also calls each tapped function in a row. Unlike the basic hook, it passes a return value from each function to the next function. Bail. A bail hook allows exiting early. When any of the tapped function returns anything, the bail hook will stop executing the remaining ones. Loop. When a plugin in a loop hook returns a non-undefined value the hook will restart from the first plugin. It will loop until all plugins return undefined. Additionally, hooks can be synchronous or asynchronous. To reflect this, there’re “Sync”, “AsyncSeries”, and “AsyncParallel” hook classes: Sync. A sync hook can only be tapped with synchronous functions (using myHook.tap()). AsyncSeries. An async-series hook can be tapped with synchronous, callback-based and promise-based functions (using myHook.tap(), myHook.tapAsync() and myHook.tapPromise()). They call each async method in a row. AsyncParallel. An async-parallel hook can also be tapped with synchronous, callback-based and promise-based functions (using myHook.tap(), myHook.tapAsync() and myHook.tapPromise()). However, they run each async method in parallel. The hook type is reflected in its class name. E.g., AsyncSeriesWaterfallHook allows asynchronous functions and runs them in series, passing each function’s return value into the next function. Interception All Hooks offer an additional interception API: myCar.hooks.calculateRoutes.intercept({ call: (source, target, routesList) => { console.log(\"Starting to calculate routes\"); }, register: (tapInfo) => { // tapInfo = { type: \"promise\", name: \"GoogleMapsPlugin\", fn: ... } console.log(`${tapInfo.name} is doing its job`); return tapInfo; // may return a new tapInfo object } }) call: (...args) => void Adding call to your interceptor will trigger when hooks are triggered. You have access to the hooks arguments. tap: (tap: Tap) => void Adding tap to your interceptor will trigger when a plugin taps into a hook. Provided is the Tap object. Tap object can't be changed. loop: (...args) => void Adding loop to your interceptor will trigger for each loop of a looping hook. register: (tap: Tap) => Tap | undefined Adding register to your interceptor will trigger for each added Tap and allows to modify it. Context Plugins and interceptors can opt-in to access an optional context object, which can be used to pass arbitrary values to subsequent plugins and interceptors. myCar.hooks.accelerate.intercept({ context: true, tap: (context, tapInfo) => { // tapInfo = { type: \"sync\", name: \"NoisePlugin\", fn: ... } console.log(`${tapInfo.name} is doing it's job`); // `context` starts as an empty object if at least one plugin uses `context: true`. // If no plugins use `context: true`, then `context` is undefined. if (context) { // Arbitrary properties can be added to `context`, which plugins can then access. context.hasMuffler = true; } } }); myCar.hooks.accelerate.tap({ name: \"NoisePlugin\", context: true }, (context, newSpeed) => { if (context && context.hasMuffler) { console.log(\"Silence...\"); } else { console.log(\"Vroom!\"); } }); HookMap A HookMap is a helper class for a Map with Hooks const keyedHook = new HookMap(key => new SyncHook([\"arg\"])) keyedHook.for(\"some-key\").tap(\"MyPlugin\", (arg) => { /* ... */ }); keyedHook.for(\"some-key\").tapAsync(\"MyPlugin\", (arg, callback) => { /* ... */ }); keyedHook.for(\"some-key\").tapPromise(\"MyPlugin\", (arg) => { /* ... */ }); const hook = keyedHook.get(\"some-key\"); if(hook !== undefined) { hook.callAsync(\"arg\", err => { /* ... */ }); } Hook/HookMap interface Public: interface Hook { tap: (name: string | Tap, fn: (context?, ...args) => Result) => void, tapAsync: (name: string | Tap, fn: (context?, ...args, callback: (err, result: Result) => void) => void) => void, tapPromise: (name: string | Tap, fn: (context?, ...args) => Promise<Result>) => void, intercept: (interceptor: HookInterceptor) => void } interface HookInterceptor { call: (context?, ...args) => void, loop: (context?, ...args) => void, tap: (context?, tap: Tap) => void, register: (tap: Tap) => Tap, context: boolean } interface HookMap { for: (key: any) => Hook, intercept: (interceptor: HookMapInterceptor) => void } interface HookMapInterceptor { factory: (key: any, hook: Hook) => Hook } interface Tap { name: string, type: string fn: Function, stage: number, context: boolean, before?: string | Array } Protected (only for the class containing the hook): interface Hook { isUsed: () => boolean, call: (...args) => Result, promise: (...args) => Promise<Result>, callAsync: (...args, callback: (err, result: Result) => void) => void, } interface HookMap { get: (key: any) => Hook | undefined, for: (key: any) => Hook } MultiHook A helper Hook-like class to redirect taps to multiple other hooks: const { MultiHook } = require(\"tapable\"); this.hooks.allHooks = new MultiHook([this.hooks.hookA, this.hooks.hookB]);"
  },
  "src/frontend/app-client/node_modules/tinyduration/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/tinyduration/LICENSE.html",
    "title": "",
    "summary": "Copyright 2020 MelleB Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/tinyduration/README.html": {
    "href": "src/frontend/app-client/node_modules/tinyduration/README.html",
    "title": "TinyDuration",
    "summary": "TinyDuration A small (< 1kb minified + gzipped) javascript package to parse and serialize ISO-8601 durations. This package does only 2 things: It parses a duration string to an object (e.g. P1DT12H to { days: 1, hours: 12 }) The reverse, i.e. serialize an object to a string. This lib has 0 dependencies. Installation NPM: npm install --save tinyduration Yarn: yarn add tinyduration Usage import { parse, serialize } from 'tinyduration' // Basic parsing const durationObj = parse('P1Y2M3DT4H5M6S') assert(durationObj, { years: 1, months: 2, days: 3, hours: 4, minutes: 5, seconds: 6, }) // Serialization assert(serialize(durationObj), 'P1Y2M3DT4H5M6S') Development This library is written in TypeScript. During publication of the package, the code is transpiled to javascript and put into the dist folder. The tests can be found the src folder under *.test.ts, testing is done using Jest Additional commands you'll need for development: npm test to run all tests npm run lint to run the linter npm run prettify to auto-fix the indenting issues npm run ci to run coverage and linting npx changeset to add a changeset npx changeset version to adopt a changeset, prepping for release npx changeset publish to publish to NPM API Type: Duration Property Type Description negative boolean or undefined Duration is positive if undefined years number or undefined months number or undefined weeks number or undefined days number or undefined hours number or undefined minutes number or undefined seconds number or undefined Type: ParseConfig Property Type Description allowMultipleFractions boolean or undefined Defaults to true. Function: parse(durationStr: string, config: ParseConfig): Duration parse accepts a string and returns a Duration object. No attempt is made to change lower units into higher ones, e.g. to change 120 minutes into 2 hours. Throws InvalidDurationError if an invalid duration string is supplied. Throws MultipleFractionsError if an the duration string contains multiple fractions while disabled in the config. According to the spec multiple fractions are not allowed. Currently this is not enforced and the allowMultipleFractions config parameter defaults to true. import { parse } from 'tinyduration' const duration = parse('P1W') assert(duration, { weeks: 1 }) try { parse('invalid-duration') } catch (e) { assert(e.message === 'Invalid duration') } Function: serialize(Duration): string serialize accepts a Duration object and returns a serialized duration according to ISO-8601. If the duration is empty (i.e. all values are 0), PT0S is returned. import * as Duration from 'tinyduration' const durationStr = Duration.serialize({ weeks: 1 }) assert(durationStr, 'P1W') const durationStr = Duration.serialize({}) assert(durationStr, 'PT0S') License MIT"
  },
  "src/frontend/app-client/node_modules/toidentifier/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/toidentifier/HISTORY.html",
    "title": "1.0.1 / 2021-11-14",
    "summary": "1.0.1 / 2021-11-14 pref: enable strict mode 1.0.0 / 2018-07-09 Initial release"
  },
  "src/frontend/app-client/node_modules/toidentifier/README.html": {
    "href": "src/frontend/app-client/node_modules/toidentifier/README.html",
    "title": "toidentifier",
    "summary": "toidentifier Convert a string of words to a JavaScript identifier Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install toidentifier Example var toIdentifier = require('toidentifier') console.log(toIdentifier('Bad Request')) // => \"BadRequest\" API This CommonJS module exports a single default function: toIdentifier. toIdentifier(string) Given a string as the argument, it will be transformed according to the following rules and the new string will be returned: Split into words separated by space characters (0x20). Upper case the first character of each word. Join the words together with no separator. Remove all non-word ([0-9a-z_]) characters. License MIT"
  },
  "src/frontend/app-client/node_modules/tsconfck/README.html": {
    "href": "src/frontend/app-client/node_modules/tsconfck/README.html",
    "title": "tsconfck",
    "summary": "tsconfck A utility to find and parse tsconfig files without depending on typescript Why Because no simple official api exists and tsconfig isn't actual json. Features [x] find closest tsconfig (tsconfig.json or jsconfig.json) [x] convert tsconfig to actual json and parse it [x] resolve \"extends\" [x] resolve \"references\" of solution-style tsconfig [x] optional caching for improved performance [x] optional findNative and parseNative to use official typescript api [x] zero dependencies (typescript optional) [x] extensive testsuite [x] completely async and optimized (it's fast) [x] tiny 4.8KB gzip [x] unbundled esm js, no sourcemaps needed [x] types generated with dts-buddy Users Used by vite*, vite-tsconfig-paths, astro and many more (*) vite bundles tsconfck so it is listed as a devDependency Install npm install --save-dev tsconfck # or pnpm, yarn Usage without typescript installed import { parse } from 'tsconfck'; const { tsconfigFile, // full path to found tsconfig tsconfig, // tsconfig object including merged values from extended configs extended, // separate unmerged results of all tsconfig files that contributed to tsconfig solution, // solution result if tsconfig is part of a solution referenced // referenced tsconfig results if tsconfig is a solution } = await parse('foo/bar.ts'); with typescript import { parseNative } from 'tsconfck'; const { tsconfigFile, // full path to found tsconfig tsconfig, // tsconfig object including merged values from extended configs, normalized result, // output of ts.parseJsonConfigFileContent solution, // solution result if tsconfig is part of a solution referenced // referenced tsconfig results if tsconfig is a solution } = await parseNative('foo/bar.ts'); API see API-DOCS Advanced ignoring tsconfig for files inside node_modules esbuild ignores node_modules so when you want to use tsconfck with esbuild, you can set ignoreNodeModules: true import { find, parse } from 'tsconfck'; // returns some-lib/tsconfig.json const fooTSConfig = await find('node_modules/some-lib/src/foo.ts'); // returns null const fooTSConfigIgnored = await find('node_modules/some-lib/src/foo.ts', { ignoreNodeModules: true }); // returns empty config const { tsconfig } = await parse('node_modules/some-lib/src/foo.ts', { ignoreNodeModules: true }); caching a TSConfckCache instance can be created and passed to find and parse functions to reduce overhead when they are called often within the same project import { find, parse, TSCOnfckCache } from 'tsconfck'; // 1. create cache instance const cache = new TSCOnfckCache(); // 2. pass cache instance in options const fooTSConfig = await find(('src/foo.ts', { cache })); // stores tsconfig for src in cache const barTSConfig = await find(('src/bar.ts', { cache })); // reuses tsconfig result for src without fs call const fooResult = await parse('src/foo.ts', { cache }); // uses cached path for tsconfig, stores parse result in cache const barResult = await parse('src/bar.ts', { cache }); // uses cached parse result without fs call or resolving cache invalidation You are responsible for clearing the cache if tsconfig files are added/removed/changed after reading them during the cache lifetime. Call cache.clear() and also discard all previous compilation results based previously cached configs. cache mutation Returned results are direct cache objects. If you want to modify them, deep-clone first. cache reuse Never use the same cache instance for mixed calls of find/findNative or parse/parseNative as result structures are different root This option can be used to limit finding tsconfig files outside of a root directory import { parse, TSConfckCache } from 'tsconfck'; const root = '.'; const parseOptions = { root }; // these calls are not going to look for tsconfig files outside root const fooResult = await find('src/foo.ts', parseOptions); const barResult = await parse('src/bar.ts', parseOptions); Using the root option can lead to errors if there is no tsconfig found inside root. error handling find and parse reject for errors they encounter, but return null or empty result if no config was found If you want them to error instead, test the result and throw import { parse } from 'tsconfck'; find('some/path/without/tsconfig/foo.ts').then((result) => { if (result === null) { throw new Error('not found'); } return result; }); parse('some/path/without/tsconfig/foo.ts').then((result) => { if (result.tsconfigFile === null) { throw new Error('not found'); } return result; }); TSConfig type (optional, requires typescript as devDependency) import type { TSConfig } from 'pkg-types'; Check out https://github.com/unjs/pkg-types cli A simple cli wrapper is included, you can use it like this find # prints /path/to/tsconfig.json on stdout tsconfck find src/index.ts find-all # prints all tsconfig.json in dir on stdout tsconfck find-all src/ parse # print content of ParseResult.tsconfig on stdout tsconfck parse src/index.ts # print to file tsconfck parse src/index.ts > output.json parse-result # print content of ParseResult on stdout tsconfck parse-result src/index.ts # print to file tsconfck parse-result src/index.ts > output.json help # print usage tsconfck -h # or --help, -?, help Links changelog Develop This repo uses pnpm changesets In every PR you have to add a changeset by running pnpm changeset and following the prompts PRs are going to be squash-merged # install dependencies pnpm install # run tests pnpm test #run tests in watch mode (doesn't require dev in parallel) pnpm test:watch License MIT"
  },
  "src/frontend/app-client/node_modules/tslib/README.html": {
    "href": "src/frontend/app-client/node_modules/tslib/README.html",
    "title": "tslib",
    "summary": "tslib This is a runtime library for TypeScript that contains all of the TypeScript helper functions. This library is primarily used by the --importHelpers flag in TypeScript. When using --importHelpers, a module that uses helper functions like __extends and __assign in the following emitted file: var __assign = (this && this.__assign) || Object.assign || function(t) { for (var s, i = 1, n = arguments.length; i < n; i++) { s = arguments[i]; for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p]; } return t; }; exports.x = {}; exports.y = __assign({}, exports.x); will instead be emitted as something like the following: var tslib_1 = require(\"tslib\"); exports.x = {}; exports.y = tslib_1.__assign({}, exports.x); Because this can avoid duplicate declarations of things like __extends, __assign, etc., this means delivering users smaller files on average, as well as less runtime overhead. For optimized bundles with TypeScript, you should absolutely consider using tslib and --importHelpers. Installing For the latest stable version, run: npm # TypeScript 3.9.2 or later npm install tslib # TypeScript 3.8.4 or earlier npm install tslib@^1 # TypeScript 2.3.2 or earlier npm install tslib@1.6.1 yarn # TypeScript 3.9.2 or later yarn add tslib # TypeScript 3.8.4 or earlier yarn add tslib@^1 # TypeScript 2.3.2 or earlier yarn add tslib@1.6.1 bower # TypeScript 3.9.2 or later bower install tslib # TypeScript 3.8.4 or earlier bower install tslib@^1 # TypeScript 2.3.2 or earlier bower install tslib@1.6.1 JSPM # TypeScript 3.9.2 or later jspm install tslib # TypeScript 3.8.4 or earlier jspm install tslib@^1 # TypeScript 2.3.2 or earlier jspm install tslib@1.6.1 Usage Set the importHelpers compiler option on the command line: tsc --importHelpers file.ts or in your tsconfig.json: { \"compilerOptions\": { \"importHelpers\": true } } For bower and JSPM users You will need to add a paths mapping for tslib, e.g. For Bower users: { \"compilerOptions\": { \"module\": \"amd\", \"importHelpers\": true, \"baseUrl\": \"./\", \"paths\": { \"tslib\" : [\"bower_components/tslib/tslib.d.ts\"] } } } For JSPM users: { \"compilerOptions\": { \"module\": \"system\", \"importHelpers\": true, \"baseUrl\": \"./\", \"paths\": { \"tslib\" : [\"jspm_packages/npm/tslib@2.x.y/tslib.d.ts\"] } } } Deployment Choose your new version number Set it in package.json and bower.json Create a tag: git tag [version] Push the tag: git push --tags Create a release in GitHub Run the publish to npm workflow Done. Contribute There are many ways to contribute to TypeScript. Submit bugs and help us verify fixes as they are checked in. Review the source code changes. Engage with other TypeScript users and developers on StackOverflow. Join the #typescript discussion on Twitter. Contribute bug fixes. Documentation Quick tutorial Programming handbook Homepage"
  },
  "src/frontend/app-client/node_modules/tslib/SECURITY.html": {
    "href": "src/frontend/app-client/node_modules/tslib/SECURITY.html",
    "title": "",
    "summary": "Security Microsoft takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, which include Microsoft, Azure, DotNet, AspNet, Xamarin, and our GitHub organizations. If you believe you have found a security vulnerability in any Microsoft-owned repository that meets Microsoft's definition of a security vulnerability, please report it to us as described below. Reporting Security Issues Please do not report security vulnerabilities through public GitHub issues. Instead, please report them to the Microsoft Security Response Center (MSRC) at https://msrc.microsoft.com/create-report. If you prefer to submit without logging in, send email to secure@microsoft.com. If possible, encrypt your message with our PGP key; please download it from the Microsoft Security Response Center PGP Key page. You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Additional information can be found at microsoft.com/msrc. Please include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. If you are reporting for a bug bounty, more complete reports can contribute to a higher bounty award. Please visit our Microsoft Bug Bounty Program page for more details about our active programs. Preferred Languages We prefer all communications to be in English. Policy Microsoft follows the principle of Coordinated Vulnerability Disclosure."
  },
  "src/frontend/app-client/node_modules/turbo-stream/README.html": {
    "href": "src/frontend/app-client/node_modules/turbo-stream/README.html",
    "title": "Turbo Stream",
    "summary": "Turbo Stream A streaming data transport format that aims to support built-in features such as Promises, Dates, RegExps, Maps, Sets and more. Decode runtime size: Shout Out! Shout out to Rich Harris and his https://github.com/rich-harris/devalue project. Devalue has heavily influenced this project and portions of the code have been directly lifted from it. I highly recommend checking it out if you need something more cusomizable or without streaming support. Installation npm install turbo-stream Usage import { decode, encode } from \"turbo-stream\"; const encodedStream = encode(Promise.resolve(42)); const decoded = await decode(encodedStream); console.log(decoded.value); // a Promise console.log(await decoded.value); // 42 await decoded.done; // wait for the stream to finish Stackblitz: https://stackblitz.com/edit/stackblitz-starters-2wm7dh?file=index.js React SSR Example: https://github.com/jacob-ebey/turbo-stream-react-example"
  },
  "src/frontend/app-client/node_modules/type-is/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/type-is/HISTORY.html",
    "title": "1.6.18 / 2019-04-26",
    "summary": "1.6.18 / 2019-04-26 Fix regression passing request object to typeis.is 1.6.17 / 2019-04-25 deps: mime-types@~2.1.24 Add Apple file extensions from IANA Add extension .csl to application/vnd.citationstyles.style+xml Add extension .es to application/ecmascript Add extension .nq to application/n-quads Add extension .nt to application/n-triples Add extension .owl to application/rdf+xml Add extensions .siv and .sieve to application/sieve Add extensions from IANA for image/* types Add extensions from IANA for model/* types Add extensions to HEIC image types Add new mime types Add text/mdx with extension .mdx perf: prevent internal throw on invalid type 1.6.16 / 2018-02-16 deps: mime-types@~2.1.18 Add application/raml+yaml with extension .raml Add application/wasm with extension .wasm Add text/shex with extension .shex Add extensions for JPEG-2000 images Add extensions from IANA for message/* types Add extension .mjs to application/javascript Add extension .wadl to application/vnd.sun.wadl+xml Add extension .gz to application/gzip Add glTF types and extensions Add new mime types Update extensions .md and .markdown to be text/markdown Update font MIME types Update text/hjson to registered application/hjson 1.6.15 / 2017-03-31 deps: mime-types@~2.1.15 Add new mime types 1.6.14 / 2016-11-18 deps: mime-types@~2.1.13 Add new mime types 1.6.13 / 2016-05-18 deps: mime-types@~2.1.11 Add new mime types 1.6.12 / 2016-02-28 deps: mime-types@~2.1.10 Add new mime types Fix extension of application/dash+xml Update primary extension for audio/mp4 1.6.11 / 2016-01-29 deps: mime-types@~2.1.9 Add new mime types 1.6.10 / 2015-12-01 deps: mime-types@~2.1.8 Add new mime types 1.6.9 / 2015-09-27 deps: mime-types@~2.1.7 Add new mime types 1.6.8 / 2015-09-04 deps: mime-types@~2.1.6 Add new mime types 1.6.7 / 2015-08-20 Fix type error when given invalid type to match against deps: mime-types@~2.1.5 Add new mime types 1.6.6 / 2015-07-31 deps: mime-types@~2.1.4 Add new mime types 1.6.5 / 2015-07-16 deps: mime-types@~2.1.3 Add new mime types 1.6.4 / 2015-07-01 deps: mime-types@~2.1.2 Add new mime types perf: enable strict mode perf: remove argument reassignment 1.6.3 / 2015-06-08 deps: mime-types@~2.1.1 Add new mime types perf: reduce try block size perf: remove bitwise operations 1.6.2 / 2015-05-10 deps: mime-types@~2.0.11 Add new mime types 1.6.1 / 2015-03-13 deps: mime-types@~2.0.10 Add new mime types 1.6.0 / 2015-02-12 fix false-positives in hasBody Transfer-Encoding check support wildcard for both type and subtype (*/*) 1.5.7 / 2015-02-09 fix argument reassignment deps: mime-types@~2.0.9 Add new mime types 1.5.6 / 2015-01-29 deps: mime-types@~2.0.8 Add new mime types 1.5.5 / 2014-12-30 deps: mime-types@~2.0.7 Add new mime types Fix missing extensions Fix various invalid MIME type entries Remove example template MIME types deps: mime-db@~1.5.0 1.5.4 / 2014-12-10 deps: mime-types@~2.0.4 Add new mime types deps: mime-db@~1.3.0 1.5.3 / 2014-11-09 deps: mime-types@~2.0.3 Add new mime types deps: mime-db@~1.2.0 1.5.2 / 2014-09-28 deps: mime-types@~2.0.2 Add new mime types deps: mime-db@~1.1.0 1.5.1 / 2014-09-07 Support Node.js 0.6 deps: media-typer@0.3.0 deps: mime-types@~2.0.1 Support Node.js 0.6 1.5.0 / 2014-09-05 fix hasbody to be true for content-length: 0 1.4.0 / 2014-09-02 update mime-types 1.3.2 / 2014-06-24 use ~ range on mime-types 1.3.1 / 2014-06-19 fix global variable leak 1.3.0 / 2014-06-19 improve type parsing invalid media type never matches media type not case-sensitive extra LWS does not affect results 1.2.2 / 2014-06-19 fix behavior on unknown type argument 1.2.1 / 2014-06-03 switch dependency from mime to mime-types@1.0.0 1.2.0 / 2014-05-11 support suffix matching: +json matches application/vnd+json */vnd+json matches application/vnd+json application/*+json matches application/vnd+json 1.1.0 / 2014-04-12 add non-array values support expose internal utilities: .is() .hasBody() .normalize() .match() 1.0.1 / 2014-03-30 add multipart as a shorthand"
  },
  "src/frontend/app-client/node_modules/type-is/README.html": {
    "href": "src/frontend/app-client/node_modules/type-is/README.html",
    "title": "type-is",
    "summary": "type-is Infer the content-type of a request. Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install type-is API var http = require('http') var typeis = require('type-is') http.createServer(function (req, res) { var istext = typeis(req, ['text/*']) res.end('you ' + (istext ? 'sent' : 'did not send') + ' me text') }) typeis(request, types) Checks if the request is one of the types. If the request has no body, even if there is a Content-Type header, then null is returned. If the Content-Type header is invalid or does not matches any of the types, then false is returned. Otherwise, a string of the type that matched is returned. The request argument is expected to be a Node.js HTTP request. The types argument is an array of type strings. Each type in the types array can be one of the following: A file extension name such as json. This name will be returned if matched. A mime type such as application/json. A mime type with a wildcard such as */* or */json or application/*. The full mime type will be returned if matched. A suffix such as +json. This can be combined with a wildcard such as */vnd+json or application/*+json. The full mime type will be returned if matched. Some examples to illustrate the inputs and returned value: // req.headers.content-type = 'application/json' typeis(req, ['json']) // => 'json' typeis(req, ['html', 'json']) // => 'json' typeis(req, ['application/*']) // => 'application/json' typeis(req, ['application/json']) // => 'application/json' typeis(req, ['html']) // => false typeis.hasBody(request) Returns a Boolean if the given request has a body, regardless of the Content-Type header. Having a body has no relation to how large the body is (it may be 0 bytes). This is similar to how file existence works. If a body does exist, then this indicates that there is data to read from the Node.js request stream. if (typeis.hasBody(req)) { // read the body, since there is one req.on('data', function (chunk) { // ... }) } typeis.is(mediaType, types) Checks if the mediaType is one of the types. If the mediaType is invalid or does not matches any of the types, then false is returned. Otherwise, a string of the type that matched is returned. The mediaType argument is expected to be a media type string. The types argument is an array of type strings. Each type in the types array can be one of the following: A file extension name such as json. This name will be returned if matched. A mime type such as application/json. A mime type with a wildcard such as */* or */json or application/*. The full mime type will be returned if matched. A suffix such as +json. This can be combined with a wildcard such as */vnd+json or application/*+json. The full mime type will be returned if matched. Some examples to illustrate the inputs and returned value: var mediaType = 'application/json' typeis.is(mediaType, ['json']) // => 'json' typeis.is(mediaType, ['html', 'json']) // => 'json' typeis.is(mediaType, ['application/*']) // => 'application/json' typeis.is(mediaType, ['application/json']) // => 'application/json' typeis.is(mediaType, ['html']) // => false Examples Example body parser var express = require('express') var typeis = require('type-is') var app = express() app.use(function bodyParser (req, res, next) { if (!typeis.hasBody(req)) { return next() } switch (typeis(req, ['urlencoded', 'json', 'multipart'])) { case 'urlencoded': // parse urlencoded body throw new Error('implement urlencoded body parsing') case 'json': // parse json body throw new Error('implement json body parsing') case 'multipart': // parse multipart body throw new Error('implement multipart body parsing') default: // 415 error code res.statusCode = 415 res.end() break } }) License MIT"
  },
  "src/frontend/app-client/node_modules/typescript/README.html": {
    "href": "src/frontend/app-client/node_modules/typescript/README.html",
    "title": "TypeScript",
    "summary": "TypeScript TypeScript is a language for application-scale JavaScript. TypeScript adds optional types to JavaScript that support tools for large-scale JavaScript applications for any browser, for any host, on any OS. TypeScript compiles to readable, standards-based JavaScript. Try it out at the playground, and stay up to date via our blog and Twitter account. Find others who are using TypeScript at our community page. Installing For the latest stable version: npm install -D typescript For our nightly builds: npm install -D typescript@next Contribute There are many ways to contribute to TypeScript. Submit bugs and help us verify fixes as they are checked in. Review the source code changes. Engage with other TypeScript users and developers on StackOverflow. Help each other in the TypeScript Community Discord. Join the #typescript discussion on Twitter. Contribute bug fixes. This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments. Documentation TypeScript in 5 minutes Programming handbook Homepage Roadmap For details on our planned features and future direction, please refer to our roadmap."
  },
  "src/frontend/app-client/node_modules/typescript/SECURITY.html": {
    "href": "src/frontend/app-client/node_modules/typescript/SECURITY.html",
    "title": "",
    "summary": "Security Microsoft takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, which include Microsoft, Azure, DotNet, AspNet and Xamarin. If you believe you have found a security vulnerability in any Microsoft-owned repository that meets Microsoft's definition of a security vulnerability, please report it to us as described below. Reporting Security Issues Please do not report security vulnerabilities through public GitHub issues. Instead, please report them to the Microsoft Security Response Center (MSRC) at https://msrc.microsoft.com/create-report. If you prefer to submit without logging in, send email to secure@microsoft.com. If possible, encrypt your message with our PGP key; please download it from the Microsoft Security Response Center PGP Key page. You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Additional information can be found at microsoft.com/msrc. Please include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. If you are reporting for a bug bounty, more complete reports can contribute to a higher bounty award. Please visit our Microsoft Bug Bounty Program page for more details about our active programs. Preferred Languages We prefer all communications to be in English. Policy Microsoft follows the principle of Coordinated Vulnerability Disclosure."
  },
  "src/frontend/app-client/node_modules/undici-types/README.html": {
    "href": "src/frontend/app-client/node_modules/undici-types/README.html",
    "title": "undici-types",
    "summary": "undici-types This package is a dual-publish of the undici library types. The undici package still contains types. This package is for users who only need undici types (such as for @types/node). It is published alongside every release of undici, so you can always use the same version. GitHub nodejs/undici Undici Documentation"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/Agent.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/Agent.html",
    "title": "Agent",
    "summary": "Agent Extends: undici.Dispatcher Agent allow dispatching requests against multiple different origins. Requests are not guaranteed to be dispatched in order of invocation. new undici.Agent([options]) Arguments: options AgentOptions (optional) Returns: Agent Parameter: AgentOptions Extends: PoolOptions factory (origin: URL, opts: Object) => Dispatcher - Default: (origin, opts) => new Pool(origin, opts) maxRedirections Integer - Default: 0. The number of HTTP redirection to follow unless otherwise specified in DispatchOptions. interceptors { Agent: DispatchInterceptor[] } - Default: [RedirectInterceptor] - A list of interceptors that are applied to the dispatch method. Additional logic can be applied (such as, but not limited to: 302 status code handling, authentication, cookies, compression and caching). Note that the behavior of interceptors is Experimental and might change at any given time. Instance Properties Agent.closed Implements Client.closed Agent.destroyed Implements Client.destroyed Instance Methods Agent.close([callback]) Implements Dispatcher.close([callback]). Agent.destroy([error, callback]) Implements Dispatcher.destroy([error, callback]). Agent.dispatch(options, handler: AgentDispatchOptions) Implements Dispatcher.dispatch(options, handler). Parameter: AgentDispatchOptions Extends: DispatchOptions origin string | URL maxRedirections Integer. Implements Dispatcher.destroy([error, callback]). Agent.connect(options[, callback]) See Dispatcher.connect(options[, callback]). Agent.dispatch(options, handler) Implements Dispatcher.dispatch(options, handler). Agent.pipeline(options, handler) See Dispatcher.pipeline(options, handler). Agent.request(options[, callback]) See Dispatcher.request(options [, callback]). Agent.stream(options, factory[, callback]) See Dispatcher.stream(options, factory[, callback]). Agent.upgrade(options[, callback]) See Dispatcher.upgrade(options[, callback])."
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/api-lifecycle.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/api-lifecycle.html",
    "title": "Client Lifecycle",
    "summary": "Client Lifecycle An Undici Client can be best described as a state machine. The following list is a summary of the various state transitions the Client will go through in its lifecycle. This document also contains detailed breakdowns of each state. This diagram is not a perfect representation of the undici Client. Since the Client class is not actually implemented as a state-machine, actual execution may deviate slightly from what is described below. Consider this as a general resource for understanding the inner workings of the Undici client rather than some kind of formal specification. State Transition Overview A Client begins in the idle state with no socket connection and no requests in queue. The connect event transitions the Client to the pending state where requests can be queued prior to processing. The close and destroy events transition the Client to the destroyed state. Since there are no requests in the queue, the close event immediately transitions to the destroyed state. The pending state indicates the underlying socket connection has been successfully established and requests are queueing. The process event transitions the Client to the processing state where requests are processed. If requests are queued, the close event transitions to the processing state; otherwise, it transitions to the destroyed state. The destroy event transitions to the destroyed state. The processing state initializes to the processing.running state. If the current request requires draining, the needDrain event transitions the Client into the processing.busy state which will return to the processing.running state with the drainComplete event. After all queued requests are completed, the keepalive event transitions the Client back to the pending state. If no requests are queued during the timeout, the close event transitions the Client to the destroyed state. If the close event is fired while the Client still has queued requests, the Client transitions to the process.closing state where it will complete all existing requests before firing the done event. The done event gracefully transitions the Client to the destroyed state. At any point in time, the destroy event will transition the Client from the processing state to the destroyed state, destroying any queued requests. The destroyed state is a final state and the Client is no longer functional. A state diagram representing an Undici Client instance: stateDiagram-v2 [*] --> idle idle --> pending : connect idle --> destroyed : destroy/close pending --> idle : timeout pending --> destroyed : destroy state close_fork <<fork>> pending --> close_fork : close close_fork --> processing close_fork --> destroyed pending --> processing : process processing --> pending : keepalive processing --> destroyed : done processing --> destroyed : destroy destroyed --> [*] state processing { [*] --> running running --> closing : close running --> busy : needDrain busy --> running : drainComplete running --> [*] : keepalive closing --> [*] : done } State details idle The idle state is the initial state of a Client instance. While an origin is required for instantiating a Client instance, the underlying socket connection will not be established until a request is queued using Client.dispatch(). By calling Client.dispatch() directly or using one of the multiple implementations (Client.connect(), Client.pipeline(), Client.request(), Client.stream(), and Client.upgrade()), the Client instance will transition from idle to pending and then most likely directly to processing. Calling Client.close() or Client.destroy() transitions directly to the destroyed state since the Client instance will have no queued requests in this state. pending The pending state signifies a non-processing Client. Upon entering this state, the Client establishes a socket connection and emits the 'connect' event signalling a connection was successfully established with the origin provided during Client instantiation. The internal queue is initially empty, and requests can start queueing. Calling Client.close() with queued requests, transitions the Client to the processing state. Without queued requests, it transitions to the destroyed state. Calling Client.destroy() transitions directly to the destroyed state regardless of existing requests. processing The processing state is a state machine within itself. It initializes to the processing.running state. The Client.dispatch(), Client.close(), and Client.destroy() can be called at any time while the Client is in this state. Client.dispatch() will add more requests to the queue while existing requests continue to be processed. Client.close() will transition to the processing.closing state. And Client.destroy() will transition to destroyed. running In the processing.running sub-state, queued requests are being processed in a FIFO order. If a request body requires draining, the needDrain event transitions to the processing.busy sub-state. The close event transitions the Client to the process.closing sub-state. If all queued requests are processed and neither Client.close() nor Client.destroy() are called, then the processing machine will trigger a keepalive event transitioning the Client back to the pending state. During this time, the Client is waiting for the socket connection to timeout, and once it does, it triggers the timeout event and transitions to the idle state. busy This sub-state is only entered when a request body is an instance of Stream and requires draining. The Client cannot process additional requests while in this state and must wait until the currently processing request body is completely drained before transitioning back to processing.running. closing This sub-state is only entered when a Client instance has queued requests and the Client.close() method is called. In this state, the Client instance continues to process requests as usual, with the one exception that no additional requests can be queued. Once all of the queued requests are processed, the Client will trigger the done event gracefully entering the destroyed state without an error. destroyed The destroyed state is a final state for the Client instance. Once in this state, a Client is nonfunctional. Calling any other Client methods will result in an ClientDestroyedError."
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/BalancedPool.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/BalancedPool.html",
    "title": "Class: BalancedPool",
    "summary": "Class: BalancedPool Extends: undici.Dispatcher A pool of Pool instances connected to multiple upstreams. Requests are not guaranteed to be dispatched in order of invocation. new BalancedPool(upstreams [, options]) Arguments: upstreams URL | string | string[] - It should only include the protocol, hostname, and port. options BalancedPoolOptions (optional) Parameter: BalancedPoolOptions Extends: PoolOptions factory (origin: URL, opts: Object) => Dispatcher - Default: (origin, opts) => new Pool(origin, opts) The PoolOptions are passed to each of the Pool instances being created. Instance Properties BalancedPool.upstreams Returns an array of upstreams that were previously added. BalancedPool.closed Implements Client.closed BalancedPool.destroyed Implements Client.destroyed Pool.stats Returns PoolStats instance for this pool. Instance Methods BalancedPool.addUpstream(upstream) Add an upstream. Arguments: upstream string - It should only include the protocol, hostname, and port. BalancedPool.removeUpstream(upstream) Removes an upstream that was previously added. BalancedPool.close([callback]) Implements Dispatcher.close([callback]). BalancedPool.destroy([error, callback]) Implements Dispatcher.destroy([error, callback]). BalancedPool.connect(options[, callback]) See Dispatcher.connect(options[, callback]). BalancedPool.dispatch(options, handlers) Implements Dispatcher.dispatch(options, handlers). BalancedPool.pipeline(options, handler) See Dispatcher.pipeline(options, handler). BalancedPool.request(options[, callback]) See Dispatcher.request(options [, callback]). BalancedPool.stream(options, factory[, callback]) See Dispatcher.stream(options, factory[, callback]). BalancedPool.upgrade(options[, callback]) See Dispatcher.upgrade(options[, callback]). Instance Events Event: 'connect' See Dispatcher Event: 'connect'. Event: 'disconnect' See Dispatcher Event: 'disconnect'. Event: 'drain' See Dispatcher Event: 'drain'."
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/CacheStorage.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/CacheStorage.html",
    "title": "CacheStorage",
    "summary": "CacheStorage Undici exposes a W3C spec-compliant implementation of CacheStorage and Cache. Opening a Cache Undici exports a top-level CacheStorage instance. You can open a new Cache, or duplicate a Cache with an existing name, by using CacheStorage.prototype.open. If you open a Cache with the same name as an already-existing Cache, its list of cached Responses will be shared between both instances. import { caches } from 'undici' const cache_1 = await caches.open('v1') const cache_2 = await caches.open('v1') // Although .open() creates a new instance, assert(cache_1 !== cache_2) // The same Response is matched in both. assert.deepStrictEqual(await cache_1.match('/req'), await cache_2.match('/req')) Deleting a Cache If a Cache is deleted, the cached Responses/Requests can still be used. const response = await cache_1.match('/req') await caches.delete('v1') await response.text() // the Response's body"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/Client.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/Client.html",
    "title": "Class: Client",
    "summary": "Class: Client Extends: undici.Dispatcher A basic HTTP/1.1 client, mapped on top a single TCP/TLS connection. Pipelining is disabled by default. Requests are not guaranteed to be dispatched in order of invocation. new Client(url[, options]) Arguments: url URL | string - Should only include the protocol, hostname, and port. options ClientOptions (optional) Returns: Client Parameter: ClientOptions ⚠️ Warning: The H2 support is experimental. bodyTimeout number | null (optional) - Default: 300e3 - The timeout after which a request will time out, in milliseconds. Monitors time between receiving body data. Use 0 to disable it entirely. Defaults to 300 seconds. Please note the timeout will be reset if you keep writing data to the scoket everytime. headersTimeout number | null (optional) - Default: 300e3 - The amount of time, in milliseconds, the parser will wait to receive the complete HTTP headers while not sending the request. Defaults to 300 seconds. keepAliveMaxTimeout number | null (optional) - Default: 600e3 - The maximum allowed keepAliveTimeout, in milliseconds, when overridden by keep-alive hints from the server. Defaults to 10 minutes. keepAliveTimeout number | null (optional) - Default: 4e3 - The timeout, in milliseconds, after which a socket without active requests will time out. Monitors time between activity on a connected socket. This value may be overridden by keep-alive hints from the server. See MDN: HTTP - Headers - Keep-Alive directives for more details. Defaults to 4 seconds. keepAliveTimeoutThreshold number | null (optional) - Default: 2e3 - A number of milliseconds subtracted from server keep-alive hints when overriding keepAliveTimeout to account for timing inaccuracies caused by e.g. transport latency. Defaults to 2 seconds. maxHeaderSize number | null (optional) - Default: --max-http-header-size or 16384 - The maximum length of request headers in bytes. Defaults to Node.js' --max-http-header-size or 16KiB. maxResponseSize number | null (optional) - Default: -1 - The maximum length of response body in bytes. Set to -1 to disable. pipelining number | null (optional) - Default: 1 - The amount of concurrent requests to be sent over the single TCP/TLS connection according to RFC7230. Carefully consider your workload and environment before enabling concurrent requests as pipelining may reduce performance if used incorrectly. Pipelining is sensitive to network stack settings as well as head of line blocking caused by e.g. long running requests. Set to 0 to disable keep-alive connections. connect ConnectOptions | Function | null (optional) - Default: null. strictContentLength Boolean (optional) - Default: true - Whether to treat request content length mismatches as errors. If true, an error is thrown when the request content-length header doesn't match the length of the request body. interceptors { Client: DispatchInterceptor[] } - Default: [RedirectInterceptor] - A list of interceptors that are applied to the dispatch method. Additional logic can be applied (such as, but not limited to: 302 status code handling, authentication, cookies, compression and caching). Note that the behavior of interceptors is Experimental and might change at any given time. Note: this is deprecated in favor of Dispatcher#compose. Support will be droped in next major. autoSelectFamily: boolean (optional) - Default: depends on local Node version, on Node 18.13.0 and above is false. Enables a family autodetection algorithm that loosely implements section 5 of RFC 8305. See here for more details. This option is ignored if not supported by the current Node version. autoSelectFamilyAttemptTimeout: number - Default: depends on local Node version, on Node 18.13.0 and above is 250. The amount of time in milliseconds to wait for a connection attempt to finish before trying the next address when using the autoSelectFamily option. See here for more details. allowH2: boolean - Default: false. Enables support for H2 if the server has assigned bigger priority to it through ALPN negotiation. maxConcurrentStreams: number - Default: 100. Dictates the maximum number of concurrent streams for a single H2 session. It can be overridden by a SETTINGS remote frame. Parameter: ConnectOptions Every Tls option, see here. Furthermore, the following options can be passed: socketPath string | null (optional) - Default: null - An IPC endpoint, either Unix domain socket or Windows named pipe. maxCachedSessions number | null (optional) - Default: 100 - Maximum number of TLS cached sessions. Use 0 to disable TLS session caching. Default: 100. timeout number | null (optional) - In milliseconds, Default 10e3. servername string | null (optional) keepAlive boolean | null (optional) - Default: true - TCP keep-alive enabled keepAliveInitialDelay number | null (optional) - Default: 60000 - TCP keep-alive interval for the socket in milliseconds Example - Basic Client instantiation This will instantiate the undici Client, but it will not connect to the origin until something is queued. Consider using client.connect to prematurely connect to the origin, or just call client.request. 'use strict' import { Client } from 'undici' const client = new Client('http://localhost:3000') Example - Custom connector This will allow you to perform some additional check on the socket that will be used for the next request. 'use strict' import { Client, buildConnector } from 'undici' const connector = buildConnector({ rejectUnauthorized: false }) const client = new Client('https://localhost:3000', { connect (opts, cb) { connector(opts, (err, socket) => { if (err) { cb(err) } else if (/* assertion */) { socket.destroy() cb(new Error('kaboom')) } else { cb(null, socket) } }) } }) Instance Methods Client.close([callback]) Implements Dispatcher.close([callback]). Client.destroy([error, callback]) Implements Dispatcher.destroy([error, callback]). Waits until socket is closed before invoking the callback (or returning a promise if no callback is provided). Client.connect(options[, callback]) See Dispatcher.connect(options[, callback]). Client.dispatch(options, handlers) Implements Dispatcher.dispatch(options, handlers). Client.pipeline(options, handler) See Dispatcher.pipeline(options, handler). Client.request(options[, callback]) See Dispatcher.request(options [, callback]). Client.stream(options, factory[, callback]) See Dispatcher.stream(options, factory[, callback]). Client.upgrade(options[, callback]) See Dispatcher.upgrade(options[, callback]). Instance Properties Client.closed boolean true after client.close() has been called. Client.destroyed boolean true after client.destroyed() has been called or client.close() has been called and the client shutdown has completed. Client.pipelining number Property to get and set the pipelining factor. Instance Events Event: 'connect' See Dispatcher Event: 'connect'. Parameters: origin URL targets Array<Dispatcher> Emitted when a socket has been created and connected. The client will connect once client.size > 0. Example - Client connect event import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' const server = createServer((request, response) => { response.end('Hello, World!') }).listen() await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) client.on('connect', (origin) => { console.log(`Connected to ${origin}`) // should print before the request body statement }) try { const { body } = await client.request({ path: '/', method: 'GET' }) body.setEncoding('utf-8') body.on('data', console.log) client.close() server.close() } catch (error) { console.error(error) client.close() server.close() } Event: 'disconnect' See Dispatcher Event: 'disconnect'. Parameters: origin URL targets Array<Dispatcher> error Error Emitted when socket has disconnected. The error argument of the event is the error which caused the socket to disconnect. The client will reconnect if or once client.size > 0. Example - Client disconnect event import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' const server = createServer((request, response) => { response.destroy() }).listen() await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) client.on('disconnect', (origin) => { console.log(`Disconnected from ${origin}`) }) try { await client.request({ path: '/', method: 'GET' }) } catch (error) { console.error(error.message) client.close() server.close() } Event: 'drain' Emitted when pipeline is no longer busy. See Dispatcher Event: 'drain'. Example - Client drain event import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' const server = createServer((request, response) => { response.end('Hello, World!') }).listen() await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) client.on('drain', () => { console.log('drain event') client.close() server.close() }) const requests = [ client.request({ path: '/', method: 'GET' }), client.request({ path: '/', method: 'GET' }), client.request({ path: '/', method: 'GET' }) ] await Promise.all(requests) console.log('requests completed') Event: 'error' Invoked for users errors such as throwing in the onError handler."
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/Connector.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/Connector.html",
    "title": "Connector",
    "summary": "Connector Undici creates the underlying socket via the connector builder. Normally, this happens automatically and you don't need to care about this, but if you need to perform some additional check over the currently used socket, this is the right place. If you want to create a custom connector, you must import the buildConnector utility. Parameter: buildConnector.BuildOptions Every Tls option, see here. Furthermore, the following options can be passed: socketPath string | null (optional) - Default: null - An IPC endpoint, either Unix domain socket or Windows named pipe. maxCachedSessions number | null (optional) - Default: 100 - Maximum number of TLS cached sessions. Use 0 to disable TLS session caching. Default: 100. timeout number | null (optional) - In milliseconds. Default 10e3. servername string | null (optional) Once you call buildConnector, it will return a connector function, which takes the following parameters. Parameter: connector.Options hostname string (required) host string (optional) protocol string (required) port string (required) servername string (optional) localAddress string | null (optional) Local address the socket should connect from. httpSocket Socket (optional) Establish secure connection on a given socket rather than creating a new socket. It can only be sent on TLS update. Basic example 'use strict' import { Client, buildConnector } from 'undici' const connector = buildConnector({ rejectUnauthorized: false }) const client = new Client('https://localhost:3000', { connect (opts, cb) { connector(opts, (err, socket) => { if (err) { cb(err) } else if (/* assertion */) { socket.destroy() cb(new Error('kaboom')) } else { cb(null, socket) } }) } }) Example: validate the CA fingerprint 'use strict' import { Client, buildConnector } from 'undici' const caFingerprint = 'FO:OB:AR' const connector = buildConnector({ rejectUnauthorized: false }) const client = new Client('https://localhost:3000', { connect (opts, cb) { connector(opts, (err, socket) => { if (err) { cb(err) } else if (getIssuerCertificate(socket).fingerprint256 !== caFingerprint) { socket.destroy() cb(new Error('Fingerprint does not match or malformed certificate')) } else { cb(null, socket) } }) } }) client.request({ path: '/', method: 'GET' }, (err, data) => { if (err) throw err const bufs = [] data.body.on('data', (buf) => { bufs.push(buf) }) data.body.on('end', () => { console.log(Buffer.concat(bufs).toString('utf8')) client.close() }) }) function getIssuerCertificate (socket) { let certificate = socket.getPeerCertificate(true) while (certificate && Object.keys(certificate).length > 0) { // invalid certificate if (certificate.issuerCertificate == null) { return null } // We have reached the root certificate. // In case of self-signed certificates, `issuerCertificate` may be a circular reference. if (certificate.fingerprint256 === certificate.issuerCertificate.fingerprint256) { break } // continue the loop certificate = certificate.issuerCertificate } return certificate }"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/ContentType.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/ContentType.html",
    "title": "MIME Type Parsing",
    "summary": "MIME Type Parsing MIMEType interface type string subtype string parameters Map<string, string> essence string parseMIMEType(input) Implements parse a MIME type. Parses a MIME type, returning its type, subtype, and any associated parameters. If the parser can't parse an input it returns the string literal 'failure'. import { parseMIMEType } from 'undici' parseMIMEType('text/html; charset=gbk') // { // type: 'text', // subtype: 'html', // parameters: Map(1) { 'charset' => 'gbk' }, // essence: 'text/html' // } Arguments: input string Returns: MIMEType|'failure' serializeAMimeType(input) Implements serialize a MIME type. Serializes a MIMEType object. import { serializeAMimeType } from 'undici' serializeAMimeType({ type: 'text', subtype: 'html', parameters: new Map([['charset', 'gbk']]), essence: 'text/html' }) // text/html;charset=gbk Arguments: mimeType MIMEType Returns: string"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/Cookies.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/Cookies.html",
    "title": "Cookie Handling",
    "summary": "Cookie Handling Cookie interface name string value string expires Date|number (optional) maxAge number (optional) domain string (optional) path string (optional) secure boolean (optional) httpOnly boolean (optional) sameSite 'String'|'Lax'|'None' (optional) unparsed string[] (optional) Left over attributes that weren't parsed. deleteCookie(headers, name[, attributes]) Sets the expiry time of the cookie to the unix epoch, causing browsers to delete it when received. import { deleteCookie, Headers } from 'undici' const headers = new Headers() deleteCookie(headers, 'name') console.log(headers.get('set-cookie')) // name=; Expires=Thu, 01 Jan 1970 00:00:00 GMT Arguments: headers Headers name string attributes { path?: string, domain?: string } (optional) Returns: void getCookies(headers) Parses the Cookie header and returns a list of attributes and values. import { getCookies, Headers } from 'undici' const headers = new Headers({ cookie: 'get=cookies; and=attributes' }) console.log(getCookies(headers)) // { get: 'cookies', and: 'attributes' } Arguments: headers Headers Returns: Record<string, string> getSetCookies(headers) Parses all Set-Cookie headers. import { getSetCookies, Headers } from 'undici' const headers = new Headers({ 'set-cookie': 'undici=getSetCookies; Secure' }) console.log(getSetCookies(headers)) // [ // { // name: 'undici', // value: 'getSetCookies', // secure: true // } // ] Arguments: headers Headers Returns: Cookie[] setCookie(headers, cookie) Appends a cookie to the Set-Cookie header. import { setCookie, Headers } from 'undici' const headers = new Headers() setCookie(headers, { name: 'undici', value: 'setCookie' }) console.log(headers.get('Set-Cookie')) // undici=setCookie Arguments: headers Headers cookie Cookie Returns: void"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/Debug.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/Debug.html",
    "title": "Debug",
    "summary": "Debug Undici (and subsenquently fetch and websocket) exposes a debug statement that can be enabled by setting NODE_DEBUG within the environment. The flags availabile are: undici This flag enables debug statements for the core undici library. NODE_DEBUG=undici node script.js UNDICI 16241: connecting to nodejs.org using https:h1 UNDICI 16241: connecting to nodejs.org using https:h1 UNDICI 16241: connected to nodejs.org using https:h1 UNDICI 16241: sending request to GET https://nodejs.org// UNDICI 16241: received response to GET https://nodejs.org// - HTTP 307 UNDICI 16241: connecting to nodejs.org using https:h1 UNDICI 16241: trailers received from GET https://nodejs.org// UNDICI 16241: connected to nodejs.org using https:h1 UNDICI 16241: sending request to GET https://nodejs.org//en UNDICI 16241: received response to GET https://nodejs.org//en - HTTP 200 UNDICI 16241: trailers received from GET https://nodejs.org//en fetch This flag enables debug statements for the fetch API. Note: statements are pretty similar to the ones in the undici flag, but scoped to fetch NODE_DEBUG=fetch node script.js FETCH 16241: connecting to nodejs.org using https:h1 FETCH 16241: connecting to nodejs.org using https:h1 FETCH 16241: connected to nodejs.org using https:h1 FETCH 16241: sending request to GET https://nodejs.org// FETCH 16241: received response to GET https://nodejs.org// - HTTP 307 FETCH 16241: connecting to nodejs.org using https:h1 FETCH 16241: trailers received from GET https://nodejs.org// FETCH 16241: connected to nodejs.org using https:h1 FETCH 16241: sending request to GET https://nodejs.org//en FETCH 16241: received response to GET https://nodejs.org//en - HTTP 200 FETCH 16241: trailers received from GET https://nodejs.org//en websocket This flag enables debug statements for the Websocket API. Note: statements can overlap with UNDICI ones if undici or fetch flag has been enabled as well. NODE_DEBUG=websocket node script.js WEBSOCKET 18309: connecting to echo.websocket.org using https:h1 WEBSOCKET 18309: connected to echo.websocket.org using https:h1 WEBSOCKET 18309: sending request to GET https://echo.websocket.org// WEBSOCKET 18309: connection opened <ip_address>"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/DiagnosticsChannel.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/DiagnosticsChannel.html",
    "title": "Diagnostics Channel Support",
    "summary": "Diagnostics Channel Support Stability: Experimental. Undici supports the diagnostics_channel (currently available only on Node.js v16+). It is the preferred way to instrument Undici and retrieve internal information. The channels available are the following. undici:request:create This message is published when a new outgoing request is created. import diagnosticsChannel from 'diagnostics_channel' diagnosticsChannel.channel('undici:request:create').subscribe(({ request }) => { console.log('origin', request.origin) console.log('completed', request.completed) console.log('method', request.method) console.log('path', request.path) console.log('headers') // array of strings, e.g: ['foo', 'bar'] request.addHeader('hello', 'world') console.log('headers', request.headers) // e.g. ['foo', 'bar', 'hello', 'world'] }) Note: a request is only loosely completed to a given socket. undici:request:bodySent import diagnosticsChannel from 'diagnostics_channel' diagnosticsChannel.channel('undici:request:bodySent').subscribe(({ request }) => { // request is the same object undici:request:create }) undici:request:headers This message is published after the response headers have been received, i.e. the response has been completed. import diagnosticsChannel from 'diagnostics_channel' diagnosticsChannel.channel('undici:request:headers').subscribe(({ request, response }) => { // request is the same object undici:request:create console.log('statusCode', response.statusCode) console.log(response.statusText) // response.headers are buffers. console.log(response.headers.map((x) => x.toString())) }) undici:request:trailers This message is published after the response body and trailers have been received, i.e. the response has been completed. import diagnosticsChannel from 'diagnostics_channel' diagnosticsChannel.channel('undici:request:trailers').subscribe(({ request, trailers }) => { // request is the same object undici:request:create console.log('completed', request.completed) // trailers are buffers. console.log(trailers.map((x) => x.toString())) }) undici:request:error This message is published if the request is going to error, but it has not errored yet. import diagnosticsChannel from 'diagnostics_channel' diagnosticsChannel.channel('undici:request:error').subscribe(({ request, error }) => { // request is the same object undici:request:create }) undici:client:sendHeaders This message is published right before the first byte of the request is written to the socket. Note: It will publish the exact headers that will be sent to the server in raw format. import diagnosticsChannel from 'diagnostics_channel' diagnosticsChannel.channel('undici:client:sendHeaders').subscribe(({ request, headers, socket }) => { // request is the same object undici:request:create console.log(`Full headers list ${headers.split('\\r\\n')}`); }) undici:client:beforeConnect This message is published before creating a new connection for any request. You can not assume that this event is related to any specific request. import diagnosticsChannel from 'diagnostics_channel' diagnosticsChannel.channel('undici:client:beforeConnect').subscribe(({ connectParams, connector }) => { // const { host, hostname, protocol, port, servername, version } = connectParams // connector is a function that creates the socket }) undici:client:connected This message is published after a connection is established. import diagnosticsChannel from 'diagnostics_channel' diagnosticsChannel.channel('undici:client:connected').subscribe(({ socket, connectParams, connector }) => { // const { host, hostname, protocol, port, servername, version } = connectParams // connector is a function that creates the socket }) undici:client:connectError This message is published if it did not succeed to create new connection import diagnosticsChannel from 'diagnostics_channel' diagnosticsChannel.channel('undici:client:connectError').subscribe(({ error, socket, connectParams, connector }) => { // const { host, hostname, protocol, port, servername, version } = connectParams // connector is a function that creates the socket console.log(`Connect failed with ${error.message}`) }) undici:websocket:open This message is published after the client has successfully connected to a server. import diagnosticsChannel from 'diagnostics_channel' diagnosticsChannel.channel('undici:websocket:open').subscribe(({ address, protocol, extensions }) => { console.log(address) // address, family, and port console.log(protocol) // negotiated subprotocols console.log(extensions) // negotiated extensions }) undici:websocket:close This message is published after the connection has closed. import diagnosticsChannel from 'diagnostics_channel' diagnosticsChannel.channel('undici:websocket:close').subscribe(({ websocket, code, reason }) => { console.log(websocket) // the WebSocket object console.log(code) // the closing status code console.log(reason) // the closing reason }) undici:websocket:socket_error This message is published if the socket experiences an error. import diagnosticsChannel from 'diagnostics_channel' diagnosticsChannel.channel('undici:websocket:socket_error').subscribe((error) => { console.log(error) }) undici:websocket:ping This message is published after the client receives a ping frame, if the connection is not closing. import diagnosticsChannel from 'diagnostics_channel' diagnosticsChannel.channel('undici:websocket:ping').subscribe(({ payload }) => { // a Buffer or undefined, containing the optional application data of the frame console.log(payload) }) undici:websocket:pong This message is published after the client receives a pong frame. import diagnosticsChannel from 'diagnostics_channel' diagnosticsChannel.channel('undici:websocket:pong').subscribe(({ payload }) => { // a Buffer or undefined, containing the optional application data of the frame console.log(payload) })"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/Dispatcher.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/Dispatcher.html",
    "title": "Dispatcher",
    "summary": "Dispatcher Extends: events.EventEmitter Dispatcher is the core API used to dispatch requests. Requests are not guaranteed to be dispatched in order of invocation. Instance Methods Dispatcher.close([callback]): Promise Closes the dispatcher and gracefully waits for enqueued requests to complete before resolving. Arguments: callback (error: Error | null, data: null) => void (optional) Returns: void | Promise<null> - Only returns a Promise if no callback argument was passed dispatcher.close() // -> Promise dispatcher.close(() => {}) // -> void Example - Request resolves before Client closes import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' const server = createServer((request, response) => { response.end('undici') }).listen() await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) try { const { body } = await client.request({ path: '/', method: 'GET' }) body.setEncoding('utf8') body.on('data', console.log) } catch (error) {} await client.close() console.log('Client closed') server.close() Dispatcher.connect(options[, callback]) Starts two-way communications with the requested resource using HTTP CONNECT. Arguments: options ConnectOptions callback (err: Error | null, data: ConnectData | null) => void (optional) Returns: void | Promise<ConnectData> - Only returns a Promise if no callback argument was passed Parameter: ConnectOptions path string headers UndiciHeaders (optional) - Default: null signal AbortSignal | events.EventEmitter | null (optional) - Default: null opaque unknown (optional) - This argument parameter is passed through to ConnectData Parameter: ConnectData statusCode number headers Record<string, string | string[] | undefined> socket stream.Duplex opaque unknown Example - Connect request with echo import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' const server = createServer((request, response) => { throw Error('should never get here') }).listen() server.on('connect', (req, socket, head) => { socket.write('HTTP/1.1 200 Connection established\\r\\n\\r\\n') let data = head.toString() socket.on('data', (buf) => { data += buf.toString() }) socket.on('end', () => { socket.end(data) }) }) await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) try { const { socket } = await client.connect({ path: '/' }) const wanted = 'Body' let data = '' socket.on('data', d => { data += d }) socket.on('end', () => { console.log(`Data received: ${data.toString()} | Data wanted: ${wanted}`) client.close() server.close() }) socket.write(wanted) socket.end() } catch (error) { } Dispatcher.destroy([error, callback]): Promise Destroy the dispatcher abruptly with the given error. All the pending and running requests will be asynchronously aborted and error. Since this operation is asynchronously dispatched there might still be some progress on dispatched requests. Both arguments are optional; the method can be called in four different ways: Arguments: error Error | null (optional) callback (error: Error | null, data: null) => void (optional) Returns: void | Promise<void> - Only returns a Promise if no callback argument was passed dispatcher.destroy() // -> Promise dispatcher.destroy(new Error()) // -> Promise dispatcher.destroy(() => {}) // -> void dispatcher.destroy(new Error(), () => {}) // -> void Example - Request is aborted when Client is destroyed import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' const server = createServer((request, response) => { response.end() }).listen() await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) try { const request = client.request({ path: '/', method: 'GET' }) client.destroy() .then(() => { console.log('Client destroyed') server.close() }) await request } catch (error) { console.error(error) } Dispatcher.dispatch(options, handler) This is the low level API which all the preceding APIs are implemented on top of. This API is expected to evolve through semver-major versions and is less stable than the preceding higher level APIs. It is primarily intended for library developers who implement higher level APIs on top of this. Arguments: options DispatchOptions handler DispatchHandler Returns: Boolean - false if dispatcher is busy and further dispatch calls won't make any progress until the 'drain' event has been emitted. Parameter: DispatchOptions origin string | URL path string method string reset boolean (optional) - Default: false - If false, the request will attempt to create a long-living connection by sending the connection: keep-alive header,otherwise will attempt to close it immediately after response by sending connection: close within the request and closing the socket afterwards. body string | Buffer | Uint8Array | stream.Readable | Iterable | AsyncIterable | null (optional) - Default: null headers UndiciHeaders | string[] (optional) - Default: null. query Record<string, any> | null (optional) - Default: null - Query string params to be embedded in the request URL. Note that both keys and values of query are encoded using encodeURIComponent. If for some reason you need to send them unencoded, embed query params into path directly instead. idempotent boolean (optional) - Default: true if method is 'HEAD' or 'GET' - Whether the requests can be safely retried or not. If false the request won't be sent until all preceding requests in the pipeline has completed. blocking boolean (optional) - Default: false - Whether the response is expected to take a long time and would end up blocking the pipeline. When this is set to true further pipelining will be avoided on the same connection until headers have been received. upgrade string | null (optional) - Default: null - Upgrade the request. Should be used to specify the kind of upgrade i.e. 'Websocket'. bodyTimeout number | null (optional) - The timeout after which a request will time out, in milliseconds. Monitors time between receiving body data. Use 0 to disable it entirely. Defaults to 300 seconds. headersTimeout number | null (optional) - The amount of time, in milliseconds, the parser will wait to receive the complete HTTP headers while not sending the request. Defaults to 300 seconds. throwOnError boolean (optional) - Default: false - Whether Undici should throw an error upon receiving a 4xx or 5xx response from the server. expectContinue boolean (optional) - Default: false - For H2, it appends the expect: 100-continue header, and halts the request body until a 100-continue is received from the remote server Parameter: DispatchHandler onConnect (abort: () => void, context: object) => void - Invoked before request is dispatched on socket. May be invoked multiple times when a request is retried when the request at the head of the pipeline fails. onError (error: Error) => void - Invoked when an error has occurred. May not throw. onUpgrade (statusCode: number, headers: Buffer[], socket: Duplex) => void (optional) - Invoked when request is upgraded. Required if DispatchOptions.upgrade is defined or DispatchOptions.method === 'CONNECT'. onResponseStarted () => void (optional) - Invoked when response is received, before headers have been read. onHeaders (statusCode: number, headers: Buffer[], resume: () => void, statusText: string) => boolean - Invoked when statusCode and headers have been received. May be invoked multiple times due to 1xx informational headers. Not required for upgrade requests. onData (chunk: Buffer) => boolean - Invoked when response payload data is received. Not required for upgrade requests. onComplete (trailers: Buffer[]) => void - Invoked when response payload and trailers have been received and the request has completed. Not required for upgrade requests. onBodySent (chunk: string | Buffer | Uint8Array) => void - Invoked when a body chunk is sent to the server. Not required. For a stream or iterable body this will be invoked for every chunk. For other body types, it will be invoked once after the body is sent. Example 1 - Dispatch GET request import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' const server = createServer((request, response) => { response.end('Hello, World!') }).listen() await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) const data = [] client.dispatch({ path: '/', method: 'GET', headers: { 'x-foo': 'bar' } }, { onConnect: () => { console.log('Connected!') }, onError: (error) => { console.error(error) }, onHeaders: (statusCode, headers) => { console.log(`onHeaders | statusCode: ${statusCode} | headers: ${headers}`) }, onData: (chunk) => { console.log('onData: chunk received') data.push(chunk) }, onComplete: (trailers) => { console.log(`onComplete | trailers: ${trailers}`) const res = Buffer.concat(data).toString('utf8') console.log(`Data: ${res}`) client.close() server.close() } }) Example 2 - Dispatch Upgrade Request import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' const server = createServer((request, response) => { response.end() }).listen() await once(server, 'listening') server.on('upgrade', (request, socket, head) => { console.log('Node.js Server - upgrade event') socket.write('HTTP/1.1 101 Web Socket Protocol Handshake\\r\\n') socket.write('Upgrade: WebSocket\\r\\n') socket.write('Connection: Upgrade\\r\\n') socket.write('\\r\\n') socket.end() }) const client = new Client(`http://localhost:${server.address().port}`) client.dispatch({ path: '/', method: 'GET', upgrade: 'websocket' }, { onConnect: () => { console.log('Undici Client - onConnect') }, onError: (error) => { console.log('onError') // shouldn't print }, onUpgrade: (statusCode, headers, socket) => { console.log('Undici Client - onUpgrade') console.log(`onUpgrade Headers: ${headers}`) socket.on('data', buffer => { console.log(buffer.toString('utf8')) }) socket.on('end', () => { client.close() server.close() }) socket.end() } }) Example 3 - Dispatch POST request import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' const server = createServer((request, response) => { request.on('data', (data) => { console.log(`Request Data: ${data.toString('utf8')}`) const body = JSON.parse(data) body.message = 'World' response.end(JSON.stringify(body)) }) }).listen() await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) const data = [] client.dispatch({ path: '/', method: 'POST', headers: { 'content-type': 'application/json' }, body: JSON.stringify({ message: 'Hello' }) }, { onConnect: () => { console.log('Connected!') }, onError: (error) => { console.error(error) }, onHeaders: (statusCode, headers) => { console.log(`onHeaders | statusCode: ${statusCode} | headers: ${headers}`) }, onData: (chunk) => { console.log('onData: chunk received') data.push(chunk) }, onComplete: (trailers) => { console.log(`onComplete | trailers: ${trailers}`) const res = Buffer.concat(data).toString('utf8') console.log(`Response Data: ${res}`) client.close() server.close() } }) Dispatcher.pipeline(options, handler) For easy use with stream.pipeline. The handler argument should return a Readable from which the result will be read. Usually it should just return the body argument unless some kind of transformation needs to be performed based on e.g. headers or statusCode. The handler should validate the response and save any required state. If there is an error, it should be thrown. The function returns a Duplex which writes to the request and reads from the response. Arguments: options PipelineOptions handler (data: PipelineHandlerData) => stream.Readable Returns: stream.Duplex Parameter: PipelineOptions Extends: RequestOptions objectMode boolean (optional) - Default: false - Set to true if the handler will return an object stream. Parameter: PipelineHandlerData statusCode number headers Record<string, string | string[] | undefined> opaque unknown body stream.Readable context object onInfo ({statusCode: number, headers: Record<string, string | string[]>}) => void | null (optional) - Default: null - Callback collecting all the info headers (HTTP 100-199) received. Example 1 - Pipeline Echo import { Readable, Writable, PassThrough, pipeline } from 'stream' import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' const server = createServer((request, response) => { request.pipe(response) }).listen() await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) let res = '' pipeline( new Readable({ read () { this.push(Buffer.from('undici')) this.push(null) } }), client.pipeline({ path: '/', method: 'GET' }, ({ statusCode, headers, body }) => { console.log(`response received ${statusCode}`) console.log('headers', headers) return pipeline(body, new PassThrough(), () => {}) }), new Writable({ write (chunk, _, callback) { res += chunk.toString() callback() }, final (callback) { console.log(`Response pipelined to writable: ${res}`) callback() } }), error => { if (error) { console.error(error) } client.close() server.close() } ) Dispatcher.request(options[, callback]) Performs a HTTP request. Non-idempotent requests will not be pipelined in order to avoid indirect failures. Idempotent requests will be automatically retried if they fail due to indirect failure from the request at the head of the pipeline. This does not apply to idempotent requests with a stream request body. All response bodies must always be fully consumed or destroyed. Arguments: options RequestOptions callback (error: Error | null, data: ResponseData) => void (optional) Returns: void | Promise<ResponseData> - Only returns a Promise if no callback argument was passed. Parameter: RequestOptions Extends: DispatchOptions opaque unknown (optional) - Default: null - Used for passing through context to ResponseData. signal AbortSignal | events.EventEmitter | null (optional) - Default: null. onInfo ({statusCode: number, headers: Record<string, string | string[]>}) => void | null (optional) - Default: null - Callback collecting all the info headers (HTTP 100-199) received. The RequestOptions.method property should not be value 'CONNECT'. Parameter: ResponseData statusCode number headers Record<string, string | string[]> - Note that all header keys are lower-cased, e. g. content-type. body stream.Readable which also implements the body mixin from the Fetch Standard. trailers Record<string, string> - This object starts out as empty and will be mutated to contain trailers after body has emitted 'end'. opaque unknown context object body contains the following additional body mixin methods and properties: .arrayBuffer() .blob() .bytes() .json() .text() body bodyUsed body can not be consumed twice. For example, calling text() after json() throws TypeError. body contains the following additional extensions: dump({ limit: Integer }), dump the response by reading up to limit bytes without killing the socket (optional) - Default: 262144. Note that body will still be a Readable even if it is empty, but attempting to deserialize it with json() will result in an exception. Recommended way to ensure there is a body to deserialize is to check if status code is not 204, and content-type header starts with application/json. Example 1 - Basic GET Request import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' const server = createServer((request, response) => { response.end('Hello, World!') }).listen() await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) try { const { body, headers, statusCode, trailers } = await client.request({ path: '/', method: 'GET' }) console.log(`response received ${statusCode}`) console.log('headers', headers) body.setEncoding('utf8') body.on('data', console.log) body.on('end', () => { console.log('trailers', trailers) }) client.close() server.close() } catch (error) { console.error(error) } Example 2 - Aborting a request Node.js v15+ is required to run this example import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' const server = createServer((request, response) => { response.end('Hello, World!') }).listen() await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) const abortController = new AbortController() try { client.request({ path: '/', method: 'GET', signal: abortController.signal }) } catch (error) { console.error(error) // should print an RequestAbortedError client.close() server.close() } abortController.abort() Alternatively, any EventEmitter that emits an 'abort' event may be used as an abort controller: import { createServer } from 'http' import { Client } from 'undici' import EventEmitter, { once } from 'events' const server = createServer((request, response) => { response.end('Hello, World!') }).listen() await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) const ee = new EventEmitter() try { client.request({ path: '/', method: 'GET', signal: ee }) } catch (error) { console.error(error) // should print an RequestAbortedError client.close() server.close() } ee.emit('abort') Destroying the request or response body will have the same effect. import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' const server = createServer((request, response) => { response.end('Hello, World!') }).listen() await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) try { const { body } = await client.request({ path: '/', method: 'GET' }) body.destroy() } catch (error) { console.error(error) // should print an RequestAbortedError client.close() server.close() } Dispatcher.stream(options, factory[, callback]) A faster version of Dispatcher.request. This method expects the second argument factory to return a stream.Writable stream which the response will be written to. This improves performance by avoiding creating an intermediate stream.Readable stream when the user expects to directly pipe the response body to a stream.Writable stream. As demonstrated in Example 1 - Basic GET stream request, it is recommended to use the option.opaque property to avoid creating a closure for the factory method. This pattern works well with Node.js Web Frameworks such as Fastify. See Example 2 - Stream to Fastify Response for more details. Arguments: options RequestOptions factory (data: StreamFactoryData) => stream.Writable callback (error: Error | null, data: StreamData) => void (optional) Returns: void | Promise<StreamData> - Only returns a Promise if no callback argument was passed Parameter: StreamFactoryData statusCode number headers Record<string, string | string[] | undefined> opaque unknown onInfo ({statusCode: number, headers: Record<string, string | string[]>}) => void | null (optional) - Default: null - Callback collecting all the info headers (HTTP 100-199) received. Parameter: StreamData opaque unknown trailers Record<string, string> context object Example 1 - Basic GET stream request import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' import { Writable } from 'stream' const server = createServer((request, response) => { response.end('Hello, World!') }).listen() await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) const bufs = [] try { await client.stream({ path: '/', method: 'GET', opaque: { bufs } }, ({ statusCode, headers, opaque: { bufs } }) => { console.log(`response received ${statusCode}`) console.log('headers', headers) return new Writable({ write (chunk, encoding, callback) { bufs.push(chunk) callback() } }) }) console.log(Buffer.concat(bufs).toString('utf-8')) client.close() server.close() } catch (error) { console.error(error) } Example 2 - Stream to Fastify Response In this example, a (fake) request is made to the fastify server using fastify.inject(). This request then executes the fastify route handler which makes a subsequent request to the raw Node.js http server using undici.dispatcher.stream(). The fastify response is passed to the opaque option so that undici can tap into the underlying writable stream using response.raw. This methodology demonstrates how one could use undici and fastify together to create fast-as-possible requests from one backend server to another. import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' import fastify from 'fastify' const nodeServer = createServer((request, response) => { response.end('Hello, World! From Node.js HTTP Server') }).listen() await once(nodeServer, 'listening') console.log('Node Server listening') const nodeServerUndiciClient = new Client(`http://localhost:${nodeServer.address().port}`) const fastifyServer = fastify() fastifyServer.route({ url: '/', method: 'GET', handler: (request, response) => { nodeServerUndiciClient.stream({ path: '/', method: 'GET', opaque: response }, ({ opaque }) => opaque.raw) } }) await fastifyServer.listen() console.log('Fastify Server listening') const fastifyServerUndiciClient = new Client(`http://localhost:${fastifyServer.server.address().port}`) try { const { statusCode, body } = await fastifyServerUndiciClient.request({ path: '/', method: 'GET' }) console.log(`response received ${statusCode}`) body.setEncoding('utf8') body.on('data', console.log) nodeServerUndiciClient.close() fastifyServerUndiciClient.close() fastifyServer.close() nodeServer.close() } catch (error) { } Dispatcher.upgrade(options[, callback]) Upgrade to a different protocol. Visit MDN - HTTP - Protocol upgrade mechanism for more details. Arguments: options UpgradeOptions callback (error: Error | null, data: UpgradeData) => void (optional) Returns: void | Promise<UpgradeData> - Only returns a Promise if no callback argument was passed Parameter: UpgradeOptions path string method string (optional) - Default: 'GET' headers UndiciHeaders (optional) - Default: null protocol string (optional) - Default: 'Websocket' - A string of comma separated protocols, in descending preference order. signal AbortSignal | EventEmitter | null (optional) - Default: null Parameter: UpgradeData headers http.IncomingHeaders socket stream.Duplex opaque unknown Example 1 - Basic Upgrade Request import { createServer } from 'http' import { Client } from 'undici' import { once } from 'events' const server = createServer((request, response) => { response.statusCode = 101 response.setHeader('connection', 'upgrade') response.setHeader('upgrade', request.headers.upgrade) response.end() }).listen() await once(server, 'listening') const client = new Client(`http://localhost:${server.address().port}`) try { const { headers, socket } = await client.upgrade({ path: '/', }) socket.on('end', () => { console.log(`upgrade: ${headers.upgrade}`) // upgrade: Websocket client.close() server.close() }) socket.end() } catch (error) { console.error(error) client.close() server.close() } Dispatcher.compose(interceptors[, interceptor]) Compose a new dispatcher from the current dispatcher and the given interceptors. Notes: The order of the interceptors matters. The first interceptor will be the first to be called. It is important to note that the interceptor function should return a function that follows the Dispatcher.dispatch signature. Any fork of the chain of interceptors can lead to unexpected results. Arguments: interceptors Interceptor[interceptor[]]: It is an array of Interceptor functions passed as only argument, or several interceptors passed as separate arguments. Returns: Dispatcher. Parameter: Interceptor A function that takes a dispatch method and returns a dispatch-like function. Example 1 - Basic Compose const { Client, RedirectHandler } = require('undici') const redirectInterceptor = dispatch => { return (opts, handler) => { const { maxRedirections } = opts if (!maxRedirections) { return dispatch(opts, handler) } const redirectHandler = new RedirectHandler( dispatch, maxRedirections, opts, handler ) opts = { ...opts, maxRedirections: 0 } // Stop sub dispatcher from also redirecting. return dispatch(opts, redirectHandler) } } const client = new Client('http://localhost:3000') .compose(redirectInterceptor) await client.request({ path: '/', method: 'GET' }) Example 2 - Chained Compose const { Client, RedirectHandler, RetryHandler } = require('undici') const redirectInterceptor = dispatch => { return (opts, handler) => { const { maxRedirections } = opts if (!maxRedirections) { return dispatch(opts, handler) } const redirectHandler = new RedirectHandler( dispatch, maxRedirections, opts, handler ) opts = { ...opts, maxRedirections: 0 } return dispatch(opts, redirectHandler) } } const retryInterceptor = dispatch => { return function retryInterceptor (opts, handler) { return dispatch( opts, new RetryHandler(opts, { handler, dispatch }) ) } } const client = new Client('http://localhost:3000') .compose(redirectInterceptor) .compose(retryInterceptor) await client.request({ path: '/', method: 'GET' }) Pre-built interceptors redirect The redirect interceptor allows you to customize the way your dispatcher handles redirects. It accepts the same arguments as the RedirectHandler constructor. Example - Basic Redirect Interceptor const { Client, interceptors } = require(\"undici\"); const { redirect } = interceptors; const client = new Client(\"http://example.com\").compose( redirect({ maxRedirections: 3, throwOnMaxRedirects: true }) ); client.request({ path: \"/\" }) retry The retry interceptor allows you to customize the way your dispatcher handles retries. It accepts the same arguments as the RetryHandler constructor. Example - Basic Redirect Interceptor const { Client, interceptors } = require(\"undici\"); const { retry } = interceptors; const client = new Client(\"http://example.com\").compose( retry({ maxRetries: 3, minTimeout: 1000, maxTimeout: 10000, timeoutFactor: 2, retryAfter: true, }) ); dump The dump interceptor enables you to dump the response body from a request upon a given limit. Options maxSize - The maximum size (in bytes) of the response body to dump. If the size of the request's body exceeds this value then the connection will be closed. Default: 1048576. The Dispatcher#options also gets extended with the options dumpMaxSize, abortOnDumped, and waitForTrailers which can be used to configure the interceptor at a request-per-request basis. Example - Basic Dump Interceptor const { Client, interceptors } = require(\"undici\"); const { dump } = interceptors; const client = new Client(\"http://example.com\").compose( dump({ maxSize: 1024, }) ); // or client.dispatch( { path: \"/\", method: \"GET\", dumpMaxSize: 1024, }, handler ); dns The dns interceptor enables you to cache DNS lookups for a given duration, per origin. It is well suited for scenarios where you want to cache DNS lookups to avoid the overhead of resolving the same domain multiple times Options maxTTL - The maximum time-to-live (in milliseconds) of the DNS cache. It should be a positive integer. Default: 10000. Set 0 to disable TTL. maxItems - The maximum number of items to cache. It should be a positive integer. Default: Infinity. dualStack - Whether to resolve both IPv4 and IPv6 addresses. Default: true. It will also attempt a happy-eyeballs-like approach to connect to the available addresses in case of a connection failure. affinity - Whether to use IPv4 or IPv6 addresses. Default: 4. It can be either '4 or 6. It will only take effect if dualStack is false. lookup: (hostname: string, options: LookupOptions, callback: (err: NodeJS.ErrnoException | null, addresses: DNSInterceptorRecord[]) => void) => void - Custom lookup function. Default: dns.lookup. For more info see dns.lookup. pick: (origin: URL, records: DNSInterceptorRecords, affinity: 4 | 6) => DNSInterceptorRecord - Custom pick function. Default: RoundRobin. The function should return a single record from the records array. By default a simplified version of Round Robin is used. The records property can be mutated to store the state of the balancing algorithm. The Dispatcher#options also gets extended with the options dns.affinity, dns.dualStack, dns.lookup and dns.pick which can be used to configure the interceptor at a request-per-request basis. DNSInterceptorRecord It represents a DNS record. family - (number) The IP family of the address. It can be either 4 or 6. address - (string) The IP address. DNSInterceptorOriginRecords It represents a map of DNS IP addresses records for a single origin. 4.ips - (DNSInterceptorRecord[] | null) The IPv4 addresses. 6.ips - (DNSInterceptorRecord[] | null) The IPv6 addresses. Example - Basic DNS Interceptor const { Client, interceptors } = require(\"undici\"); const { dns } = interceptors; const client = new Agent().compose([ dns({ ...opts }) ]) const response = await client.request({ origin: `http://localhost:3030`, ...requestOpts }) Response Error Interceptor Introduction The Response Error Interceptor is designed to handle HTTP response errors efficiently. It intercepts responses and throws detailed errors for responses with status codes indicating failure (4xx, 5xx). This interceptor enhances error handling by providing structured error information, including response headers, data, and status codes. ResponseError Class The ResponseError class extends the UndiciError class and encapsulates detailed error information. It captures the response status code, headers, and data, providing a structured way to handle errors. Definition class ResponseError extends UndiciError { constructor (message, code, { headers, data }) { super(message); this.name = 'ResponseError'; this.message = message || 'Response error'; this.code = 'UND_ERR_RESPONSE'; this.statusCode = code; this.data = data; this.headers = headers; } } Interceptor Handler The interceptor's handler class extends DecoratorHandler and overrides methods to capture response details and handle errors based on the response status code. Methods onConnect: Initializes response properties. onHeaders: Captures headers and status code. Decodes body if content type is application/json or text/plain. onData: Appends chunks to the body if status code indicates an error. onComplete: Finalizes error handling, constructs a ResponseError, and invokes the onError method. onError: Propagates errors to the handler. Definition class Handler extends DecoratorHandler { // Private properties #handler; #statusCode; #contentType; #decoder; #headers; #body; constructor (opts, { handler }) { super(handler); this.#handler = handler; } onConnect (abort) { this.#statusCode = 0; this.#contentType = null; this.#decoder = null; this.#headers = null; this.#body = ''; return this.#handler.onConnect(abort); } onHeaders (statusCode, rawHeaders, resume, statusMessage, headers = parseHeaders(rawHeaders)) { this.#statusCode = statusCode; this.#headers = headers; this.#contentType = headers['content-type']; if (this.#statusCode < 400) { return this.#handler.onHeaders(statusCode, rawHeaders, resume, statusMessage, headers); } if (this.#contentType === 'application/json' || this.#contentType === 'text/plain') { this.#decoder = new TextDecoder('utf-8'); } } onData (chunk) { if (this.#statusCode < 400) { return this.#handler.onData(chunk); } this.#body += this.#decoder?.decode(chunk, { stream: true }) ?? ''; } onComplete (rawTrailers) { if (this.#statusCode >= 400) { this.#body += this.#decoder?.decode(undefined, { stream: false }) ?? ''; if (this.#contentType === 'application/json') { try { this.#body = JSON.parse(this.#body); } catch { // Do nothing... } } let err; const stackTraceLimit = Error.stackTraceLimit; Error.stackTraceLimit = 0; try { err = new ResponseError('Response Error', this.#statusCode, this.#headers, this.#body); } finally { Error.stackTraceLimit = stackTraceLimit; } this.#handler.onError(err); } else { this.#handler.onComplete(rawTrailers); } } onError (err) { this.#handler.onError(err); } } module.exports = (dispatch) => (opts, handler) => opts.throwOnError ? dispatch(opts, new Handler(opts, { handler })) : dispatch(opts, handler); Tests Unit tests ensure the interceptor functions correctly, handling both error and non-error responses appropriately. Example Tests No Error if throwOnError is False: test('should not error if request is not meant to throw error', async (t) => { const opts = { throwOnError: false }; const handler = { onError: () => {}, onData: () => {}, onComplete: () => {} }; const interceptor = createResponseErrorInterceptor((opts, handler) => handler.onComplete()); assert.doesNotThrow(() => interceptor(opts, handler)); }); Error if Status Code is in Specified Error Codes: test('should error if request status code is in the specified error codes', async (t) => { const opts = { throwOnError: true, statusCodes: [500] }; const response = { statusCode: 500 }; let capturedError; const handler = { onError: (err) => { capturedError = err; }, onData: () => {}, onComplete: () => {} }; const interceptor = createResponseErrorInterceptor((opts, handler) => { if (opts.throwOnError && opts.statusCodes.includes(response.statusCode)) { handler.onError(new Error('Response Error')); } else { handler.onComplete(); } }); interceptor({ ...opts, response }, handler); await new Promise(resolve => setImmediate(resolve)); assert(capturedError, 'Expected error to be captured but it was not.'); assert.strictEqual(capturedError.message, 'Response Error'); assert.strictEqual(response.statusCode, 500); }); No Error if Status Code is Not in Specified Error Codes: test('should not error if request status code is not in the specified error codes', async (t) => { const opts = { throwOnError: true, statusCodes: [500] }; const response = { statusCode: 404 }; const handler = { onError: () => {}, onData: () => {}, onComplete: () => {} }; const interceptor = createResponseErrorInterceptor((opts, handler) => { if (opts.throwOnError && opts.statusCodes.includes(response.statusCode)) { handler.onError(new Error('Response Error')); } else { handler.onComplete(); } }); assert.doesNotThrow(() => interceptor({ ...opts, response }, handler)); }); Conclusion The Response Error Interceptor provides a robust mechanism for handling HTTP response errors by capturing detailed error information and propagating it through a structured ResponseError class. This enhancement improves error handling and debugging capabilities in applications using the interceptor. Instance Events Event: 'connect' Parameters: origin URL targets Array<Dispatcher> Event: 'disconnect' Parameters: origin URL targets Array<Dispatcher> error Error Emitted when the dispatcher has been disconnected from the origin. Note: For HTTP/2, this event is also emitted when the dispatcher has received the GOAWAY Frame with an Error with the message HTTP/2: \"GOAWAY\" frame received and the code UND_ERR_INFO. Due to nature of the protocol of using binary frames, it is possible that requests gets hanging as a frame can be received between the HEADER and DATA frames. It is recommended to handle this event and close the dispatcher to create a new HTTP/2 session. Event: 'connectionError' Parameters: origin URL targets Array<Dispatcher> error Error Emitted when dispatcher fails to connect to origin. Event: 'drain' Parameters: origin URL Emitted when dispatcher is no longer busy. Parameter: UndiciHeaders Record<string, string | string[] | undefined> | string[] | Iterable<[string, string | string[] | undefined]> | null Header arguments such as options.headers in Client.dispatch can be specified in three forms: As an object specified by the Record<string, string | string[] | undefined> (IncomingHttpHeaders) type. As an array of strings. An array representation of a header list must have an even length, or an InvalidArgumentError will be thrown. As an iterable that can encompass Headers, Map, or a custom iterator returning key-value pairs. Keys are lowercase and values are not modified. Response headers will derive a host from the url of the Client instance if no host header was previously specified. Example 1 - Object { 'content-length': '123', 'content-type': 'text/plain', connection: 'keep-alive', host: 'mysite.com', accept: '*/*' } Example 2 - Array [ 'content-length', '123', 'content-type', 'text/plain', 'connection', 'keep-alive', 'host', 'mysite.com', 'accept', '*/*' ] Example 3 - Iterable new Headers({ 'content-length': '123', 'content-type': 'text/plain', connection: 'keep-alive', host: 'mysite.com', accept: '*/*' }) or new Map([ ['content-length', '123'], ['content-type', 'text/plain'], ['connection', 'keep-alive'], ['host', 'mysite.com'], ['accept', '*/*'] ]) or { *[Symbol.iterator] () { yield ['content-length', '123'] yield ['content-type', 'text/plain'] yield ['connection', 'keep-alive'] yield ['host', 'mysite.com'] yield ['accept', '*/*'] } }"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/DispatchInterceptor.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/DispatchInterceptor.html",
    "title": "Interface: DispatchInterceptor",
    "summary": "Interface: DispatchInterceptor Extends: Function A function that can be applied to the Dispatcher.Dispatch function before it is invoked with a dispatch request. This allows one to write logic to intercept both the outgoing request, and the incoming response. Parameter: Dispatcher.Dispatch The base dispatch function you are decorating. ReturnType: Dispatcher.Dispatch A dispatch function that has been altered to provide additional logic Basic Example Here is an example of an interceptor being used to provide a JWT bearer token 'use strict' const insertHeaderInterceptor = dispatch => { return function InterceptedDispatch(opts, handler){ opts.headers.push('Authorization', 'Bearer [Some token]') return dispatch(opts, handler) } } const client = new Client('https://localhost:3000', { interceptors: { Client: [insertHeaderInterceptor] } }) Basic Example 2 Here is a contrived example of an interceptor stripping the headers from a response. 'use strict' const clearHeadersInterceptor = dispatch => { const { DecoratorHandler } = require('undici') class ResultInterceptor extends DecoratorHandler { onHeaders (statusCode, headers, resume) { return super.onHeaders(statusCode, [], resume) } } return function InterceptedDispatch(opts, handler){ return dispatch(opts, new ResultInterceptor(handler)) } } const client = new Client('https://localhost:3000', { interceptors: { Client: [clearHeadersInterceptor] } })"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/EnvHttpProxyAgent.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/EnvHttpProxyAgent.html",
    "title": "Class: EnvHttpProxyAgent",
    "summary": "Class: EnvHttpProxyAgent Stability: Experimental. Extends: undici.Dispatcher EnvHttpProxyAgent automatically reads the proxy configuration from the environment variables http_proxy, https_proxy, and no_proxy and sets up the proxy agents accordingly. When http_proxy and https_proxy are set, http_proxy is used for HTTP requests and https_proxy is used for HTTPS requests. If only http_proxy is set, http_proxy is used for both HTTP and HTTPS requests. If only https_proxy is set, it is only used for HTTPS requests. no_proxy is a comma or space-separated list of hostnames that should not be proxied. The list may contain leading wildcard characters (*). If no_proxy is set, the EnvHttpProxyAgent will bypass the proxy for requests to hosts that match the list. If no_proxy is set to \"*\", the EnvHttpProxyAgent will bypass the proxy for all requests. Uppercase environment variables are also supported: HTTP_PROXY, HTTPS_PROXY, and NO_PROXY. However, if both the lowercase and uppercase environment variables are set, the uppercase environment variables will be ignored. new EnvHttpProxyAgent([options]) Arguments: options EnvHttpProxyAgentOptions (optional) - extends the Agent options. Returns: EnvHttpProxyAgent Parameter: EnvHttpProxyAgentOptions Extends: AgentOptions httpProxy string (optional) - When set, it will override the HTTP_PROXY environment variable. httpsProxy string (optional) - When set, it will override the HTTPS_PROXY environment variable. noProxy string (optional) - When set, it will override the NO_PROXY environment variable. Examples: import { EnvHttpProxyAgent } from 'undici' const envHttpProxyAgent = new EnvHttpProxyAgent() // or const envHttpProxyAgent = new EnvHttpProxyAgent({ httpProxy: 'my.proxy.server:8080', httpsProxy: 'my.proxy.server:8443', noProxy: 'localhost' }) Example - EnvHttpProxyAgent instantiation This will instantiate the EnvHttpProxyAgent. It will not do anything until registered as the agent to use with requests. import { EnvHttpProxyAgent } from 'undici' const envHttpProxyAgent = new EnvHttpProxyAgent() Example - Basic Proxy Fetch with global agent dispatcher import { setGlobalDispatcher, fetch, EnvHttpProxyAgent } from 'undici' const envHttpProxyAgent = new EnvHttpProxyAgent() setGlobalDispatcher(envHttpProxyAgent) const { status, json } = await fetch('http://localhost:3000/foo') console.log('response received', status) // response received 200 const data = await json() // data { foo: \"bar\" } Example - Basic Proxy Request with global agent dispatcher import { setGlobalDispatcher, request, EnvHttpProxyAgent } from 'undici' const envHttpProxyAgent = new EnvHttpProxyAgent() setGlobalDispatcher(envHttpProxyAgent) const { statusCode, body } = await request('http://localhost:3000/foo') console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo } Example - Basic Proxy Request with local agent dispatcher import { EnvHttpProxyAgent, request } from 'undici' const envHttpProxyAgent = new EnvHttpProxyAgent() const { statusCode, body } = await request('http://localhost:3000/foo', { dispatcher: envHttpProxyAgent }) console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo } Example - Basic Proxy Fetch with local agent dispatcher import { EnvHttpProxyAgent, fetch } from 'undici' const envHttpProxyAgent = new EnvHttpProxyAgent() const { status, json } = await fetch('http://localhost:3000/foo', { dispatcher: envHttpProxyAgent }) console.log('response received', status) // response received 200 const data = await json() // data { foo: \"bar\" } Instance Methods EnvHttpProxyAgent.close([callback]) Implements Dispatcher.close([callback]). EnvHttpProxyAgent.destroy([error, callback]) Implements Dispatcher.destroy([error, callback]). EnvHttpProxyAgent.dispatch(options, handler: AgentDispatchOptions) Implements Dispatcher.dispatch(options, handler). Parameter: AgentDispatchOptions Extends: DispatchOptions origin string | URL maxRedirections Integer. Implements Dispatcher.destroy([error, callback]). EnvHttpProxyAgent.connect(options[, callback]) See Dispatcher.connect(options[, callback]). EnvHttpProxyAgent.dispatch(options, handler) Implements Dispatcher.dispatch(options, handler). EnvHttpProxyAgent.pipeline(options, handler) See Dispatcher.pipeline(options, handler). EnvHttpProxyAgent.request(options[, callback]) See Dispatcher.request(options [, callback]). EnvHttpProxyAgent.stream(options, factory[, callback]) See Dispatcher.stream(options, factory[, callback]). EnvHttpProxyAgent.upgrade(options[, callback]) See Dispatcher.upgrade(options[, callback])."
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/Errors.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/Errors.html",
    "title": "Errors",
    "summary": "Errors Undici exposes a variety of error objects that you can use to enhance your error handling. You can find all the error objects inside the errors key. import { errors } from 'undici' Error Error Codes Description UndiciError UND_ERR all errors below are extended from UndiciError. ConnectTimeoutError UND_ERR_CONNECT_TIMEOUT socket is destroyed due to connect timeout. HeadersTimeoutError UND_ERR_HEADERS_TIMEOUT socket is destroyed due to headers timeout. HeadersOverflowError UND_ERR_HEADERS_OVERFLOW socket is destroyed due to headers' max size being exceeded. BodyTimeoutError UND_ERR_BODY_TIMEOUT socket is destroyed due to body timeout. ResponseStatusCodeError UND_ERR_RESPONSE_STATUS_CODE an error is thrown when throwOnError is true for status codes >= 400. InvalidArgumentError UND_ERR_INVALID_ARG passed an invalid argument. InvalidReturnValueError UND_ERR_INVALID_RETURN_VALUE returned an invalid value. RequestAbortedError UND_ERR_ABORTED the request has been aborted by the user ClientDestroyedError UND_ERR_DESTROYED trying to use a destroyed client. ClientClosedError UND_ERR_CLOSED trying to use a closed client. SocketError UND_ERR_SOCKET there is an error with the socket. NotSupportedError UND_ERR_NOT_SUPPORTED encountered unsupported functionality. RequestContentLengthMismatchError UND_ERR_REQ_CONTENT_LENGTH_MISMATCH request body does not match content-length header ResponseContentLengthMismatchError UND_ERR_RES_CONTENT_LENGTH_MISMATCH response body does not match content-length header InformationalError UND_ERR_INFO expected error with reason ResponseExceededMaxSizeError UND_ERR_RES_EXCEEDED_MAX_SIZE response body exceed the max size allowed SecureProxyConnectionError UND_ERR_PRX_TLS tls connection to a proxy failed SocketError The SocketError has a .socket property which holds socket metadata: interface SocketInfo { localAddress?: string localPort?: number remoteAddress?: string remotePort?: number remoteFamily?: string timeout?: number bytesWritten?: number bytesRead?: number } Be aware that in some cases the .socket property can be null."
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/EventSource.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/EventSource.html",
    "title": "EventSource",
    "summary": "EventSource ⚠️ Warning: the EventSource API is experimental. Undici exposes a WHATWG spec-compliant implementation of EventSource for Server-Sent Events. Instantiating EventSource Undici exports a EventSource class. You can instantiate the EventSource as follows: import { EventSource } from 'undici' const eventSource = new EventSource('http://localhost:3000') eventSource.onmessage = (event) => { console.log(event.data) } Using a custom Dispatcher undici allows you to set your own Dispatcher in the EventSource constructor. An example which allows you to modify the request headers is: import { EventSource, Agent } from 'undici' class CustomHeaderAgent extends Agent { dispatch (opts) { opts.headers['x-custom-header'] = 'hello world' return super.dispatch(...arguments) } } const eventSource = new EventSource('http://localhost:3000', { dispatcher: new CustomHeaderAgent() }) More information about the EventSource API can be found on MDN."
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/Fetch.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/Fetch.html",
    "title": "Fetch",
    "summary": "Fetch Undici exposes a fetch() method starts the process of fetching a resource from the network. Documentation and examples can be found on MDN. FormData This API is implemented as per the standard, you can find documentation on MDN. If any parameters are passed to the FormData constructor other than undefined, an error will be thrown. Other parameters are ignored. Response This API is implemented as per the standard, you can find documentation on MDN Request This API is implemented as per the standard, you can find documentation on MDN Header This API is implemented as per the standard, you can find documentation on MDN Body Mixins Response and Request body inherit body mixin methods. These methods include: .arrayBuffer() .blob() .bytes() .formData() .json() .text() There is an ongoing discussion regarding .formData() and its usefulness and performance in server environments. It is recommended to use a dedicated library for parsing multipart/form-data bodies, such as Busboy or @fastify/busboy. These libraries can be interfaced with fetch with the following example code: import { Busboy } from '@fastify/busboy' import { Readable } from 'node:stream' const response = await fetch('...') const busboy = new Busboy({ headers: { 'content-type': response.headers.get('content-type') } }) Readable.fromWeb(response.body).pipe(busboy)"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/MockAgent.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/MockAgent.html",
    "title": "Class: MockAgent",
    "summary": "Class: MockAgent Extends: undici.Dispatcher A mocked Agent class that implements the Agent API. It allows one to intercept HTTP requests made through undici and return mocked responses instead. new MockAgent([options]) Arguments: options MockAgentOptions (optional) - It extends the Agent options. Returns: MockAgent Parameter: MockAgentOptions Extends: AgentOptions agent Agent (optional) - Default: new Agent([options]) - a custom agent encapsulated by the MockAgent. Example - Basic MockAgent instantiation This will instantiate the MockAgent. It will not do anything until registered as the agent to use with requests and mock interceptions are added. import { MockAgent } from 'undici' const mockAgent = new MockAgent() Example - Basic MockAgent instantiation with custom agent import { Agent, MockAgent } from 'undici' const agent = new Agent() const mockAgent = new MockAgent({ agent }) Instance Methods MockAgent.get(origin) This method creates and retrieves MockPool or MockClient instances which can then be used to intercept HTTP requests. If the number of connections on the mock agent is set to 1, a MockClient instance is returned. Otherwise a MockPool instance is returned. For subsequent MockAgent.get calls on the same origin, the same mock instance will be returned. Arguments: origin string | RegExp | (value) => boolean - a matcher for the pool origin to be retrieved from the MockAgent. Matcher type Condition to pass string Exact match against string RegExp Regex must pass Function Function must return true Returns: MockClient | MockPool. MockAgentOptions Mock instance returned connections === 1 MockClient connections > 1 MockPool Example - Basic Mocked Request import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo' }).reply(200, 'foo') const { statusCode, body } = await request('http://localhost:3000/foo') console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo } Example - Basic Mocked Request with local mock agent dispatcher import { MockAgent, request } from 'undici' const mockAgent = new MockAgent() const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo' }).reply(200, 'foo') const { statusCode, body } = await request('http://localhost:3000/foo', { dispatcher: mockAgent }) console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo } Example - Basic Mocked Request with local mock pool dispatcher import { MockAgent, request } from 'undici' const mockAgent = new MockAgent() const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo' }).reply(200, 'foo') const { statusCode, body } = await request('http://localhost:3000/foo', { dispatcher: mockPool }) console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo } Example - Basic Mocked Request with local mock client dispatcher import { MockAgent, request } from 'undici' const mockAgent = new MockAgent({ connections: 1 }) const mockClient = mockAgent.get('http://localhost:3000') mockClient.intercept({ path: '/foo' }).reply(200, 'foo') const { statusCode, body } = await request('http://localhost:3000/foo', { dispatcher: mockClient }) console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo } Example - Basic Mocked requests with multiple intercepts import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo' }).reply(200, 'foo') mockPool.intercept({ path: '/hello'}).reply(200, 'hello') const result1 = await request('http://localhost:3000/foo') console.log('response received', result1.statusCode) // response received 200 for await (const data of result1.body) { console.log('data', data.toString('utf8')) // data foo } const result2 = await request('http://localhost:3000/hello') console.log('response received', result2.statusCode) // response received 200 for await (const data of result2.body) { console.log('data', data.toString('utf8')) // data hello } Example - Mock different requests within the same file const { MockAgent, setGlobalDispatcher } = require('undici'); const agent = new MockAgent(); agent.disableNetConnect(); setGlobalDispatcher(agent); describe('Test', () => { it('200', async () => { const mockAgent = agent.get('http://test.com'); // your test }); it('200', async () => { const mockAgent = agent.get('http://testing.com'); // your test }); }); Example - Mocked request with query body, headers and trailers import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo?hello=there&see=ya', method: 'POST', body: 'form1=data1&form2=data2' }).reply(200, { foo: 'bar' }, { headers: { 'content-type': 'application/json' }, trailers: { 'Content-MD5': 'test' } }) const { statusCode, headers, trailers, body } = await request('http://localhost:3000/foo?hello=there&see=ya', { method: 'POST', body: 'form1=data1&form2=data2' }) console.log('response received', statusCode) // response received 200 console.log('headers', headers) // { 'content-type': 'application/json' } for await (const data of body) { console.log('data', data.toString('utf8')) // '{\"foo\":\"bar\"}' } console.log('trailers', trailers) // { 'content-md5': 'test' } Example - Mocked request with origin regex import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get(new RegExp('http://localhost:3000')) mockPool.intercept({ path: '/foo' }).reply(200, 'foo') const { statusCode, body } = await request('http://localhost:3000/foo') console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo } Example - Mocked request with origin function import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get((origin) => origin === 'http://localhost:3000') mockPool.intercept({ path: '/foo' }).reply(200, 'foo') const { statusCode, body } = await request('http://localhost:3000/foo') console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo } MockAgent.close() Closes the mock agent and waits for registered mock pools and clients to also close before resolving. Returns: Promise<void> Example - clean up after tests are complete import { MockAgent, setGlobalDispatcher } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) await mockAgent.close() MockAgent.dispatch(options, handlers) Implements Agent.dispatch(options, handlers). MockAgent.request(options[, callback]) See Dispatcher.request(options [, callback]). Example - MockAgent request import { MockAgent } from 'undici' const mockAgent = new MockAgent() const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo' }).reply(200, 'foo') const { statusCode, body } = await mockAgent.request({ origin: 'http://localhost:3000', path: '/foo', method: 'GET' }) console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo } MockAgent.deactivate() This method disables mocking in MockAgent. Returns: void Example - Deactivate Mocking import { MockAgent, setGlobalDispatcher } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) mockAgent.deactivate() MockAgent.activate() This method enables mocking in a MockAgent instance. When instantiated, a MockAgent is automatically activated. Therefore, this method is only effective after MockAgent.deactivate has been called. Returns: void Example - Activate Mocking import { MockAgent, setGlobalDispatcher } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) mockAgent.deactivate() // No mocking will occur // Later mockAgent.activate() MockAgent.enableNetConnect([host]) When requests are not matched in a MockAgent intercept, a real HTTP request is attempted. We can control this further through the use of enableNetConnect. This is achieved by defining host matchers so only matching requests will be attempted. When using a string, it should only include the hostname and optionally, the port. In addition, calling this method multiple times with a string will allow all HTTP requests that match these values. Arguments: host string | RegExp | (value) => boolean - (optional) Returns: void Example - Allow all non-matching urls to be dispatched in a real HTTP request import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) mockAgent.enableNetConnect() await request('http://example.com') // A real request is made Example - Allow requests matching a host string to make real requests import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) mockAgent.enableNetConnect('example-1.com') mockAgent.enableNetConnect('example-2.com:8080') await request('http://example-1.com') // A real request is made await request('http://example-2.com:8080') // A real request is made await request('http://example-3.com') // Will throw Example - Allow requests matching a host regex to make real requests import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) mockAgent.enableNetConnect(new RegExp('example.com')) await request('http://example.com') // A real request is made Example - Allow requests matching a host function to make real requests import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) mockAgent.enableNetConnect((value) => value === 'example.com') await request('http://example.com') // A real request is made MockAgent.disableNetConnect() This method causes all requests to throw when requests are not matched in a MockAgent intercept. Returns: void Example - Disable all non-matching requests by throwing an error for each import { MockAgent, request } from 'undici' const mockAgent = new MockAgent() mockAgent.disableNetConnect() await request('http://example.com') // Will throw MockAgent.pendingInterceptors() This method returns any pending interceptors registered on a mock agent. A pending interceptor meets one of the following criteria: Is registered with neither .times(<number>) nor .persist(), and has not been invoked; Is persistent (i.e., registered with .persist()) and has not been invoked; Is registered with .times(<number>) and has not been invoked <number> of times. Returns: PendingInterceptor[] (where PendingInterceptor is a MockDispatch with an additional origin: string) Example - List all pending inteceptors const agent = new MockAgent() agent.disableNetConnect() agent .get('https://example.com') .intercept({ method: 'GET', path: '/' }) .reply(200) const pendingInterceptors = agent.pendingInterceptors() // Returns [ // { // timesInvoked: 0, // times: 1, // persist: false, // consumed: false, // pending: true, // path: '/', // method: 'GET', // body: undefined, // headers: undefined, // data: { // error: null, // statusCode: 200, // data: '', // headers: {}, // trailers: {} // }, // origin: 'https://example.com' // } // ] MockAgent.assertNoPendingInterceptors([options]) This method throws if the mock agent has any pending interceptors. A pending interceptor meets one of the following criteria: Is registered with neither .times(<number>) nor .persist(), and has not been invoked; Is persistent (i.e., registered with .persist()) and has not been invoked; Is registered with .times(<number>) and has not been invoked <number> of times. Example - Check that there are no pending interceptors const agent = new MockAgent() agent.disableNetConnect() agent .get('https://example.com') .intercept({ method: 'GET', path: '/' }) .reply(200) agent.assertNoPendingInterceptors() // Throws an UndiciError with the following message: // // 1 interceptor is pending: // // ┌─────────┬────────┬───────────────────────┬──────┬─────────────┬────────────┬─────────────┬───────────┐ // │ (index) │ Method │ Origin │ Path │ Status code │ Persistent │ Invocations │ Remaining │ // ├─────────┼────────┼───────────────────────┼──────┼─────────────┼────────────┼─────────────┼───────────┤ // │ 0 │ 'GET' │ 'https://example.com' │ '/' │ 200 │ '❌' │ 0 │ 1 │ // └─────────┴────────┴───────────────────────┴──────┴─────────────┴────────────┴─────────────┴───────────┘"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/MockClient.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/MockClient.html",
    "title": "Class: MockClient",
    "summary": "Class: MockClient Extends: undici.Client A mock client class that implements the same api as MockPool. new MockClient(origin, [options]) Arguments: origin string - It should only include the protocol, hostname, and port. options MockClientOptions - It extends the Client options. Returns: MockClient Parameter: MockClientOptions Extends: ClientOptions agent Agent - the agent to associate this MockClient with. Example - Basic MockClient instantiation We can use MockAgent to instantiate a MockClient ready to be used to intercept specified requests. It will not do anything until registered as the agent to use and any mock request are registered. import { MockAgent } from 'undici' // Connections must be set to 1 to return a MockClient instance const mockAgent = new MockAgent({ connections: 1 }) const mockClient = mockAgent.get('http://localhost:3000') Instance Methods MockClient.intercept(options) Implements: MockPool.intercept(options) MockClient.close() Implements: MockPool.close() MockClient.dispatch(options, handlers) Implements Dispatcher.dispatch(options, handlers). MockClient.request(options[, callback]) See Dispatcher.request(options [, callback]). Example - MockClient request import { MockAgent } from 'undici' const mockAgent = new MockAgent({ connections: 1 }) const mockClient = mockAgent.get('http://localhost:3000') mockClient.intercept({ path: '/foo' }).reply(200, 'foo') const { statusCode, body } = await mockClient.request({ origin: 'http://localhost:3000', path: '/foo', method: 'GET' }) console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo }"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/MockErrors.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/MockErrors.html",
    "title": "MockErrors",
    "summary": "MockErrors Undici exposes a variety of mock error objects that you can use to enhance your mock error handling. You can find all the mock error objects inside the mockErrors key. import { mockErrors } from 'undici' Mock Error Mock Error Codes Description MockNotMatchedError UND_MOCK_ERR_MOCK_NOT_MATCHED The request does not match any registered mock dispatches."
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/MockPool.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/MockPool.html",
    "title": "Class: MockPool",
    "summary": "Class: MockPool Extends: undici.Pool A mock Pool class that implements the Pool API and is used by MockAgent to intercept real requests and return mocked responses. new MockPool(origin, [options]) Arguments: origin string - It should only include the protocol, hostname, and port. options MockPoolOptions - It extends the Pool options. Returns: MockPool Parameter: MockPoolOptions Extends: PoolOptions agent Agent - the agent to associate this MockPool with. Example - Basic MockPool instantiation We can use MockAgent to instantiate a MockPool ready to be used to intercept specified requests. It will not do anything until registered as the agent to use and any mock request are registered. import { MockAgent } from 'undici' const mockAgent = new MockAgent() const mockPool = mockAgent.get('http://localhost:3000') Instance Methods MockPool.intercept(options) This method defines the interception rules for matching against requests for a MockPool or MockPool. We can intercept multiple times on a single instance, but each intercept is only used once. For example if you expect to make 2 requests inside a test, you need to call intercept() twice. Assuming you use disableNetConnect() you will get MockNotMatchedError on the second request when you only call intercept() once. When defining interception rules, all the rules must pass for a request to be intercepted. If a request is not intercepted, a real request will be attempted. Matcher type Condition to pass string Exact match against string RegExp Regex must pass Function Function must return true Arguments: options MockPoolInterceptOptions - Interception options. Returns: MockInterceptor corresponding to the input options. Parameter: MockPoolInterceptOptions path string | RegExp | (path: string) => boolean - a matcher for the HTTP request path. When a RegExp or callback is used, it will match against the request path including all query parameters in alphabetical order. When a string is provided, the query parameters can be conveniently specified through the MockPoolInterceptOptions.query setting. method string | RegExp | (method: string) => boolean - (optional) - a matcher for the HTTP request method. Defaults to GET. body string | RegExp | (body: string) => boolean - (optional) - a matcher for the HTTP request body. headers Record<string, string | RegExp | (body: string) => boolean> - (optional) - a matcher for the HTTP request headers. To be intercepted, a request must match all defined headers. Extra headers not defined here may (or may not) be included in the request and do not affect the interception in any way. query Record<string, any> | null - (optional) - a matcher for the HTTP request query string params. Only applies when a string was provided for MockPoolInterceptOptions.path. Return: MockInterceptor We can define the behaviour of an intercepted request with the following options. reply (statusCode: number, replyData: string | Buffer | object | MockInterceptor.MockResponseDataHandler, responseOptions?: MockResponseOptions) => MockScope - define a reply for a matching request. You can define the replyData as a callback to read incoming request data. Default for responseOptions is {}. reply (callback: MockInterceptor.MockReplyOptionsCallback) => MockScope - define a reply for a matching request, allowing dynamic mocking of all reply options rather than just the data. replyWithError (error: Error) => MockScope - define an error for a matching request to throw. defaultReplyHeaders (headers: Record<string, string>) => MockInterceptor - define default headers to be included in subsequent replies. These are in addition to headers on a specific reply. defaultReplyTrailers (trailers: Record<string, string>) => MockInterceptor - define default trailers to be included in subsequent replies. These are in addition to trailers on a specific reply. replyContentLength () => MockInterceptor - define automatically calculated content-length headers to be included in subsequent replies. The reply data of an intercepted request may either be a string, buffer, or JavaScript object. Objects are converted to JSON while strings and buffers are sent as-is. By default, reply and replyWithError define the behaviour for the first matching request only. Subsequent requests will not be affected (this can be changed using the returned MockScope). Parameter: MockResponseOptions headers Record<string, string> - headers to be included on the mocked reply. trailers Record<string, string> - trailers to be included on the mocked reply. Return: MockScope A MockScope is associated with a single MockInterceptor. With this, we can configure the default behaviour of a intercepted reply. delay (waitInMs: number) => MockScope - delay the associated reply by a set amount in ms. persist () => MockScope - any matching request will always reply with the defined response indefinitely. times (repeatTimes: number) => MockScope - any matching request will reply with the defined response a fixed amount of times. This is overridden by persist. Example - Basic Mocked Request import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) // MockPool const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo' }).reply(200, 'foo') const { statusCode, body } = await request('http://localhost:3000/foo') console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo } Example - Mocked request using reply data callbacks import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/echo', method: 'GET', headers: { 'User-Agent': 'undici', Host: 'example.com' } }).reply(200, ({ headers }) => ({ message: headers.get('message') })) const { statusCode, body, headers } = await request('http://localhost:3000', { headers: { message: 'hello world!' } }) console.log('response received', statusCode) // response received 200 console.log('headers', headers) // { 'content-type': 'application/json' } for await (const data of body) { console.log('data', data.toString('utf8')) // { \"message\":\"hello world!\" } } Example - Mocked request using reply options callback import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/echo', method: 'GET', headers: { 'User-Agent': 'undici', Host: 'example.com' } }).reply(({ headers }) => ({ statusCode: 200, data: { message: headers.get('message') }}))) const { statusCode, body, headers } = await request('http://localhost:3000', { headers: { message: 'hello world!' } }) console.log('response received', statusCode) // response received 200 console.log('headers', headers) // { 'content-type': 'application/json' } for await (const data of body) { console.log('data', data.toString('utf8')) // { \"message\":\"hello world!\" } } Example - Basic Mocked requests with multiple intercepts import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo', method: 'GET' }).reply(200, 'foo') mockPool.intercept({ path: '/hello', method: 'GET', }).reply(200, 'hello') const result1 = await request('http://localhost:3000/foo') console.log('response received', result1.statusCode) // response received 200 for await (const data of result1.body) { console.log('data', data.toString('utf8')) // data foo } const result2 = await request('http://localhost:3000/hello') console.log('response received', result2.statusCode) // response received 200 for await (const data of result2.body) { console.log('data', data.toString('utf8')) // data hello } Example - Mocked request with query body, request headers and response headers and trailers import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo?hello=there&see=ya', method: 'POST', body: 'form1=data1&form2=data2', headers: { 'User-Agent': 'undici', Host: 'example.com' } }).reply(200, { foo: 'bar' }, { headers: { 'content-type': 'application/json' }, trailers: { 'Content-MD5': 'test' } }) const { statusCode, headers, trailers, body } = await request('http://localhost:3000/foo?hello=there&see=ya', { method: 'POST', body: 'form1=data1&form2=data2', headers: { foo: 'bar', 'User-Agent': 'undici', Host: 'example.com' } }) console.log('response received', statusCode) // response received 200 console.log('headers', headers) // { 'content-type': 'application/json' } for await (const data of body) { console.log('data', data.toString('utf8')) // '{\"foo\":\"bar\"}' } console.log('trailers', trailers) // { 'content-md5': 'test' } Example - Mocked request using different matchers import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo', method: /^GET$/, body: (value) => value === 'form=data', headers: { 'User-Agent': 'undici', Host: /^example.com$/ } }).reply(200, 'foo') const { statusCode, body } = await request('http://localhost:3000/foo', { method: 'GET', body: 'form=data', headers: { foo: 'bar', 'User-Agent': 'undici', Host: 'example.com' } }) console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo } Example - Mocked request with reply with a defined error import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo', method: 'GET' }).replyWithError(new Error('kaboom')) try { await request('http://localhost:3000/foo', { method: 'GET' }) } catch (error) { console.error(error) // Error: kaboom } Example - Mocked request with defaultReplyHeaders import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo', method: 'GET' }).defaultReplyHeaders({ foo: 'bar' }) .reply(200, 'foo') const { headers } = await request('http://localhost:3000/foo') console.log('headers', headers) // headers { foo: 'bar' } Example - Mocked request with defaultReplyTrailers import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo', method: 'GET' }).defaultReplyTrailers({ foo: 'bar' }) .reply(200, 'foo') const { trailers } = await request('http://localhost:3000/foo') console.log('trailers', trailers) // trailers { foo: 'bar' } Example - Mocked request with automatic content-length calculation import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo', method: 'GET' }).replyContentLength().reply(200, 'foo') const { headers } = await request('http://localhost:3000/foo') console.log('headers', headers) // headers { 'content-length': '3' } Example - Mocked request with automatic content-length calculation on an object import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo', method: 'GET' }).replyContentLength().reply(200, { foo: 'bar' }) const { headers } = await request('http://localhost:3000/foo') console.log('headers', headers) // headers { 'content-length': '13' } Example - Mocked request with persist enabled import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo', method: 'GET' }).reply(200, 'foo').persist() const result1 = await request('http://localhost:3000/foo') // Will match and return mocked data const result2 = await request('http://localhost:3000/foo') // Will match and return mocked data // Etc Example - Mocked request with times enabled import { MockAgent, setGlobalDispatcher, request } from 'undici' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo', method: 'GET' }).reply(200, 'foo').times(2) const result1 = await request('http://localhost:3000/foo') // Will match and return mocked data const result2 = await request('http://localhost:3000/foo') // Will match and return mocked data const result3 = await request('http://localhost:3000/foo') // Will not match and make attempt a real request Example - Mocked request with path callback import { MockAgent, setGlobalDispatcher, request } from 'undici' import querystring from 'querystring' const mockAgent = new MockAgent() setGlobalDispatcher(mockAgent) const mockPool = mockAgent.get('http://localhost:3000') const matchPath = requestPath => { const [pathname, search] = requestPath.split('?') const requestQuery = querystring.parse(search) if (!pathname.startsWith('/foo')) { return false } if (!Object.keys(requestQuery).includes('foo') || requestQuery.foo !== 'bar') { return false } return true } mockPool.intercept({ path: matchPath, method: 'GET' }).reply(200, 'foo') const result = await request('http://localhost:3000/foo?foo=bar') // Will match and return mocked data MockPool.close() Closes the mock pool and de-registers from associated MockAgent. Returns: Promise<void> Example - clean up after tests are complete import { MockAgent } from 'undici' const mockAgent = new MockAgent() const mockPool = mockAgent.get('http://localhost:3000') await mockPool.close() MockPool.dispatch(options, handlers) Implements Dispatcher.dispatch(options, handlers). MockPool.request(options[, callback]) See Dispatcher.request(options [, callback]). Example - MockPool request import { MockAgent } from 'undici' const mockAgent = new MockAgent() const mockPool = mockAgent.get('http://localhost:3000') mockPool.intercept({ path: '/foo', method: 'GET', }).reply(200, 'foo') const { statusCode, body } = await mockPool.request({ origin: 'http://localhost:3000', path: '/foo', method: 'GET' }) console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo }"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/Pool.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/Pool.html",
    "title": "Class: Pool",
    "summary": "Class: Pool Extends: undici.Dispatcher A pool of Client instances connected to the same upstream target. Requests are not guaranteed to be dispatched in order of invocation. new Pool(url[, options]) Arguments: url URL | string - It should only include the protocol, hostname, and port. options PoolOptions (optional) Parameter: PoolOptions Extends: ClientOptions factory (origin: URL, opts: Object) => Dispatcher - Default: (origin, opts) => new Client(origin, opts) connections number | null (optional) - Default: null - The number of Client instances to create. When set to null, the Pool instance will create an unlimited amount of Client instances. interceptors { Pool: DispatchInterceptor[] } } - Default: { Pool: [] } - A list of interceptors that are applied to the dispatch method. Additional logic can be applied (such as, but not limited to: 302 status code handling, authentication, cookies, compression and caching). Instance Properties Pool.closed Implements Client.closed Pool.destroyed Implements Client.destroyed Pool.stats Returns PoolStats instance for this pool. Instance Methods Pool.close([callback]) Implements Dispatcher.close([callback]). Pool.destroy([error, callback]) Implements Dispatcher.destroy([error, callback]). Pool.connect(options[, callback]) See Dispatcher.connect(options[, callback]). Pool.dispatch(options, handler) Implements Dispatcher.dispatch(options, handler). Pool.pipeline(options, handler) See Dispatcher.pipeline(options, handler). Pool.request(options[, callback]) See Dispatcher.request(options [, callback]). Pool.stream(options, factory[, callback]) See Dispatcher.stream(options, factory[, callback]). Pool.upgrade(options[, callback]) See Dispatcher.upgrade(options[, callback]). Instance Events Event: 'connect' See Dispatcher Event: 'connect'. Event: 'disconnect' See Dispatcher Event: 'disconnect'. Event: 'drain' See Dispatcher Event: 'drain'."
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/PoolStats.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/PoolStats.html",
    "title": "Class: PoolStats",
    "summary": "Class: PoolStats Aggregate stats for a Pool or BalancedPool. new PoolStats(pool) Arguments: pool Pool - Pool or BalancedPool from which to return stats. Instance Properties PoolStats.connected Number of open socket connections in this pool. PoolStats.free Number of open socket connections in this pool that do not have an active request. PoolStats.pending Number of pending requests across all clients in this pool. PoolStats.queued Number of queued requests across all clients in this pool. PoolStats.running Number of currently active requests across all clients in this pool. PoolStats.size Number of active, pending, or queued requests across all clients in this pool."
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/ProxyAgent.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/ProxyAgent.html",
    "title": "Class: ProxyAgent",
    "summary": "Class: ProxyAgent Extends: undici.Dispatcher A Proxy Agent class that implements the Agent API. It allows the connection through proxy in a simple way. new ProxyAgent([options]) Arguments: options ProxyAgentOptions (required) - It extends the Agent options. Returns: ProxyAgent Parameter: ProxyAgentOptions Extends: AgentOptions uri string | URL (required) - The URI of the proxy server. This can be provided as a string, as an instance of the URL class, or as an object with a uri property of type string. If the uri is provided as a string or uri is an object with an uri property of type string, then it will be parsed into a URL object according to the WHATWG URL Specification. For detailed information on the parsing process and potential validation errors, please refer to the \"Writing\" section of the WHATWG URL Specification. token string (optional) - It can be passed by a string of token for authentication. auth string (deprecated) - Use token. clientFactory (origin: URL, opts: Object) => Dispatcher (optional) - Default: (origin, opts) => new Pool(origin, opts) requestTls BuildOptions (optional) - Options object passed when creating the underlying socket via the connector builder for the request. See TLS. proxyTls BuildOptions (optional) - Options object passed when creating the underlying socket via the connector builder for the proxy server. See TLS. Examples: import { ProxyAgent } from 'undici' const proxyAgent = new ProxyAgent('my.proxy.server') // or const proxyAgent = new ProxyAgent(new URL('my.proxy.server')) // or const proxyAgent = new ProxyAgent({ uri: 'my.proxy.server' }) Example - Basic ProxyAgent instantiation This will instantiate the ProxyAgent. It will not do anything until registered as the agent to use with requests. import { ProxyAgent } from 'undici' const proxyAgent = new ProxyAgent('my.proxy.server') Example - Basic Proxy Request with global agent dispatcher import { setGlobalDispatcher, request, ProxyAgent } from 'undici' const proxyAgent = new ProxyAgent('my.proxy.server') setGlobalDispatcher(proxyAgent) const { statusCode, body } = await request('http://localhost:3000/foo') console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo } Example - Basic Proxy Request with local agent dispatcher import { ProxyAgent, request } from 'undici' const proxyAgent = new ProxyAgent('my.proxy.server') const { statusCode, body } = await request('http://localhost:3000/foo', { dispatcher: proxyAgent }) console.log('response received', statusCode) // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')) // data foo } Example - Basic Proxy Request with authentication import { setGlobalDispatcher, request, ProxyAgent } from 'undici'; const proxyAgent = new ProxyAgent({ uri: 'my.proxy.server', // token: 'Bearer xxxx' token: `Basic ${Buffer.from('username:password').toString('base64')}` }); setGlobalDispatcher(proxyAgent); const { statusCode, body } = await request('http://localhost:3000/foo'); console.log('response received', statusCode); // response received 200 for await (const data of body) { console.log('data', data.toString('utf8')); // data foo } ProxyAgent.close() Closes the proxy agent and waits for registered pools and clients to also close before resolving. Returns: Promise<void> Example - clean up after tests are complete import { ProxyAgent, setGlobalDispatcher } from 'undici' const proxyAgent = new ProxyAgent('my.proxy.server') setGlobalDispatcher(proxyAgent) await proxyAgent.close() ProxyAgent.dispatch(options, handlers) Implements Agent.dispatch(options, handlers). ProxyAgent.request(options[, callback]) See Dispatcher.request(options [, callback])."
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/RedirectHandler.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/RedirectHandler.html",
    "title": "Class: RedirectHandler",
    "summary": "Class: RedirectHandler A class that handles redirection logic for HTTP requests. new RedirectHandler(dispatch, maxRedirections, opts, handler, redirectionLimitReached) Arguments: dispatch function - The dispatch function to be called after every retry. maxRedirections number - Maximum number of redirections allowed. opts object - Options for handling redirection. handler object - An object containing handlers for different stages of the request lifecycle. redirectionLimitReached boolean (default: false) - A flag that the implementer can provide to enable or disable the feature. If set to false, it indicates that the caller doesn't want to use the feature and prefers the old behavior. Returns: RedirectHandler Parameters dispatch (options: Dispatch.DispatchOptions, handlers: Dispatch.DispatchHandlers) => Promise<Dispatch.DispatchResponse> (required) - Dispatch function to be called after every redirection. maxRedirections number (required) - Maximum number of redirections allowed. opts object (required) - Options for handling redirection. handler object (required) - Handlers for different stages of the request lifecycle. redirectionLimitReached boolean (default: false) - A flag that the implementer can provide to enable or disable the feature. If set to false, it indicates that the caller doesn't want to use the feature and prefers the old behavior. Properties location string - The current redirection location. abort function - The abort function. opts object - The options for handling redirection. maxRedirections number - Maximum number of redirections allowed. handler object - Handlers for different stages of the request lifecycle. history Array - An array representing the history of URLs during redirection. redirectionLimitReached boolean - Indicates whether the redirection limit has been reached. Methods onConnect(abort) Called when the connection is established. Parameters: abort function - The abort function. onUpgrade(statusCode, headers, socket) Called when an upgrade is requested. Parameters: statusCode number - The HTTP status code. headers object - The headers received in the response. socket object - The socket object. onError(error) Called when an error occurs. Parameters: error Error - The error that occurred. onHeaders(statusCode, headers, resume, statusText) Called when headers are received. Parameters: statusCode number - The HTTP status code. headers object - The headers received in the response. resume function - The resume function. statusText string - The status text. onData(chunk) Called when data is received. Parameters: chunk Buffer - The data chunk received. onComplete(trailers) Called when the request is complete. Parameters: trailers object - The trailers received. onBodySent(chunk) Called when the request body is sent. Parameters: chunk Buffer - The chunk of the request body sent."
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/RetryAgent.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/RetryAgent.html",
    "title": "Class: RetryAgent",
    "summary": "Class: RetryAgent Extends: undici.Dispatcher A undici.Dispatcher that allows to automatically retry a request. Wraps a undici.RetryHandler. new RetryAgent(dispatcher, [options]) Arguments: dispatcher undici.Dispatcher (required) - the dispatcher to wrap options RetryHandlerOptions (optional) - the options Returns: ProxyAgent Parameter: RetryHandlerOptions retry (err: Error, context: RetryContext, callback: (err?: Error | null) => void) => void (optional) - Function to be called after every retry. It should pass error if no more retries should be performed. maxRetries number (optional) - Maximum number of retries. Default: 5 maxTimeout number (optional) - Maximum number of milliseconds to wait before retrying. Default: 30000 (30 seconds) minTimeout number (optional) - Minimum number of milliseconds to wait before retrying. Default: 500 (half a second) timeoutFactor number (optional) - Factor to multiply the timeout by for each retry attempt. Default: 2 retryAfter boolean (optional) - It enables automatic retry after the Retry-After header is received. Default: true methods string[] (optional) - Array of HTTP methods to retry. Default: ['GET', 'PUT', 'HEAD', 'OPTIONS', 'DELETE'] statusCodes number[] (optional) - Array of HTTP status codes to retry. Default: [429, 500, 502, 503, 504] errorCodes string[] (optional) - Array of Error codes to retry. Default: ['ECONNRESET', 'ECONNREFUSED', 'ENOTFOUND', 'ENETDOWN','ENETUNREACH', 'EHOSTDOWN', 'UND_ERR_SOCKET'] RetryContext state: RetryState - Current retry state. It can be mutated. opts: Dispatch.DispatchOptions & RetryOptions - Options passed to the retry handler. Example: import { Agent, RetryAgent } from 'undici' const agent = new RetryAgent(new Agent()) const res = await agent.request('http://example.com') console.log(res.statuCode) console.log(await res.body.text())"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/RetryHandler.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/RetryHandler.html",
    "title": "Class: RetryHandler",
    "summary": "Class: RetryHandler Extends: undici.DispatcherHandlers A handler class that implements the retry logic for a request. new RetryHandler(dispatchOptions, retryHandlers, [retryOptions]) Arguments: options Dispatch.DispatchOptions & RetryOptions (required) - It is an intersection of Dispatcher.DispatchOptions and RetryOptions. retryHandlers RetryHandlers (required) - Object containing the dispatch to be used on every retry, and handler for handling the dispatch lifecycle. Returns: retryHandler Parameter: Dispatch.DispatchOptions & RetryOptions Extends: Dispatch.DispatchOptions. RetryOptions retry (err: Error, context: RetryContext, callback: (err?: Error | null) => void) => number | null (optional) - Function to be called after every retry. It should pass error if no more retries should be performed. maxRetries number (optional) - Maximum number of retries. Default: 5 maxTimeout number (optional) - Maximum number of milliseconds to wait before retrying. Default: 30000 (30 seconds) minTimeout number (optional) - Minimum number of milliseconds to wait before retrying. Default: 500 (half a second) timeoutFactor number (optional) - Factor to multiply the timeout by for each retry attempt. Default: 2 retryAfter boolean (optional) - It enables automatic retry after the Retry-After header is received. Default: true methods string[] (optional) - Array of HTTP methods to retry. Default: ['GET', 'PUT', 'HEAD', 'OPTIONS', 'DELETE'] statusCodes number[] (optional) - Array of HTTP status codes to retry. Default: [429, 500, 502, 503, 504] errorCodes string[] (optional) - Array of Error codes to retry. Default: ['ECONNRESET', 'ECONNREFUSED', 'ENOTFOUND', 'ENETDOWN','ENETUNREACH', 'EHOSTDOWN', 'UND_ERR_SOCKET'] RetryContext state: RetryState - Current retry state. It can be mutated. opts: Dispatch.DispatchOptions & RetryOptions - Options passed to the retry handler. RetryState It represents the retry state for a given request. counter: number - Current retry attempt. Parameter RetryHandlers dispatch (options: Dispatch.DispatchOptions, handlers: Dispatch.DispatchHandlers) => Promise<Dispatch.DispatchResponse> (required) - Dispatch function to be called after every retry. handler Extends Dispatch.DispatchHandlers (required) - Handler function to be called after the request is successful or the retries are exhausted. Note: The RetryHandler does not retry over stateful bodies (e.g. streams, AsyncIterable) as those, once consumed, are left in an state that cannot be reutilized. For these situations the RetryHandler will identify the body as stateful and will not retry the request rejecting with the error UND_ERR_REQ_RETRY. Examples: const client = new Client(`http://localhost:${server.address().port}`); const chunks = []; const handler = new RetryHandler( { ...dispatchOptions, retryOptions: { // custom retry function retry: function (err, state, callback) { counter++; if (err.code && err.code === \"UND_ERR_DESTROYED\") { callback(err); return; } if (err.statusCode === 206) { callback(err); return; } setTimeout(() => callback(null), 1000); }, }, }, { dispatch: (...args) => { return client.dispatch(...args); }, handler: { onConnect() {}, onBodySent() {}, onHeaders(status, _rawHeaders, resume, _statusMessage) { // do something with headers }, onData(chunk) { chunks.push(chunk); return true; }, onComplete() {}, onError() { // handle error properly }, }, } ); Example - Basic RetryHandler with defaults const client = new Client(`http://localhost:${server.address().port}`); const handler = new RetryHandler(dispatchOptions, { dispatch: client.dispatch.bind(client), handler: { onConnect() {}, onBodySent() {}, onHeaders(status, _rawHeaders, resume, _statusMessage) {}, onData(chunk) {}, onComplete() {}, onError(err) {}, }, });"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/Util.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/Util.html",
    "title": "Util",
    "summary": "Util Utility API for third-party implementations of the dispatcher API. parseHeaders(headers, [obj]) Receives a header object and returns the parsed value. Arguments: headers (Buffer | string | (Buffer | string)[])[] (required) - Header object. obj Record<string, string | string[]> (optional) - Object to specify a proxy object. The parsed value is assigned to this object. But, if headers is an object, it is not used. Returns: Record<string, string | string[]> If obj is specified, it is equivalent to obj. headerNameToString(value) Retrieves a header name and returns its lowercase value. Arguments: value string | Buffer (required) - Header name. Returns: string"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/api/WebSocket.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/api/WebSocket.html",
    "title": "Class: WebSocket",
    "summary": "Class: WebSocket ⚠️ Warning: the WebSocket API is experimental. Extends: EventTarget The WebSocket object provides a way to manage a WebSocket connection to a server, allowing bidirectional communication. The API follows the WebSocket spec and RFC 6455. new WebSocket(url[, protocol]) Arguments: url URL | string - The url's protocol must be ws or wss. protocol string | string[] | WebSocketInit (optional) - Subprotocol(s) to request the server use, or a Dispatcher. Example: This example will not work in browsers or other platforms that don't allow passing an object. import { WebSocket, ProxyAgent } from 'undici' const proxyAgent = new ProxyAgent('my.proxy.server') const ws = new WebSocket('wss://echo.websocket.events', { dispatcher: proxyAgent, protocols: ['echo', 'chat'] }) If you do not need a custom Dispatcher, it's recommended to use the following pattern: import { WebSocket } from 'undici' const ws = new WebSocket('wss://echo.websocket.events', ['echo', 'chat']) Read More MDN - WebSocket The WebSocket Specification The WHATWG WebSocket Specification"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/best-practices/client-certificate.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/best-practices/client-certificate.html",
    "title": "Client certificate",
    "summary": "Client certificate Client certificate authentication can be configured with the Client, the required options are passed along through the connect option. The client certificates must be signed by a trusted CA. The Node.js default is to trust the well-known CAs curated by Mozilla. Setting the server option requestCert: true tells the server to request the client certificate. The server option rejectUnauthorized: false allows us to handle any invalid certificate errors in client code. The authorized property on the socket of the incoming request will show if the client certificate was valid. The authorizationError property will give the reason if the certificate was not valid. Client Certificate Authentication const { readFileSync } = require('node:fs') const { join } = require('node:path') const { createServer } = require('node:https') const { Client } = require('undici') const serverOptions = { ca: [ readFileSync(join(__dirname, 'client-ca-crt.pem'), 'utf8') ], key: readFileSync(join(__dirname, 'server-key.pem'), 'utf8'), cert: readFileSync(join(__dirname, 'server-crt.pem'), 'utf8'), requestCert: true, rejectUnauthorized: false } const server = createServer(serverOptions, (req, res) => { // true if client cert is valid if(req.client.authorized === true) { console.log('valid') } else { console.error(req.client.authorizationError) } res.end() }) server.listen(0, function () { const tls = { ca: [ readFileSync(join(__dirname, 'server-ca-crt.pem'), 'utf8') ], key: readFileSync(join(__dirname, 'client-key.pem'), 'utf8'), cert: readFileSync(join(__dirname, 'client-crt.pem'), 'utf8'), rejectUnauthorized: false, servername: 'agent1' } const client = new Client(`https://localhost:${server.address().port}`, { connect: tls }) client.request({ path: '/', method: 'GET' }, (err, { body }) => { body.on('data', (buf) => {}) body.on('end', () => { client.close() server.close() }) }) })"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/best-practices/mocking-request.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/best-practices/mocking-request.html",
    "title": "Mocking Request",
    "summary": "Mocking Request Undici has its own mocking utility. It allow us to intercept undici HTTP requests and return mocked values instead. It can be useful for testing purposes. Example: // bank.mjs import { request } from 'undici' export async function bankTransfer(recipient, amount) { const { body } = await request('http://localhost:3000/bank-transfer', { method: 'POST', headers: { 'X-TOKEN-SECRET': 'SuperSecretToken', }, body: JSON.stringify({ recipient, amount }) } ) return await body.json() } And this is what the test file looks like: // index.test.mjs import { strict as assert } from 'assert' import { MockAgent, setGlobalDispatcher, } from 'undici' import { bankTransfer } from './bank.mjs' const mockAgent = new MockAgent(); setGlobalDispatcher(mockAgent); // Provide the base url to the request const mockPool = mockAgent.get('http://localhost:3000'); // intercept the request mockPool.intercept({ path: '/bank-transfer', method: 'POST', headers: { 'X-TOKEN-SECRET': 'SuperSecretToken', }, body: JSON.stringify({ recipient: '1234567890', amount: '100' }) }).reply(200, { message: 'transaction processed' }) const success = await bankTransfer('1234567890', '100') assert.deepEqual(success, { message: 'transaction processed' }) // if you dont want to check whether the body or the headers contain the same value // just remove it from interceptor mockPool.intercept({ path: '/bank-transfer', method: 'POST', }).reply(400, { message: 'bank account not found' }) const badRequest = await bankTransfer('1234567890', '100') assert.deepEqual(badRequest, { message: 'bank account not found' }) Explore other MockAgent functionality here Debug Mock Value When the interceptor and the request options are not the same, undici will automatically make a real HTTP request. To prevent real requests from being made, use mockAgent.disableNetConnect(): const mockAgent = new MockAgent(); setGlobalDispatcher(mockAgent); mockAgent.disableNetConnect() // Provide the base url to the request const mockPool = mockAgent.get('http://localhost:3000'); mockPool.intercept({ path: '/bank-transfer', method: 'POST', }).reply(200, { message: 'transaction processed' }) const badRequest = await bankTransfer('1234567890', '100') // Will throw an error // MockNotMatchedError: Mock dispatch not matched for path '/bank-transfer': // subsequent request to origin http://localhost:3000 was not allowed (net.connect disabled) Reply with data based on request If the mocked response needs to be dynamically derived from the request parameters, you can provide a function instead of an object to reply: mockPool.intercept({ path: '/bank-transfer', method: 'POST', headers: { 'X-TOKEN-SECRET': 'SuperSecretToken', }, body: JSON.stringify({ recipient: '1234567890', amount: '100' }) }).reply(200, (opts) => { // do something with opts return { message: 'transaction processed' } }) in this case opts will be { method: 'POST', headers: { 'X-TOKEN-SECRET': 'SuperSecretToken' }, body: '{\"recipient\":\"1234567890\",\"amount\":\"100\"}', origin: 'http://localhost:3000', path: '/bank-transfer' }"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/best-practices/proxy.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/best-practices/proxy.html",
    "title": "Connecting through a proxy",
    "summary": "Connecting through a proxy Connecting through a proxy is possible by: Using ProxyAgent. Configuring Client or Pool constructor. The proxy url should be passed to the Client or Pool constructor, while the upstream server url should be added to every request call in the path. For instance, if you need to send a request to the /hello route of your upstream server, the path should be path: 'http://upstream.server:port/hello?foo=bar'. If you proxy requires basic authentication, you can send it via the proxy-authorization header. Connect without authentication import { Client } from 'undici' import { createServer } from 'http' import { createProxy } from 'proxy' const server = await buildServer() const proxyServer = await buildProxy() const serverUrl = `http://localhost:${server.address().port}` const proxyUrl = `http://localhost:${proxyServer.address().port}` server.on('request', (req, res) => { console.log(req.url) // '/hello?foo=bar' res.setHeader('content-type', 'application/json') res.end(JSON.stringify({ hello: 'world' })) }) const client = new Client(proxyUrl) const response = await client.request({ method: 'GET', path: serverUrl + '/hello?foo=bar' }) response.body.setEncoding('utf8') let data = '' for await (const chunk of response.body) { data += chunk } console.log(response.statusCode) // 200 console.log(JSON.parse(data)) // { hello: 'world' } server.close() proxyServer.close() client.close() function buildServer () { return new Promise((resolve, reject) => { const server = createServer() server.listen(0, () => resolve(server)) }) } function buildProxy () { return new Promise((resolve, reject) => { const server = createProxy(createServer()) server.listen(0, () => resolve(server)) }) } Connect with authentication import { Client } from 'undici' import { createServer } from 'http' import { createProxy } from 'proxy' const server = await buildServer() const proxyServer = await buildProxy() const serverUrl = `http://localhost:${server.address().port}` const proxyUrl = `http://localhost:${proxyServer.address().port}` proxyServer.authenticate = function (req) { return req.headers['proxy-authorization'] === `Basic ${Buffer.from('user:pass').toString('base64')}` } server.on('request', (req, res) => { console.log(req.url) // '/hello?foo=bar' res.setHeader('content-type', 'application/json') res.end(JSON.stringify({ hello: 'world' })) }) const client = new Client(proxyUrl) const response = await client.request({ method: 'GET', path: serverUrl + '/hello?foo=bar', headers: { 'proxy-authorization': `Basic ${Buffer.from('user:pass').toString('base64')}` } }) response.body.setEncoding('utf8') let data = '' for await (const chunk of response.body) { data += chunk } console.log(response.statusCode) // 200 console.log(JSON.parse(data)) // { hello: 'world' } server.close() proxyServer.close() client.close() function buildServer () { return new Promise((resolve, reject) => { const server = createServer() server.listen(0, () => resolve(server)) }) } function buildProxy () { return new Promise((resolve, reject) => { const server = createProxy(createServer()) server.listen(0, () => resolve(server)) }) }"
  },
  "src/frontend/app-client/node_modules/undici/docs/docs/best-practices/writing-tests.html": {
    "href": "src/frontend/app-client/node_modules/undici/docs/docs/best-practices/writing-tests.html",
    "title": "Writing tests",
    "summary": "Writing tests Undici is tuned for a production use case and its default will keep a socket open for a few seconds after an HTTP request is completed to remove the overhead of opening up a new socket. These settings that makes Undici shine in production are not a good fit for using Undici in automated tests, as it will result in longer execution times. The following are good defaults that will keep the socket open for only 10ms: import { request, setGlobalDispatcher, Agent } from 'undici' const agent = new Agent({ keepAliveTimeout: 10, // milliseconds keepAliveMaxTimeout: 10 // milliseconds }) setGlobalDispatcher(agent)"
  },
  "src/frontend/app-client/node_modules/undici/README.html": {
    "href": "src/frontend/app-client/node_modules/undici/README.html",
    "title": "undici",
    "summary": "undici An HTTP/1.1 client, written from scratch for Node.js. Undici means eleven in Italian. 1.1 -> 11 -> Eleven -> Undici. It is also a Stranger Things reference. How to get involved Have a question about using Undici? Open a Q&A Discussion or join our official OpenJS Slack channel. Looking to contribute? Start by reading the contributing guide Install npm i undici Benchmarks The benchmark is a simple getting data example using a 50 TCP connections with a pipelining depth of 10 running on Node 20.10.0. Tests Samples Result Tolerance Difference with slowest undici - fetch 30 3704.43 req/sec ± 2.95 % - http - no keepalive 20 4275.30 req/sec ± 2.60 % + 15.41 % node-fetch 10 4759.42 req/sec ± 0.87 % + 28.48 % request 40 4803.37 req/sec ± 2.77 % + 29.67 % axios 45 4951.97 req/sec ± 2.88 % + 33.68 % got 10 5969.67 req/sec ± 2.64 % + 61.15 % superagent 10 9471.48 req/sec ± 1.50 % + 155.68 % http - keepalive 25 10327.49 req/sec ± 2.95 % + 178.79 % undici - pipeline 10 15053.41 req/sec ± 1.63 % + 306.36 % undici - request 10 19264.24 req/sec ± 1.74 % + 420.03 % undici - stream 15 20317.29 req/sec ± 2.13 % + 448.46 % undici - dispatch 10 24883.28 req/sec ± 1.54 % + 571.72 % The benchmark is a simple sending data example using a 50 TCP connections with a pipelining depth of 10 running on Node 20.10.0. Tests Samples Result Tolerance Difference with slowest undici - fetch 20 1968.42 req/sec ± 2.63 % - http - no keepalive 25 2330.30 req/sec ± 2.99 % + 18.38 % node-fetch 20 2485.36 req/sec ± 2.70 % + 26.26 % got 15 2787.68 req/sec ± 2.56 % + 41.62 % request 30 2805.10 req/sec ± 2.59 % + 42.50 % axios 10 3040.45 req/sec ± 1.72 % + 54.46 % superagent 20 3358.29 req/sec ± 2.51 % + 70.61 % http - keepalive 20 3477.94 req/sec ± 2.51 % + 76.69 % undici - pipeline 25 3812.61 req/sec ± 2.80 % + 93.69 % undici - request 10 6067.00 req/sec ± 0.94 % + 208.22 % undici - stream 10 6391.61 req/sec ± 1.98 % + 224.71 % undici - dispatch 10 6397.00 req/sec ± 1.48 % + 224.98 % Quick Start import { request } from 'undici' const { statusCode, headers, trailers, body } = await request('http://localhost:3000/foo') console.log('response received', statusCode) console.log('headers', headers) for await (const data of body) { console.log('data', data) } console.log('trailers', trailers) Body Mixins The body mixins are the most common way to format the request/response body. Mixins include: .arrayBuffer() .blob() .bytes() .json() .text() Note The body returned from undici.request does not implement .formData(). Example usage: import { request } from 'undici' const { statusCode, headers, trailers, body } = await request('http://localhost:3000/foo') console.log('response received', statusCode) console.log('headers', headers) console.log('data', await body.json()) console.log('trailers', trailers) Note: Once a mixin has been called then the body cannot be reused, thus calling additional mixins on .body, e.g. .body.json(); .body.text() will result in an error TypeError: unusable being thrown and returned through the Promise rejection. Should you need to access the body in plain-text after using a mixin, the best practice is to use the .text() mixin first and then manually parse the text to the desired format. For more information about their behavior, please reference the body mixin from the Fetch Standard. Common API Methods This section documents our most commonly used API methods. Additional APIs are documented in their own files within the docs folder and are accessible via the navigation list on the left side of the docs site. undici.request([url, options]): Promise Arguments: url string | URL | UrlObject options RequestOptions dispatcher Dispatcher - Default: getGlobalDispatcher method String - Default: PUT if options.body, otherwise GET maxRedirections Integer - Default: 0 Returns a promise with the result of the Dispatcher.request method. Calls options.dispatcher.request(options). See Dispatcher.request for more details, and request examples for examples. undici.stream([url, options, ]factory): Promise Arguments: url string | URL | UrlObject options StreamOptions dispatcher Dispatcher - Default: getGlobalDispatcher method String - Default: PUT if options.body, otherwise GET maxRedirections Integer - Default: 0 factory Dispatcher.stream.factory Returns a promise with the result of the Dispatcher.stream method. Calls options.dispatcher.stream(options, factory). See Dispatcher.stream for more details. undici.pipeline([url, options, ]handler): Duplex Arguments: url string | URL | UrlObject options PipelineOptions dispatcher Dispatcher - Default: getGlobalDispatcher method String - Default: PUT if options.body, otherwise GET maxRedirections Integer - Default: 0 handler Dispatcher.pipeline.handler Returns: stream.Duplex Calls options.dispatch.pipeline(options, handler). See Dispatcher.pipeline for more details. undici.connect([url, options]): Promise Starts two-way communications with the requested resource using HTTP CONNECT. Arguments: url string | URL | UrlObject options ConnectOptions dispatcher Dispatcher - Default: getGlobalDispatcher maxRedirections Integer - Default: 0 callback (err: Error | null, data: ConnectData | null) => void (optional) Returns a promise with the result of the Dispatcher.connect method. Calls options.dispatch.connect(options). See Dispatcher.connect for more details. undici.fetch(input[, init]): Promise Implements fetch. https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/fetch https://fetch.spec.whatwg.org/#fetch-method Basic usage example: import { fetch } from 'undici' const res = await fetch('https://example.com') const json = await res.json() console.log(json) You can pass an optional dispatcher to fetch as: import { fetch, Agent } from 'undici' const res = await fetch('https://example.com', { // Mocks are also supported dispatcher: new Agent({ keepAliveTimeout: 10, keepAliveMaxTimeout: 10 }) }) const json = await res.json() console.log(json) request.body A body can be of the following types: ArrayBuffer ArrayBufferView AsyncIterables Blob Iterables String URLSearchParams FormData In this implementation of fetch, request.body now accepts Async Iterables. It is not present in the Fetch Standard. import { fetch } from 'undici' const data = { async *[Symbol.asyncIterator]() { yield 'hello' yield 'world' }, } await fetch('https://example.com', { body: data, method: 'POST', duplex: 'half' }) FormData besides text data and buffers can also utilize streams via Blob objects: import { openAsBlob } from 'node:fs' const file = await openAsBlob('./big.csv') const body = new FormData() body.set('file', file, 'big.csv') await fetch('http://example.com', { method: 'POST', body }) request.duplex half In this implementation of fetch, request.duplex must be set if request.body is ReadableStream or Async Iterables, however, fetch requests are currently always full duplex. For more detail refer to the Fetch Standard.. response.body Nodejs has two kinds of streams: web streams, which follow the API of the WHATWG web standard found in browsers, and an older Node-specific streams API. response.body returns a readable web stream. If you would prefer to work with a Node stream you can convert a web stream using .fromWeb(). import { fetch } from 'undici' import { Readable } from 'node:stream' const response = await fetch('https://example.com') const readableWebStream = response.body const readableNodeStream = Readable.fromWeb(readableWebStream) Specification Compliance This section documents parts of the Fetch Standard that Undici does not support or does not fully implement. Garbage Collection https://fetch.spec.whatwg.org/#garbage-collection The Fetch Standard allows users to skip consuming the response body by relying on garbage collection to release connection resources. Undici does not do the same. Therefore, it is important to always either consume or cancel the response body. Garbage collection in Node is less aggressive and deterministic (due to the lack of clear idle periods that browsers have through the rendering refresh rate) which means that leaving the release of connection resources to the garbage collector can lead to excessive connection usage, reduced performance (due to less connection re-use), and even stalls or deadlocks when running out of connections. // Do const headers = await fetch(url) .then(async res => { for await (const chunk of res.body) { // force consumption of body } return res.headers }) // Do not const headers = await fetch(url) .then(res => res.headers) However, if you want to get only headers, it might be better to use HEAD request method. Usage of this method will obviate the need for consumption or cancelling of the response body. See MDN - HTTP - HTTP request methods - HEAD for more details. const headers = await fetch(url, { method: 'HEAD' }) .then(res => res.headers) Forbidden and Safelisted Header Names https://fetch.spec.whatwg.org/#cors-safelisted-response-header-name https://fetch.spec.whatwg.org/#forbidden-header-name https://fetch.spec.whatwg.org/#forbidden-response-header-name https://github.com/wintercg/fetch/issues/6 The Fetch Standard requires implementations to exclude certain headers from requests and responses. In browser environments, some headers are forbidden so the user agent remains in full control over them. In Undici, these constraints are removed to give more control to the user. undici.upgrade([url, options]): Promise Upgrade to a different protocol. See MDN - HTTP - Protocol upgrade mechanism for more details. Arguments: url string | URL | UrlObject options UpgradeOptions dispatcher Dispatcher - Default: getGlobalDispatcher maxRedirections Integer - Default: 0 callback (error: Error | null, data: UpgradeData) => void (optional) Returns a promise with the result of the Dispatcher.upgrade method. Calls options.dispatcher.upgrade(options). See Dispatcher.upgrade for more details. undici.setGlobalDispatcher(dispatcher) dispatcher Dispatcher Sets the global dispatcher used by Common API Methods. undici.getGlobalDispatcher() Gets the global dispatcher used by Common API Methods. Returns: Dispatcher undici.setGlobalOrigin(origin) origin string | URL | undefined Sets the global origin used in fetch. If undefined is passed, the global origin will be reset. This will cause Response.redirect, new Request(), and fetch to throw an error when a relative path is passed. setGlobalOrigin('http://localhost:3000') const response = await fetch('/api/ping') console.log(response.url) // http://localhost:3000/api/ping undici.getGlobalOrigin() Gets the global origin used in fetch. Returns: URL UrlObject port string | number (optional) path string (optional) pathname string (optional) hostname string (optional) origin string (optional) protocol string (optional) search string (optional) Specification Compliance This section documents parts of the HTTP/1.1 specification that Undici does not support or does not fully implement. Expect Undici does not support the Expect request header field. The request body is always immediately sent and the 100 Continue response will be ignored. Refs: https://tools.ietf.org/html/rfc7231#section-5.1.1 Pipelining Undici will only use pipelining if configured with a pipelining factor greater than 1. Undici always assumes that connections are persistent and will immediately pipeline requests, without checking whether the connection is persistent. Hence, automatic fallback to HTTP/1.0 or HTTP/1.1 without pipelining is not supported. Undici will immediately pipeline when retrying requests after a failed connection. However, Undici will not retry the first remaining requests in the prior pipeline and instead error the corresponding callback/promise/stream. Undici will abort all running requests in the pipeline when any of them are aborted. Refs: https://tools.ietf.org/html/rfc2616#section-8.1.2.2 Refs: https://tools.ietf.org/html/rfc7230#section-6.3.2 Manual Redirect Since it is not possible to manually follow an HTTP redirect on the server-side, Undici returns the actual response instead of an opaqueredirect filtered one when invoked with a manual redirect. This aligns fetch() with the other implementations in Deno and Cloudflare Workers. Refs: https://fetch.spec.whatwg.org/#atomic-http-redirect-handling Workarounds Network address family autoselection. If you experience problem when connecting to a remote server that is resolved by your DNS servers to a IPv6 (AAAA record) first, there are chances that your local router or ISP might have problem connecting to IPv6 networks. In that case undici will throw an error with code UND_ERR_CONNECT_TIMEOUT. If the target server resolves to both a IPv6 and IPv4 (A records) address and you are using a compatible Node version (18.3.0 and above), you can fix the problem by providing the autoSelectFamily option (support by both undici.request and undici.Agent) which will enable the family autoselection algorithm when establishing the connection. Collaborators Daniele Belardi, https://www.npmjs.com/~dnlup Ethan Arrowood, https://www.npmjs.com/~ethan_arrowood Matteo Collina, https://www.npmjs.com/~matteo.collina Matthew Aitken, https://www.npmjs.com/~khaf Robert Nagy, https://www.npmjs.com/~ronag Szymon Marczak, https://www.npmjs.com/~szmarczak Tomas Della Vedova, https://www.npmjs.com/~delvedor Releasers Ethan Arrowood, https://www.npmjs.com/~ethan_arrowood Matteo Collina, https://www.npmjs.com/~matteo.collina Robert Nagy, https://www.npmjs.com/~ronag Matthew Aitken, https://www.npmjs.com/~khaf License MIT"
  },
  "src/frontend/app-client/node_modules/undici/types/README.html": {
    "href": "src/frontend/app-client/node_modules/undici/types/README.html",
    "title": "undici-types",
    "summary": "undici-types This package is a dual-publish of the undici library types. The undici package still contains types. This package is for users who only need undici types (such as for @types/node). It is published alongside every release of undici, so you can always use the same version. GitHub nodejs/undici Undici Documentation"
  },
  "src/frontend/app-client/node_modules/universalify/README.html": {
    "href": "src/frontend/app-client/node_modules/universalify/README.html",
    "title": "universalify",
    "summary": "universalify Make a callback- or promise-based function support both promises and callbacks. Uses the native promise implementation. Installation npm install universalify API universalify.fromCallback(fn) Takes a callback-based function to universalify, and returns the universalified function. Function must take a callback as the last parameter that will be called with the signature (error, result). universalify does not support calling the callback with three or more arguments, and does not ensure that the callback is only called once. function callbackFn (n, cb) { setTimeout(() => cb(null, n), 15) } const fn = universalify.fromCallback(callbackFn) // Works with Promises: fn('Hello World!') .then(result => console.log(result)) // -> Hello World! .catch(error => console.error(error)) // Works with Callbacks: fn('Hi!', (error, result) => { if (error) return console.error(error) console.log(result) // -> Hi! }) universalify.fromPromise(fn) Takes a promise-based function to universalify, and returns the universalified function. Function must return a valid JS promise. universalify does not ensure that a valid promise is returned. function promiseFn (n) { return new Promise(resolve => { setTimeout(() => resolve(n), 15) }) } const fn = universalify.fromPromise(promiseFn) // Works with Promises: fn('Hello World!') .then(result => console.log(result)) // -> Hello World! .catch(error => console.error(error)) // Works with Callbacks: fn('Hi!', (error, result) => { if (error) return console.error(error) console.log(result) // -> Hi! }) License MIT"
  },
  "src/frontend/app-client/node_modules/unpipe/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/unpipe/HISTORY.html",
    "title": "1.0.0 / 2015-06-14",
    "summary": "1.0.0 / 2015-06-14 Initial release"
  },
  "src/frontend/app-client/node_modules/unpipe/README.html": {
    "href": "src/frontend/app-client/node_modules/unpipe/README.html",
    "title": "unpipe",
    "summary": "unpipe Unpipe a stream from all destinations. Installation $ npm install unpipe API var unpipe = require('unpipe') unpipe(stream) Unpipes all destinations from a given stream. With stream 2+, this is equivalent to stream.unpipe(). When used with streams 1 style streams (typically Node.js 0.8 and below), this module attempts to undo the actions done in stream.pipe(dest). License MIT"
  },
  "src/frontend/app-client/node_modules/update-browserslist-db/README.html": {
    "href": "src/frontend/app-client/node_modules/update-browserslist-db/README.html",
    "title": "Update Browserslist DB",
    "summary": "Update Browserslist DB CLI tool to update caniuse-lite with browsers DB from Browserslist config. Some queries like last 2 versions or >1% depend on actual data from caniuse-lite. npx update-browserslist-db@latest Docs Read full docs here."
  },
  "src/frontend/app-client/node_modules/use-callback-ref/README.html": {
    "href": "src/frontend/app-client/node_modules/use-callback-ref/README.html",
    "title": "\uD83E\uDD19 use-callback-ref \uD83D\uDCDE",
    "summary": "\uD83E\uDD19 use-callback-ref \uD83D\uDCDE The same `useRef` but it will callback: \uD83D\uDCDE Hello! Your ref was changed! Keep in mind that useRef doesn't notify you when its content changes. Mutating the .current property doesn't cause a re-render. If you want to run some code when React attaches or detaches a ref to a DOM node, you may want to use a callback ref instead .... useCallbackRef instead. – Hooks API Reference Read more about use-callback pattern and use cases: https://dev.to/thekashey/the-same-useref-but-it-will-callback-8bo This library exposes helpers to handle any case related to ref lifecycle useCallbackRef - react on a ref change (replacement for useRef) createCallbackRef - - low level version of useCallbackRef useMergeRefs - merge multiple refs together creating a stable return ref mergeRefs - low level version of useMergeRefs useTransformRef - transform one ref to another (replacement for useImperativeHandle) transformRef - low level version of useTransformRef useRefToCallback - convert RefObject to an old callback-style ref refToCallback - low level version of useRefToCallback assignRef - assign value to the ref, regardless it is RefCallback or RefObject All functions are tree shakable, but even together it's less then 300b. API \uD83D\uDCA1 Some commands are hooks based, and returns the same refs/functions every render. But some are not, to be used in classes or non-react code. useRef API \uD83E\uDD14 Use case: every time you have to react to ref change API is 99% compatible with React createRef and useRef, and just adds another argument - callback, which would be called on ref update. createCallbackRef - to replace React.createRef createCallbackRef(callback) - would call provided callback when ref is changed. useCallbackRef - to replace React.useRef useCallbackRef(initialValue, callback) - would call provided callback when ref is changed. callback in both cases is callback(newValue, oldValue). Callback would not be called if newValue and oldValue is the same. import { useRef, createRef, useState } from 'react'; import { useCallbackRef, createCallbackRef } from 'use-callback-ref'; const Component = () => { const [, forceUpdate] = useState(); // I dont need callback when ref changes const ref = useRef(null); // but sometimes - it could be what you need const anotherRef = useCallbackRef(null, () => forceUpdate()); useEffect(() => { // now it's just possible }, [anotherRef.current]); // react to dom node change }; \uD83D\uDCA1 You can use useCallbackRef to convert RefObject into RefCallback, creating bridges between the old and the new code // some old component const onRefUpdate = (newRef) => {...} const refObject = useCallbackRef(null, onRefUpdate); // ... <SomeNewComponent ref={refObject}/> assignRef \uD83E\uDD14 Use case: every time you need to assign ref manually, and you dont know the shape of the ref assignRef(ref, value) - assigns values to the ref. ref could be RefObject or RefCallback. \uD83D\uDEAB ref.current = value // what if it's a callback-ref? \uD83D\uDEAB ref(value) // but what if it's a object ref? import {assignRef} from \"use-callback-ref\"; ✅ assignRef(ref, value); useTransformRef (to replace React.useImperativeHandle) \uD83E\uDD14 Use case: ref could be different. transformRef(ref, tranformer):Ref - return a new ref which would propagate all changes to the provided ref with applied transform // before const ResizableWithRef = forwardRef((props, ref) => <Resizable {...props} ref={(i) => i && ref(i.resizable)} />); // after const ResizableWithRef = forwardRef((props, ref) => ( <Resizable {...props} ref={transformRef(ref, (i) => (i ? i.resizable : null))} /> )); refToCallback refToCallback(ref: RefObject): RefCallback - for compatibility between the old and the new code. For the compatibility between RefCallback and RefObject use useCallbackRef(undefined, callback) useMergeRefs mergeRefs(refs: arrayOfRefs, [defaultValue]):ReactMutableRef - merges a few refs together When developing low level UI components, it is common to have to use a local ref but also support an external one using React.forwardRef. Natively, React does not offer a way to set two refs inside the ref property. This is the goal of this small utility. import React from 'react'; import { useMergeRefs } from 'use-callback-ref'; const MergedComponent = React.forwardRef((props, ref) => { const localRef = React.useRef(); // ... // both localRef and ref would be populated with the `ref` to a `div` return <div ref={useMergeRefs([localRef, ref])} />; }); \uD83D\uDCA1 - useMergeRefs will always give you the same return, and you don't have to worry about [localRef, ref] unique every render. mergeRefs mergeRefs(refs: arrayOfRefs, [defaultValue]):ReactMutableRef - merges a few refs together is a non-hook based version. Will produce the new ref every run, causing the old one to unmount, and be populated with the null value. mergeRefs are based on https://github.com/smooth-code/react-merge-refs, just exposes a RefObject, instead of a callback mergeRefs are \"safe\" to use as a part of other hooks-based commands, but don't forget - it returns a new object every call. Similar packages: apply-ref - applyRefs is simular to mergeRef, applyRef is similar to assignRef useForkRef - useForkRef is simular to useMergeRefs, but accepts only two arguments. react-merge-refs - merge-refs is simular to useMergeRefs, but not a hook and does not provide \"stable\" reference. Is it a rocket science? No, RefObject is no more than {current: ref}, and use-callback-ref is no more than getter and setter on that field. License MIT"
  },
  "src/frontend/app-client/node_modules/use-sidecar/README.html": {
    "href": "src/frontend/app-client/node_modules/use-sidecar/README.html",
    "title": "\uD83C\uDFCE side car",
    "summary": "\uD83C\uDFCE side car Alternative way to code splitting UI/Effects code splitting pattern read the original article to understand concepts behind. read how Google split view and logic. watch how Facebook defers \"interactivity\" effects. Terminology: sidecar - non UI component, which may carry effects for a paired UI component. UI - UI component, which interactivity is moved to a sidecar. UI is a view, sidecar is the logic for it. Like Batman(UI) and his sidekick Robin(effects). Concept a package exposes 3 entry points using a nested package.json format: default aka combination, and lets hope tree shaking will save you UI, with only UI part sidecar, with all the logic UI + sidecar === combination. The size of UI+sidecar might a bit bigger than size of their combination. Use size-limit to control their size independently. package uses a medium to talk with own sidecar, breaking explicit dependency. if package depends on another sidecar package: it shall export dependency side car among own sidecar. package imports own sidecar via medium, thus able to export multiple sidecars via one export. final consumer uses sidecar or useSidecar to combine pieces together. Rules UI components might use/import any other UI components sidecar could use/import any other sidecar That would form two different code branches, you may load separately - UI first, and effect sidecar later. That also leads to a obvious consequence - one sidecar may export all sidecars. to decouple sidecars from module exports, and be able to pick \"the right\" one at any point you have to use exportSidecar(medium, component) to export it, and use the same medium to import it back. this limitation is for libraries only, as long as in the usercode you might dynamically import whatever and whenever you want. useMedium is always async - action would be executed in a next tick, or on the logic load. sidecar is always async - is does not matter have you loaded logic or not - component would be rendered at least in the next tick. except medium.read, which synchronously read the data from a medium, and medium.assingSyncMedium which changes useMedium to be sync. SSR and usage tracking Sidecar pattern is clear: you dont need to use/render any sidecars on server. you dont have to load sidecars prior main render. Thus - no usage tracking, and literally no SSR. It's just skipped. API createMedium() Type: Util. Creates shared effect medium for algebraic effect. Goal: To decouple modules from each other. Usage: use in UI side, and assign from side-car. All effects would be executed. Analog: WeakMap, React.__SECRET_DOM_DO_NOT_USE_OR_YOU_WILL_BE_FIRED const medium = createMedium(defaultValue); const cancelCb = medium.useMedium(someData); // like useEffect(() => medium.useMedium(someData), []); medium.assignMedium(someDataProcessor) // createSidecarMedium is a helper for createMedium to create a \"sidecar\" symbol const effectCar = createSidecarMedium(); ! For consistence useMedium is async - sidecar load status should not affect function behavior, thus effect would be always executed at least in the \"next tick\". You may alter this behavior by using medium.assingSyncMedium. exportSidecar(medium, component) Type: HOC Goal: store component inside medium and return external wrapper Solving: decoupling module exports to support exporting multiple sidecars via a single entry point. Usage: use to export a sidecar Analog: WeakMap import {effectCar} from './medium'; import {EffectComponent} from './Effect'; // !!! - to prevent Effect from being imported // `effectCar` medium __have__ to be defined in another file // const effectCar = createSidecarMedium(); export default exportSidecar(effectCar, EffectComponent); sidecar(importer) Type: HOC Goal: React.lazy analog for code splitting, but does not require Suspense, might provide error failback. Usage: like React.lazy to load a side-car component. Analog: React.Lazy import {sidecar} from \"use-sidecar\"; const Sidecar = sidecar(() => import('./sidecar'), <span>on fail</span>); <> <Sidecar /> <UI /> </> Importing exportedSidecar Would require additional prop to be set - <Sidecar sideCar={effectCar} /> useSidecar(importer) Type: hook, loads a sideCar using provided importer which shall follow React.lazy API Goal: to load a side car without displaying any \"spinners\". Usage: load side car for a component Analog: none import {useSidecar} from 'use-sidecar'; const [Car, error] = useSidecar(() => import('./sideCar')); return ( <> {Car ? <Car {...props} /> : null} <UIComponent {...props}> </> ); Importing exportedSideCar You have to specify effect medium to read data from, as long as export itself is empty. import {useSidecar} from 'use-sidecar'; /* medium.js: */ export const effectCar = useMedium({}); /* sideCar.js: */export default exportSidecar(effectCar, EffectComponent); const [Car, error] = useSidecar(() => import('./sideCar'), effectCar); return ( <> {Car ? <Car {...props} /> : null} <UIComponent {...props}> </> ); renderCar(Component) Type: HOC, moves renderProp component to a side channel Goal: Provide render prop support, ie defer component loading keeping tree untouched. Usage: Provide defaults and use them until sidecar is loaded letting you code split (non visual) render-prop component Analog: - Analog: code split library like react-imported-library or @loadable/lib. import {renderCar, sidecar} from \"use-sidecar\"; const RenderCar = renderCar( // will move side car to a side channel sidecar(() => import('react-powerplug').then(imports => imports.Value)), // default render props [{value: 0}] ); <RenderCar> {({value}) => <span>{value}</span>} </RenderCar> setConfig(config) setConfig({ onError, // sets default error handler }); Examples Deferred effect Let's imagine - on element focus you have to do \"something\", for example focus anther element Original code onFocus = event => { if (event.currentTarget === event.target) { document.querySelectorAll('button', event.currentTarget) } } Sidecar code Use medium (yes, .3) // we are calling medium with an original event as an argument const onFocus = event => focusMedium.useMedium(event); Define reaction // in a sidecar // we are setting handler for the effect medium // effect is complicated - we are skipping event \"bubbling\", // and focusing some button inside a parent focusMedium.assignMedium(event => { if (event.currentTarget === event.target) { document.querySelectorAll('button', event.currentTarget) } }); Create medium Having these constrains - we have to clone event, as long as React would eventually reuse SyntheticEvent, thus not preserve target and currentTarget. // const focusMedium = createMedium(null, event => ({...event})); Now medium side effect is ok to be async Example: Effect for react-focus-lock - 1kb UI, 4kb sidecar Medium callback Like a library level code splitting Original code import {x, y} from './utils'; useEffect(() => { if (x()) { y() } }, []); Sidecar code // medium const utilMedium = createMedium(); // utils const x = () => { /* ... */}; const y = () => { /* ... */}; // medium will callback with exports exposed utilMedium.assignMedium(cb => cb({ x, y })); // UI // not importing x and y from the module system, but would be given via callback useEffect(() => { utilMedium.useMedium(({x,y}) => { if (x()) { y() } }) }, []); Hint: there is a easy way to type it const utilMedium = createMedium<(cb: typeof import('./utils')) => void>(); Example: Callback API for react-focus-lock Split effects Lets take an example from a Google - Calendar app, with view and logic separated. To be honest - it's not easy to extract logic from application like calendar - usually it's tight coupled. Original code const CalendarUI = () => { const [date, setDate] = useState(); const onButtonClick = useCallback(() => setDate(Date.now), []); return ( <> <input type=\"date\" onChange={setDate} value={date} /> <input type=\"button\" onClick={onButtonClick}>Set Today</button> </> ) } Sidecar code const CalendarUI = () => { const [events, setEvents] = useState({}); const [date, setDate] = useState(); return ( <> <Sidecar setDate={setDate} setEvents={setEvents}/> <UILayout {...events} date={date}/> </> ) } const UILayout = ({onDateChange, onButtonClick, date}) => ( <> <input type=\"date\" onChange={onDateChange} value={date} /> <input type=\"button\" onClick={onButtonClick}>Set Today</button> </> ); // in a sidecar // we are providing callbacks back to UI const Sidecar = ({setDate, setEvents}) => { useEffect(() => setEvents({ onDateChange:setDate, onButtonClick: () => setDate(Date.now), }), []); return null; } While in this example this looks a bit, you know, strange - there are 3 times more code that in the original example - that would make a sense for a real Calendar, especially if some helper library, like moment, has been used. Example: Effect for react-remove-scroll - 300b UI, 2kb sidecar Licence MIT"
  },
  "src/frontend/app-client/node_modules/util-deprecate/History.html": {
    "href": "src/frontend/app-client/node_modules/util-deprecate/History.html",
    "title": "1.0.2 / 2015-10-07",
    "summary": "1.0.2 / 2015-10-07 use try/catch when checking localStorage (#3, @kumavis) 1.0.1 / 2014-11-25 browser: use console.warn() for deprecation calls browser: more jsdocs 1.0.0 / 2014-04-30 initial commit"
  },
  "src/frontend/app-client/node_modules/util-deprecate/README.html": {
    "href": "src/frontend/app-client/node_modules/util-deprecate/README.html",
    "title": "util-deprecate",
    "summary": "util-deprecate The Node.js util.deprecate() function with browser support In Node.js, this module simply re-exports the util.deprecate() function. In the web browser (i.e. via browserify), a browser-specific implementation of the util.deprecate() function is used. API A deprecate() function is the only thing exposed by this module. // setup: exports.foo = deprecate(foo, 'foo() is deprecated, use bar() instead'); // users see: foo(); // foo() is deprecated, use bar() instead foo(); foo(); License (The MIT License) Copyright (c) 2014 Nathan Rajlich nathan@tootallnate.net Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/utils-merge/README.html": {
    "href": "src/frontend/app-client/node_modules/utils-merge/README.html",
    "title": "utils-merge",
    "summary": "utils-merge Merges the properties from a source object into a destination object. Install $ npm install utils-merge Usage var a = { foo: 'bar' } , b = { bar: 'baz' }; merge(a, b); // => { foo: 'bar', bar: 'baz' } License The MIT License Copyright (c) 2013-2017 Jared Hanson <http://jaredhanson.net/>"
  },
  "src/frontend/app-client/node_modules/uuid/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/uuid/CHANGELOG.html",
    "title": "Changelog",
    "summary": "Changelog All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 8.3.2 (2020-12-08) Bug Fixes lazy load getRandomValues (#537) (16c8f6d), closes #536 8.3.1 (2020-10-04) Bug Fixes support expo>=39.0.0 (#515) (c65a0f3), closes #375 8.3.0 (2020-07-27) Features add parse/stringify/validate/version/NIL APIs (#479) (0e6c10b), closes #475 #478 #480 #481 #180 8.2.0 (2020-06-23) Features improve performance of v1 string representation (#453) (0ee0b67) remove deprecated v4 string parameter (#454) (88ce3ca), closes #437 support jspm (#473) (e9f2587) Bug Fixes prepare package exports for webpack 5 (#468) (8d6e6a5) 8.1.0 (2020-05-20) Features improve v4 performance by reusing random number array (#435) (bf4af0d) optimize V8 performance of bytesToUuid (#434) (e156415) Bug Fixes export package.json required by react-native and bundlers (#449) (be1c8fe), closes ai/nanoevents#44 #444 8.0.0 (2020-04-29) ⚠ BREAKING CHANGES For native ECMAScript Module (ESM) usage in Node.js only named exports are exposed, there is no more default export. -import uuid from 'uuid'; -console.log(uuid.v4()); // -> 'cd6c3b08-0adc-4f4b-a6ef-36087a1c9869' +import { v4 as uuidv4 } from 'uuid'; +uuidv4(); // ⇨ '9b1deb4d-3b7d-4bad-9bdd-2b0d7b3dcb6d' Deep requiring specific algorithms of this library like require('uuid/v4'), which has been deprecated in uuid@7, is no longer supported. Instead use the named exports that this module exports. For ECMAScript Modules (ESM): -import uuidv4 from 'uuid/v4'; +import { v4 as uuidv4 } from 'uuid'; uuidv4(); For CommonJS: -const uuidv4 = require('uuid/v4'); +const { v4: uuidv4 } = require('uuid'); uuidv4(); Features native Node.js ES Modules (wrapper approach) (#423) (2d9f590), closes #245 #419 #342 remove deep requires (#426) (daf72b8) Bug Fixes add CommonJS syntax example to README quickstart section (#417) (e0ec840) 7.0.3 (2020-03-31) Bug Fixes make deep require deprecation warning work in browsers (#409) (4b71107), closes #408 7.0.2 (2020-03-04) Bug Fixes make access to msCrypto consistent (#393) (8bf2a20) simplify link in deprecation warning (#391) (bb2c8e4) update links to match content in readme (#386) (44f2f86) 7.0.1 (2020-02-25) Bug Fixes clean up esm builds for node and browser (#383) (59e6a49) provide browser versions independent from module system (#380) (4344a22), closes #378 7.0.0 (2020-02-24) ⚠ BREAKING CHANGES The default export, which used to be the v4() method but which was already discouraged in v3.x of this library, has been removed. Explicitly note that deep imports of the different uuid version functions are deprecated and no longer encouraged and that ECMAScript module named imports should be used instead. Emit a deprecation warning for people who deep-require the different algorithm variants. Remove builtin support for insecure random number generators in the browser. Users who want that will have to supply their own random number generator function. Remove support for generating v3 and v5 UUIDs in Node.js<4.x Convert code base to ECMAScript Modules (ESM) and release CommonJS build for node and ESM build for browser bundlers. Features add UMD build to npm package (#357) (4e75adf), closes #345 add various es module and CommonJS examples (b238510) ensure that docs are up-to-date in CI (ee5e77d) hybrid CommonJS & ECMAScript modules build (a3f078f) remove insecure fallback random number generator (3a5842b), closes #173 remove support for pre Node.js v4 Buffer API (#356) (b59b5c5) rename repository to github:uuidjs/uuid (#351) (c37a518), closes #338 Bug Fixes add deep-require proxies for local testing and adjust tests (#365) (7fedc79) add note about removal of default export (#372) (12749b7), closes #370 deprecated deep requiring of the different algorithm versions (#361) (c0bdf15) 3.4.0 (2020-01-16) Features rename repository to github:uuidjs/uuid (#351) (e2d7314), closes #338 3.3.3 (2019-08-19) Bug Fixes no longer run ci tests on node v4 upgrade dependencies 3.3.2 (2018-06-28) Bug Fixes typo (305d877) 3.3.1 (2018-06-28) Bug Fixes fix #284 by setting function name in try-catch (f2a60f2) 3.3.0 (2018-06-22) Bug Fixes assignment to readonly property to allow running in strict mode (#270) (d062fdc) fix #229 (c9684d4) Get correct version of IE11 crypto (#274) (153d331) mem issue when generating uuid (#267) (c47702c) Features enforce Conventional Commit style commit messages (#282) (cc9a182) 3.2.1 (2018-01-16) Bug Fixes use msCrypto if available. Fixes #241 (#247) (1fef18b) 3.2.0 (2018-01-16) Bug Fixes remove mistakenly added typescript dependency, rollback version (standard-version will auto-increment) (09fa824) use msCrypto if available. Fixes #241 (#247) (1fef18b) Features Add v3 Support (#217) (d94f726) 3.1.0 (2017-06-17) Bug Fixes (fix) Add .npmignore file to exclude test/ and other non-essential files from packing. (#183) Fix typo (#178) Simple typo fix (#165) Features v5 support in CLI (#197) V5 support (#188) 3.0.1 (2016-11-28) split uuid versions into separate files 3.0.0 (2016-11-17) remove .parse and .unparse 2.0.0 Removed uuid.BufferClass 1.4.0 Improved module context detection Removed public RNG functions 1.3.2 Improve tests and handling of v1() options (Issue #24) Expose RNG option to allow for perf testing with different generators 1.3.0 Support for version 1 ids, thanks to @ctavan! Support for node.js crypto API De-emphasizing performance in favor of a) cryptographic quality PRNGs where available and b) more manageable code"
  },
  "src/frontend/app-client/node_modules/uuid/CONTRIBUTING.html": {
    "href": "src/frontend/app-client/node_modules/uuid/CONTRIBUTING.html",
    "title": "Contributing",
    "summary": "Contributing Please feel free to file GitHub Issues or propose Pull Requests. We're always happy to discuss improvements to this library! Testing npm test Releasing Releases are supposed to be done from master, version bumping is automated through standard-version: npm run release -- --dry-run # verify output manually npm run release # follow the instructions from the output of this command"
  },
  "src/frontend/app-client/node_modules/uuid/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/uuid/LICENSE.html",
    "title": "",
    "summary": "The MIT License (MIT) Copyright (c) 2010-2020 Robert Kieffer and other contributors Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/uuid/README.html": {
    "href": "src/frontend/app-client/node_modules/uuid/README.html",
    "title": "uuid",
    "summary": "uuid For the creation of RFC4122 UUIDs Complete - Support for RFC4122 version 1, 3, 4, and 5 UUIDs Cross-platform - Support for ... CommonJS, ECMAScript Modules and CDN builds Node 8, 10, 12, 14 Chrome, Safari, Firefox, Edge, IE 11 browsers Webpack and rollup.js module bundlers React Native / Expo Secure - Cryptographically-strong random values Small - Zero-dependency, small footprint, plays nice with \"tree shaking\" packagers CLI - Includes the uuid command line utility Upgrading from uuid@3.x? Your code is probably okay, but check out Upgrading From uuid@3.x for details. Quickstart To create a random UUID... 1. Install npm install uuid 2. Create a UUID (ES6 module syntax) import { v4 as uuidv4 } from 'uuid'; uuidv4(); // ⇨ '9b1deb4d-3b7d-4bad-9bdd-2b0d7b3dcb6d' ... or using CommonJS syntax: const { v4: uuidv4 } = require('uuid'); uuidv4(); // ⇨ '1b9d6bcd-bbfd-4b2d-9b5d-ab8dfbbd4bed' For timestamp UUIDs, namespace UUIDs, and other options read on ... API Summary uuid.NIL The nil UUID string (all zeros) New in uuid@8.3 uuid.parse() Convert UUID string to array of bytes New in uuid@8.3 uuid.stringify() Convert array of bytes to UUID string New in uuid@8.3 uuid.v1() Create a version 1 (timestamp) UUID uuid.v3() Create a version 3 (namespace w/ MD5) UUID uuid.v4() Create a version 4 (random) UUID uuid.v5() Create a version 5 (namespace w/ SHA-1) UUID uuid.validate() Test a string to see if it is a valid UUID New in uuid@8.3 uuid.version() Detect RFC version of a UUID New in uuid@8.3 API uuid.NIL The nil UUID string (all zeros). Example: import { NIL as NIL_UUID } from 'uuid'; NIL_UUID; // ⇨ '00000000-0000-0000-0000-000000000000' uuid.parse(str) Convert UUID string to array of bytes str A valid UUID String returns Uint8Array[16] throws TypeError if str is not a valid UUID Note: Ordering of values in the byte arrays used by parse() and stringify() follows the left ↠ right order of hex-pairs in UUID strings. As shown in the example below. Example: import { parse as uuidParse } from 'uuid'; // Parse a UUID const bytes = uuidParse('6ec0bd7f-11c0-43da-975e-2a8ad9ebae0b'); // Convert to hex strings to show byte order (for documentation purposes) [...bytes].map((v) => v.toString(16).padStart(2, '0')); // ⇨ // [ // '6e', 'c0', 'bd', '7f', // '11', 'c0', '43', 'da', // '97', '5e', '2a', '8a', // 'd9', 'eb', 'ae', '0b' // ] uuid.stringify(arr[, offset]) Convert array of bytes to UUID string arr Array-like collection of 16 values (starting from offset) between 0-255. [offset = 0] Number Starting index in the Array returns String throws TypeError if a valid UUID string cannot be generated Note: Ordering of values in the byte arrays used by parse() and stringify() follows the left ↠ right order of hex-pairs in UUID strings. As shown in the example below. Example: import { stringify as uuidStringify } from 'uuid'; const uuidBytes = [ 0x6e, 0xc0, 0xbd, 0x7f, 0x11, 0xc0, 0x43, 0xda, 0x97, 0x5e, 0x2a, 0x8a, 0xd9, 0xeb, 0xae, 0x0b, ]; uuidStringify(uuidBytes); // ⇨ '6ec0bd7f-11c0-43da-975e-2a8ad9ebae0b' uuid.v1([options[, buffer[, offset]]]) Create an RFC version 1 (timestamp) UUID [options] Object with one or more of the following properties: [options.node ] RFC \"node\" field as an Array[6] of byte values (per 4.1.6) [options.clockseq] RFC \"clock sequence\" as a Number between 0 - 0x3fff [options.msecs] RFC \"timestamp\" field (Number of milliseconds, unix epoch) [options.nsecs] RFC \"timestamp\" field (Number of nanseconds to add to msecs, should be 0-10,000) [options.random] Array of 16 random bytes (0-255) [options.rng] Alternative to options.random, a Function that returns an Array of 16 random bytes (0-255) [buffer] Array \\| Buffer If specified, uuid will be written here in byte-form, starting at offset [offset = 0] Number Index to start writing UUID bytes in buffer returns UUID String if no buffer is specified, otherwise returns buffer throws Error if more than 10M UUIDs/sec are requested Note: The default node id (the last 12 digits in the UUID) is generated once, randomly, on process startup, and then remains unchanged for the duration of the process. Note: options.random and options.rng are only meaningful on the very first call to v1(), where they may be passed to initialize the internal node and clockseq fields. Example: import { v1 as uuidv1 } from 'uuid'; uuidv1(); // ⇨ '2c5ea4c0-4067-11e9-8bad-9b1deb4d3b7d' Example using options: import { v1 as uuidv1 } from 'uuid'; const v1options = { node: [0x01, 0x23, 0x45, 0x67, 0x89, 0xab], clockseq: 0x1234, msecs: new Date('2011-11-01').getTime(), nsecs: 5678, }; uuidv1(v1options); // ⇨ '710b962e-041c-11e1-9234-0123456789ab' uuid.v3(name, namespace[, buffer[, offset]]) Create an RFC version 3 (namespace w/ MD5) UUID API is identical to v5(), but uses \"v3\" instead. ⚠️ Note: Per the RFC, \"If backward compatibility is not an issue, SHA-1 [Version 5] is preferred.\" uuid.v4([options[, buffer[, offset]]]) Create an RFC version 4 (random) UUID [options] Object with one or more of the following properties: [options.random] Array of 16 random bytes (0-255) [options.rng] Alternative to options.random, a Function that returns an Array of 16 random bytes (0-255) [buffer] Array \\| Buffer If specified, uuid will be written here in byte-form, starting at offset [offset = 0] Number Index to start writing UUID bytes in buffer returns UUID String if no buffer is specified, otherwise returns buffer Example: import { v4 as uuidv4 } from 'uuid'; uuidv4(); // ⇨ '1b9d6bcd-bbfd-4b2d-9b5d-ab8dfbbd4bed' Example using predefined random values: import { v4 as uuidv4 } from 'uuid'; const v4options = { random: [ 0x10, 0x91, 0x56, 0xbe, 0xc4, 0xfb, 0xc1, 0xea, 0x71, 0xb4, 0xef, 0xe1, 0x67, 0x1c, 0x58, 0x36, ], }; uuidv4(v4options); // ⇨ '109156be-c4fb-41ea-b1b4-efe1671c5836' uuid.v5(name, namespace[, buffer[, offset]]) Create an RFC version 5 (namespace w/ SHA-1) UUID name String \\| Array namespace String \\| Array[16] Namespace UUID [buffer] Array \\| Buffer If specified, uuid will be written here in byte-form, starting at offset [offset = 0] Number Index to start writing UUID bytes in buffer returns UUID String if no buffer is specified, otherwise returns buffer Note: The RFC DNS and URL namespaces are available as v5.DNS and v5.URL. Example with custom namespace: import { v5 as uuidv5 } from 'uuid'; // Define a custom namespace. Readers, create your own using something like // https://www.uuidgenerator.net/ const MY_NAMESPACE = '1b671a64-40d5-491e-99b0-da01ff1f3341'; uuidv5('Hello, World!', MY_NAMESPACE); // ⇨ '630eb68f-e0fa-5ecc-887a-7c7a62614681' Example with RFC URL namespace: import { v5 as uuidv5 } from 'uuid'; uuidv5('https://www.w3.org/', uuidv5.URL); // ⇨ 'c106a26a-21bb-5538-8bf2-57095d1976c1' uuid.validate(str) Test a string to see if it is a valid UUID str String to validate returns true if string is a valid UUID, false otherwise Example: import { validate as uuidValidate } from 'uuid'; uuidValidate('not a UUID'); // ⇨ false uuidValidate('6ec0bd7f-11c0-43da-975e-2a8ad9ebae0b'); // ⇨ true Using validate and version together it is possible to do per-version validation, e.g. validate for only v4 UUIds. import { version as uuidVersion } from 'uuid'; import { validate as uuidValidate } from 'uuid'; function uuidValidateV4(uuid) { return uuidValidate(uuid) && uuidVersion(uuid) === 4; } const v1Uuid = 'd9428888-122b-11e1-b85c-61cd3cbb3210'; const v4Uuid = '109156be-c4fb-41ea-b1b4-efe1671c5836'; uuidValidateV4(v4Uuid); // ⇨ true uuidValidateV4(v1Uuid); // ⇨ false uuid.version(str) Detect RFC version of a UUID str A valid UUID String returns Number The RFC version of the UUID throws TypeError if str is not a valid UUID Example: import { version as uuidVersion } from 'uuid'; uuidVersion('45637ec4-c85f-11ea-87d0-0242ac130003'); // ⇨ 1 uuidVersion('6ec0bd7f-11c0-43da-975e-2a8ad9ebae0b'); // ⇨ 4 Command Line UUIDs can be generated from the command line using uuid. $ uuid ddeb27fb-d9a0-4624-be4d-4615062daed4 The default is to generate version 4 UUIDS, however the other versions are supported. Type uuid --help for details: $ uuid --help Usage: uuid uuid v1 uuid v3 <name> <namespace uuid> uuid v4 uuid v5 <name> <namespace uuid> uuid --help Note: <namespace uuid> may be \"URL\" or \"DNS\" to use the corresponding UUIDs defined by RFC4122 ECMAScript Modules This library comes with ECMAScript Modules (ESM) support for Node.js versions that support it (example) as well as bundlers like rollup.js (example) and webpack (example) (targeting both, Node.js and browser environments). import { v4 as uuidv4 } from 'uuid'; uuidv4(); // ⇨ '1b9d6bcd-bbfd-4b2d-9b5d-ab8dfbbd4bed' To run the examples you must first create a dist build of this library in the module root: npm run build CDN Builds ECMAScript Modules To load this module directly into modern browsers that support loading ECMAScript Modules you can make use of jspm: <script type=\"module\"> import { v4 as uuidv4 } from 'https://jspm.dev/uuid'; console.log(uuidv4()); // ⇨ '1b9d6bcd-bbfd-4b2d-9b5d-ab8dfbbd4bed' </script> UMD To load this module directly into older browsers you can use the UMD (Universal Module Definition) builds from any of the following CDNs: Using UNPKG: <script src=\"https://unpkg.com/uuid@latest/dist/umd/uuidv4.min.js\"></script> Using jsDelivr: <script src=\"https://cdn.jsdelivr.net/npm/uuid@latest/dist/umd/uuidv4.min.js\"></script> Using cdnjs: <script src=\"https://cdnjs.cloudflare.com/ajax/libs/uuid/8.1.0/uuidv4.min.js\"></script> These CDNs all provide the same uuidv4() method: <script> uuidv4(); // ⇨ '55af1e37-0734-46d8-b070-a1e42e4fc392' </script> Methods for the other algorithms (uuidv1(), uuidv3() and uuidv5()) are available from the files uuidv1.min.js, uuidv3.min.js and uuidv5.min.js respectively. \"getRandomValues() not supported\" This error occurs in environments where the standard crypto.getRandomValues() API is not supported. This issue can be resolved by adding an appropriate polyfill: React Native / Expo Install react-native-get-random-values Import it before uuid. Since uuid might also appear as a transitive dependency of some other imports it's safest to just import react-native-get-random-values as the very first thing in your entry point: import 'react-native-get-random-values'; import { v4 as uuidv4 } from 'uuid'; Note: If you are using Expo, you must be using at least react-native-get-random-values@1.5.0 and expo@39.0.0. Web Workers / Service Workers (Edge <= 18) In Edge <= 18, Web Crypto is not supported in Web Workers or Service Workers and we are not aware of a polyfill (let us know if you find one, please). Upgrading From uuid@7.x Only Named Exports Supported When Using with Node.js ESM uuid@7.x did not come with native ECMAScript Module (ESM) support for Node.js. Importing it in Node.js ESM consequently imported the CommonJS source with a default export. This library now comes with true Node.js ESM support and only provides named exports. Instead of doing: import uuid from 'uuid'; uuid.v4(); you will now have to use the named exports: import { v4 as uuidv4 } from 'uuid'; uuidv4(); Deep Requires No Longer Supported Deep requires like require('uuid/v4') which have been deprecated in uuid@7.x are no longer supported. Upgrading From uuid@3.x \"Wait... what happened to uuid@4.x - uuid@6.x?!?\" In order to avoid confusion with RFC version 4 and version 5 UUIDs, and a possible version 6, releases 4 thru 6 of this module have been skipped. Deep Requires Now Deprecated uuid@3.x encouraged the use of deep requires to minimize the bundle size of browser builds: const uuidv4 = require('uuid/v4'); // <== NOW DEPRECATED! uuidv4(); As of uuid@7.x this library now provides ECMAScript modules builds, which allow packagers like Webpack and Rollup to do \"tree-shaking\" to remove dead code. Instead, use the import syntax: import { v4 as uuidv4 } from 'uuid'; uuidv4(); ... or for CommonJS: const { v4: uuidv4 } = require('uuid'); uuidv4(); Default Export Removed uuid@3.x was exporting the Version 4 UUID method as a default export: const uuid = require('uuid'); // <== REMOVED! This usage pattern was already discouraged in uuid@3.x and has been removed in uuid@7.x. Markdown generated from README_js.md by"
  },
  "src/frontend/app-client/node_modules/valibot/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/valibot/LICENSE.html",
    "title": "",
    "summary": "MIT License Copyright (c) Fabian Hiller Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/valibot/README.html": {
    "href": "src/frontend/app-client/node_modules/valibot/README.html",
    "title": "Valibot",
    "summary": "Valibot Hello, I am Valibot and I would like to help you validate data easily using a schema. No matter if it is incoming data on a server, a form or even configuration files. I have no dependencies and can run in any JavaScript environment. I highly recommend you read the announcement post, and if you are a nerd like me, the bachelor's thesis I am based on. Highlights Fully type safe with static type inference Small bundle size starting at less than 600 bytes Validate everything from strings to complex objects Open source and fully tested with 100 % coverage Many transformation and validation actions included Well structured source code without dependencies Minimal, readable and well thought out API Example First you create a schema that describes a structured data set. A schema can be compared to a type definition in TypeScript. The big difference is that TypeScript types are \"not executed\" and are more or less a DX feature. A schema on the other hand, apart from the inferred type definition, can also be executed at runtime to guarantee type safety of unknown data. import * as v from 'valibot'; // 1.2 kB // Create login schema with email and password const LoginSchema = v.object({ email: v.pipe(v.string(), v.email()), password: v.pipe(v.string(), v.minLength(8)), }); // Infer output TypeScript type of login schema type LoginData = v.InferOutput<typeof LoginSchema>; // { email: string; password: string } // Throws error for `email` and `password` v.parse(LoginSchema, { email: '', password: '' }); // Returns data as { email: string; password: string } v.parse(LoginSchema, { email: 'jane@example.com', password: '12345678' }); Apart from parse I also offer a non-exception-based API with safeParse and a type guard function with is. You can read more about it here. Comparison Instead of relying on a few large functions with many methods, my API design and source code is based on many small and independent functions, each with just a single task. This modular design has several advantages. For example, this allows a bundler to use the import statements to remove code that is not needed. This way, only the code that is actually used gets into your production build. This can reduce the bundle size by up to 95 % compared to Zod. In addition, it allows you to easily extend my functionality with external code and makes my source code more robust and secure because the functionality of the individual functions can be tested much more easily through unit tests. Credits My friend Fabian created me as part of his bachelor thesis at Stuttgart Media University, supervised by Walter Kriha, Miško Hevery and Ryan Carniato. My role models also include Colin McDonnell, who had a big influence on my API design with Zod. Feedback Find a bug or have an idea how to improve my code? Please fill out an issue. Together we can make the library even better! License I am completely free and licensed under the MIT license. But if you like, you can feed me with a star on GitHub."
  },
  "src/frontend/app-client/node_modules/validate-npm-package-license/README.html": {
    "href": "src/frontend/app-client/node_modules/validate-npm-package-license/README.html",
    "title": "validate-npm-package-license",
    "summary": "validate-npm-package-license Give me a string and I'll tell you if it's a valid npm package license string. var valid = require('validate-npm-package-license'); SPDX license identifiers are valid license strings: var assert = require('assert'); var validSPDXExpression = { validForNewPackages: true, validForOldPackages: true, spdx: true }; assert.deepEqual(valid('MIT'), validSPDXExpression); assert.deepEqual(valid('BSD-2-Clause'), validSPDXExpression); assert.deepEqual(valid('Apache-2.0'), validSPDXExpression); assert.deepEqual(valid('ISC'), validSPDXExpression); The function will return a warning and suggestion for nearly-correct license identifiers: assert.deepEqual( valid('Apache 2.0'), { validForOldPackages: false, validForNewPackages: false, warnings: [ 'license should be ' + 'a valid SPDX license expression (without \"LicenseRef\"), ' + '\"UNLICENSED\", or ' + '\"SEE LICENSE IN <filename>\"', 'license is similar to the valid expression \"Apache-2.0\"' ] } ); SPDX expressions are valid, too ... // Simple SPDX license expression for dual licensing assert.deepEqual( valid('(GPL-3.0-only OR BSD-2-Clause)'), validSPDXExpression ); ... except if they contain LicenseRef: var warningAboutLicenseRef = { validForOldPackages: false, validForNewPackages: false, spdx: true, warnings: [ 'license should be ' + 'a valid SPDX license expression (without \"LicenseRef\"), ' + '\"UNLICENSED\", or ' + '\"SEE LICENSE IN <filename>\"', ] }; assert.deepEqual( valid('LicenseRef-Made-Up'), warningAboutLicenseRef ); assert.deepEqual( valid('(MIT OR LicenseRef-Made-Up)'), warningAboutLicenseRef ); If you can't describe your licensing terms with standardized SPDX identifiers, put the terms in a file in the package and point users there: assert.deepEqual( valid('SEE LICENSE IN LICENSE.txt'), { validForNewPackages: true, validForOldPackages: true, inFile: 'LICENSE.txt' } ); assert.deepEqual( valid('SEE LICENSE IN license.md'), { validForNewPackages: true, validForOldPackages: true, inFile: 'license.md' } ); If there aren't any licensing terms, use UNLICENSED: var unlicensed = { validForNewPackages: true, validForOldPackages: true, unlicensed: true }; assert.deepEqual(valid('UNLICENSED'), unlicensed); assert.deepEqual(valid('UNLICENCED'), unlicensed);"
  },
  "src/frontend/app-client/node_modules/validate-npm-package-name/README.html": {
    "href": "src/frontend/app-client/node_modules/validate-npm-package-name/README.html",
    "title": "validate-npm-package-name",
    "summary": "validate-npm-package-name Give me a string and I'll tell you if it's a valid npm package name. This package exports a single synchronous function that takes a string as input and returns an object with two properties: validForNewPackages :: Boolean validForOldPackages :: Boolean Contents Naming rules Examples Valid Names Invalid Names Legacy Names Tests License Naming Rules Below is a list of rules that valid npm package name should conform to. package name length should be greater than zero all the characters in the package name must be lowercase i.e., no uppercase or mixed case names are allowed package name can consist of hyphens package name must not contain any non-url-safe characters (since name ends up being part of a URL) package name should not start with . or _ package name should not contain any spaces package name should not contain any of the following characters: ~)('!* package name cannot be the same as a node.js/io.js core module nor a reserved/blacklisted name. For example, the following names are invalid: http stream node_modules favicon.ico package name length cannot exceed 214 Examples Valid Names var validate = require(\"validate-npm-package-name\") validate(\"some-package\") validate(\"example.com\") validate(\"under_score\") validate(\"123numeric\") validate(\"@npm/thingy\") validate(\"@jane/foo.js\") All of the above names are valid, so you'll get this object back: { validForNewPackages: true, validForOldPackages: true } Invalid Names validate(\"excited!\") validate(\" leading-space:and:weirdchars\") That was never a valid package name, so you get this: { validForNewPackages: false, validForOldPackages: false, errors: [ 'name cannot contain leading or trailing spaces', 'name can only contain URL-friendly characters' ] } Legacy Names In the old days of npm, package names were wild. They could have capital letters in them. They could be really long. They could be the name of an existing module in node core. If you give this function a package name that used to be valid, you'll see a change in the value of validForNewPackages property, and a warnings array will be present: validate(\"eLaBorAtE-paCkAgE-with-mixed-case-and-more-than-214-characters-----------------------------------------------------------------------------------------------------------------------------------------------------------\") returns: { validForNewPackages: false, validForOldPackages: true, warnings: [ \"name can no longer contain capital letters\", \"name can no longer contain more than 214 characters\" ] } Tests npm install npm test License ISC"
  },
  "src/frontend/app-client/node_modules/vary/HISTORY.html": {
    "href": "src/frontend/app-client/node_modules/vary/HISTORY.html",
    "title": "1.1.2 / 2017-09-23",
    "summary": "1.1.2 / 2017-09-23 perf: improve header token parsing speed 1.1.1 / 2017-03-20 perf: hoist regular expression 1.1.0 / 2015-09-29 Only accept valid field names in the field argument Ensures the resulting string is a valid HTTP header value 1.0.1 / 2015-07-08 Fix setting empty header from empty field perf: enable strict mode perf: remove argument reassignments 1.0.0 / 2014-08-10 Accept valid Vary header string as field Add vary.append for low-level string manipulation Move to jshttp orgainzation 0.1.0 / 2014-06-05 Support array of fields to set 0.0.0 / 2014-06-04 Initial release"
  },
  "src/frontend/app-client/node_modules/vary/README.html": {
    "href": "src/frontend/app-client/node_modules/vary/README.html",
    "title": "vary",
    "summary": "vary Manipulate the HTTP Vary header Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install vary API var vary = require('vary') vary(res, field) Adds the given header field to the Vary response header of res. This can be a string of a single field, a string of a valid Vary header, or an array of multiple fields. This will append the header if not already listed, otherwise leaves it listed in the current location. // Append \"Origin\" to the Vary header of the response vary(res, 'Origin') vary.append(header, field) Adds the given header field to the Vary response header string header. This can be a string of a single field, a string of a valid Vary header, or an array of multiple fields. This will append the header if not already listed, otherwise leaves it listed in the current location. The new header string is returned. // Get header string appending \"Origin\" to \"Accept, User-Agent\" vary.append('Accept, User-Agent', 'Origin') Examples Updating the Vary header when content is based on it var http = require('http') var vary = require('vary') http.createServer(function onRequest (req, res) { // about to user-agent sniff vary(res, 'User-Agent') var ua = req.headers['user-agent'] || '' var isMobile = /mobi|android|touch|mini/i.test(ua) // serve site, depending on isMobile res.setHeader('Content-Type', 'text/html') res.end('You are (probably) ' + (isMobile ? '' : 'not ') + 'a mobile user') }) Testing $ npm test License MIT"
  },
  "src/frontend/app-client/node_modules/vite-node/README.html": {
    "href": "src/frontend/app-client/node_modules/vite-node/README.html",
    "title": "vite-node",
    "summary": "vite-node Vite as Node runtime. The engine that powers Vitest and Nuxt 3 Dev SSR. Features On-demand evaluation Vite's pipeline, plugins, resolve, aliasing Out-of-box ESM & TypeScript support Respect vite.config.ts Hot module replacement (HMR) Separate server/client architecture Top-level await Shims for __dirname and __filename in ESM Access to native node modules like fs, path, etc. CLI Usage Run JS/TS file on Node.js using Vite's resolvers and transformers. npx vite-node index.ts Options: npx vite-node -h Options via CLI All ViteNodeServer options are supported by the CLI. They may be defined through the dot syntax, as shown below: npx vite-node --options.deps.inline=\"module-name\" --options.deps.external=\"/module-regexp/\" index.ts Note that for options supporting RegExps, strings passed to the CLI must start and end with a /; Hashbang If you prefer to write scripts that don't need to be passed into Vite Node, you can declare it in the hashbang. Simply add #!/usr/bin/env vite-node --script at the top of your file: file.ts #!/usr/bin/env vite-node --script console.log('argv:', process.argv.slice(2)) And make the file executable: chmod +x ./file.ts Now, you can run the file without passing it into Vite Node: $ ./file.ts hello argv: [ 'hello' ] Note that when using the --script option, Vite Node forwards every argument and option to the script to execute, even the one supported by Vite Node itself. Programmatic Usage In Vite Node, the server and runner (client) are separated, so you can integrate them in different contexts (workers, cross-process, or remote) if needed. The demo below shows a simple example of having both (server and runner) running in the same context import { createServer } from 'vite' import { ViteNodeRunner } from 'vite-node/client' import { ViteNodeServer } from 'vite-node/server' import { installSourcemapsSupport } from 'vite-node/source-map' // create vite server const server = await createServer({ optimizeDeps: { // It's recommended to disable deps optimization disabled: true, }, }) // this is need to initialize the plugins await server.pluginContainer.buildStart({}) // create vite-node server const node = new ViteNodeServer(server) // fixes stacktraces in Errors installSourcemapsSupport({ getSourceMap: source => node.getSourceMap(source), }) // create vite-node runner const runner = new ViteNodeRunner({ root: server.config.root, base: server.config.base, // when having the server and runner in a different context, // you will need to handle the communication between them // and pass to this function fetchModule(id) { return node.fetchModule(id) }, resolveId(id, importer) { return node.resolveId(id, importer) }, }) // execute the file await runner.executeFile('./example.ts') // close the vite server await server.close() Debugging Debug Transformation Sometimes you might want to inspect the transformed code to investigate issues. You can set environment variable VITE_NODE_DEBUG_DUMP=true to let vite-node write the transformed result of each module under .vite-node/dump. If you want to debug by modifying the dumped code, you can change the value of VITE_NODE_DEBUG_DUMP to load and search for the dumped files and use them for executing. VITE_NODE_DEBUG_DUMP=load vite-node example.ts Or programmatically: import { ViteNodeServer } from 'vite-node/server' const server = new ViteNodeServer(viteServer, { debug: { dumpModules: true, loadDumppedModules: true, }, }) Debug Execution If the process gets stuck, it might be because there are unresolvable circular dependencies. You can set VITE_NODE_DEBUG_RUNNER=true for vite-node to warn about this. VITE_NODE_DEBUG_RUNNER=true vite-node example.ts Or programmatically: import { ViteNodeRunner } from 'vite-node/client' const runner = new ViteNodeRunner({ debug: true, }) Credits Based on @pi0's brilliant idea of having a Vite server as the on-demand transforming service for Nuxt's Vite SSR. Thanks @brillout for kindly sharing this package name. Sponsors License MIT License © 2021 Anthony Fu"
  },
  "src/frontend/app-client/node_modules/vite-tsconfig-paths/README.html": {
    "href": "src/frontend/app-client/node_modules/vite-tsconfig-paths/README.html",
    "title": "vite-tsconfig-paths",
    "summary": "\uD83D\uDC4B Check out Radashi, my latest endeavor. vite-tsconfig-paths Give vite the ability to resolve imports using TypeScript's path mapping. Usage Install as dev dependency Ensure the project either has \"type\": \"module\" set or that the Vite config is renamed to vite.config.mjs / vite.config.mts depending on whether TypeScript is used Inject vite-tsconfig-paths in the Vite config import { defineConfig } from 'vite' import tsconfigPaths from 'vite-tsconfig-paths' export default defineConfig({ plugins: [tsconfigPaths()], }) (optional) ⚠️ To enable path resolution in non-TypeScript modules (e.g. .vue, .svelte, .mdx), you must set the allowJs option to true in your tsconfig.json file. If that doesn't work, you might need to enable loose: true to resolve all files. Note that, due to a Vite limitation, CSS files (and CSS dialects) cannot be resolved with this plugin (see #30). Note: You need to restart Vite when you update your paths mappings. This is being tracked in #17 (contributions welcome). Options root: string The directory to search for tsconfig.json files. The default value of this option depends on whether projects is defined. If it is, then the Vite project root is used. Otherwise, Vite's searchForWorkspaceRoot function is used. projects: string[] If you have an esoteric setup, you might need this option to specify where your tsconfig files are located. The paths within are relative to the root option. If defined, the root directory won't be searched for tsconfig files. You should always try using just the root option first, because this option is more brittle. loose: boolean Disable strictness that limits path resolution to TypeScript and JavaScript importers. Useful if you want imports in Vue templates to be resolved, but don't want to use allowJs in your tsconfig, for example. In other words, when loose: true is used, any file that gets transpiled into JavaScript will have its imports resolved by this plugin. parseNative: boolean Enable use of the tsconfck.parseNative function, which delegates the loading of tsconfig files to the TypeScript compiler. You'll probably never need this, but I added it just in case. ⚠️ This option can slow down Vite's startup time by as much as 600ms, due to the size of the TypeScript compiler. Only use it when necessary. ignoreConfigErrors: boolean When true, parsing errors encountered while loading tsconfig files will be ignored. This is useful if you have a monorepo with multiple tsconfig files, and you don't want to see errors for the ones that aren't relevant to the current project. skip: (dir: string) => boolean A function that determines which directories to skip when searching for tsconfig.json files. While .git and node_modules directories are always skipped, this option allows you to skip additional directories, which is useful in large monorepos to improve performance. allowJs If your tsconfig file has \"allowJs\": true in it, path resolution will be expanded beyond TypeScript importers. The following extensions will have their imports resolved by this plugin: .vue, .svelte, .mdx, .mjs, .js, .jsx baseUrl If the baseUrl is defined, it gets prepended to all bare imports, and its resolution will take precedence over node_modules. This is also how TypeScript does it. Say the baseUrl is ../root and you import react. This plugin will use ../root/react if it exists. If not found, then react is resolved normally. The baseUrl is relative to the project root (where tsconfig.json lives). include/exclude The include and exclude tsconfig options are respected. Internally, globrex is used for glob matching. Troubleshooting The DEBUG environment variable can be used to figure out why this plugin isn't working as you may have expected. DEBUG=vite-tsconfig-paths yarn vite Also, check out the Troubleshooting wiki page for more guidance."
  },
  "src/frontend/app-client/node_modules/vite/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/vite/LICENSE.html",
    "title": "Vite core license",
    "summary": "Vite core license Vite is released under the MIT license: MIT License Copyright (c) 2019-present, VoidZero Inc. and Vite contributors Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Licenses of bundled dependencies The published Vite artifact additionally contains code with the following licenses: Apache-2.0, BSD-2-Clause, CC0-1.0, ISC, MIT Bundled dependencies: @ampproject/remapping License: Apache-2.0 By: Justin Ridgewell Repository: git+https://github.com/ampproject/remapping.git Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. @jridgewell/gen-mapping, @jridgewell/set-array License: MIT By: Justin Ridgewell Repositories: https://github.com/jridgewell/gen-mapping, https://github.com/jridgewell/set-array Copyright 2022 Justin Ridgewell jridgewell@google.com Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @jridgewell/resolve-uri License: MIT By: Justin Ridgewell Repository: https://github.com/jridgewell/resolve-uri Copyright 2019 Justin Ridgewell jridgewell@google.com Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @jridgewell/sourcemap-codec License: MIT By: Rich Harris Repository: git+https://github.com/jridgewell/sourcemap-codec.git The MIT License Copyright (c) 2015 Rich Harris Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @jridgewell/trace-mapping License: MIT By: Justin Ridgewell Repository: git+https://github.com/jridgewell/trace-mapping.git Copyright 2022 Justin Ridgewell justin@ridgewell.name Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. @polka/compression License: MIT Repository: lukeed/polka @polka/url License: MIT By: Luke Edwards Repository: lukeed/polka @rollup/plugin-alias, @rollup/plugin-commonjs, @rollup/plugin-dynamic-import-vars, @rollup/pluginutils License: MIT By: Johannes Stein Repository: rollup/plugins License: MIT By: Rich Harris Repository: rollup/plugins License: MIT By: LarsDenBakker Repository: rollup/plugins License: MIT By: Rich Harris Repository: rollup/plugins The MIT License (MIT) Copyright (c) 2019 RollupJS Plugin Contributors (https://github.com/rollup/plugins/graphs/contributors) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. anymatch License: ISC By: Elan Shanker Repository: https://github.com/micromatch/anymatch The ISC License Copyright (c) 2019 Elan Shanker, Paul Miller (https://paulmillr.com) Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. artichokie License: MIT By: sapphi-red, Evan You Repository: git+https://github.com/sapphi-red/artichokie.git MIT License Copyright (c) 2020-present, Yuxi (Evan) You Copyright (c) 2023-present, sapphi-red Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. binary-extensions License: MIT By: Sindre Sorhus Repository: sindresorhus/binary-extensions MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Copyright (c) Paul Miller (https://paulmillr.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. braces, fill-range, is-number License: MIT By: Jon Schlinkert, Brian Woodward, Elan Shanker, Eugene Sharygin, hemanth.hm Repository: micromatch/braces License: MIT By: Jon Schlinkert, Edo Rivai, Paul Miller, Rouven Weßling Repository: jonschlinkert/fill-range License: MIT By: Jon Schlinkert, Olsten Larck, Rouven Weßling Repository: jonschlinkert/is-number The MIT License (MIT) Copyright (c) 2014-present, Jon Schlinkert. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. bundle-name, default-browser, default-browser-id, define-lazy-prop, is-docker, is-inside-container, is-wsl, open, run-applescript License: MIT By: Sindre Sorhus Repositories: sindresorhus/bundle-name, sindresorhus/default-browser, sindresorhus/default-browser-id, sindresorhus/define-lazy-prop, sindresorhus/is-docker, sindresorhus/is-inside-container, sindresorhus/is-wsl, sindresorhus/open, sindresorhus/run-applescript MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. cac License: MIT By: egoist Repository: egoist/cac The MIT License (MIT) Copyright (c) EGOIST 0x142857@gmail.com (https://github.com/egoist) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. chokidar License: MIT By: Paul Miller, Elan Shanker Repository: git+https://github.com/paulmillr/chokidar.git The MIT License (MIT) Copyright (c) 2012-2019 Paul Miller (https://paulmillr.com), Elan Shanker Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. commondir, shell-quote License: MIT By: James Halliday Repositories: http://github.com/substack/node-commondir.git, http://github.com/ljharb/shell-quote.git The MIT License Copyright (c) 2013 James Halliday (mail@substack.net) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. connect License: MIT By: TJ Holowaychuk, Douglas Christopher Wilson, Jonathan Ong, Tim Caswell Repository: senchalabs/connect (The MIT License) Copyright (c) 2010 Sencha Inc. Copyright (c) 2011 LearnBoost Copyright (c) 2011-2014 TJ Holowaychuk Copyright (c) 2015 Douglas Christopher Wilson Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. convert-source-map License: MIT By: Thorsten Lorenz Repository: git://github.com/thlorenz/convert-source-map.git Copyright 2013 Thorsten Lorenz. All rights reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. cors License: MIT By: Troy Goode Repository: expressjs/cors (The MIT License) Copyright (c) 2013 Troy Goode troygoode@gmail.com Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. cross-spawn License: MIT By: André Cruz Repository: git@github.com:moxystudio/node-cross-spawn.git The MIT License (MIT) Copyright (c) 2018 Made With MOXY Lda hello@moxy.studio Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. cssesc License: MIT By: Mathias Bynens Repository: https://github.com/mathiasbynens/cssesc.git Copyright Mathias Bynens https://mathiasbynens.be/ Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. debug License: MIT By: Josh Junon, TJ Holowaychuk, Nathan Rajlich, Andrew Rhyne Repository: git://github.com/debug-js/debug.git (The MIT License) Copyright (c) 2014-2017 TJ Holowaychuk tj@vision-media.ca Copyright (c) 2018-2021 Josh Junon Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. dotenv License: BSD-2-Clause Repository: git://github.com/motdotla/dotenv.git Copyright (c) 2015, Scott Motte All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. dotenv-expand License: BSD-2-Clause By: motdotla Repository: https://github.com/motdotla/dotenv-expand Copyright (c) 2016, Scott Motte All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. ee-first License: MIT By: Jonathan Ong, Douglas Christopher Wilson Repository: jonathanong/ee-first The MIT License (MIT) Copyright (c) 2014 Jonathan Ong me@jongleberry.com Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. encodeurl License: MIT By: Douglas Christopher Wilson Repository: pillarjs/encodeurl (The MIT License) Copyright (c) 2016 Douglas Christopher Wilson Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. entities License: BSD-2-Clause By: Felix Boehm Repository: git://github.com/fb55/entities.git Copyright (c) Felix Böhm All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. es-module-lexer License: MIT By: Guy Bedford Repository: git+https://github.com/guybedford/es-module-lexer.git MIT License Copyright (C) 2018-2022 Guy Bedford Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. escape-html License: MIT Repository: component/escape-html (The MIT License) Copyright (c) 2012-2013 TJ Holowaychuk Copyright (c) 2015 Andreas Lubbe Copyright (c) 2015 Tiancheng \"Timothy\" Gu Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. estree-walker License: MIT By: Rich Harris Repository: https://github.com/Rich-Harris/estree-walker Copyright (c) 2015-20 these people Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. etag License: MIT By: Douglas Christopher Wilson, David Björklund Repository: jshttp/etag (The MIT License) Copyright (c) 2014-2016 Douglas Christopher Wilson Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. eventemitter3 License: MIT By: Arnout Kazemier Repository: git://github.com/primus/eventemitter3.git The MIT License (MIT) Copyright (c) 2014 Arnout Kazemier Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. fdir License: MIT By: thecodrr Repository: git+https://github.com/thecodrr/fdir.git Copyright 2023 Abdullah Atta Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. finalhandler License: MIT By: Douglas Christopher Wilson Repository: pillarjs/finalhandler (The MIT License) Copyright (c) 2014-2017 Douglas Christopher Wilson doug@somethingdoug.com Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. follow-redirects License: MIT By: Ruben Verborgh, Olivier Lalonde, James Talmage Repository: git+ssh://git@github.com/follow-redirects/follow-redirects.git Copyright 2014–present Olivier Lalonde olalonde@gmail.com, James Talmage james@talmage.io, Ruben Verborgh Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. generic-names License: MIT By: Alexey Litvinov Repository: git+https://github.com/css-modules/generic-names.git The MIT License (MIT) Copyright (c) 2015 Alexey Litvinov Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. glob-parent License: ISC By: Gulp Team, Elan Shanker, Blaine Bublitz Repository: gulpjs/glob-parent The ISC License Copyright (c) 2015, 2019 Elan Shanker Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. http-proxy License: MIT By: Charlie Robbins, jcrugzz jcrugzz@gmail.com Repository: https://github.com/http-party/node-http-proxy.git node-http-proxy Copyright (c) 2010-2016 Charlie Robbins, Jarrett Cruger & the Contributors. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. icss-utils License: ISC By: Glen Maddern Repository: git+https://github.com/css-modules/icss-utils.git ISC License (ISC) Copyright 2018 Glen Maddern Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. is-binary-path License: MIT By: Sindre Sorhus Repository: sindresorhus/is-binary-path MIT License Copyright (c) 2019 Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com), Paul Miller (https://paulmillr.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. is-extglob License: MIT By: Jon Schlinkert Repository: jonschlinkert/is-extglob The MIT License (MIT) Copyright (c) 2014-2016, Jon Schlinkert Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. is-glob License: MIT By: Jon Schlinkert, Brian Woodward, Daniel Perez Repository: micromatch/is-glob The MIT License (MIT) Copyright (c) 2014-2017, Jon Schlinkert. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. is-reference License: MIT By: Rich Harris Repository: git+https://github.com/Rich-Harris/is-reference.git isexe, which License: ISC By: Isaac Z. Schlueter Repositories: git+https://github.com/isaacs/isexe.git, git://github.com/isaacs/node-which.git The ISC License Copyright (c) Isaac Z. Schlueter and Contributors Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. js-tokens License: MIT By: Simon Lydell Repository: lydell/js-tokens The MIT License (MIT) Copyright (c) 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024 Simon Lydell Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. launch-editor, launch-editor-middleware License: MIT By: Evan You Repositories: git+https://github.com/yyx990803/launch-editor.git, git+https://github.com/yyx990803/launch-editor.git The MIT License (MIT) Copyright (c) 2017-present, Yuxi (Evan) You Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. lilconfig License: MIT By: antonk52 Repository: https://github.com/antonk52/lilconfig MIT License Copyright (c) 2022 Anton Kastritskiy Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. loader-utils License: MIT By: Tobias Koppers @sokra Repository: https://github.com/webpack/loader-utils.git Copyright JS Foundation and other contributors Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. lodash.camelcase License: MIT By: John-David Dalton, Blaine Bublitz, Mathias Bynens Repository: lodash/lodash Copyright jQuery Foundation and other contributors https://jquery.org/ Based on Underscore.js, copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors http://underscorejs.org/ This software consists of voluntary contributions made by many individuals. For exact contribution history, see the revision history available at https://github.com/lodash/lodash The following license applies to all parts of this software except as documented below: ==== Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. ==== Copyright and related rights for sample code are waived via CC0. Sample code is defined as all source code displayed within the prose of the documentation. CC0: http://creativecommons.org/publicdomain/zero/1.0/ ==== Files located in the node_modules and vendor directories are externally maintained libraries used by this software which have their own licenses; we recommend you read them, as their terms may differ from the terms above. magic-string License: MIT By: Rich Harris Repository: https://github.com/rich-harris/magic-string Copyright 2018 Rich Harris Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. mlly, ufo License: MIT Repositories: unjs/mlly, unjs/ufo MIT License Copyright (c) Pooya Parsa pooya@pi0.io Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. mrmime License: MIT By: Luke Edwards Repository: lukeed/mrmime The MIT License (MIT) Copyright (c) Luke Edwards luke.edwards05@gmail.com (https://lukeed.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. ms License: MIT Repository: vercel/ms The MIT License (MIT) Copyright (c) 2020 Vercel, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. normalize-path License: MIT By: Jon Schlinkert, Blaine Bublitz Repository: jonschlinkert/normalize-path The MIT License (MIT) Copyright (c) 2014-2018, Jon Schlinkert. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. object-assign License: MIT By: Sindre Sorhus Repository: sindresorhus/object-assign The MIT License (MIT) Copyright (c) Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. on-finished License: MIT By: Douglas Christopher Wilson, Jonathan Ong Repository: jshttp/on-finished (The MIT License) Copyright (c) 2013 Jonathan Ong me@jongleberry.com Copyright (c) 2014 Douglas Christopher Wilson doug@somethingdoug.com Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. parse5 License: MIT By: Ivan Nikulin, https://github.com/inikulin/parse5/graphs/contributors Repository: git://github.com/inikulin/parse5.git Copyright (c) 2013-2019 Ivan Nikulin (ifaaan@gmail.com, https://github.com/inikulin) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. parseurl License: MIT By: Douglas Christopher Wilson, Jonathan Ong Repository: pillarjs/parseurl (The MIT License) Copyright (c) 2014 Jonathan Ong me@jongleberry.com Copyright (c) 2014-2017 Douglas Christopher Wilson doug@somethingdoug.com Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. path-key, shebang-regex License: MIT By: Sindre Sorhus Repositories: sindresorhus/path-key, sindresorhus/shebang-regex MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. periscopic License: MIT Repository: Rich-Harris/periscopic Copyright (c) 2019 Rich Harris Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. picocolors License: ISC By: Alexey Raspopov Repository: alexeyraspopov/picocolors ISC License Copyright (c) 2021-2024 Oleksii Raspopov, Kostiantyn Denysov, Anton Verinov Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. picomatch License: MIT By: Jon Schlinkert Repository: micromatch/picomatch The MIT License (MIT) Copyright (c) 2017-present, Jon Schlinkert. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. postcss-import License: MIT By: Maxime Thirouin Repository: https://github.com/postcss/postcss-import.git The MIT License (MIT) Copyright (c) 2014 Maxime Thirouin, Jason Campbell & Kevin Mårtensson Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. postcss-load-config License: MIT By: Michael Ciniawky, Ryan Dunckel, Mateusz Derks, Dalton Santos, Patrick Gilday, François Wouts Repository: postcss/postcss-load-config The MIT License (MIT) Copyright Michael Ciniawsky michael.ciniawsky@gmail.com Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. postcss-modules License: MIT By: Alexander Madyankin Repository: https://github.com/css-modules/postcss-modules.git The MIT License (MIT) Copyright 2015-present Alexander Madyankin alexander@madyankin.name Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. postcss-modules-extract-imports License: ISC By: Glen Maddern Repository: https://github.com/css-modules/postcss-modules-extract-imports.git Copyright 2015 Glen Maddern Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. postcss-modules-local-by-default License: MIT By: Mark Dalgleish Repository: https://github.com/css-modules/postcss-modules-local-by-default.git The MIT License (MIT) Copyright 2015 Mark Dalgleish mark.john.dalgleish@gmail.com Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. postcss-modules-scope License: ISC By: Glen Maddern Repository: https://github.com/css-modules/postcss-modules-scope.git ISC License (ISC) Copyright (c) 2015, Glen Maddern Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. postcss-modules-values License: ISC By: Glen Maddern Repository: git+https://github.com/css-modules/postcss-modules-values.git ISC License (ISC) Copyright (c) 2015, Glen Maddern Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. postcss-selector-parser License: MIT By: Ben Briggs, Chris Eppstein Repository: postcss/postcss-selector-parser Copyright (c) Ben Briggs beneb.info@gmail.com (http://beneb.info) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. postcss-value-parser License: MIT By: Bogdan Chadkin Repository: https://github.com/TrySound/postcss-value-parser.git Copyright (c) Bogdan Chadkin trysound@yandex.ru Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. readdirp License: MIT By: Thorsten Lorenz, Paul Miller Repository: git://github.com/paulmillr/readdirp.git MIT License Copyright (c) 2012-2019 Thorsten Lorenz, Paul Miller (https://paulmillr.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. requires-port License: MIT By: Arnout Kazemier Repository: https://github.com/unshiftio/requires-port The MIT License (MIT) Copyright (c) 2015 Unshift.io, Arnout Kazemier, the Contributors. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. resolve.exports, totalist License: MIT By: Luke Edwards Repositories: lukeed/resolve.exports, lukeed/totalist The MIT License (MIT) Copyright (c) Luke Edwards luke.edwards05@gmail.com (lukeed.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. shebang-command License: MIT By: Kevin Mårtensson Repository: kevva/shebang-command MIT License Copyright (c) Kevin Mårtensson kevinmartensson@gmail.com (github.com/kevva) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. sirv License: MIT By: Luke Edwards Repository: lukeed/sirv statuses License: MIT By: Douglas Christopher Wilson, Jonathan Ong Repository: jshttp/statuses The MIT License (MIT) Copyright (c) 2014 Jonathan Ong me@jongleberry.com Copyright (c) 2016 Douglas Christopher Wilson doug@somethingdoug.com Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. string-hash License: CC0-1.0 By: The Dark Sky Company Repository: git://github.com/darkskyapp/string-hash.git strip-literal License: MIT By: Anthony Fu Repository: git+https://github.com/antfu/strip-literal.git MIT License Copyright (c) 2022 Anthony Fu https://github.com/antfu Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. tinyglobby License: MIT By: Superchupu Repository: git+https://github.com/SuperchupuDev/tinyglobby.git MIT License Copyright (c) 2024 Madeline Gurriarán Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. to-regex-range License: MIT By: Jon Schlinkert, Rouven Weßling Repository: micromatch/to-regex-range The MIT License (MIT) Copyright (c) 2015-present, Jon Schlinkert. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. tsconfck License: MIT By: dominikg Repository: git+https://github.com/dominikg/tsconfck.git MIT License Copyright (c) 2021-present dominikg and contributors Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. -- Licenses for 3rd-party code included in tsconfck -- strip-bom and strip-json-comments MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. unpipe License: MIT By: Douglas Christopher Wilson Repository: stream-utils/unpipe (The MIT License) Copyright (c) 2015 Douglas Christopher Wilson doug@somethingdoug.com Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. util-deprecate License: MIT By: Nathan Rajlich Repository: git://github.com/TooTallNate/util-deprecate.git (The MIT License) Copyright (c) 2014 Nathan Rajlich nathan@tootallnate.net Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. utils-merge License: MIT By: Jared Hanson Repository: git://github.com/jaredhanson/utils-merge.git The MIT License (MIT) Copyright (c) 2013-2017 Jared Hanson Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. vary License: MIT By: Douglas Christopher Wilson Repository: jshttp/vary (The MIT License) Copyright (c) 2014-2017 Douglas Christopher Wilson Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. ws License: MIT By: Einar Otto Stangvik Repository: git+https://github.com/websockets/ws.git Copyright (c) 2011 Einar Otto Stangvik einaros@gmail.com Copyright (c) 2013 Arnout Kazemier and contributors Copyright (c) 2016 Luigi Pinca and contributors Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "src/frontend/app-client/node_modules/vite/README.html": {
    "href": "src/frontend/app-client/node_modules/vite/README.html",
    "title": "vite ⚡",
    "summary": "vite ⚡ Next Generation Frontend Tooling \uD83D\uDCA1 Instant Server Start ⚡️ Lightning Fast HMR \uD83D\uDEE0️ Rich Features \uD83D\uDCE6 Optimized Build \uD83D\uDD29 Universal Plugin Interface \uD83D\uDD11 Fully Typed APIs Vite (French word for \"fast\", pronounced /vit/) is a new breed of frontend build tool that significantly improves the frontend development experience. It consists of two major parts: A dev server that serves your source files over native ES modules, with rich built-in features and astonishingly fast Hot Module Replacement (HMR). A build command that bundles your code with Rollup, pre-configured to output highly optimized static assets for production. In addition, Vite is highly extensible via its Plugin API and JavaScript API with full typing support. Read the Docs to Learn More."
  },
  "src/frontend/app-client/node_modules/warning/CHANGELOG.html": {
    "href": "src/frontend/app-client/node_modules/warning/CHANGELOG.html",
    "title": "",
    "summary": "v2.0.0 - July 11, 2015 1a33d40fa1 add browserify.js v1.0.2 - May 30, 2015 2ac6962 fix return args in replace"
  },
  "src/frontend/app-client/node_modules/warning/LICENSE.html": {
    "href": "src/frontend/app-client/node_modules/warning/LICENSE.html",
    "title": "",
    "summary": "BSD License For React software Copyright (c) 2013-2015, Facebook, Inc. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name Facebook nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  "src/frontend/app-client/node_modules/warning/README.html": {
    "href": "src/frontend/app-client/node_modules/warning/README.html",
    "title": "Warning",
    "summary": "Warning A mirror of Facebook's Warning Usage npm install warning // some script var warning = require('warning'); var ShouldBeTrue = false; warning( ShouldBeTrue, 'This thing should be true but you set to false. No soup for you!' ); // 'This thing should be true but you set to false. No soup for you!' Similar to Facebook's invariant but only logs a warning if the condition is not met. This can be used to log issues in development environments in critical paths. Removing the logging code for production environments will keep the same logic and follow the same code paths. Browserify When using browserify, the browser.js file will be imported instead of invariant.js and browserify will be told to transform the file with envify. The only difference between browser.js and invariant.js is the process.env.NODE_ENV variable isn't cached. This, in combination with envify and (optionally) uglifyjs, will result in a noop in production environments. Otherwise behavior is as expected. Use in Production It is recommended to add babel-plugin-dev-expression with this module to remove warning messages in production. Don't Forget To Be Awesome"
  },
  "src/frontend/app-client/node_modules/which/README.html": {
    "href": "src/frontend/app-client/node_modules/which/README.html",
    "title": "which",
    "summary": "which Like the unix which utility. Finds the first instance of a specified executable in the PATH environment variable. Does not cache the results, so hash -r is not needed when the PATH changes. USAGE const which = require('which') // async usage // rejects if not found const resolved = await which('node') // if nothrow option is used, returns null if not found const resolvedOrNull = await which('node', { nothrow: true }) // sync usage // throws if not found const resolved = which.sync('node') // if nothrow option is used, returns null if not found const resolvedOrNull = which.sync('node', { nothrow: true }) // Pass options to override the PATH and PATHEXT environment vars. await which('node', { path: someOtherPath, pathExt: somePathExt }) CLI USAGE Just like the BSD which(1) binary but using node-which. usage: node-which [-as] program ... You can learn more about why the binary is node-which and not which here OPTIONS You may pass an options object as the second argument. path: Use instead of the PATH environment variable. pathExt: Use instead of the PATHEXT environment variable. all: Return all matches, instead of just the first one. Note that this means the function returns an array of strings instead of a single string."
  },
  "src/frontend/app-client/node_modules/wrap-ansi-cjs/node_modules/ansi-regex/readme.html": {
    "href": "src/frontend/app-client/node_modules/wrap-ansi-cjs/node_modules/ansi-regex/readme.html",
    "title": "ansi-regex",
    "summary": "ansi-regex Regular expression for matching ANSI escape codes Install $ npm install ansi-regex Usage const ansiRegex = require('ansi-regex'); ansiRegex().test('\\u001B[4mcake\\u001B[0m'); //=> true ansiRegex().test('cake'); //=> false '\\u001B[4mcake\\u001B[0m'.match(ansiRegex()); //=> ['\\u001B[4m', '\\u001B[0m'] '\\u001B[4mcake\\u001B[0m'.match(ansiRegex({onlyFirst: true})); //=> ['\\u001B[4m'] '\\u001B]8;;https://github.com\\u0007click\\u001B]8;;\\u0007'.match(ansiRegex()); //=> ['\\u001B]8;;https://github.com\\u0007', '\\u001B]8;;\\u0007'] API ansiRegex(options?) Returns a regex for matching ANSI escape codes. options Type: object onlyFirst Type: boolean Default: false (Matches any ANSI escape codes in a string) Match only the first ANSI escape. FAQ Why do you test for codes not in the ECMA 48 standard? Some of the codes we run as a test are codes that we acquired finding various lists of non-standard or manufacturer specific codes. We test for both standard and non-standard codes, as most of them follow the same or similar format and can be safely matched in strings without the risk of removing actual string content. There are a few non-standard control codes that do not follow the traditional format (i.e. they end in numbers) thus forcing us to exclude them from the test because we cannot reliably match them. On the historical side, those ECMA standards were established in the early 90's whereas the VT100, for example, was designed in the mid/late 70's. At that point in time, control codes were still pretty ungoverned and engineers used them for a multitude of things, namely to activate hardware ports that may have been proprietary. Somewhere else you see a similar 'anarchy' of codes is in the x86 architecture for processors; there are a ton of \"interrupts\" that can mean different things on certain brands of processors, most of which have been phased out. Maintainers Sindre Sorhus Josh Junon Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "src/frontend/app-client/node_modules/wrap-ansi-cjs/node_modules/ansi-styles/readme.html": {
    "href": "src/frontend/app-client/node_modules/wrap-ansi-cjs/node_modules/ansi-styles/readme.html",
    "title": "ansi-styles",
    "summary": "ansi-styles ANSI escape codes for styling strings in the terminal You probably want the higher-level chalk module for styling your strings. Install $ npm install ansi-styles Usage const style = require('ansi-styles'); console.log(`${style.green.open}Hello world!${style.green.close}`); // Color conversion between 16/256/truecolor // NOTE: If conversion goes to 16 colors or 256 colors, the original color // may be degraded to fit that color palette. This means terminals // that do not support 16 million colors will best-match the // original color. console.log(style.bgColor.ansi.hsl(120, 80, 72) + 'Hello world!' + style.bgColor.close); console.log(style.color.ansi256.rgb(199, 20, 250) + 'Hello world!' + style.color.close); console.log(style.color.ansi16m.hex('#abcdef') + 'Hello world!' + style.color.close); API Each style has an open and close property. Styles Modifiers reset bold dim italic (Not widely supported) underline inverse hidden strikethrough (Not widely supported) Colors black red green yellow blue magenta cyan white blackBright (alias: gray, grey) redBright greenBright yellowBright blueBright magentaBright cyanBright whiteBright Background colors bgBlack bgRed bgGreen bgYellow bgBlue bgMagenta bgCyan bgWhite bgBlackBright (alias: bgGray, bgGrey) bgRedBright bgGreenBright bgYellowBright bgBlueBright bgMagentaBright bgCyanBright bgWhiteBright Advanced usage By default, you get a map of styles, but the styles are also available as groups. They are non-enumerable so they don't show up unless you access them explicitly. This makes it easier to expose only a subset in a higher-level module. style.modifier style.color style.bgColor Example console.log(style.color.green.open); Raw escape codes (i.e. without the CSI escape prefix \\u001B[ and render mode postfix m) are available under style.codes, which returns a Map with the open codes as keys and close codes as values. Example console.log(style.codes.get(36)); //=> 39 256 / 16 million (TrueColor) support ansi-styles uses the color-convert package to allow for converting between various colors and ANSI escapes, with support for 256 and 16 million colors. The following color spaces from color-convert are supported: rgb hex keyword hsl hsv hwb ansi ansi256 To use these, call the associated conversion function with the intended output, for example: style.color.ansi.rgb(100, 200, 15); // RGB to 16 color ansi foreground code style.bgColor.ansi.rgb(100, 200, 15); // RGB to 16 color ansi background code style.color.ansi256.hsl(120, 100, 60); // HSL to 256 color ansi foreground code style.bgColor.ansi256.hsl(120, 100, 60); // HSL to 256 color ansi foreground code style.color.ansi16m.hex('#C0FFEE'); // Hex (RGB) to 16 million color foreground code style.bgColor.ansi16m.hex('#C0FFEE'); // Hex (RGB) to 16 million color background code Related ansi-escapes - ANSI escape codes for manipulating the terminal Maintainers Sindre Sorhus Josh Junon For enterprise Available as part of the Tidelift Subscription. The maintainers of ansi-styles and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "src/frontend/app-client/node_modules/wrap-ansi-cjs/node_modules/emoji-regex/README.html": {
    "href": "src/frontend/app-client/node_modules/wrap-ansi-cjs/node_modules/emoji-regex/README.html",
    "title": "emoji-regex",
    "summary": "emoji-regex emoji-regex offers a regular expression to match all emoji symbols (including textual representations of emoji) as per the Unicode Standard. This repository contains a script that generates this regular expression based on the data from Unicode v12. Because of this, the regular expression can easily be updated whenever new emoji are added to the Unicode standard. Installation Via npm: npm install emoji-regex In Node.js: const emojiRegex = require('emoji-regex'); // Note: because the regular expression has the global flag set, this module // exports a function that returns the regex rather than exporting the regular // expression itself, to make it impossible to (accidentally) mutate the // original regular expression. const text = ` \\u{231A}: ⌚ default emoji presentation character (Emoji_Presentation) \\u{2194}\\u{FE0F}: ↔️ default text presentation character rendered as emoji \\u{1F469}: \uD83D\uDC69 emoji modifier base (Emoji_Modifier_Base) \\u{1F469}\\u{1F3FF}: \uD83D\uDC69\uD83C\uDFFF emoji modifier base followed by a modifier `; const regex = emojiRegex(); let match; while (match = regex.exec(text)) { const emoji = match[0]; console.log(`Matched sequence ${ emoji } — code points: ${ [...emoji].length }`); } Console output: Matched sequence ⌚ — code points: 1 Matched sequence ⌚ — code points: 1 Matched sequence ↔️ — code points: 2 Matched sequence ↔️ — code points: 2 Matched sequence \uD83D\uDC69 — code points: 1 Matched sequence \uD83D\uDC69 — code points: 1 Matched sequence \uD83D\uDC69\uD83C\uDFFF — code points: 2 Matched sequence \uD83D\uDC69\uD83C\uDFFF — code points: 2 To match emoji in their textual representation as well (i.e. emoji that are not Emoji_Presentation symbols and that aren’t forced to render as emoji by a variation selector), require the other regex: const emojiRegex = require('emoji-regex/text.js'); Additionally, in environments which support ES2015 Unicode escapes, you may require ES2015-style versions of the regexes: const emojiRegex = require('emoji-regex/es2015/index.js'); const emojiRegexText = require('emoji-regex/es2015/text.js'); Author Mathias Bynens License emoji-regex is available under the MIT license."
  },
  "src/frontend/app-client/node_modules/wrap-ansi-cjs/node_modules/string-width/readme.html": {
    "href": "src/frontend/app-client/node_modules/wrap-ansi-cjs/node_modules/string-width/readme.html",
    "title": "string-width",
    "summary": "string-width Get the visual width of a string - the number of columns required to display it Some Unicode characters are fullwidth and use double the normal width. ANSI escape codes are stripped and doesn't affect the width. Useful to be able to measure the actual width of command-line output. Install $ npm install string-width Usage const stringWidth = require('string-width'); stringWidth('a'); //=> 1 stringWidth('古'); //=> 2 stringWidth('\\u001B[1m古\\u001B[22m'); //=> 2 Related string-width-cli - CLI for this module string-length - Get the real length of a string widest-line - Get the visual width of the widest line in a string Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "src/frontend/app-client/node_modules/wrap-ansi-cjs/node_modules/strip-ansi/readme.html": {
    "href": "src/frontend/app-client/node_modules/wrap-ansi-cjs/node_modules/strip-ansi/readme.html",
    "title": "strip-ansi",
    "summary": "strip-ansi Strip ANSI escape codes from a string Install $ npm install strip-ansi Usage const stripAnsi = require('strip-ansi'); stripAnsi('\\u001B[4mUnicorn\\u001B[0m'); //=> 'Unicorn' stripAnsi('\\u001B]8;;https://github.com\\u0007Click\\u001B]8;;\\u0007'); //=> 'Click' strip-ansi for enterprise Available as part of the Tidelift Subscription. The maintainers of strip-ansi and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more. Related strip-ansi-cli - CLI for this module strip-ansi-stream - Streaming version of this module has-ansi - Check if a string has ANSI escape codes ansi-regex - Regular expression for matching ANSI escape codes chalk - Terminal string styling done right Maintainers Sindre Sorhus Josh Junon"
  },
  "src/frontend/app-client/node_modules/wrap-ansi-cjs/readme.html": {
    "href": "src/frontend/app-client/node_modules/wrap-ansi-cjs/readme.html",
    "title": "wrap-ansi",
    "summary": "wrap-ansi Wordwrap a string with ANSI escape codes Install $ npm install wrap-ansi Usage const chalk = require('chalk'); const wrapAnsi = require('wrap-ansi'); const input = 'The quick brown ' + chalk.red('fox jumped over ') + 'the lazy ' + chalk.green('dog and then ran away with the unicorn.'); console.log(wrapAnsi(input, 20)); API wrapAnsi(string, columns, options?) Wrap words to the specified column width. string Type: string String with ANSI escape codes. Like one styled by chalk. Newline characters will be normalized to \\n. columns Type: number Number of columns to wrap the text to. options Type: object hard Type: boolean Default: false By default the wrap is soft, meaning long words may extend past the column width. Setting this to true will make it hard wrap at the column width. wordWrap Type: boolean Default: true By default, an attempt is made to split words at spaces, ensuring that they don't extend past the configured columns. If wordWrap is false, each column will instead be completely filled splitting words as necessary. trim Type: boolean Default: true Whitespace on all lines is removed by default. Set this option to false if you don't want to trim. Related slice-ansi - Slice a string with ANSI escape codes cli-truncate - Truncate a string to a specific width in the terminal chalk - Terminal string styling done right jsesc - Generate ASCII-only output from Unicode strings. Useful for creating test fixtures. Maintainers Sindre Sorhus Josh Junon Benjamin Coe Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "src/frontend/app-client/node_modules/wrap-ansi/readme.html": {
    "href": "src/frontend/app-client/node_modules/wrap-ansi/readme.html",
    "title": "wrap-ansi",
    "summary": "wrap-ansi Wordwrap a string with ANSI escape codes Install $ npm install wrap-ansi Usage import chalk from 'chalk'; import wrapAnsi from 'wrap-ansi'; const input = 'The quick brown ' + chalk.red('fox jumped over ') + 'the lazy ' + chalk.green('dog and then ran away with the unicorn.'); console.log(wrapAnsi(input, 20)); API wrapAnsi(string, columns, options?) Wrap words to the specified column width. string Type: string String with ANSI escape codes. Like one styled by chalk. Newline characters will be normalized to \\n. columns Type: number Number of columns to wrap the text to. options Type: object hard Type: boolean Default: false By default the wrap is soft, meaning long words may extend past the column width. Setting this to true will make it hard wrap at the column width. wordWrap Type: boolean Default: true By default, an attempt is made to split words at spaces, ensuring that they don't extend past the configured columns. If wordWrap is false, each column will instead be completely filled splitting words as necessary. trim Type: boolean Default: true Whitespace on all lines is removed by default. Set this option to false if you don't want to trim. Related slice-ansi - Slice a string with ANSI escape codes cli-truncate - Truncate a string to a specific width in the terminal chalk - Terminal string styling done right jsesc - Generate ASCII-only output from Unicode strings. Useful for creating test fixtures. Maintainers Sindre Sorhus Josh Junon Benjamin Coe Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "src/frontend/app-client/node_modules/yallist/README.html": {
    "href": "src/frontend/app-client/node_modules/yallist/README.html",
    "title": "yallist",
    "summary": "yallist Yet Another Linked List There are many doubly-linked list implementations like it, but this one is mine. For when an array would be too big, and a Map can't be iterated in reverse order. basic usage var yallist = require('yallist') var myList = yallist.create([1, 2, 3]) myList.push('foo') myList.unshift('bar') // of course pop() and shift() are there, too console.log(myList.toArray()) // ['bar', 1, 2, 3, 'foo'] myList.forEach(function (k) { // walk the list head to tail }) myList.forEachReverse(function (k, index, list) { // walk the list tail to head }) var myDoubledList = myList.map(function (k) { return k + k }) // now myDoubledList contains ['barbar', 2, 4, 6, 'foofoo'] // mapReverse is also a thing var myDoubledListReverse = myList.mapReverse(function (k) { return k + k }) // ['foofoo', 6, 4, 2, 'barbar'] var reduced = myList.reduce(function (set, entry) { set += entry return set }, 'start') console.log(reduced) // 'startfoo123bar' api The whole API is considered \"public\". Functions with the same name as an Array method work more or less the same way. There's reverse versions of most things because that's the point. Yallist Default export, the class that holds and manages a list. Call it with either a forEach-able (like an array) or a set of arguments, to initialize the list. The Array-ish methods all act like you'd expect. No magic length, though, so if you change that it won't automatically prune or add empty spots. Yallist.create(..) Alias for Yallist function. Some people like factories. yallist.head The first node in the list yallist.tail The last node in the list yallist.length The number of nodes in the list. (Change this at your peril. It is not magic like Array length.) yallist.toArray() Convert the list to an array. yallist.forEach(fn, [thisp]) Call a function on each item in the list. yallist.forEachReverse(fn, [thisp]) Call a function on each item in the list, in reverse order. yallist.get(n) Get the data at position n in the list. If you use this a lot, probably better off just using an Array. yallist.getReverse(n) Get the data at position n, counting from the tail. yallist.map(fn, thisp) Create a new Yallist with the result of calling the function on each item. yallist.mapReverse(fn, thisp) Same as map, but in reverse. yallist.pop() Get the data from the list tail, and remove the tail from the list. yallist.push(item, ...) Insert one or more items to the tail of the list. yallist.reduce(fn, initialValue) Like Array.reduce. yallist.reduceReverse Like Array.reduce, but in reverse. yallist.reverse Reverse the list in place. yallist.shift() Get the data from the list head, and remove the head from the list. yallist.slice([from], [to]) Just like Array.slice, but returns a new Yallist. yallist.sliceReverse([from], [to]) Just like yallist.slice, but the result is returned in reverse. yallist.toArray() Create an array representation of the list. yallist.toArrayReverse() Create a reversed array representation of the list. yallist.unshift(item, ...) Insert one or more items to the head of the list. yallist.unshiftNode(node) Move a Node object to the front of the list. (That is, pull it out of wherever it lives, and make it the new head.) If the node belongs to a different list, then that list will remove it first. yallist.pushNode(node) Move a Node object to the end of the list. (That is, pull it out of wherever it lives, and make it the new tail.) If the node belongs to a list already, then that list will remove it first. yallist.removeNode(node) Remove a node from the list, preserving referential integrity of head and tail and other nodes. Will throw an error if you try to have a list remove a node that doesn't belong to it. Yallist.Node The class that holds the data and is actually the list. Call with var n = new Node(value, previousNode, nextNode) Note that if you do direct operations on Nodes themselves, it's very easy to get into weird states where the list is broken. Be careful :) node.next The next node in the list. node.prev The previous node in the list. node.value The data the node contains. node.list The list to which this node belongs. (Null if it does not belong to any list.)"
  },
  "src/frontend/app-client/node_modules/yaml/README.html": {
    "href": "src/frontend/app-client/node_modules/yaml/README.html",
    "title": "YAML",
    "summary": "YAML yaml is a definitive library for YAML, the human friendly data serialization standard. This library: Supports both YAML 1.1 and YAML 1.2 and all common data schemas, Passes all of the yaml-test-suite tests, Can accept any string as input without throwing, parsing as much YAML out of it as it can, and Supports parsing, modifying, and writing YAML comments and blank lines. The library is released under the ISC open source license, and the code is available on GitHub. It has no external dependencies and runs on Node.js as well as modern browsers. For the purposes of versioning, any changes that break any of the documented endpoints or APIs will be considered semver-major breaking changes. Undocumented library internals may change between minor versions, and previous APIs may be deprecated (but not removed). The minimum supported TypeScript version of the included typings is 3.9; for use in earlier versions you may need to set skipLibCheck: true in your config. This requirement may be updated between minor versions of the library. For more information, see the project's documentation site: eemeli.org/yaml To install: npm install yaml # or deno add jsr:@eemeli/yaml Note: These docs are for yaml@2. For v1, see the v1.10.0 tag for the source and eemeli.org/yaml/v1 for the documentation. The development and maintenance of this library is sponsored by: API Overview The API provided by yaml has three layers, depending on how deep you need to go: Parse & Stringify, Documents, and the underlying Lexer/Parser/Composer. The first has the simplest API and \"just works\", the second gets you all the bells and whistles supported by the library along with a decent AST, and the third lets you get progressively closer to YAML source, if that's your thing. A command-line tool is also included. Parse & Stringify import { parse, stringify } from 'yaml' parse(str, reviver?, options?): value stringify(value, replacer?, options?): string Documents import { Document, isDocument, parseAllDocuments, parseDocument } from 'yaml' Document constructor(value, replacer?, options?) #contents #directives #errors #warnings isDocument(foo): boolean parseAllDocuments(str, options?): Document[] parseDocument(str, options?): Document Content Nodes import { isAlias, isCollection, isMap, isNode, isPair, isScalar, isSeq, Scalar, visit, visitAsync, YAMLMap, YAMLSeq } from 'yaml' isAlias(foo): boolean isCollection(foo): boolean isMap(foo): boolean isNode(foo): boolean isPair(foo): boolean isScalar(foo): boolean isSeq(foo): boolean new Scalar(value) new YAMLMap() new YAMLSeq() doc.createAlias(node, name?): Alias doc.createNode(value, options?): Node doc.createPair(key, value): Pair visit(node, visitor) visitAsync(node, visitor) Parsing YAML import { Composer, Lexer, Parser } from 'yaml' new Lexer().lex(src) new Parser(onNewLine?).parse(src) new Composer(options?).compose(tokens) YAML.parse # file.yml YAML: - A human-readable data serialization language - https://en.wikipedia.org/wiki/YAML yaml: - A complete JavaScript implementation - https://www.npmjs.com/package/yaml import fs from 'fs' import YAML from 'yaml' YAML.parse('3.14159') // 3.14159 YAML.parse('[ true, false, maybe, null ]\\n') // [ true, false, 'maybe', null ] const file = fs.readFileSync('./file.yml', 'utf8') YAML.parse(file) // { YAML: // [ 'A human-readable data serialization language', // 'https://en.wikipedia.org/wiki/YAML' ], // yaml: // [ 'A complete JavaScript implementation', // 'https://www.npmjs.com/package/yaml' ] } YAML.stringify import YAML from 'yaml' YAML.stringify(3.14159) // '3.14159\\n' YAML.stringify([true, false, 'maybe', null]) // `- true // - false // - maybe // - null // ` YAML.stringify({ number: 3, plain: 'string', block: 'two\\nlines\\n' }) // `number: 3 // plain: string // block: | // two // lines // ` Browser testing provided by:"
  },
  "src/frontend/app-client/README.html": {
    "href": "src/frontend/app-client/README.html",
    "title": "Welcome to React Router!",
    "summary": "Welcome to React Router! A modern, production-ready template for building full-stack React applications using React Router. Features \uD83D\uDE80 Server-side rendering ⚡️ Hot Module Replacement (HMR) \uD83D\uDCE6 Asset bundling and optimization \uD83D\uDD04 Data loading and mutations \uD83D\uDD12 TypeScript by default \uD83C\uDF89 TailwindCSS for styling \uD83D\uDCD6 React Router docs Getting Started Installation Install the dependencies: npm install Development Start the development server with HMR: npm run dev Your application will be available at http://localhost:5173. Building for Production Create a production build: npm run build Deployment Docker Deployment To build and run using Docker: docker build -t my-app . # Run the container docker run -p 3000:3000 my-app The containerized application can be deployed to any platform that supports Docker, including: AWS ECS Google Cloud Run Azure Container Apps Digital Ocean App Platform Fly.io Railway DIY Deployment If you're familiar with deploying Node applications, the built-in app server is production-ready. Make sure to deploy the output of npm run build ├── package.json ├── package-lock.json (or pnpm-lock.yaml, or bun.lockb) ├── build/ │ ├── client/ # Static assets │ └── server/ # Server-side code Styling This template comes with Tailwind CSS already configured for a simple default starting experience. You can use whatever CSS framework you prefer. Built with ❤️ using React Router."
  }
}